{"posts":[{"title":"关于本站","content":"分享自己的所见所得，后端技术、供应链、任务调度（AI阅片任务调度、渲染任务调度）、摄影相关。 一、关于本站 博客基于 Github + Gridea，由于众所周知的原因，科学上网后才能流畅阅读。 博客使用的 Featured Image 和正文首部插图来源: unsplash 、FILMGRAB、豆瓣、 screenmusings、影视飓风，大多数图片也需要科学上网才能正常加载。 当然，也有部分是我自己的“摄影作品”。 二、供应链 目前做的是供应链领域的后端开发，看过一些书和资料，结合日常工作内容，写了一个小系列。 具体可以看：https://panson.top/post/supply-chain/，也在这个站点下。 三、任务调度 更早之前的两份工作内容都和任务调度有关，主要是关于 AI 任务调度和渲染任务调度。当然这种“任务” 和后端开发中的任务调度框架不太一样，类似 XXL-JOB 这种，我一般理解为定时任务，不带业务属性，但之前做的 AI 任务调度和渲染任务调度则更偏向于业务。下面简单介绍一下我参与做过的内容（其实本来应该写一个开源脚手架的，最近沉迷摄影，一直没时间去回想这些东西，时间过去有点久了，细节忘记了~提醒我及时记录）。 1. AI 任务调度系统 属于医疗领域，核心是为了将医院、体检机构拍摄的片子，借助 AI 智能阅片，并输出诊断结果，辅助治疗。 数据来源：体检机构、大中小医院的片子 文件系统：上传的片子预处理，存储文件、预处理的数据 任务调度系统： Master 将处理好的片子，做任务分发到各个 Slave 机器上 Slave 上的算法服务会将任务做AI 分析，存储分析结果 其他的还有阅片系统、SSO 平台、前置机之类的，还有单机平台、一体机之类的，非调度核心系统。 2. 渲染任务调度 核心逻辑其实与上面讲的差不多，不过业务逻辑更加复杂，链路也更加长一些，数据量的话日均有千万级别。 负责的东西主要包括以下几个部分： 渲染弹窗相关：渲染配置、分辨率体系、渲染券相关 中台相关业务：国际版 CooHom、灯光动画、遮罩渲染相关能力的开发、对象存储迁移（阿里OSS -&gt; 腾讯 COS）等等 渲染任务回归平台的开发 四、摄影 单独建了一个网站，买了 10 年的域名：www.timelesslens.site。 ","link":"https://panson.top/post/zhi-ding-tie/"},{"title":"一次 JVM “神优化” 导致的日志丢失问题","content":"一、问题发生 今天同事私聊我，问了我一个问题，他说在一个美国的海外仓项目中发现一个奇怪的报错日志：只有error 日志信息和一个 NPE 日常，但是没有打印出具体的堆栈。 他问我有没有遇到过。 我心里第一个想法：是不是打印日志的地方写得不规范，只把 Exception 的 message 打印了，类似这样： log.error(&quot;…… &quot;, exception.getMessage()); 去看了一下代码，发现代码中其实是完整打印的： try { // 执行调度逻辑：方法内部调用算法服务，分配库存 } catch (Exception exception) { log.error(&quot;……&quot;, exception); } finally { // } 二、求助 AI 面对这个反常的现象，我一开始也向我的好帮手——AI 提问了。 我尝试了各种姿势，并给了一些上下文，去问 AI，得到了一些排查方向： ​1. 确认日志框架​ 确认项目使用的是 Logback, Log4j2 还是其他日志框架。 ​2. 检查日志级别​ 确保记录异常时使用的级别（如 ERROR）在配置中是启用的。 ​3. 检查日志配置​ 核对配置文件（如 logback.xml, log4j2.xml），看输出目的地（控制台、文件）是否正确。 ​4. 验证日志实现​ 在 catch块中增加简单输出（如 System.out.println），确认代码执行路径。 …… 但似乎没找到我想要的答案。 三、拨云见日：十年前的“老帖子” 我决定重新梳理所有上下文，包括业务的调用频率、JVM 的运行环境等等。这个定时器是高频运行的，且每次都会在同一个地方报 NPE。 我抱着试一试的心态，在 Google/知乎上搜索一些“Java 异常 堆栈 丢失 性能优化”之类的关键词。结果，R 大在 十年前 的回答，瞬间击碎了所有的迷雾！ 帖子地址： 重载 Throwable.fillInStackTrace() 方法以提高Java性能这样的做法对吗？ - RednaxelaFX的回答 - 知乎 R 大的回答里提到了一个 HotSpot VM 的“神优化”——fast throw！ HotSpot VM 有个许多人觉得“匪夷所思”的优化，叫做 fast throw：有些特定的隐式异常类型（NullPointerException、ArithmeticException（ / 0）之类）如果在代码里某个特定位置被抛出过多次的话，HotSpot Server Compiler（C2）会透明地决定用 fast throw 来优化这个抛出异常的地方——直接抛出一个事先分配好的、类型匹配的异常对象。这个对象的 message 和 stack trace 都被清空。 划重点： message 和 stack trace 都被清空！ 简直是醍醐灌顶！ 这种优化的目的是：**抛出这个异常的速度是非常快，不但不用额外分配内存，而且也不用爬栈；**但反面就是：可能正好是需要知道哪里出问题的时候看不到 stack trace 了。 这不就是我的问题吗？！ 顺着这个思路，看了一下这个定时器最早的一次报错，果然是带完整的堆栈信息的。 结合我们的代码，至此可以破案了：获取库位信息并遍历的代码，它被高频调用，而且由于数据问题，它一直在报 NPE。 JVM 的 C2 编译器一看：“呦，指这行代码天天抛一样的异常，怪累的，我帮他优化一下吧！” 于是，它启动了 fast throw 机制，直接抛出预先分配好的、没有堆栈的 NPE 对象，大大提升了抛出异常的速度，但同时也“贴心”地清空了我的日志堆栈！ 四、反思 这事儿说到底，是因为我们代码里的 NPE Bug 成了 JVM 优化的“燃料”。 当然，知道原因后，我们首先要做的肯定是修复那个导致 NPE 的 Bug。 但从 JVM 层面，如果你确实需要知道高频异常的堆栈，你可以通过一个 VM 参数来禁用这个优化： -XX:-OmitStackTraceInFastThrow 不过，这个参数的意义是“以性能为代价，换取更完整的堆栈信息”，所以，更正确的姿势，永远是写出健壮的代码，避免高频抛出隐式异常！ ","link":"https://panson.top/post/yi-ci-jvm-shen-you-hua-dao-zhi-de-ri-zhi-diu-shi-wen-ti/"},{"title":"提示词工程学习记录","content":"一、大语言模型设置 Temperature： 简单来说，temperature 的参数值越小，模型就会返回越确定的一个结果。如果调高该参数值，大语言模型可能会返回更随机的结果，也就是说这可能会带来更多样化或更具创造性的产出。（调小temperature）实质上，你是在增加其他可能的 token 的权重。在实际应用方面，对于质量保障（QA）等任务，我们可以设置更低的 temperature 值，以促使模型基于事实返回更真实和简洁的结果。 对于诗歌生成或其他创造性任务，适度地调高 temperature 参数值可能会更好。 Top_p： 同样，使用 top_p（与 temperature 一起称为核采样（nucleus sampling）的技术），可以用来控制模型返回结果的确定性。如果你需要准确和事实的答案，就把参数值调低。如果你在寻找更多样化的响应，可以将其值调高点。 使用Top_P意味着只有词元集合（tokens）中包含top_p概率质量的才会被考虑用于响应，因此较低的Top_p值会选择最有信心的响应。这意味着较高的top_p值将使模型考虑更多可能的词语，包括不太可能的词语，从而导致更多样化的输出。 一般建议是改变 Temperature 和 Top P 其中一个参数就行，不用两个都调整。 Max Length： 可以通过调整 max length 来控制大模型生成的 token 数。指定 Max Length 有助于防止大模型生成冗长或不相关的响应并控制成本。 Stop Sequences： stop sequence 是一个字符串，可以阻止模型生成 token，指定 stop sequences 是控制大模型响应长度和结构的另一种方法。例如，您可以通过添加 “11” 作为 stop sequence 来告诉模型生成不超过 10 个项的列表。 Frequency Penalty： frequency penalty 是对下一个生成的 token 进行惩罚，这个惩罚和 token 在响应和提示中已出现的次数成比例， frequency penalty 越高，某个词再次出现的可能性就越小，这个设置通过给 重复数量多的 Token 设置更高的惩罚来减少响应中单词的重复。 Presence Penalty： presence penalty 也是对重复的 token 施加惩罚，但与 frequency penalty 不同的是，惩罚对于所有重复 token 都是相同的。出现两次的 token 和出现 10 次的 token 会受到相同的惩罚。 此设置可防止模型在响应中过于频繁地生成重复的词。 如果您希望模型生成多样化或创造性的文本，可以设置更高的 presence penalty，如果您希望模型生成更专注的内容，您可以设置更低的 presence penalty。 与 temperature 和 top_p 一样，一般建议是改变 frequency penalty 和 presence penalty 其中一个参数就行，不要同时调整两个。 ","link":"https://panson.top/post/ti-shi-ci-gong-cheng-xue-xi-ji-lu/"},{"title":"LLM 的发展史","content":"大型语言模型(LLM)的发展史是一部从简单到复杂、从专用到通用、从规则驱动到数据驱动的技术进化史。这一演进过程经历了三个关键阶段：统计语言模型时代、神经网络语言模型时代和基于Transformer的大型语言模型时代。 每个阶段都带来了对自然语言处理(NLP)能力的质的飞跃。从早期的简单单词预测到如今能够进行复杂推理、多模态交互的通用人工智能，LLM的发展不仅重塑了人机交互方式，也为各行业带来了革命性变革。 一、统计语言模型时代(1950s-2010s) 统计语言模型是LLM的前身，其核心思想是通过概率统计方法来建模语言的分布规律。这一阶段的技术特点是基于离散变量表示单词，依赖人工设计的规则和统计方法处理语言，主要包括 N-gram模型和隐马尔可夫模型(HMM)。 N-gram 模型作为最基础的统计语言模型，最早可以追溯到 20 世纪 50 年代。它通过计算特定n个单词连续出现的概率来预测下一个单词。例如，二元语法模型(Bigram Model)计算的是当前单词和下一个单词的共现概率，三元语法模型(Trigram Model)则考虑当前单词和前两个单词的组合。这种模型结构简单、时间复杂度低，但存在明显的局限性：维度灾难、泛化能力差，以及无法处理一词多义问题 。 随着计算能力的提高和大规模文本语料库的增加，统计方法在 20 世纪 80-90 年代逐渐占据主导地位，特别是在机器翻译领域 。然而，由于统计语言模型学习能力有限，需要学习的词组太多，如果训练集中缺少某些词组，模型的输出概率就会变成0，导致零概率问题。 尽管研究者们通过平滑技术解决这一问题，但依然无法从根本上克服统计语言模型的局限性 。 这一阶段的技术突破包括： 1950年：图灵测试提出，成为衡量机器智能的重要标准 1980-1990年代：统计机器翻译(SMT)成为主流，基于 n-gram 模型的系统如 IBM 的 MOSES 开始应用 2001年：Google推出PageRank算法，间接推动了语言模型的语义理解能力 2003年：约书亚·本吉奥提出第一个前馈神经网络语言模型(FFNNLM)，开始尝试将神经网络与语言模型结合 二、神经网络语言模型时代(2010s) 2010年代，随着深度学习的兴起，基于神经网络的语言模型逐渐取代了统计语言模型。这一阶段的核心突破是词向量表示和循环神经网络(RNN)的引入，使语言模型能够更好地捕捉语义信息 。 2013年，Word2Vec和GloVe等词向量表示模型的提出实现了文本语义的分布式向量表示，解决了统计语言模型的离散变量问题。这些模型将单词映射为连续的向量空间，使得计算机能够理解单词之间的语义关系 。然而，这些静态词向量表示模型对单词的词向量表示无法随着上下文语境改变而改变，例如单词&quot;apple&quot;在苹果水果和苹果公司的语境下具有不同的含义，但静态词向量无法区分 。 2014年，Seq2Seq(sequence to sequence)模型被提出，这是基于RNN的模型，首次应用于机器翻译领域 。Seq2Seq模型采用编码器-解码器架构，编码器将源句子编码为特征表示，解码器根据该特征表示生成目标句子。这一模型能够实现完全端到端训练，为生成任务提供了新思路 。然而，Seq2Seq模型主要基于RNN，存在长距离依赖问题，即当输入序列比较长时，模型容易失去对位置靠前字词的记忆。 为解决这一问题，2015年注意力机制(attention)被引入，用以改进Seq2Seq模型。注意力机制允许模型在处理序列时关注不同的位置，通过权重系数计算出哪些单词之间的关联性更大，提高了模型的可解释性 。这一创新为后续的Transformer架构奠定了基础。 这一阶段的主要技术突破包括： 2013年：Word2Vec和GloVe词向量模型发布，开创分布式语义表示 2014年：Seq2Seq模型提出，采用RNN实现端到端序列建模 2015年：注意力机制引入，改善RNN的长距离依赖问题 2016年：LSTM(长短期记忆网络)在机器翻译中的应用，提升模型记忆能力 2017年：Transformer架构提出，彻底解决RNN的长距离依赖问题 三、基于Transformer的大型语言模型时代(2017年至今) 2017年，Vaswani等人在论文《Attention Is All You Need》中提出Transformer架构，这一架构完全摒弃了传统的循环和卷积网络，仅依靠自注意力机制来处理序列数据 。 Transformer的出现是LLM发展的里程碑，它通过并行计算和位置编码，能够高效捕捉长距离的依赖关系，显著提升了模型性能。 1. 初期探索阶段(2017-2019) Transformer架构刚提出时，主要用于机器翻译等特定任务 。2018年，Google的高级AI研究员雅各布·德夫林等人在论文《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》中提出BERT模型，首次将Transformer应用于双向语言建模，使模型能够同时考虑单词的前后上下文 。BERT通过掩码语言模型(MLM)和下一句预测(NSP)两个任务进行预训练，显著提升了模型在自然语言理解任务上的表现 。 同年，OpenAI发布了GPT-1模型，基于Transformer的解码器架构，提出&quot;预训练+微调&quot;范式 。GPT-1有1.1亿个参数，通过在大量文本数据上进行预训练，然后针对特定任务进行微调，实现了在多种NLP任务上的出色表现 。 2019年，Google推出了T5模型，首次将所有NLP任务统一为文本到文本(text-to-text)格式，使模型能够处理更广泛的任务 。T5采用跨度掩码策略，随机遮蔽输入文本中的连续跨度，然后让模型预测被遮蔽的内容，这一方法进一步提升了模型的生成能力 。 2. 参数量爆发阶段(2020-2022) 2020年，OpenAI发布了GPT-3模型，拥有1750亿个参数，验证了&quot;大模型+大数据&quot;的缩放定律(Scaling Law) 。GPT-3通过大规模预训练，实现了强大的少样本学习(few-shot learning)能力，仅通过输入任务描述和少量示例，就能在翻译、问答、文本生成等任务上取得极具竞争力的表现 。 同年，Google推出了PaLM模型，参数规模达到5400亿，强调多步推理能力 。PaLM在多种复杂推理任务上表现出色，超过了人类在BIG-bench基准上的平均水平 。 2021年，Meta发布了LLaMA系列模型，包括7B、13B、33B和65B参数的不同变体，展示了开源大模型的潜力 。LLaMA在多种NLP任务上达到或接近闭源模型的性能，为研究者提供了重要的研究工具 。 3. 对齐与优化阶段(2022-2023) 2022年，OpenAI发布了 ChatGPT 和 InstructGPT 模型，首次系统应用基于人类反馈的强化学习(RLHF)技术优化模型的指令遵循能力 。RLHF通过三阶段流程(监督微调、奖励模型训练、PPO优化)使模型输出更符合人类偏好，显著降低了幻觉和有害内容的生成概率 。 同年，Google推出了LaMDA模型，专注于对话应用，进一步提升了模型的对话能力 。LaMDA采用更高效的训练策略，能够在保持高性能的同时降低计算成本 。 2023年，Anthropic发布了Claude模型，强调安全对齐和推理能力。Claude采用不同的对齐方法，如通过对比人类和AI的思考过程来优化模型行为，为LLM的安全应用提供了新思路。 4. 多模态与专业化阶段(2023-2025) 2023年，OpenAI发布了GPT-4，首次将文本和图像的多模态信号整合到LLM中 。GPT-4的多模态能力使模型能够理解并生成图文结合的内容，大大扩展了应用场景 。 2024年，Claude 3系列发布，包括Claude 3.5 Haiku和Sonnet，以及2025年发布的Claude 3.7 Sonnet 。Claude 3.7引入&quot;标准+扩展&quot;双模式，用户可通过API控制&quot;思考预算&quot;，在速度、成本与准确性间灵活权衡 。这一创新使模型能够在不同场景下提供最佳性能。 2025年，LLM的发展呈现出两大趋势：一是多模态能力的深化，从文本+图像扩展到视频、3D生成 ；二是垂直领域的专业化，通过适配微调和技术融合，使模型更好地适应特定行业需求 。 这一阶段的关键技术突破包括： 2022年：RLHF技术系统化应用，优化模型指令遵循能力 2023年：GPT-4多模态能力发布，整合文本和图像信号 2023年：LoRA(Low-Rank Adaptation)微调技术提出，显著提升微调效率 2024年：Claude 3.5系列发布，支持PDF解析和跨模态推理 2025年：Claude 3.7 Sonnet引入混合推理模式，支持动态计算资源分配 四、LLM的训练方法演进 LLM的发展不仅体现在模型架构和参数规模上，其训练方法也经历了重要变革。从早期的简单预训练到如今的复杂多阶段训练流程，LLM的训练方法不断优化，以提高模型性能和降低训练成本 。 1. 预训练技术 预训练是LLM获取通用语言知识的基础阶段。早期的预训练目标主要是预测下一个单词，如GPT系列模型采用的自回归建模 。BERT则采用了掩码语言模型(MLM)和下一句预测(NSP)两个任务，使模型能够同时考虑单词的前后上下文 。 预训练数据来源也经历了从封闭到开放的转变 。早期的模型主要使用书籍和特定网站数据，如GPT-1使用了Common Crawl的网页数据和书籍数据。随着模型规模的扩大，数据量也大幅增加，如GPT-3使用了570GB的文本数据 。如今，数据清洗和处理成为预训练的关键环节，如Data-Juicer等系统专门用于大规模文本数据的清洗和预处理 。 2. 微调技术 微调是使预训练模型适应特定任务的关键步骤。早期的微调主要是全参数微调，即更新模型的所有参数 。然而，随着模型参数量的增加，全参数微调的成本也大幅提高。 参数效率微调方法的出现显著降低了微调成本 。2022年，LoRA(Low-Rank Adaptation)技术提出，通过低秩矩阵分解仅更新少量参数，微调效率大幅提升 。2023年，AdaLoRA在LoRA基础上改进，能够自适应选择需要更新的参数层，进一步提升了微调效率 。2024年，LISA(Layerwise Importance Sampled Adam)策略通过分层重要性采样，随机激活少数中间层进行优化，平衡了性能与资源消耗 。 此外，检索增强生成(RAG)技术也被广泛应用于提升LLM的实时性和准确性 。RAG通过结合外部知识库和LLM的能力，使模型能够生成更精确、更即时的回答，有效减少幻觉问题 。 3. 对齐技术 随着LLM能力的增强，如何使模型输出符合人类价值观成为重要问题。RLHF(基于人类反馈的强化学习)技术的出现为模型对齐提供了有效解决方案 。 RLHF的三阶段流程包括：监督微调(SFT)、奖励模型(RM)训练和PPO优化 。SFT阶段使模型能够理解指令并生成初步回答；RM阶段通过人工对SFT输出排序，训练能够评估模型输出质量的奖励模型；PPO阶段则使用近端策略优化算法，使模型生成的输出尽可能获得更高的奖励分数，从而更符合人类偏好 。 RLHF技术的改进方向包括： FINE-GRAINED RLHF：将回答拆解为以句子为单位，分别评估事实准确性、相关性和信息完整性 RAFT/RRHF：通过RM对生成模型的输出排序，再使用类似SFT的技术训练选定的样本，减少对PPO的依赖 DPO(Direct Preference Optimization)：直接优化偏好而非依赖RL阶段，大幅减少计算量 五、LLM的未来发展趋势 展望未来，LLM的发展将沿着多模态深化、垂直领域专业化、轻量化与效率提升、技术融合以及伦理治理等方向演进。 1. 多模态能力深化 从文本到图像，再到视频和3D生成，LLM的多模态能力将持续深化 。目前，GPT-4和Claude 3.5已支持图文结合的内容生成，但视频和3D生成仍处于初级阶段。未来，通过更高效的跨模态注意力机制和数据处理技术，LLM将能够处理更复杂的多模态数据，如视频理解、3D场景生成等 。 2. 垂直领域专业化 通用大模型将向垂直领域专业化发展 ，通过适配微调和技术融合，使模型更好地适应特定行业需求。 例如，在医疗领域，LLM可以结合医学知识图谱和专业数据库，提供更准确的诊断建议和治疗方案；在法律领域，LLM可以学习法律条文和案例，辅助法律研究和文书起草；在金融领域，LLM可以分析市场数据和风险因素，提供投资建议和风险管理方案 。 3. 轻量化与效率提升 随着模型规模的扩大，轻量化和效率提升将成为重要研究方向 。混合专家(MoE)架构、参数效率微调方法和专用硬件加速等技术将共同推动LLM的轻量化发展 。例如，Claude 3.7的混合推理模式允许用户根据需求在速度、成本与准确性间灵活权衡 ；专用AI芯片如NVIDIA Hopper将为端侧LLM轻量化提供硬件支持 。 4. 量子计算与LLM结合 量子计算与LLM的结合将开启新的可能性。 虽然目前仍处于理论探索阶段，但已有研究表明，LLM可以辅助量子电路设计，如在变分量子特征求解器(VQE)中作为控制器进行经典优化 。同时，量子机器学习框架如MAQA通过量子态制备提升计算效率，为LLM的训练和推理提供新的计算范式 。 5. 实时学习与知识更新 解决LLM的知识过时问题将成为关键挑战 。目前，LLM主要依赖预训练和RAG技术来获取最新知识，但这一方法存在检索速度和准确性上的局限性。未来，通过增量学习、在线学习和自适应知识更新等技术，LLM将能够实时吸纳新知识，减少对模型本身已有知识的依赖 。 6. 伦理治理与安全应用 随着LLM能力的增强，其伦理治理和安全应用将受到更多关注 。目前，LLM仍存在非真实性和偏见性输出的问题，如编造学术文献和链接。 未来，通过动态偏见检测、可解释性增强和跨法域适配等技术，LLM的安全性和可靠性将得到提升。同时，多维度评估框架如HELM和IN结构调整也将帮助更好地评估和改进模型性能 。 六、LLM发展史的时间线 年份 关键技术/模型 参数规模 主要贡献 2013 Word2Vec - 首个分布式词向量模型 2014 Seq2Seq - 基于RNN的序列到序列模型 2015 注意力机制 - 解决RNN的长距离依赖问题 2017 Transformer - 引入自注意力机制，实现并行计算 2018 BERT 3.5B/4B 首个双向Transformer预训练模型 2018 GPT-1 110M 预训练+微调范式 2019 GPT-2 1.5B 展示生成文本的可控性挑战 2019 Megatron-LM 83B 验证模型规模扩展的可行性 2019 T5 11B/3B 统一文本任务为&quot;文本到文本&quot;格式 2020 GPT-3 175B 验证少样本学习能力 2020 PaLM 540B 强调多步推理能力 2021 LLaMA 7B-65B 开源大模型系列 2022 InstructGPT 175B 首次系统应用RLHF技术 2022 ChatGPT - 人机对话能力突破 2023 GPT-4 1.8T 多模态能力整合 2023 Claude 1 - 安全对齐和推理能力 2023 LoRA - 参数效率微调技术 2024 Claude 3.5 - 支持PDF解析和跨模态推理 2025 Claude 3.7 Sonnet - 混合推理模式，动态计算资源分配 七、LLM对社会和行业的影响 LLM的发展不仅推动了技术进步，也对社会和行业产生了深远影响。在内容创作领域，LLM大幅提高了内容生成效率，降低了创作门槛 ；在客户服务领域，LLM驱动的智能客服能够提供24/7的服务，显著提升用户体验 ；在教育领域，LLM可以作为个性化学习助手，帮助学生解决问题和获取知识 ；在医疗领域，LLM可以辅助诊断和治疗方案制定，提高医疗效率 ；在法律领域，LLM可以处理法律文档和研究案例，帮助律师提高工作效率 。 然而，LLM也带来了新的挑战和风险。模型的非真实性和偏见性输出可能导致虚假信息传播和社会不平等 ；模型的实时自主学习能力欠缺使得知识更新滞后；模型的强依赖数据集质量和数量也限制了其在特定领域的应用 。未来，随着LLM技术的成熟和应用场景的扩展，这些挑战和风险也将得到更多关注和解决方案。 八、结语 从统计语言模型到基于Transformer的大型语言模型，LLM的发展史是一部技术不断突破、能力不断提升的历程。随着参数规模的扩大、训练方法的优化和多模态能力的深化，LLM正逐步向通用人工智能方向演进 。然而，这一演进过程也伴随着技术局限和安全风险，需要研究者、开发者和政策制定者共同努力，推动LLM技术的健康发展和广泛应用。 未来，LLM的发展将更加注重轻量化、专业化和安全性，通过与图神经网络、量子计算等技术的融合，进一步拓展其应用边界和能力上限 。在这一过程中，LLM不仅将重塑人机交互方式，也将成为推动各行业数字化转型和智能化升级的重要力量 。 ","link":"https://panson.top/post/llm-de-fa-zhan-shi/"},{"title":"从零开始学 AI 总集篇","content":"想多了解一点这个快速发展的世界，学习一下 AI 相关的知识。 工具篇 本地部署试过 Ollama + DeepSeek R1 32 b，19 年的英特尔芯片已经带不动了。 目前主要用的是 Cherry Studio + 字节方舟的 DeepSeek R1，主要是因为当时领了几十块钱的券~ 但是腾讯元宝真的很方便，而且免费。 Web 端的话各种官网混用：腾讯元宝 、ChatGpt、Claude、通义千问。 编辑器的话，用的是Trae，之前用 Trae + Hugo 搭了一个摄影小站： www.timelesslens.site AI 名词 RAG RAG 的全称是：Retrieval-Augmented Generation，翻译成中文是：检索增强生成。 简而言之就是让大语言模型（比如 ChatGPT）在“生成答案”之前，先去找资料（检索）来增强它的知识，再用这些资料来生成更准确的回答。 为什么需要RAG？ 因为对于很多大语言模型来说，他的知识是基于历史数据训练出来的，比如GPT-4是截止到2023年的数据，而在这之后发生的所有的新的事件，新的数据，他都是不知道的，那么他的回答就会有这部分的局限性。 还有就是，很多大模型是基于公开的资料训练出来的，而很多私域的信息他是没有学习过的，而很多知识是私有的知识，这就需要通过资料的方式增强他原来不熟悉的知识。 所以，有了RAG之后，就可以基于自己的知识构建自己的知识库，这样就能做到知识的更新和迭代，也能弥补大模型不知道一些特性领域的专业知识的不足。这样就能让大模型的回答更加的准确， 减少幻觉的发生。 如何构建一个RAG？ 1、前置准备 首先我们需要做数据准备，把你要用的资料收集好，比如：公司内部文档（PDF、Word、Markdown）、FAQ列表、产品手册等，然后清洗这些数据，比如去掉无关信息、切分成合理的小段。 然后把每一小段文本用Embedding模型转成向量，把这些向量存到向量数据库里，比如FAISS、Milvus等。 2、检索查询 当用户提问时，先用相同的Embedding模型把问题也转成向量。然后在向量数据库里用向量相似度搜索，找出最相关的几段资料（比如Top 5）。这些找到的内容就是上下文增强材料。 3、生成回答 紧接着，就可以把用户的问题 + 检索到的资料一起，作为Prompt发给大语言模型（LLM）。 这样可以保证模型只在资料范围内生成答案，降低幻觉。 MCP MCP 的全称是 Model Context Protocol，下面是官网上的解释： MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools. MCP全称是模型上下文协议（Model Context Protocol），由Anthropic在2024年11月推出。它本质上是大模型与外部世界连接的标准化接口，就像给大模型装了个万能插座。 MCP中有三个核心组件 MCP Hosts：如Claude Desktop或IDE（比如Cursor），作为AI应用的入口，发起数据请求。 MCP Servers：轻量级服务，负责对接具体数据源或工具（如GitHub API、本地文件系统），提供标准化接口。（一般是别人开发好的，你要用的工具） MCP Clients：协议客户端，维护与服务器的连接并转发请求。 有了MCP之后，当用户提出一个问题时，就是大致下面的流程： 客户端（Claude Desktop / Cursor）将你的问题发送给大模型（如Claude）。 Claude 分析可用的工具，并决定使用哪一个（或多个）。 客户端通过 MCP Server 执行所选的工具。 工具的执行结果被送回给 Claude。 Claude 结合执行结果构造最终的 prompt 并生成自然语言的回应。 回应最终展示给用户 我让 DeepSeek 以生动形象的语言给我解释了一下 MCP，以下是它的回答： 用大白话解释，大模型中的 MCP 就像一个“万能插座”，让原本被困在知识牢笼里的 AI 大模型，突然长出了能连接现实世界的手脚。以下是生动解析： 🔌 1. 大模型原本是个“孤岛天才” 想象大模型是个满腹经纶的学者，但被关在没有窗户的房间里： 知识是旧的：只能复述训练时学过的内容（比如不知道今天天气）； 无法动手操作：知道“怎么发邮件”，但没法真的帮你发； 数据隔离：你电脑里的文件、公司数据库，它都摸不着[citation:1][citation:7]。 💡 就像让厨师背熟菜谱却不给厨房——空有理论，做不出菜！ 🛠️ 2. MCP 是给大模型配的“万能工具箱” MCP（Model Context Protocol）是一套标准化接口协议，核心功能类似 “插座+适配器”： 统一接口：所有外部工具（数据库、天气 API、微信、Excel）只要装上“MCP 插头”（即 MCP 服务器），就能被大模型即插即用[citation:4][citation:6]； 双向通信：大模型能查数据（如“读销售报表”），也能执行操作（如“订会议室”）[citation:2]； 本地安全防护：数据不用上传云端，直接在本地处理，像给插座加了保险开关[citation:1][citation:5]。 ✅ 举个栗子： 你说：“把上周销售数据整理成图表，邮件发给老板。” 大模型通过 MCP 自动调用： 1️⃣ 数据库插件 → 拉取数据； 2️⃣ Python 插件 → 生成图表； 3️⃣ 邮箱插件 → 发送邮件。 ⚙️ 3. 工作流程像“AI 指挥官” 你下指令：“导航去公司附近最火的川菜馆。” 大模型分析：需要调用地图工具 + 实时路况。 MCP 客户端：找到“百度地图 MCP 服务器”（已装好插头）。 地图服务器：返回路线、排队时长、评分（数据不离开你手机）。 大模型整合：“推荐‘蜀香阁’，车程 15 分钟，当前不用排队哦！”。 🌟 关键突破： 不用重复开发：每个工具只需一次适配 MCP，所有大模型都能用； 动态扩展能力：装个“股票插件”，AI 立刻懂炒股；装个“Git 插件”，秒变编程助手[citation:4][citation:5]。 🚀 4. 实际效果：AI 从“嘴强王者”变身“全能助理” 查私人数据：直接问“帮我找昨天写的年终总结 PPT”； 操作跨平台工具：“订明早 9 点的机票，同步到日历并提醒小李”； 实时响应：“现在美股苹果股价多少？” → 调用金融数据插件秒回[citation:2][citation:6]。 💡 一句话总结： MCP 就是大模型的“手脚延伸器”——让 AI 走出虚拟牢笼，用标准化插座连接万物，从此能动手就别吵吵！ 当前百度地图、高德、企业微信等均已支持 MCP，未来你的每一个操作指令，背后可能都是 MCP 在默默调度。 Agent todo SpringAI todo ","link":"https://panson.top/post/ai/"},{"title":"G1系列（一）： G1核心参数","content":"在 G1 GC 中，一些 JVM 参数对性能至关重要。本文将这些参数分为三类，并提供了生产环境下的常用配置建议。 一、必须配置的参数 这些参数在生产环境中几乎总是需要显式设置，否则 JVM 的默认值可能会不合适。 堆大小设置 我们通常使用 -Xms 和 -Xmx 参数来设定 Java 堆的初始大小和最大大小。一个常见的优化建议是将这两个值设为相同，例如 -Xms4g -Xmx4g。这样做可以避免 JVM 在运行时动态调整堆大小，从而减少可能触发的 Full GC。 在容器化部署环境中（如 Docker 和 Kubernetes），JVM 的默认行为可能会自动根据物理内存的百分比来设置堆大小，这有时会带来问题。 -XX:InitialRAMPercentage: 当没有显式设置 -Xms 时，JVM 会根据此参数的值来计算初始堆大小。例如，-XX:InitialRAMPercentage=50.0 会将初始堆大小设为容器可用物理内存的 50%。 -XX:MaxRAMPercentage: 类似地，当没有设置 -Xmx 时，此参数决定了最大堆大小。默认值通常为 80%，这意味着 JVM 可能占用容器 80% 的内存，这在资源紧张的环境中可能会导致问题。 GC 日志 GC 日志是排查 JVM 问题的关键。建议在生产环境中总是开启，并指定日志文件路径。 JDK 8 -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/path/gc.log JDK 9 及更高版本 -Xlog:gc*,gc+heap=debug:file=/path/gc.log:time,uptime,level,tags 元空间（Metaspace）大小 元空间用于存储类的元数据。如果应用加载的类非常多，默认的元空间大小可能会导致 java.lang.OutOfMemoryError: Metaspace 错误。你可以通过设置 -XX:MaxMetaspaceSize=&lt;size&gt; 来限制元空间的最大大小，防止它无限制地占用系统内存。例如，-XX:MaxMetaspaceSize=512m 是一个常见的设置。 二、强烈推荐配置的参数 这些参数可以让你更好地控制应用的延迟和吞吐量。 延迟目标: 使用 -XX:MaxGCPauseMillis=&lt;milliseconds&gt; 来设置 G1 GC 的最大停顿时间目标。G1 会努力在运行时调整其策略以满足这个目标。默认值为 200 毫秒，但在对延迟要求高的系统中，你可以将其调小，例如设置为 100 毫秒。 GC 线程数: G1 使用并行 GC 线程（ParallelGCThreads）和并发 GC 线程（ConcGCThreads）来执行垃圾回收。通常情况下，JVM 会根据 CPU 核心数自动计算最佳线程数。但在具有大量核心（比如 64 核以上）和巨大内存的机器上，过多的 GC 线程可能会占用过多的 CPU 资源，影响应用程序的正常运行。这时，你可能需要手动调整这些参数，减少线程数量。 三、仅在特殊场景下调整的参数 这类参数通常无需配置，除非你遇到特定的性能问题。 晋升阈值: 参数 -XX:InitiatingHeapOccupancyPercent=&lt;percent&gt; 决定了老年代占用堆空间的百分比。当老年代达到这个阈值时，G1 会触发并发标记周期。默认值为 45%。如果你的应用经常发生 Full GC，你可能需要将这个值调低到 30% 到 40% 之间，以提前触发并发回收，避免 Full GC。 大对象（Humongous Object）优化: G1 将超过 Region 大小一半的对象视为 Humongous 对象。这些对象会直接分配到老年代，可能导致内存碎片。如果你知道应用会产生大量此类大对象，可以尝试调整 -XX:G1HeapRegionSize=&lt;size&gt; 来增加 Region 的大小，以减少碎片并提高效率。 防止 Full GC: 在大内存应用中，如果因为老年代空间不足导致晋升失败，可能会触发 Full GC。G1ReservePercent 参数用于设置 G1 预留的老年代空间百分比，以应对这种突发情况。默认值为 10%。在某些极端场景下，你可以适当调高这个值，比如到 15%。 四、总结 对于大多数生产应用，可以重点关注以下参数： -Xms4g -Xmx4g -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -Xlog:gc*:file=/path/gc.log:time,uptime,level,tags ","link":"https://panson.top/post/g1-xi-lie-yi-g1-he-xin-can-shu/"},{"title":"自己动手写动态线程池框架 03——基于线程池扩展点增加插件体系","content":"JDK 线程池的生命周期中包含多个关键扩展点，通过这些扩展点我们可以实现监控、调优、报警等高级功能。 一、核心扩展点 任务执行监听点 beforeExecute()：任务执行前触发 afterExecute()：任务完成后触发（含异常情况） 应用场景：耗时统计、超时检测、任务埋点 线程池关闭监听点 beforeShutdown()：关闭线程池前触发 afterShutdown()：关闭线程池后触发（带未完成任务） afterTerminated()：线程池完全终止后触发 应用场景：资源释放、优雅关机 任务拒绝拦截点 beforeRejectedExecution()：触发拒绝策略前执行 应用场景：拒绝计数、预警通知 任务创建/执行拦截点 beforeTaskCreate()：创建任务对象前（支持Runnable/Callable） beforeTaskExecute()：任务执行前最后处理点 应用场景：任务装饰、上下文传递 二、插件体系设计 classDiagram class ThreadPoolPlugin { &lt;&lt;Interface&gt;&gt; +start() +stop() } class ExecuteAwarePlugin { +beforeExecute() +afterExecute() } class RejectedAwarePlugin { +beforeRejectedExecution() } class ShutdownAwarePlugin { +beforeShutdown() +afterShutdown() +afterTerminated() } class TaskAwarePlugin { +beforeTaskCreate() +beforeTaskExecute() } ThreadPoolPlugin &lt;|-- ExecuteAwarePlugin ThreadPoolPlugin &lt;|-- RejectedAwarePlugin ThreadPoolPlugin &lt;|-- ShutdownAwarePlugin ThreadPoolPlugin &lt;|-- TaskAwarePlugin classDiagram direction BT class AbstractTaskTimerPlugin { + AbstractTaskTimerPlugin() + beforeExecute(Thread, Runnable) void # currentTime() long # processTaskTime(long) void + afterExecute(Runnable, Throwable) void } class ExecuteAwarePlugin { &lt;&lt;Interface&gt;&gt; + beforeExecute(Thread, Runnable) void + afterExecute(Runnable, Throwable) void } class RejectedAwarePlugin { &lt;&lt;Interface&gt;&gt; + beforeRejectedExecution(Runnable, ThreadPoolExecutor) void } class ShutdownAwarePlugin { &lt;&lt;Interface&gt;&gt; + afterShutdown(ThreadPoolExecutor, List~Runnable~) void + afterTerminated(ExtensibleThreadPoolExecutor) void + beforeShutdown(ThreadPoolExecutor) void } class Summary { + Summary(long, long, long, long) - long taskCount - long minTaskTimeMillis - long totalTaskTimeMillis - long maxTaskTimeMillis long maxTaskTimeMillis long taskCount long minTaskTimeMillis long totalTaskTimeMillis long avgTaskTimeMillis } class TaskAwarePlugin { &lt;&lt;Interface&gt;&gt; + beforeTaskCreate(ThreadPoolExecutor, Runnable, V) Runnable + beforeTaskCreate(ThreadPoolExecutor, Callable~V~) Callable~V~ + beforeTaskExecute(Runnable) Runnable } class TaskDecoratorPlugin { + TaskDecoratorPlugin() - List~TaskDecorator~ decorators + removeDecorator(TaskDecorator) void + clearDecorators() void + beforeTaskExecute(Runnable) Runnable + addDecorator(TaskDecorator) void PluginRuntime pluginRuntime String id List~TaskDecorator~ decorators } class TaskRejectCountRecordPlugin { + TaskRejectCountRecordPlugin() - AtomicLong rejectCount + beforeRejectedExecution(Runnable, ThreadPoolExecutor) void PluginRuntime pluginRuntime Long rejectCountNum AtomicLong rejectCount String id } class TaskRejectNotifyAlarmPlugin { + TaskRejectNotifyAlarmPlugin() + beforeRejectedExecution(Runnable, ThreadPoolExecutor) void String id } class TaskTimeRecordPlugin { + TaskTimeRecordPlugin() + summarize() Summary # processTaskTime(long) void PluginRuntime pluginRuntime String id } class TaskTimeoutNotifyAlarmPlugin { + TaskTimeoutNotifyAlarmPlugin(String, Long, ThreadPoolExecutor) - Long executeTimeOut # processTaskTime(long) void String id Long executeTimeOut } class ThreadPoolExecutorShutdownPlugin { + ThreadPoolExecutorShutdownPlugin(long) + long awaitTerminationMillis - awaitTerminationIfNecessary(ExtensibleThreadPoolExecutor) void + beforeShutdown(ThreadPoolExecutor) void # cancelRemainingTask(Runnable) void + afterShutdown(ThreadPoolExecutor, List~Runnable~) void PluginRuntime pluginRuntime String id long awaitTerminationMillis } class ThreadPoolPlugin { &lt;&lt;Interface&gt;&gt; + start() void + stop() void PluginRuntime pluginRuntime String id } AbstractTaskTimerPlugin ..&gt; ExecuteAwarePlugin ExecuteAwarePlugin --&gt; ThreadPoolPlugin RejectedAwarePlugin --&gt; ThreadPoolPlugin ShutdownAwarePlugin --&gt; ThreadPoolPlugin TaskTimeRecordPlugin --&gt; Summary TaskAwarePlugin --&gt; ThreadPoolPlugin TaskDecoratorPlugin ..&gt; TaskAwarePlugin TaskRejectCountRecordPlugin ..&gt; RejectedAwarePlugin TaskRejectNotifyAlarmPlugin ..&gt; RejectedAwarePlugin TaskTimeRecordPlugin --&gt; AbstractTaskTimerPlugin TaskTimeoutNotifyAlarmPlugin --&gt; AbstractTaskTimerPlugin ThreadPoolExecutorShutdownPlugin ..&gt; ShutdownAwarePlugin 三、实用插件实现 1. 监控类插件 任务耗时统计插件 (TaskTimeRecordPlugin) public class TaskTimeRecordPlugin extends AbstractTaskTimerPlugin { // 记录最小、最大、平均耗时 public Summary summarize() { return new Summary(taskCount, minTaskTime, totalTaskTime, maxTaskTime); } } 拒绝任务计数器 (TaskRejectCountRecordPlugin) public class TaskRejectCountRecordPlugin implements RejectedAwarePlugin { private final AtomicLong rejectCount = new AtomicLong(); public void beforeRejectedExecution(Runnable task, ThreadPoolExecutor executor) { rejectCount.incrementAndGet(); } } 2. 告警类插件 任务超时报警 (TaskTimeoutNotifyAlarmPlugin) public class TaskTimeoutNotifyAlarmPlugin extends AbstractTaskTimerPlugin { private final Long executeTimeOut; // 超时阈值 protected void processTaskTime(long taskTime) { if(taskTime &gt; executeTimeOut) { // 触发告警逻辑 } } } 拒绝任务告警 (TaskRejectNotifyAlarmPlugin) public class TaskRejectNotifyAlarmPlugin implements RejectedAwarePlugin { public void beforeRejectedExecution(Runnable task, ThreadPoolExecutor executor) { // 发送实时告警通知 } } 3. 增强类插件 任务装饰器 (TaskDecoratorPlugin) public class TaskDecoratorPlugin implements TaskAwarePlugin { private final List&lt;TaskDecorator&gt; decorators = new ArrayList&lt;&gt;(); public Runnable beforeTaskExecute(Runnable task) { Runnable wrapped = task; for(TaskDecorator decorator : decorators) { wrapped = decorator.decorate(wrapped); } return wrapped; } } 优雅停机插件 (ThreadPoolExecutorShutdownPlugin) public class ThreadPoolExecutorShutdownPlugin implements ShutdownAwarePlugin { private final long awaitTerminationMillis; public void afterShutdown(ThreadPoolExecutor executor, List&lt;Runnable&gt; remainingTasks) { // 等待配置时间让任务完成 executor.awaitTermination(awaitTerminationMillis, TimeUnit.MILLISECONDS); } } ","link":"https://panson.top/post/zi-ji-dong-shou-xie-dong-tai-xian-cheng-chi-kuang-jia-03-ji-yu-xian-cheng-chi-kuo-zhan-dian-zeng-jia-cha-jian-ti-xi/"},{"title":"自己动手写动态线程池框架 02——自定义可变容量的阻塞队列","content":"考虑到JDK原生阻塞队列的容量不可变性与线程池动态调参需求存在根本性冲突，动态线程池框架需要自定义可变容量的阻塞队列。 一、原生阻塞队列的致命缺陷：静态容量 JDK提供的常用阻塞队列（如ArrayBlockingQueue、LinkedBlockingQueue）均在构造时固定容量： // 容量一旦设定即不可修改 BlockingQueue&lt;Runnable&gt; queue = new ArrayBlockingQueue&lt;&gt;(100); 这意味着： 无法运行时扩容：当流量突增时，即使线程池已动态调大maximumPoolSize，任务仍因队列满被拒绝 无法运行时缩容：低峰期需释放内存时，无法缩小队列占用空间 二、动态线程池的核心诉求：资源弹性 动态线程池的核心价值在于根据系统负载实时调整资源： graph LR A[监控指标] --&gt;|队列堆积| B(扩容线程数) A --&gt;|队列持续空| C(缩容线程数) B --&gt; D{队列满？} D --&gt;|是| E[需扩容队列容量] 此时暴露矛盾： 线程数可动态调整：通过setMaximumPoolSize()实时生效 队列容量仍固定：成为系统弹性能力的瓶颈 三、解决方案：自定义可变容量队列 通过重写阻塞队列实现运行时动态调整容量： public class ResizableBlockingQueue&lt;T&gt; extends LinkedBlockingQueue&lt;T&gt; { // ……省略其他代码，基本与 jdk 父类一致 // 动态更新capacity的方法 public void setCapacity(int capacity) { final int oldCapacity = this.capacity; //给capacity成员变量赋值 this.capacity = capacity; final int size = count.get(); if (capacity &gt; size &amp;&amp; size &gt;= oldCapacity) { //因为队列扩容了，所以可以唤醒阻塞的入队线程了 signalNotFull(); } } // 增加唤醒入队线程的方法 private void signalNotFull() { final ReentrantLock putLock = this.putLock; putLock.lock(); try { notFull.signal(); } finally { putLock.unlock(); } } } 动态调优过程示例： // 初始化动态队列（初始容量=50） ResizableBlockingQueue queue = new ResizableBlockingQueue(50); // 监控到队列持续满载时 if (queue.isFull()) { // 动态扩容队列（避免触发拒绝策略） queue.setCapacity(100); // 同步扩容线程数（双维度弹性） executor.setMaximumPoolSize(200); } 四、自定义队列的核心价值 1. 突破资源死锁困境 场景 原生队列 动态队列 突发流量 + 队列满 触发拒绝策略丢任务 即时扩容队列避免任务丢失 低峰期内存回收 队列持续占用内存 缩容队列释放内存 2. 实现精准流量控制 graph TD F[流量探测器] --&gt;|队列使用率&gt;90%| G[队列扩容+线程扩容] F --&gt;|队列使用率&lt;30%| H[队列缩容+线程缩容] G --&gt; I[避免任务拒绝] H --&gt; J[减少内存占用] 3. 保证弹性策略完整性 线程池弹性 = 线程数弹性 + 队列容量弹性 二者缺一即会导致： 仅线程扩容 → 队列满载时新线程无用武之地 仅队列扩容 → 消费者不足导致响应延迟飙升 五、生产环境注意事项 容量缩容安全机制 public synchronized void setCapacity(int newCapacity) { // 禁止缩容到小于当前元素数 if (newCapacity &lt; this.size()) { throw new IllegalStateException(&quot;Can't reduce below current size&quot;); } ... } 避免频繁震荡 增加扩容/缩容的冷却时间（如5分钟内仅允许调整1次） ","link":"https://panson.top/post/zi-ji-dong-shou-xie-dong-tai-xian-cheng-chi-kuang-jia-02-zi-ding-yi-ke-bian-rong-liang-de-zu-sai-dui-lie/"},{"title":"自己动手写动态线程池框架01——监控线程池基础信息","content":"动态线程池线程池的价值体现在两个维度： 状态观测：实时捕获运行时指标，绘制性能趋势； 动态干预：基于流量变化动态调整参数，实现弹性伸缩。 如果我们需要实现动态线程池，那我们就需要熟悉线程池的基础信息，了解线程池有哪些基础信息以及如何动态更新这些信息。 一、线程池源码基础信息概览 从线程池源码中可以发现，线程池提供了 get 方法的成员变量，是可以被收集的数据，比如： 线程池的核心线程数 corePoolSize 最大线程数 maximumPoolSize 线程池线程的空闲时间 keepAliveTime 核心线程是否允许超时回收 allowCoreThreadTimeOut 线程池的拒绝策略 RejectedExecutionHandler 任务队列 workQueue 线程池当前创建的线程数量 poolSize 曾经创建线程的最大数量 largestPoolSize 当前活跃线程数量 activeCount 线程池的执行的任务总数 taskCount 已经执行完毕的任务总数 completedTaskCount 从线程池源码中可以发现：提供了 set 方法的成员变量，是可以被更新的数据，比如： 线程池的核心线程数量 corePoolSize 线程池的最大线程数量 maximumPoolSize 线程池的拒绝策略处理器 RejectedExecutionHandler 。 线程池核心线程是否允许超时回收的标志 allowCoreThreadTimeOut 线程池线程的最大空闲时间 keepAliveTime 二、信息总结 从 ThreadPoolExecutor 源码中提取的核心监控参数： 指标类型 参数 源码字段/方法 监控意义 静态配置 corePoolSize 核心线程数 系统常驻处理能力基线 maximumPoolSize 最大线程数 突发流量承载上限 keepAliveTime 空闲线程存活时间 资源回收策略敏感度 allowCoreThreadTimeOut 核心线程超时回收 是否允许核心线程闲置退出（true/false） workQueue 任务队列实现类 队列类型（ArrayBlockingQueue, LinkedBlockingQueue等）影响排队策略 动态运行时 poolSize getPoolSize() 当前存活线程总数（包含空闲线程） activeCount getActiveCount() 正在执行任务的线程数 → 真实并发负载 largestPoolSize getLargestPoolSize() 历史最大线程数 → 判断线程池扩容峰值需求 taskCount getTaskCount() 总提交任务数（包括队列中未执行的任务） completedTaskCount getCompletedTaskCount() 已完成任务数 → 结合taskCount计算吞吐量 拒绝策略 RejectedExecutionHandler 拒绝策略实例 当队列满且线程达上限时的处理逻辑（AbortPolicy/CallerRunsPolicy等） 🚨 备注： activeCount / maximumPoolSize &gt; 70% → 提示线程资源紧张； (taskCount - completedTaskCount) &gt; queueSize → 表明存在任务堆积风险。 三、动态调参：运行时可修改的关键参数 线程池支持热更新的参数（通过 setter 方法）： // 示例：动态调整核心线程数 executor.setCorePoolSize(newCoreSize); // 调整最大线程数（触发条件：newMax &gt; current threads） executor.setMaximumPoolSize(newMaxSize); // 允许核心线程超时（适用于低流量时段缩容） executor.allowCoreThreadTimeOut(true); // 调整空闲线程存活时间（单位：纳秒） executor.setKeepAliveTime(30, TimeUnit.SECONDS); // 更换拒绝策略（无需重启） executor.setRejectedExecutionHandler(new CustomPolicy()); ⚠️ 生产注意事项： 调大 corePoolSize 会立即创建新线程，但调小需等待线程超时退出； 修改 maximumPoolSize 时，若新值小于当前线程数，不会强制销毁线程； 动态调参建议配合监控告警，避免频繁操作引发震荡。 ","link":"https://panson.top/post/zi-ji-dong-shou-xie-dong-tai-xian-cheng-chi-kuang-jia-01-jian-kong-xian-cheng-chi-ji-chu-xin-xi/"},{"title":"一次上游更改接口导致的百万级数据扫描引起的宕机问题","content":"一、问题分析过程 深圳某智能仓现场反馈报错： 接着全场工作站页面无法点击。 立即连接该仓库的服务器，查看 WES 服务 Docker 容器的状态，是 unhealthy 状态。考虑恢复优先，立即重启容器。现场恢复，但过一会儿，现场又反馈很卡顿。重新连线，发现容器状态又变成 unhealthy 了。 执行 jstat -gc pid 1000： 最近有 Full GC 过。 GC 很频繁。 而且慢 SQL 很多，一次三十秒以上的有很多。从慢 SQL 语句内容上分析： 查询的表内容主要集中在出库单明细、出库单实操明细、反馈明细上。 查询条件都是 in (id1, id2……),并且都是大列表查询。 状态都与待反馈或者反馈中有关。 从业务关联上猜测是发货相关逻辑出现了问题。 查看出库单状态： select count(*) from 出库单表 where state = 待发货状态 好家伙，两百多万条全是待发货。 再看反馈明细，未反馈的实操明细更多，600 多万…… 已经有了初步怀疑，反馈逻辑出问题了。 扒代码，流程大概如下: WES 发送 MQ 消息，告知单据已拣选完成，需要反馈上游告知单据的拣选信息。 反馈服务收到消息后，请求上游告知出库单拣选信息。 收到上游接口成功的 response 后，调用接口，处理一些逻辑，最后更新单据反馈明细为反馈完成。 WES 定时器逻辑： WES 定时器查询订单状态为待发货并且反馈状态为反馈中的订单。 根据订单查询反馈明细。 如果反馈明细都反馈完成了，则更新订单反馈状态为反馈完成。 了解上述简要逻辑之后，我们再来分析现场问题。 查看反馈日志，捞了一些待发货的单子，发现所有的单子都反馈了。理论上对于上游来说，所有的流程已经走完了。 那只能是最后一步更新单据反馈明细状态出了问题：更新单据反馈明细为反馈完成。 看 log，很多 response error， 但是实际的 http status code 是 200。感觉不太对劲，应该是最关键的信息了。 细看日志上下文，发现上游返回的 response 格式不对，理论上按约定是： { &quot;一些额外信息&quot;: &quot;&quot;, &quot;body&quot;: { &quot;code&quot;: &quot;200&quot;, &quot;data&quot;: &quot;……&quot;, &quot;message&quot;: &quot;success&quot;, &quot;success&quot;: false } } 但上游实际返回的是： { &quot;success&quot;: true, &quot;code&quot;: 0, &quot;message&quot;: &quot;success&quot;, &quot;data&quot;: &quot;……&quot;, } 导致反馈服务根据约定格式解析的时候发现获取不到 body 信息，以为出错了。 收到上游接口成功的 response 后，调用接口，处理一些逻辑，最后更新单据反馈明细为反馈完成。 所以单据反馈明细一直是反馈中的状态，导致后续的逻辑一直无法正常执行。 二、故障原因总结 上游在升级的时候，误改了接口格式，导致 WES 按照约定的格式处理接口返回数据时，拿不到指定格式的数据，导致单据无法正常完结。 三、如何快速恢复 写 SQL 批量更新单据状态为完成，并打上特殊标记： 先避免重启一直扫表查大量数据问题，让现场恢复。 重启线上服务。 代码层面： 增量数据： 兼容上游数据格式。 与上游再次沟通，约定不要随意更改接口格式。 存量数据更改定时器逻辑： 记录最大 ID。 每次根据状态加特殊标记捞取 1000 条数据。 批量执行：收到上游接口成功的 response 后，调用接口，处理一些逻辑，最后更新单据反馈明细为反馈完成。 ","link":"https://panson.top/post/yi-ci-shang-you-geng-gai-jie-kou-dao-zhi-de-bai-wan-ji-shu-ju-sao-miao-yin-qi-de-dang-ji-wen-ti-md/"},{"title":"订单号、作业单号、任务号如何设计?","content":" 一、 业务背景 在智能仓储系统（WES）中，上游下发的出库单、入库单、盘点单等单据都携带了单号，但上游业务方提供的单据号格式并不统一，因此不能直接用做 WES 中的内部调度，因此 WES 内部需要提供一套自有的单号生成逻辑。除了单号外，在 WES 的调度过程中，还存在作业单号、任务号，也都需要类似的唯一 ID 生成逻辑。 二、 单号生成要求 唯一性：全局唯一，避免重复， JDK 提供的 UUID 不具备可读性，所以不推荐，因为智能仓的业务逻辑基本是仓内使用，所以使用雪花算法生成的唯一 id + 具体的业务类型来实现。 可读性：可快速识别订单的时间、来源、类型等信息。比如说业务含义，出库单号与入库单号，两者单据业务不一致，在单号上要能体现出来。 高性能：支持高并发场景下的快速生成。 三、 雪花算法 雪花算法（Snowflake）是一种 分布式唯一 ID 生成算法，最早由 Twitter 提出，目标是高性能地生成全局唯一、有时间顺序的 64 位整数 ID，广泛用于数据库主键、消息系统等场景。 雪花算法核心思想 生成的 ID 是一个 64 位的 long 类型整数，结构如下（经典版）： | 1bit | 41bits | 10bits | 12bits | |------|-------------|--------------|-------------| | 符号位 | 时间戳差值 | 机器标识（节点）| 序列号 | 各部分含义 字段 长度 说明 符号位 1 位 永远为 0（long 是有符号数） 时间戳 41 位 当前时间戳 - 起始时间戳（单位毫秒），可用 69 年 机器ID 10 位 5 位数据中心ID + 5 位机器ID，可部署 1024 个节点 序列号 12 位 每毫秒最多生成 4096 个 ID，超出则等待下一毫秒 ID 示例（一个实际的 long 值） ID: 152344303535407104 Binary: 000000000001010000000011010000110000101111000010100000000000 雪花算法优缺点 优点： 高性能：单机每秒生成百万级 ID 趋势递增：按时间递增，便于排序 无中心节点：适合分布式部署 ID 结构可解码：能提取时间戳、机器信息等 缺点： 依赖系统时间，时钟回拨会导致 ID 重复或异常 不适用于无状态架构（需保存机器标识） 长整型不如 UUID 直观，可读性差 如果你想用雪花算法但解决时间回拨问题，可以考虑： 时间回拨容忍机制 引入 NTP 监控 使用 Redis/Zookeeper 发号器 或使用改进版如 百度 UID Generator、美团 Leaf、Sonyflake（Go） 四、雪花算法的使用 可以直接使用 Hutool 提供的 IdUtil 生成 id，格式参考： 业务类型 + 雪花 id + 分表（货主） 单仓情况下，使用归档即可，无需分表。 ","link":"https://panson.top/post/01ding-dan-hao-zuo-ye-dan-hao-ren-wu-hao-ru-he-she-ji/"},{"title":"一次线上 MySQL 锁超时问题记录","content":"一、故障现象 海外仓项目入库流程出现异常，线上日志报错： org.springframework.dao.CannotAcquireLockException: Lock wait timeout exceeded; try restarting transaction 从日志上看，很明显，MySQL 锁超时了。 二、故障定位与分析 1. 问题SQL锁定（已脱敏） UPDATE table1 SET column1 = value1, column2 = value2 WHERE a_id_1 = 666 AND id = 888 AND sku_id IS NULL -- 问题关键点 2. 锁等待分析 有监控系统的话，可以直接看监控系统。 我在本地复现了该问题，学习一下相关命令： -- 查看当前锁等待 SELECT * FROM information_schema.innodb_lock_waits; -- 查看持锁和等待锁的事务 SELECT * FROM information_schema.innodb_trx; -- 查看被锁的行 SELECT * FROM information_schema.innodb_locks; /* 锁等待分析语句 */ SELECT r.trx_id waiting_trx_id, r.trx_mysql_thread_id waiting_thread, r.trx_query waiting_query, b.trx_id blocking_trx_id, b.trx_mysql_thread_id blocking_thread, b.trx_query blocking_query FROM information_schema.innodb_lock_waits w JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id; SQL 执行结果如下图： 可以看出具体的 SQL 语句。 看代码，简化后的逻辑： 事务开启： ……省略前置逻辑…… 保存新行到 table1 …… 省略中间逻辑…… if 满足条件 { 开启异步线程池，异步更新新行 } …… 省略后续逻辑…… 提交事务 3. 根本原因分析 问题维度 具体原因 影响程度 事务边界 在未提交的事务内启动异步更新 ⭐⭐⭐⭐ SQL设计 sku_id IS NULL导致额外锁定检查 ⭐⭐⭐ 架构设计 主事务与异步操作竞争同一资源 ⭐⭐ 超时配置 默认50秒等待时间未优化 ⭐ 三、故障恢复 1. SQL优化 UPDATE table1 SET column1 = value1, column2 = value2 WHERE a_id_1 = 666 AND id = 888 - AND sku_id IS NULL 优化依据： 业务验证确认sku_id IS NULL条件冗余（当a_id_1和id确定时记录唯一） 2. 事务架构重构 // 改造前（问题版本） @Transactional void process() { save(table1); // 锁定行 // 在事务内启动异步 executor.execute(() -&gt; updateTable()); // ...其他业务逻辑 } // 事务提交 // 改造后（修复版本） void process() { // 1. 在主事务中完成核心操作 transactionTemplate.execute(status -&gt; { save(table1); return null; }); // 2. 事务提交后启动异步 executor.execute(() -&gt; { // 3. 异步操作使用独立事务 transactionTemplate.execute(status -&gt; { updateTable(); return null; }); }); } 3. 异步处理规范 关键原则： 事务分离：主事务与异步任务完全解耦 后置启动：确保在事务提交后才触发异步 独立事务：异步任务使用全新事务上下文 ","link":"https://panson.top/post/yi-ci-xian-shang-mysql-suo-chao-shi-wen-ti-ji-lu/"},{"title":"一次线上任务到站不弹实操问题","content":"欧洲某第三方仓库，现场反馈某个工作站，车辆到站，但无实操任务，页面业务任何报错。 按经验，第一时间怀疑到站推实操的 mq 监听出问题了。 先看任务状态：等待实操。也就是说没有推送成功，但小车调度系统其实已经推送到站消息了。 但奇怪的是，这个等待实操状态的任务已经卡在这个状态几分钟了。正常业务逻辑中，这个任务状态的流转会非常快。 大概率问题出在这个任务了。 根据唯一任务 ID 查了一下上下文日志，并没有明显报错。 再按照时间线细看流程，有一个诡异的点，任务状态先完结，后面又被更新为等待实操。 查看任务状态变更表：从已回滚状态转变为了等待实操。 至此已经开始怀疑是不是出现了多线程 ABA 问题。 查看任务更新线程：都是 mq 线程。 工作站下线 mq 监听：将任务状态改为回滚状态 到站等待推实操监听：将任务状态改为等待实操 看代码才发现这个老旧系统数据库更新压根就没做状态限制和乐观锁…… 导致工作站下线 mq 监听回滚完任务之后，到站等待推实操监听又把任务回滚到等待实操状态了。 许多智能仓工作站下线都是到下班把任务都做完之后才下线，所以不会出现这个问题。今天属于中途下线，把问题暴露出来了。 修复方案也比较简单，到站等待实操监听中更新任务状态时只更新非终点状态的任务，并加上版本号。 ","link":"https://panson.top/post/yi-ci-xian-shang-ren-wu-dao-zhan-bu-dan-shi-cao-wen-ti/"},{"title":"数据一致性组件之任务生命周期","content":"组件以二方包的形式提供，使用方可以直接在 maven 中添加相关依赖，支持自定义配置，本质上是一个 springboot starter。 对于所有需要一致性的操作，我们都将其封装成一个任务，支持持久化到 MySQL 中。 本文主要聊一下任务的生命周期。 一、Starter 初始化 项目引入 Starter 依赖 @SpringBootApplication → @EnableAutoConfiguration → AutoConfigurationImportSelector 读取 spring.factories/.imports 找到自动配置类 解析 @Conditional 系列注解决定是否生效 注册 Bean 到 Spring 容器 绑定 application.yml 配置到属性类 初始化 Bean 二、持久化任务 基于 SpringAOP 机制拦截@WesConsistencyTask 注解修饰的方法。 解析注解配置、方法全路径名称、参数列表等数据，并封装为任务。 将任务持久化到数据库。 三、执行任务 扫表倒序读取未完成的任务 根据任务执行模式判断是否立即执行（异步执行） 标记任务状态为执行中 反射执行任务 标记任务状态为执行成功 如果执行失败，任务标记为执行失败，更新重试次数，等待下次重试 ","link":"https://panson.top/post/shu-ju-yi-zhi-xing-zu-jian-zhi-ren-wu-sheng-ming-zhou-qi/"},{"title":"数据一致性组件之自定义 Starter","content":"既然要作为组件提供出去，那么肯定要封装为一个 Spring Boot Starter。 那如何自定义一个 Spring Boot Starter 呢？ 老生常谈的问题。 自定义 Starter 就是把业务功能封装成自动配置类，然后在 spring.factories 或者 .imports 中声明，让 Spring Boot 在启动时自动发现并注册。 核心点是：业务类、属性类、自动配置类、条件注解、注册配置文件。 加载流程就是 @EnableAutoConfiguration 触发 SpringFactoriesLoader 读取配置，再由 @Conditional 系列注解判断是否装配 Bean。 内部使用方只需要在 maven 配置中加入一致性行组件的依赖，根据需要修改配置文件即可。 1. 创建模块 好像 spring 官方推荐 两模块模式，不过我看许多开源项目都是一个模块 xxx-spring-boot-starter（Starter 壳模块） 只负责依赖管理，依赖 autoconfigure 模块 xxx-spring-boot-autoconfigure（自动配置模块） 包含配置类、业务类、spring.factories/.imports 也可以直接做成单模块，但不利于复用 2. 编写核心业务类 提供 Starter 对外功能的核心逻辑 public class DemoService { private final String prefix; public DemoService(String prefix) { this.prefix = prefix; } public String sayHello(String name) { return prefix + &quot; &quot; + name; } } 3. 属性绑定类 用于将 application.yml 配置绑定到 Java 对象 @ConfigurationProperties(prefix = &quot;demo&quot;) public class DemoProperties { private String prefix = &quot;Hello&quot;; // getter/setter } 4. 自动配置类 使用条件注解，按需装配 Bean @Configuration @EnableConfigurationProperties(DemoProperties.class) @ConditionalOnProperty(prefix = &quot;demo&quot;, name = &quot;enabled&quot;, havingValue = &quot;true&quot;, matchIfMissing = true) public class DemoAutoConfiguration { @Bean @ConditionalOnMissingBean public DemoService demoService(DemoProperties properties) { return new DemoService(properties.getPrefix()); } } 常用条件注解： @ConditionalOnClass → 类路径存在某个类时生效 @ConditionalOnMissingBean → 容器没有这个 Bean 时生效 @ConditionalOnProperty → 配置开关控制 5. 注册自动配置类 Spring Boot 2.x：META-INF/spring.factories org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.example.demo.DemoAutoConfiguration Spring Boot 3.x：META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports com.example.demo.DemoAutoConfiguration 使用时的执行流程 项目引入 Starter 依赖 @SpringBootApplication → @EnableAutoConfiguration → AutoConfigurationImportSelector 读取 spring.factories/.imports 找到自动配置类 解析 @Conditional 系列注解决定是否生效 注册 Bean 到 Spring 容器 绑定 application.yml 配置到属性类 Bean 初始化完成，应用可以直接使用 ","link":"https://panson.top/post/shu-ju-yi-zhi-xing-zu-jian-zhi-zi-ding-yi-starter/"},{"title":"数据一致性组件之任务模型","content":"任务模型 业内处理数据一致性的处理方案有许多，我们目前的业务并不要求数据强一致性，最终一致性即可。 我们参照本地消息表的设计了一个以任务为模型的一致性组件。 什么是任务：将需要保障一致性的业务逻辑封装为一个任务。 比如在入库实操反馈时： 操作 1：完结单据、调度任务 操作 2：发送 mq 消息 其中操作 1 和操作 2 我们封装为一个任务。 在代码层面，多个业务逻辑对应的方法以注解@WesConsistencyTask声明，通过 SpringAOP 机制封装成任务落地到数据库，我们用的是 MySQL。 数据模型 字段名 类型 允许为空 默认值 说明 id BIGINT 否 自增 主键自增 gmt_create DATETIME 否 CURRENT_TIMESTAMP 创建时间 gmt_modified DATETIME 否 CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP 修改时间 task_id VARCHAR(500) 否 - 任务唯一标识（用户自定义或方法签名） state TINYINT 否 0 任务状态：0待执行 1执行中 2执行成功 3执行失败 execute_times INT 否 0 已执行次数 next_execute_time DATETIME 否 - 下一次执行时间 parameter_types VARCHAR(255) 否 - 参数类型（类全路径） method_name VARCHAR(100) 否 - 方法名 method_sign_name VARCHAR(200) 否 '' 方法签名 execute_interval_second INT 否 60 执行间隔秒 delay_time INT 否 60 初始延迟秒 task_parameter VARCHAR(200) 否 '' 任务参数（序列化字符串） execute_mode TINYINT 否 - 执行模式：1立即执行 2调度执行 thread_way TINYINT 否 - 线程模型：1异步 2同步 error_message TEXT 是 NULL 最后一次执行的错误信息 ","link":"https://panson.top/post/shu-ju-yi-zhi-xing-zu-jian-zhi-ren-wu-mo-xing/"},{"title":"如何设计本地消息表？","content":"本地消息表是用于解决业务操作与消息发送的原子性问题，本文主要针对 RocketMQ 来说。 1、 首先一个表肯定要有主键 ID。 2、因为本地消息表是为消息服务的，所以要有一个字段存储消息内容 3、还要有一个字段存储具体的 Topic 4、为了幂等性，需要标识消息的状态，已经发送了还是待发送 5、为了防止消息一直重试，增加重试次数 6、模拟延时队列，增加下一次重试时间 7、还有上一次执行时间 8、如果多业务共用一张表，还需要增加业务字段，用来区分业务 9、增加业务幂等键 10、创建时间与修改时间 11、创建代码类（系统）和修改代码类（系统） 整理成表格的话： 字段名 类型 允许为空 默认值 说明 id BIGINT(20) NOT NULL AUTO_INCREMENT 主键 ID biz_key VARCHAR(64) NOT NULL 业务幂等键，用于防止重复处理同一业务消息 biz_type VARCHAR(32) NOT NULL 业务类型（如 order_create、stock_update） topic VARCHAR(64) NOT NULL 消息所属 RocketMQ Topic message_body TEXT NOT NULL 消息内容（建议存储 JSON 序列化后的数据） status TINYINT(3) NOT NULL 0 消息状态：0-待发送，1-发送中，2-已发送，3-发送失败 retry_count INT(11) NOT NULL 0 重试次数 next_retry_time DATETIME YES NULL 下次重试时间（用于模拟延时队列） last_execute_time DATETIME YES NULL 上一次执行（发送）时间 fail_reason VARCHAR(255) YES NULL 发送失败原因（错误码、异常信息摘要） create_by VARCHAR(64) YES NULL 创建人（代码类名/系统名） update_by VARCHAR(64) YES NULL 最后更新人（代码类名/系统名） gmt_create DATETIME NOT NULL CURRENT_TIMESTAMP 创建时间 gmt_modified DATETIME NOT NULL CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP 修改时间 索引上，根据查询条件设置： -- 扫描待发送的消息 CREATE INDEX idx_state_nextretry ON local_message (state, next_retry_time); -- 按业务幂等键查找 CREATE UNIQUE INDEX uk_biz_type_key ON local_message (biz_type, biz_key); -- 按 topic 查找 CREATE INDEX idx_topic ON local_message (topic); CREATE TABLE `t_local_message` ( `id` bigint NOT NULL AUTO_INCREMENT COMMENT '主键ID', `biz_type` varchar(64) NOT NULL COMMENT '业务类型（区分不同业务，例如order_create、stock_lock等）', `biz_key` varchar(128) NOT NULL COMMENT '业务幂等键（关联具体业务记录，例如订单号）', `topic` varchar(255) NOT NULL COMMENT 'RocketMQ Topic', `message_body` text NOT NULL COMMENT '消息内容（JSON格式）', `status` tinyint NOT NULL COMMENT '消息状态：0-待发送，1-发送中，2-已发送，3-发送失败', `retry_count` int NOT NULL DEFAULT 0 COMMENT '消息已重试次数', `next_retry_time` datetime DEFAULT NULL COMMENT '下一次重试时间（可实现延时发送）', `last_exec_time` datetime DEFAULT NULL COMMENT '最后一次发送时间', `fail_reason` varchar(512) DEFAULT NULL COMMENT '最后一次失败原因', `created_by` varchar(64) NOT NULL COMMENT '创建人或系统代码标识', `updated_by` varchar(64) NOT NULL COMMENT '修改人或系统代码标识', `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间', PRIMARY KEY (`id`), UNIQUE KEY `uk_biz_type_key` (`biz_type`, `biz_key`) COMMENT '业务幂等约束', KEY `idx_status_next_retry` (`status`, `next_retry_time`) COMMENT '扫描待重试的消息', KEY `idx_topic` (`topic`) COMMENT '按 topic 查找' ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='本地消息表（生产者侧）'; ┌───────────────────────┐ │ 0 待发送 │ │（事务提交后写入表） │ └──────────┬────────────┘ │ 定时任务扫描(status=0) ▼ ┌───────────────────────┐ │ 1 发送中 │ │（调用 MQ 发送接口） │ └───────┬───────┬───────┘ │ │ MQ 发送成功 │ │ MQ 发送失败 │ ▼ │ ┌────────────────────────────┐ │ │ 记录 fail_reason │ │ │ retry_count += 1 │ │ │ 设置 next_retry_time │ │ └───────────┬────────────────┘ │ │ │ ▼ │ 达到最大重试次数？ │ │ │ │ 否 │ ▼ │ 回到 1 发送中（下次扫描） │ ▼ ┌────────────────────────────┐ │ 2 已发送 │ │（成功投递至 Broker，归档或删） │ └────────────────────────────┘ │ │ 是 ▼ ┌───────────────────────┐ │ 3 发送失败 │ │（人工处理或补偿机制） │ └───────────────────────┘ ","link":"https://panson.top/post/ru-he-she-ji-ben-di-xiao-xi-biao/"},{"title":"什么是本地消息表？","content":"本地消息表是一种在分布式系统中，用于确保数据一致性的解决方案。其实本质上是一张状态表。 核心思想 它的核心思想是利用数据库事务来保证业务操作和发送消息这两个步骤的原子性。简单来说，就是把业务数据的变更和一条“待发送消息”的记录放在同一个本地数据库事务中。这样一来，这两个操作要么都成功，要么都失败，不会出现业务数据更新了但消息没发出去，或者反过来的情况。 工作流程 业务操作与消息写入：当你的业务逻辑需要通知其他服务时，它会执行以下操作，并且把这两个操作放在同一个数据库事务中： 更新业务数据。 在本地消息表中插入一条新的消息记录，状态通常是“待发送”。 消息发送：有一个独立的后台任务（例如定时任务或常驻服务）会不断扫描本地消息表，查找状态为“待发送”的消息。 消息消费：后台任务将这些消息发送到消息队列（如 Kafka、RabbitMQMQ）中。发送成功后，它会更新本地消息表中该消息的状态为“已发送”。 消费方处理：其他服务从消息队列中消费到这条消息，并执行相应的业务逻辑。 本地消息表解决了什么问题？ 本地消息表主要解决了分布式事务中最终一致性的问题。在微服务架构中，当一个服务需要通知另一个服务进行操作时，如果直接调用，可能因为网络问题或对方服务宕机而失败。如果使用消息队列，又可能因为业务操作成功但发送消息失败，导致数据不一致。本地消息表利用本地事务的可靠性，完美地解决了这个问题，确保了业务操作和消息通知的最终一致性。 优点和缺点 优点： 实现简单：它利用了数据库本身的事务能力，逻辑清晰，易于理解和实现。 可靠性高：确保了业务操作和消息发送的原子性，数据不会丢失。 缺点： 资源占用：需要额外的数据库表来存储消息，增加了数据库的读写压力。 实时性弱：消息的发送不是实时的，依赖于后台任务的扫描周期，有一定的延迟。 代码侵入性：业务代码中需要额外加入消息表的插入逻辑。 ","link":"https://panson.top/post/shi-me-shi-ben-di-xiao-xi-biao/"},{"title":"为什么要设计一个数据一致性组件","content":"首先说一下智能仓储系统的场景：智能仓储系统的核心链路涉及多个系统，但是对于数据最终一致性有要求，且部分场景需要补偿机制。 我们需要与诸多二方系统和三方系统对接，比如： 车辆调度系统，可能就会遇到： 车不来：下发调度信息的时候，消息发送失败，导致车辆不来 来错车：下发调度信息的时候，消息乱序，导致来错车 车不走：下发车辆离站消息的时候，消息发送失败，导致车辆不走 与算法服务对接 离线任务下发失败 调用算法计算热度 与外设系统交互，可能会遇到： 灯不亮： 发送亮灯消息的时候，消息发送失败，导致外设系统未接收到消息，灯不亮 外设系统与物理设备交互，调用相关接口失败 灯不灭： 发送灭灯消息的时候，消息发送失败，导致外设系统未接收到消息，灯不灭 外设系统与物理设备交互，调用相关接口失败，灯不灭 亮错灯： 发送亮灯消息的时候，消息乱序，导致外设系统亮灯错乱 与打印系统交互，可能会遇到： 没打印：接口调用失败，导致单据打印失败 与上游系统交互： 各种单据的实操结果未正常反馈上游 出库单按单反馈 出库单按箱反馈 入库单按单反馈 入库单按箱反馈 盘点单按单反馈 库存调整单按单反馈 …… 与基础数据系统交互 货架热度计算结果更新失败 料箱热度计算结果更新失败 容器位置更新 这些场景无法使用本地事务实现，因为是分布式系统。有些场景也不能纯用 MQ 的消息事务实现，因为 RocketMQ 事务消息重试机制不灵活。 ","link":"https://panson.top/post/wei-shi-me-yao-she-ji-yi-ge-shu-ju-yi-zhi-xing-zu-jian-md/"},{"title":"Panson-Weekly-043","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 988. 从叶结点开始的最小字符串 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { String res = null; StringBuilder path = new StringBuilder(); public String smallestFromLeaf(TreeNode root) { traverse(root); return res; } public void traverse(TreeNode root) { if(root == null) { return; } // 如果到达叶子节点 if(root.left == null &amp;&amp; root.right == null) { path.append((char)('a' + root.val)); path.reverse(); String tmp = path.toString(); if(res == null || res.compareTo(tmp) &gt; 0) { res = tmp; } path.deleteCharAt(0); path.reverse(); return; } path.append((char)('a' + root.val)); traverse(root.left); traverse(root.right); path.deleteCharAt(path.length() - 1); } } 1022. 从根到叶的二进制数之和 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { int res = 0; int path = 0; public int sumRootToLeaf(TreeNode root) { traverse(root); return res; } public void traverse(TreeNode root) { if(root == null) { return; } if(root.left == null &amp;&amp; root.right == null) { res += path &lt;&lt; 1 | root.val; return; } path = path &lt;&lt; 1 | root.val; traverse(root.left); traverse(root.right); path = path &gt;&gt; 1; } } 1457. 二叉树中的伪回文路径 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { int res = 0; int[] count = new int[10]; public int pseudoPalindromicPaths (TreeNode root) { traverse(root); return res; } public void traverse(TreeNode root) { if(root == null) { return; } if(root.left == null &amp;&amp; root.right == null) { // 叶子节点 count[root.val]++; int oddCount = getOddCount(count); if(oddCount &lt;= 1) { res++; } count[root.val]--; } count[root.val]++; traverse(root.left); traverse(root.right); count[root.val]--; } public int getOddCount(int[] count) { int oddCount = 0; for(int num : count) { if(num % 2 != 0) { oddCount++; } } return oddCount; } } 404. 左叶子之和 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { int res = 0; public int sumOfLeftLeaves(TreeNode root) { traverse(root); return res; } public void traverse(TreeNode root) { if(root == null) { return; } if(root.left != null &amp;&amp; root.left.left == null &amp;&amp; root.left.right == null) { res += root.left.val; } traverse(root.left); traverse(root.right); } } 623. 在二叉树中增加一行 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { int curDepth = 0; int nodeVal; int nodeDepth; public TreeNode addOneRow(TreeNode root, int val, int depth) { nodeVal = val; nodeDepth = depth; if(depth == 1) { TreeNode newNode = new TreeNode(nodeVal, root, null); return newNode; } traverse(root); return root; } public void traverse(TreeNode root) { if(root == null) { return; } curDepth++; if(curDepth == nodeDepth - 1) { TreeNode newNodeLeft = new TreeNode(nodeVal, root.left, null); TreeNode newNodeRight = new TreeNode(nodeVal, null, root.right); root.left = newNodeLeft; root.right = newNodeRight; } traverse(root.left); traverse(root.right); curDepth--; } } 971. 翻转二叉树以匹配先序遍历 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { List&lt;Integer&gt; res = new LinkedList&lt;&gt;(); int i = 0; int[] voyage; boolean canFlip = true; public List&lt;Integer&gt; flipMatchVoyage(TreeNode root, int[] voyage) { this.voyage = voyage; traverse(root); if(canFlip) { return res; } else { return Arrays.asList(-1); } } public void traverse(TreeNode root) { if(root == null || !canFlip) { return; } if(root.val != voyage[i]) { canFlip = false; i++; return; } i++; if(root.left != null &amp;&amp; root.left.val != voyage[i]) { TreeNode tmp = root.left; root.left = root.right; root.right = tmp; res.add(root.val); } traverse(root.left); traverse(root.right); } } 993. 二叉树的堂兄弟节点 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { int x,y; TreeNode parrentX = null; TreeNode parrentY = null; int depthX = 0; int depthY = 0; public boolean isCousins(TreeNode root, int x, int y) { this.x = x; this.y = y; traverse(root, 0, null); if(depthX == depthY &amp;&amp; parrentX != parrentY) { return true; } return false; } public void traverse(TreeNode root, int depth, TreeNode parent) { if(root == null) { return; } if(root.val == x) { parrentX = parent; depthX = depth; } if(root.val == y) { parrentY = parent; depthY = depth; } traverse(root.left, depth + 1, root); traverse(root.right, depth + 1, root); } } 1315. 祖父节点值为偶数的节点和 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { int sum = 0; public int sumEvenGrandparent(TreeNode root) { traverse(root); return sum; } public void traverse(TreeNode root) { if(root == null) { return; } if(root.val % 2 == 0) { if(root.left != null) { if(root.left.left != null) { sum += root.left.left.val; } if(root.left.right != null) { sum += root.left.right.val; } } if(root.right != null) { if(root.right.left != null) { sum += root.right.left.val; } if(root.right.right != null) { sum += root.right.right.val; } } } traverse(root.left); traverse(root.right); } } ","link":"https://panson.top/post/panson-weekly-043/"},{"title":"Panson-Weekly-042","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 257. 二叉树的所有路径 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { public List&lt;String&gt; binaryTreePaths(TreeNode root) { List&lt;String&gt; res = new ArrayList&lt;&gt;(); binaryTreePaths(root, new StringBuilder(), res); return res; } public void binaryTreePaths(TreeNode root, StringBuilder path, List&lt;String&gt; res) { if(root == null) { return; } StringBuilder stb = new StringBuilder(path); stb.append(String.valueOf(root.val)); if(root.left == null &amp;&amp; root.right == null) { res.add(stb.toString()); } else { stb.append(&quot;-&gt;&quot;); binaryTreePaths(root.left, stb, res); binaryTreePaths(root.right, stb, res); } } } 129. 求根节点到叶节点数字之和 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { int res = 0; public int sumNumbers(TreeNode root) { traverse(root, new StringBuilder()); return res; } public void traverse(TreeNode root, StringBuilder path) { if(root == null) { return; } StringBuilder stb = new StringBuilder(path); stb.append(root.val); if(root.left == null &amp;&amp; root.right == null) { res += Integer.parseInt(stb.toString()); } else { if(root.left != null) { traverse(root.left, stb); } if(root.right != null) { traverse(root.right, stb); } } } } ","link":"https://panson.top/post/panson-weekly-042/"},{"title":"一次线上 MySQL 死锁问题记录","content":"一、现象 海外日本仓现场遇到一个问题，现场反馈某个工作站在做入库业务，但调度来的车辆不离站了。 二、问题分析 此前关于入库车辆不离站的问题已经发生过许多次了，但多数时候发生在开仓阶段，由于现场配置的问题，导致的车辆调度问题。 但是这一次有点不一样，我查看了现场所有的配置，都是正常的。 只能从业务流程分析了，我捋了入库业务逻辑链路： 入库车辆到站，调度系统给仓储执行系统发送到站消息 储执行系统进行业务处理，封装成实操任务推送给工作站系统 工作站系统任务引擎调度实操任务，按照工作流形式提示仓储人员绑箱、绑库位 绑箱、绑库位后，工作站系统通知仓储执行系统进行实操反馈 仓储执行系统进行业务处理，通知下游车辆调度系统，车辆离站 现在现象是车不走，我按链路流程逐一检查，排除了 1、2、3，定位到问题出现在步骤 4 的实操反馈上。 三、关键信息 根据上下文排查到有死锁报错日志，所以立刻查看数据库死锁日志： SHOW ENGINE INNODB STATUS\\G 捞出来死锁日志，日志很长，重点看： ------------------------ LATEST DETECTED DEADLOCK ------------------------ *** (1) TRANSACTION: TRANSACTION 994952163, ACTIVE 0 sec starting index read mysql tables in use 1, locked 1 LOCK WAIT 11 lock struct(s), heap size 1136, 6 row lock(s), undo log entries 6 MySQL thread id 1380714, OS thread handle 140592418154240, query id 12281738268 172.16.12.200 root updating update 入库单明细表 d set d.combined_quantity = IF((IFNULL(d.combined_quantity, 0) + -240) &gt;0 , (IFNULL(d.combined_quantity, 0) + -240), 0) where d.id = 18075 and d.warehouse_id = 1 *** (1) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 2153 page no 410 n bits 128 index PRIMARY of table `入库单明细表` trx id 994952163 lock_mode X locks rec but not gap waiting Record lock, heap no 55 PHYSICAL RECORD: n_fields 46; compact format; info bits 0 *** (2) TRANSACTION: TRANSACTION 994952206, ACTIVE 0 sec starting index read, thread declared inside InnoDB 5000 mysql tables in use 1, locked 1 6 lock struct(s), heap size 1136, 3 row lock(s), undo log entries 2 MySQL thread id 1381375, OS thread handle 140592409773824, query id 12281738303 172.16.12.200 root updating update evo_wes_replenish.replenish_work_detail set fulfill_quantity = IFNULL(fulfill_quantity, 0) + 240 where warehouse_id = 1 and id = 271602 *** (2) HOLDS THE LOCK(S): RECORD LOCKS space id 2153 page no 410 n bits 128 index PRIMARY of table `入库单明细表` trx id 994952206 lock_mode X locks rec but not gap Record lock, heap no 55 PHYSICAL RECORD: n_fields 46; compact format; info bits 0 *** (2) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 2161 page no 1142 n bits 136 index PRIMARY of table `入库作业单明细表` trx id 994952206 lock_mode X locks rec but not gap waiting Record lock, heap no 65 PHYSICAL RECORD: n_fields 33; compact format; info bits 0 *** WE ROLL BACK TRANSACTION (2) ------------ TRANSACTIONS ------------ 四、信息梳理 从死锁日志中，我们结合日志，定位到了报错的代码，是取消组箱与整箱上架同一个入库单明细时，两个逻辑加锁顺序不一致导致了死锁。 ┌──────────────────────────────┐ │ 事务 (1) │ │ TRANSACTION 994952163 │ │ SQL: 更新 入库单明细表 d │ │ WHERE id = 18075 │ └─────────────┬────────────────┘ │ │ 持有锁：入库作业单明细表 (space id 2161, heap no 65) │ 等待锁：入库单明细表 (space id 2153, heap no 55) ▼ ┌──────────────────────────────┐ │ 事务 (2) │ │ TRANSACTION 994952206 │ │ SQL: 更新 replenish_work_detail│ │ WHERE id = 271602 │ └─────────────┬────────────────┘ │ │ 持有锁：入库单明细表 (space id 2153, heap no 55) │ 等待锁：入库作业单明细表 (space id 2161, heap no 65) ▼ [死锁形成，事务(2)回滚] 死锁链路解释 事务 (1) 正在更新 入库单明细表（id=18075），需要获取 PRIMARY 索引行锁（space id 2153, heap no 55）。 已经持有 入库作业单明细表（space id 2161, heap no 65）的行锁。 事务 (2) 正在更新 replenish_work_detail，但在执行过程中持有了 入库单明细表（space id 2153, heap no 55）的行锁。 同时想获取 入库作业单明细表（space id 2161, heap no 65）的行锁。 循环等待 事务 (1) 等事务 (2) 释放 入库单明细表 锁。 事务 (2) 等事务 (1) 释放 入库作业单明细表 锁。 MySQL 检测到循环等待 → 回滚事务 (2)。 五、问题解决 其实知道知道了具体的问题，还蛮好解决死锁的，无非是破坏死锁的 4 个必要条件： 互斥条件 资源在同一时刻只能被一个事务（或线程）占用，其他事务必须等待。 在 MySQL 中，行锁、表锁等都满足互斥性。 请求与保持条件 事务已经持有了至少一个资源（锁），同时又去申请新的资源，并且在等待过程中不释放已有的资源。 事务 (1) 持有 入库作业单明细表 的锁，还要申请 入库单明细表 的锁。 事务 (2) 持有 入库单明细表 的锁，还要申请 入库作业单明细表 的锁。 不可剥夺条件 资源（锁）一旦被事务持有，在事务自己释放之前，其他事务不能强行夺走。 MySQL 不会强制中断一个持锁事务去抢锁。 循环等待条件 存在一个事务等待链，链上的事务相互等待对方持有的资源，形成一个环路。 事务 (1) 等 事务 (2) 的锁 事务 (2) 等 事务 (1) 的锁 → 环形等待 我们修改了代码，将申请锁的顺序保持一致即可： 所有业务都先更新入库单明细，再更新入库作业单明细。 ","link":"https://panson.top/post/yi-ci-xian-shang-mysql-si-suo-wen-ti-ji-lu/"},{"title":"Panson-Weekly-041","content":"日拱一卒 1 一周见闻 1.1 技术文章 京东零售：后端开发和你聊聊 JVM 如何优化 京东零售：看完这篇, 你的服务设计能力将再次进化! 京东零售：动态线程池学习及实践 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 1658. 将 x 减到 0 的最小操作数 class Solution { public int minOperations(int[] nums, int x) { int n = nums.length, sum = 0; for (int i = 0; i &lt; n; i++) { sum += nums[i]; } // 滑动窗口需要寻找的子数组目标和 int target = sum - x; int left = 0, right = 0; // 记录窗口内所有元素和 int windowSum = 0; // 记录目标子数组的最大长度 int maxLen = Integer.MIN_VALUE; // 开始执行滑动窗口框架 while (right &lt; nums.length) { // 扩大窗口 windowSum += nums[right]; right++; while (windowSum &gt; target &amp;&amp; left &lt; right) { // 缩小窗口 windowSum -= nums[left]; left++; } // 寻找目标子数组 if (windowSum == target) { maxLen = Math.max(maxLen, right - left); } } // 目标子数组的最大长度可以推导出需要删除的字符数量 return maxLen == Integer.MIN_VALUE ? -1 : n - maxLen; } } 713. 乘积小于 K 的子数组 class Solution { public int numSubarrayProductLessThanK(int[] nums, int k) { int left = 0, right = 0; // 滑动窗口，初始化为乘法单位元 int windowProduct = 1; // 记录符合条件的子数组个数 int count = 0; while (right &lt; nums.length) { // 扩大窗口，并更新窗口数据 windowProduct = windowProduct * nums[right]; right++; while (left &lt; right &amp;&amp; windowProduct &gt;= k) { // 缩小窗口，并更新窗口数据 windowProduct = windowProduct / nums[left]; left++; } count += right - left; } return count; } } 1004. 最大连续1的个数 III class Solution { public int longestOnes(int[] nums, int k) { int left = 0, right = 0; // 记录窗口中 1 的出现次数 int windowOneCount = 0; // 记录结果长度 int res = 0; // 开始滑动窗口模板 while (right &lt; nums.length) { // 扩大窗口 if (nums[right] == 1) { windowOneCount++; } right++; while (right - left - windowOneCount &gt; k) { // 当窗口中需要替换的 0 的数量大于 k，缩小窗口 if (nums[left] == 1) { windowOneCount--; } left++; } // 此时一定是一个合法的窗口，求最大窗口长度 res = Math.max(res, right - left); } return res; } } 219. 存在重复元素 II class Solution { public boolean containsNearbyDuplicate(int[] nums, int k) { int left = 0; int right = 0; Set&lt;Integer&gt; window = new HashSet&lt;&gt;(); while(right &lt; nums.length) { if(right - left &lt;= k &amp;&amp; window.contains(nums[right])) { return true; } window.add(nums[right]); right++; if(right - left &gt; k) { window.remove(nums[left]); left++; } } return false; } } 424. 替换后的最长重复字符 class Solution { public int characterReplacement(String s, int k) { int left = 0, right = 0; // 统计窗口中每个字符的出现次数 int[] windowCharCount = new int[26]; // 记录窗口中字符的最多重复次数 // 记录这个值的意义在于，最划算的替换方法肯定是把其他字符替换成出现次数最多的那个字符 // 所以窗口大小减去 windowMaxCount 就是所需的替换次数 int windowMaxCount = 0; // 记录结果长度 int res = 0; // 开始滑动窗口模板 while (right &lt; s.length()) { // 扩大窗口 windowCharCount[s.charAt(right) - 'A']++; windowMaxCount = Math.max(windowMaxCount, windowCharCount[s.charAt(right) - 'A']); right++; while (right - left - windowMaxCount &gt; k) { // 缩小窗口 windowCharCount[s.charAt(left) - 'A']--; left++; // 这里不用更新 windowMaxCount // 因为只有 windowMaxCount 变得更大的时候才可能获得更长的重复子串，才会更新 res } // 此时一定是一个合法的窗口 res = Math.max(res, right - left); } return res; } } 2824. 统计和小于目标的下标对数目 class Solution { public int countPairs(List&lt;Integer&gt; nums, int target) { Collections.sort(nums); int left = 0; int right = nums.size() - 1; int res = 0; while(left &lt; right) { int sum = nums.get(left) + nums.get(right); if(sum &lt; target) { res += right - left; left++; } else if(sum &gt;= target) { right--; } else { left++; } } return res; } } ","link":"https://panson.top/post/panson-weekly-041/"},{"title":"Panson-Weekly-040","content":"日拱一卒 1 一周见闻 1.1 技术文章 京东零售：后端开发和你聊聊 JVM 如何优化 京东零售：看完这篇, 你的服务设计能力将再次进化! 京东零售：动态线程池学习及实践 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 1658. 将 x 减到 0 的最小操作数 class Solution { public int minOperations(int[] nums, int x) { int n = nums.length, sum = 0; for (int i = 0; i &lt; n; i++) { sum += nums[i]; } // 滑动窗口需要寻找的子数组目标和 int target = sum - x; int left = 0, right = 0; // 记录窗口内所有元素和 int windowSum = 0; // 记录目标子数组的最大长度 int maxLen = Integer.MIN_VALUE; // 开始执行滑动窗口框架 while (right &lt; nums.length) { // 扩大窗口 windowSum += nums[right]; right++; while (windowSum &gt; target &amp;&amp; left &lt; right) { // 缩小窗口 windowSum -= nums[left]; left++; } // 寻找目标子数组 if (windowSum == target) { maxLen = Math.max(maxLen, right - left); } } // 目标子数组的最大长度可以推导出需要删除的字符数量 return maxLen == Integer.MIN_VALUE ? -1 : n - maxLen; } } 713. 乘积小于 K 的子数组 class Solution { public int numSubarrayProductLessThanK(int[] nums, int k) { int left = 0, right = 0; // 滑动窗口，初始化为乘法单位元 int windowProduct = 1; // 记录符合条件的子数组个数 int count = 0; while (right &lt; nums.length) { // 扩大窗口，并更新窗口数据 windowProduct = windowProduct * nums[right]; right++; while (left &lt; right &amp;&amp; windowProduct &gt;= k) { // 缩小窗口，并更新窗口数据 windowProduct = windowProduct / nums[left]; left++; } count += right - left; } return count; } } 1004. 最大连续1的个数 III class Solution { public int longestOnes(int[] nums, int k) { int left = 0, right = 0; // 记录窗口中 1 的出现次数 int windowOneCount = 0; // 记录结果长度 int res = 0; // 开始滑动窗口模板 while (right &lt; nums.length) { // 扩大窗口 if (nums[right] == 1) { windowOneCount++; } right++; while (right - left - windowOneCount &gt; k) { // 当窗口中需要替换的 0 的数量大于 k，缩小窗口 if (nums[left] == 1) { windowOneCount--; } left++; } // 此时一定是一个合法的窗口，求最大窗口长度 res = Math.max(res, right - left); } return res; } } 219. 存在重复元素 II class Solution { public boolean containsNearbyDuplicate(int[] nums, int k) { int left = 0; int right = 0; Set&lt;Integer&gt; window = new HashSet&lt;&gt;(); while(right &lt; nums.length) { if(right - left &lt;= k &amp;&amp; window.contains(nums[right])) { return true; } window.add(nums[right]); right++; if(right - left &gt; k) { window.remove(nums[left]); left++; } } return false; } } 424. 替换后的最长重复字符 class Solution { public int characterReplacement(String s, int k) { int left = 0, right = 0; // 统计窗口中每个字符的出现次数 int[] windowCharCount = new int[26]; // 记录窗口中字符的最多重复次数 // 记录这个值的意义在于，最划算的替换方法肯定是把其他字符替换成出现次数最多的那个字符 // 所以窗口大小减去 windowMaxCount 就是所需的替换次数 int windowMaxCount = 0; // 记录结果长度 int res = 0; // 开始滑动窗口模板 while (right &lt; s.length()) { // 扩大窗口 windowCharCount[s.charAt(right) - 'A']++; windowMaxCount = Math.max(windowMaxCount, windowCharCount[s.charAt(right) - 'A']); right++; while (right - left - windowMaxCount &gt; k) { // 缩小窗口 windowCharCount[s.charAt(left) - 'A']--; left++; // 这里不用更新 windowMaxCount // 因为只有 windowMaxCount 变得更大的时候才可能获得更长的重复子串，才会更新 res } // 此时一定是一个合法的窗口 res = Math.max(res, right - left); } return res; } } ","link":"https://panson.top/post/panson-weekly-040/"},{"title":"Panson-Weekly-039","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 76. 最小覆盖子串 class Solution { public String minWindow(String s, String t) { Map&lt;Character, Integer&gt; need = new HashMap&lt;&gt;(); Map&lt;Character, Integer&gt; window = new HashMap&lt;&gt;(); for(char c : t.toCharArray()) { need.put(c, need.getOrDefault(c, 0) + 1); } int left = 0; int right = 0; int valid = 0; int start = 0; int length = Integer.MAX_VALUE; while(right &lt; s.length()) { char c = s.charAt(right); right++; if(need.containsKey(c)) { window.put(c, window.getOrDefault(c, 0) + 1); if(window.get(c).equals(need.get(c))) { valid++; } } while(valid == need.size()) { if(right - left &lt; length) { start = left; length = right - left; } char d = s.charAt(left); left++; if(need.containsKey(d)) { if(window.get(d).equals(need.get(d))) { valid--; } window.put(d, window.get(d) - 1); } } } return length == Integer.MAX_VALUE ? &quot;&quot; : s.substring(start, start + length); } } 567. 字符串的排列 class Solution { public boolean checkInclusion(String s1, String s2) { Map&lt;Character, Integer&gt; need = new HashMap&lt;&gt;(); Map&lt;Character, Integer&gt; window = new HashMap&lt;&gt;(); for(char c : s1.toCharArray()) { need.put(c, need.getOrDefault(c, 0) + 1); } int left = 0; int right = 0; int valid = 0; while(right &lt; s2.length()) { char c = s2.charAt(right); right++; // 进行窗口内数据更新 if(need.containsKey(c)) { window.put(c, window.getOrDefault(c, 0) + 1); if(window.get(c).intValue() == need.get(c).intValue()) { valid++; } } // 判断左侧窗口是否要收缩 while(right - left &gt;= s1.length()) { if(valid == need.size()) { return true; } char d = s2.charAt(left); left++; if(need.containsKey(d)) { if(need.get(d) == window.get(d)) { valid--; } window.put(d, window.get(d) - 1); } } } return false; } } 438. 找到字符串中所有字母异位词 class Solution { public List&lt;Integer&gt; findAnagrams(String s, String p) { Map&lt;Character, Integer&gt; need = new HashMap&lt;&gt;(); Map&lt;Character, Integer&gt; window = new HashMap&lt;&gt;(); for(char c : p.toCharArray()) { need.put(c, need.getOrDefault(c, 0) + 1); } int left = 0; int right = 0; int valid = 0; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); while(right &lt; s.length()) { char c = s.charAt(right); right++; // 进行窗口内数据更新 if(need.containsKey(c)) { window.put(c, window.getOrDefault(c, 0) + 1); if(window.get(c).intValue() == need.get(c).intValue()) { valid++; } } // 判断左侧窗口是否要收缩 while(right - left &gt;= p.length()) { if(valid == need.size()) { res.add(left); } char d = s.charAt(left); left++; if(need.containsKey(d)) { if(need.get(d).equals(window.get(d))) { valid--; } window.put(d, window.get(d) - 1); } } } return res; } } 3. 无重复字符的最长子串 class Solution { public int lengthOfLongestSubstring(String s) { Map&lt;Character, Integer&gt; window = new HashMap&lt;&gt;(); int left = 0; int right = 0; int res = 0; while(right &lt; s.length()) { char c = s.charAt(right); right++; window.put(c, window.getOrDefault(c, 0) + 1); while(window.get(c) &gt; 1) { char d = s.charAt(left); left++; window.put(d, window.get(d) - 1); } res = Math.max(res, right - left); } return res; } } ","link":"https://panson.top/post/panson-weekly-039/"},{"title":"Panson-Weekly-038","content":"日拱一卒 1 一周见闻 1.1 技术文章 如何设计一个抽奖系统 如何设计一个百万级用户的抽奖系统？ 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) ","link":"https://panson.top/post/panson-weekly-038/"},{"title":"Panson-Weekly-037","content":"日拱一卒 1 一周见闻 1.1 技术文章 转转技术：服了！DELETE 同一行记录也会造成死锁！！ 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) ","link":"https://panson.top/post/panson-weekly-037/"},{"title":"Panson-Weekly-036","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 384. 打乱数组 class Solution { int[] nums; Random random = new Random(); public Solution(int[] nums) { this.nums = nums; } public int[] reset() { return nums; } public int[] shuffle() { int n = nums.length; int[] copy = Arrays.copyOf(nums, n); for(int i = 0; i &lt; n; i++) { int next = i + random.nextInt(n - i); int tmp = copy[i]; copy[i] = copy[next]; copy[next] = tmp; } return copy; } } /** * Your Solution object will be instantiated and called as such: * Solution obj = new Solution(nums); * int[] param_1 = obj.reset(); * int[] param_2 = obj.shuffle(); */ 382. 链表随机节点 class Solution { ListNode head; Random random = new Random(20220116); public Solution(ListNode _head) { head = _head; } public int getRandom() { int i = 0, res = 0; ListNode p = head; // while 循环遍历链表 while (p != null) { i++; // 生成一个 [0, i) 之间的整数 // 这个整数等于 0 的概率就是 1/i if (0 == random.nextInt(i)) { res = p.val; } p = p.next; } return res; } } 398. 随机数索引 class Solution { Random random; Map&lt;Integer, List&lt;Integer&gt;&gt; map; public Solution(int[] nums) { map = new HashMap&lt;&gt;(); random = new Random(); for(int i = 0; i &lt; nums.length; i++) { map.putIfAbsent(nums[i], new ArrayList&lt;Integer&gt;()); map.get(nums[i]).add(i); } } public int pick(int target) { List&lt;Integer&gt; indices = map.get(target); return indices.get(random.nextInt(indices.size())); } } /** * Your Solution object will be instantiated and called as such: * Solution obj = new Solution(nums); * int param_1 = obj.pick(target); */ 172. 阶乘后的零 class Solution { public int trailingZeroes(int n) { if(n &lt; 5) { return 0; } int res = 0; while(n &gt; 0) { n /= 5; res += n; } return res; } } 793. 阶乘函数后 K 个零 //leetcode submit region begin(Prohibit modification and deletion) class Solution { /* 主函数 */ public int preimageSizeFZF(int K) { // 左边界和右边界之差 + 1 就是答案 return (int)(rightBound(K) - leftBound(K) + 1); } /* 搜索 trailingZeroes(n) == K 的左侧边界 */ long leftBound(int target) { long lo = 0, hi = Long.MAX_VALUE; while (lo &lt; hi) { long mid = lo + (hi - lo) / 2; if (trailingZeroes(mid) &lt; target) { lo = mid + 1; } else if (trailingZeroes(mid) &gt; target) { hi = mid; } else { hi = mid; } } return lo; } /* 搜索 trailingZeroes(n) == K 的右侧边界 */ long rightBound(int target) { long lo = 0, hi = Long.MAX_VALUE; while (lo &lt; hi) { long mid = lo + (hi - lo) / 2; if (trailingZeroes(mid) &lt; target) { lo = mid + 1; } else if (trailingZeroes(mid) &gt; target) { hi = mid; } else { lo = mid + 1; } } return lo - 1; } // 逻辑不变，数据类型全部改成 long long trailingZeroes(long n) { long res = 0; while(n &gt; 0) { n /= 5; res += n; } return res; } } //leetcode submit region end(Prohibit modification and deletion) 204. 计数质数 class Solution { public int countPrimes(int n) { boolean[] isPrime = new boolean[n]; Arrays.fill(isPrime, true); for(int i = 2; i * i &lt; n; i++) { if(isPrime[i]) { for(int j = i * i; j &lt; n; j += i) { isPrime[j] = false; } } } int count = 0; for(int i = 2; i &lt; n; i++) { if(isPrime[i]) { count++; } } return count; } } 372. 超级次方 class Solution { int MOD = 1337; public int superPow(int a, int[] b) { return dfs(a, b, b.length - 1); } int dfs(int a, int[] b, int u) { if (u == -1) return 1; return qpow(dfs(a, b, u - 1), 10) * qpow(a, b[u]) % MOD; } int qpow(int a, int b) { int ans = 1; a %= MOD; while (b != 0) { if ((b &amp; 1) != 0) ans = ans * a % MOD; a = a * a % MOD; b &gt;&gt;= 1; } return ans; } } 645. 错误的集合 class Solution { public int[] findErrorNums(int[] nums) { int n = nums.length; for(int i = 0; i &lt; n; i++) { // 4321 // 0123 while(nums[i] != i + 1 &amp;&amp; nums[nums[i] - 1] != nums[i]) { swap(nums, i, nums[i] - 1); } } int a = -1, b = -1; for(int i = 0; i &lt; n; i++) { if(nums[i] != i + 1) { a = nums[i]; b = i == 0 ? 1 : nums[i - 1] + 1; } } return new int[]{a, b}; } void swap(int[] nums, int i, int j) { int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; } } ","link":"https://panson.top/post/panson-weekly-036/"},{"title":"Panson-Weekly-035","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 238. 除自身以外数组的乘积 class Solution { public int[] productExceptSelf(int[] nums) { int n = nums.length; int[] pre = new int[n]; pre[0] = 1; int[] post = new int[n]; post[n - 1] = 1; int[] res = new int[n]; // 维护一个前缀积 和 后缀积 for(int i = 1; i &lt; n; i++) { pre[i] = pre[i - 1] * nums[i - 1]; } for(int i = n - 2; i &gt;= 0; i--) { post[i] = post[i + 1] * nums[i + 1]; } res[0] = post[0]; res[n - 1] = pre[n - 1]; for(int i = 1; i &lt; n - 1; i++) { res[i] = pre[i] * post[i]; } return res; } } 525. 连续数组 class Solution { public int findMaxLength(int[] nums) { int res = 0; int n = nums.length; int[] preSum = new int[n + 1]; preSum[0] = 0; Map&lt;Integer, Integer&gt; val2Index = new HashMap&lt;&gt;(); for(int i = 0; i &lt; n; i++) { preSum[i + 1] = preSum[i] + (nums[i] == 0 ? -1 : 1); } for(int i = 0; i &lt; preSum.length; i++) { if(!val2Index.containsKey(preSum[i])) { val2Index.put(preSum[i], i); } else { res = Math.max(res, i - val2Index.get(preSum[i])); } } return res; } } 1124. 表现良好的最长时间段 class Solution { public int longestWPI(int[] hours) { int n = hours.length; for(int i = 0; i &lt; n; i++) { hours[i] = hours[i] &gt; 8 ? 1 : -1; } int[] preSum = new int[n + 1]; for(int i = 0; i &lt; n; i++) { preSum[i + 1] = preSum[i] + hours[i]; } int res = 0; Map&lt;Integer, Integer&gt; val2Index = new HashMap&lt;&gt;(); for(int i = 0; i &lt; n; i++) { if(preSum[i + 1] &gt; 0) { res = Math.max(res, i + 1); } else { if(val2Index.containsKey(preSum[i + 1] - 1)) { res = Math.max(res, i - val2Index.get(preSum[i + 1] - 1)); } } if (!val2Index.containsKey(preSum[i + 1])) { val2Index.put(preSum[i + 1], i); } } return res; } } 523. 连续的子数组和 class Solution { public boolean checkSubarraySum(int[] nums, int k) { int n = nums.length; int[] preSum = new int[n + 1]; preSum[0] = 0; for(int i = 0; i &lt; n; i++) { preSum[i + 1] = preSum[i] + nums[i]; } System.out.println(Arrays.toString(preSum)); Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for(int i = 1; i &lt; preSum.length; i++) { int remain = preSum[i] % k; if(remain == 0 &amp;&amp; i &gt;= 2) { return true; } else { if(map.containsKey(remain) &amp;&amp; (i - map.get(remain)) &gt;= 2) { return true; } } map.putIfAbsent(remain, i); } return false; } } 560. 和为 K 的子数组 class Solution { public int subarraySum(int[] nums, int k) { int n = nums.length; int[] preSum = new int[n + 1]; for(int i = 0; i &lt; n; i++) { preSum[i + 1] = preSum[i] + nums[i]; } Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); map.put(0, 1); int res = 0; for(int i = 1; i &lt; preSum.length; i++) { if(map.containsKey(preSum[i] - k)) { res += map.get(preSum[i] - k); } map.put(preSum[i], map.getOrDefault(preSum[i], 0) + 1); } return res; } } 1658. 将 x 减到 0 的最小操作数 class Solution { public int minOperations(int[] nums, int x) { x = -x; for (int v : nums) { x += v; } Map&lt;Integer, Integer&gt; vis = new HashMap&lt;&gt;(); vis.put(0, -1); int n = nums.length; int ans = 1 &lt;&lt; 30; for (int i = 0, s = 0; i &lt; n; ++i) { s += nums[i]; vis.putIfAbsent(s, i); if (vis.containsKey(s - x)) { int j = vis.get(s - x); ans = Math.min(ans, n - (i - j)); } } return ans == 1 &lt;&lt; 30 ? -1 : ans; } } /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { int res; long targetSumMem; public int pathSum(TreeNode root, long targetSum) { targetSumMem = targetSum; // dfs1 用于搜索所有节点 dfs1(root); return res; } void dfs1(TreeNode root) { if(root == null) { return; } // 搜索当前搜索节点为根节点的路径的路径和 dfs2(root, root.val); dfs1(root.left); dfs1(root.right); } void dfs2(TreeNode root, long sum) { if(sum == targetSumMem) { res++; } if(root.left != null) { dfs2(root.left, sum + root.left.val); } if(root.right != null) { dfs2(root.right, sum + root.right.val); } } } 713. 乘积小于 K 的子数组 class Solution { public int numSubarrayProductLessThanK(int[] nums, int k) { if(k &lt;= 1) { return 0; } int left = 0; int right = 0; int product = 1; int ans = 0; while(right &lt; nums.length) { product *= nums[right]; while(product &gt;= k) { product /= nums[left]; left++; } ans += right -left + 1; right++; } return ans; } } LCR 180. 文件组合 class Solution { public int[][] fileCombination(int target) { if(target &lt; 3) { return new int[0][]; } int i = 1; int j = 1; int sum = 0; List&lt;int[]&gt; res = new ArrayList&lt;&gt;(); // 123 3 while(i &lt;= target / 2) { if(sum &lt; target) { sum += j; j++; } else if(sum &gt; target) { sum -= i; i++; } else { int[] subRes = new int[j - i]; for(int k = i; k &lt; j; k++) { subRes[k - i] = k; } res.add(subRes); sum -= i; i++; } } return res.toArray(new int[res.size()][]); } } 628. 三个数的最大乘积 class Solution { public int maximumProduct(int[] nums) { // 没有正数，三个最大数 // 有正有负：一个最大正数两个最小负数 // 全是正数：三个最大数 // 所以只需要 5 个数，3 个最大数和两个最小负数 int max1 = -1001; int max2 = -1001; int max3 = -1001; int min1 = 1001; int min2 = 1001; for(int num : nums) { if(num &lt; min1) { min2 = min1; min1 = num; } else if(num &lt; min2){ min2 = num; } if(num &gt; max1) { max3 = max2; max2 = max1; max1 = num; }else if(num &gt; max2) { max3 = max2; max2 = num; } else if(num &gt; max3) { max3 = num; } } return Math.max(min1 * min2 * max1, max1 * max2 * max3); } } 292. Nim 游戏 class Solution { public boolean canWinNim(int n) { return n % 4 != 0; } } 877. 石子游戏 class Solution { public boolean stoneGame(int[] piles) { return true; } } 319. 灯泡开关 class Solution { public int bulbSwitch(int n) { return (int)Math.sqrt(n); } } 136. 只出现一次的数字 class Solution { public int singleNumber(int[] nums) { int res = 0; for(int num : nums) { res ^= num; } return res; } } 191. 位1的个数 class Solution { public int hammingWeight(int n) { int res = 0; while(n != 0){ n &amp;= (n - 1); res++; } return res; } } 231. 2 的幂 class Solution { public boolean isPowerOfTwo(int n) { if(n &lt;= 0) { return false; } return (n &amp; (n - 1)) == 0; } } 268. 丢失的数字 class Solution { public int missingNumber(int[] nums) { int res = nums.length; for(int i = 0; i &lt; nums.length; i++) { res = res ^ nums[i] ^ i; } return res; } } ","link":"https://panson.top/post/panson-weekly-035/"},{"title":"Panson-Weekly-034","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 303. 区域和检索 - 数组不可变 class NumArray { int[] numsMemory; public NumArray(int[] nums) { numsMemory = new int[nums.length]; numsMemory[0] = nums[0]; for(int i = 1; i &lt; nums.length; i++) { numsMemory[i] = nums[i] + numsMemory[i - 1]; } } public int sumRange(int left, int right) { if(left &gt; right) { return 0; } if(left == 0) { return numsMemory[right]; } return numsMemory[right] - numsMemory[left - 1]; } } /** * Your NumArray object will be instantiated and called as such: * NumArray obj = new NumArray(nums); * int param_1 = obj.sumRange(left,right); */ 304. 二维区域和检索 - 矩阵不可变 class NumMatrix { int[][] numsMemory; public NumMatrix(int[][] matrix) { numsMemory = new int[matrix.length][matrix[0].length]; for(int i = 0; i &lt; matrix.length; i++) { for(int j = 0; j &lt; matrix[0].length; j++) { if(i == 0 &amp;&amp; j == 0) { numsMemory[i][j] = matrix[i][j]; } else if(i == 0) { numsMemory[i][j] = matrix[i][j] + numsMemory[i][j - 1]; } else if(j == 0) { numsMemory[i][j] = matrix[i][j] + numsMemory[i - 1][j]; } else { numsMemory[i][j] = matrix[i][j] + numsMemory[i - 1][j] + numsMemory[i][j - 1] - numsMemory[i - 1][j - 1]; } } } } public int sumRegion(int row1, int col1, int row2, int col2) { if(row1 == 0 &amp;&amp; col1 == 0) { return numsMemory[row2][col2]; } if(row1 == 0) { return numsMemory[row2][col2] - numsMemory[row2][col1 - 1]; } if(col1 == 0) { return numsMemory[row2][col2] - numsMemory[row1 - 1][col2]; } return numsMemory[row2][col2] - numsMemory[row2][col1 - 1] - numsMemory[row1 - 1][col2] + numsMemory[row1 - 1][col1 - 1]; } } /** * Your NumMatrix object will be instantiated and called as such: * NumMatrix obj = new NumMatrix(matrix); * int param_1 = obj.sumRegion(row1,col1,row2,col2); */ 1081. 不同字符的最小子序列 class Solution { public String smallestSubsequence(String s) { Deque&lt;Character&gt; stack = new ArrayDeque&lt;&gt;(); boolean[] exist = new boolean[255]; int[] count = new int[255]; for(int i = 0; i &lt; s.length(); i++) { count[s.charAt(i)]++; } for(int i = 0; i &lt; s.length(); i++) { char cur = s.charAt(i); count[cur]--; if(exist[cur]) { continue; } while(!stack.isEmpty() &amp;&amp; stack.peek() &gt; cur) { if(count[stack.peek()] == 0) { break; } exist[stack.pop()] = false; } stack.push(cur); exist[cur] = true; } StringBuilder sb = new StringBuilder(); while(!stack.isEmpty()) { sb.append(stack.pop()); } return sb.reverse().toString(); } } 1314. 矩阵区域和 class Solution { public int[][] matrixBlockSum(int[][] mat, int k) { int m = mat.length; int n = mat[0].length; int[][] presum = new int[m][n]; int[][] answer = new int[m][n]; for(int i = 0; i &lt; m; i++) { for(int j = 0; j &lt; n; j++) { if(i == 0 &amp;&amp; j == 0) { presum[i][j] = mat[i][j]; } else if(i == 0) { presum[i][j] = mat[i][j] + presum[i][j - 1]; } else if(j == 0) { presum[i][j] = mat[i][j] + presum[i - 1][j]; } else { presum[i][j] = mat[i][j] + presum[i - 1][j] + presum[i][j - 1] - presum[i - 1][j - 1]; } } } for(int i = 0; i &lt; m; i++) { for(int j = 0; j &lt; n; j++) { int r1 = Math.max(0, i - k); int c1 = Math.max(0, j - k); int r2 = Math.min(m - 1, i + k); int c2 = Math.min(n - 1, j + k); if(r1 &gt; 0 &amp;&amp; c1 &gt; 0) { answer[i][j] = presum[r2][c2] - presum[r1 - 1][c2] - presum[r2][c1 - 1] + presum[r1 - 1][c1 - 1]; } else if(r1 &gt; 0){ answer[i][j] = presum[r2][c2] - presum[r1 - 1][c2]; } else if(c1 &gt; 0) { answer[i][j] = presum[r2][c2] - presum[r2][c1 - 1]; } else { answer[i][j] = presum[r2][c2]; } } } return answer; } } 724. 寻找数组的中心下标 class Solution { public int pivotIndex(int[] nums) { int[] preSum = new int[nums.length]; preSum[0] = nums[0]; for(int i = 1; i &lt; nums.length; i++) { preSum[i] = preSum[i - 1] + nums[i]; } if(preSum[nums.length - 1] - nums[0] == 0) { return 0; } for(int i = 1; i &lt; nums.length; i++) { if(preSum[i - 1] * 2 == preSum[nums.length - 1] - nums[i]) { return i; } } return -1; } } ","link":"https://panson.top/post/panson-weekly-034/"},{"title":"Panson-Weekly-033","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 977. 有序数组的平方 class Solution { /** * 给你一个按 非递减顺序 排序的整数数组 nums，返回 每个数字的平方 组成的新数组，要求也按 非递减顺序 排序。 * * 示例 1： * * 输入：nums = [-4,-1,0,3,10] * 输出：[0,1,9,16,100] * 解释：平方后，数组变为 [16,1,0,9,100] * 排序后，数组变为 [0,1,9,16,100] * 示例 2： * * 输入：nums = [-7,-3,2,3,11] * 输出：[4,9,9,49,121] * 提示： * * 1 &lt;= nums.length &lt;= 104 * -104 &lt;= nums[i] &lt;= 104 * nums 已按 非递减顺序 排序 * 进阶： * * 请你设计时间复杂度为 O(n) 的算法解决本问题 * @param nums * @return */ public int[] sortedSquares(int[] nums) { int n = nums.length; int p1 = 0; int p2 = n - 1; int[] res = new int[n]; int i = n - 1; while(p1 &lt;= p2) { if(nums[p2] * nums[p2] &gt; nums[p1] * nums[p1]) { res[i] = nums[p2] * nums[p2]; p2--; } else { res[i] = nums[p1] * nums[p1]; p1++; } i--; } return res; } } ","link":"https://panson.top/post/panson-weekly-033/"},{"title":"Panson-Weekly-032","content":"日拱一卒 1 一周见闻 1.1 技术文章 京东技术-供应链大屏设计实践 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 204. 计数质数 class Solution { public int countPrimes(int n) { boolean[] isPrime = new boolean[n]; Arrays.fill(isPrime, true); for(int i = 2; i * i &lt; n; i++) { if(isPrime[i]) { for(int j = i * i; j &lt; n; j += i) { isPrime[j] = false; } } } int count = 0; for(int i = 2; i &lt; n; i++) { if(isPrime[i]) { count++; } } return count; } } 263. 丑数 //leetcode submit region begin(Prohibit modification and deletion) class Solution { /** * 丑数 就是只包含质因数 2、3 和 5 的正整数。 * * 给你一个整数 n ，请你判断 n 是否为 丑数 。如果是，返回 true ；否则，返回 false 。 * * 示例 1： * * 输入：n = 6 * 输出：true * 解释：6 = 2 × 3 * 示例 2： * * 输入：n = 1 * 输出：true * 解释：1 没有质因数，因此它的全部质因数是 {2, 3, 5} 的空集。习惯上将其视作第一个丑数。 * 示例 3： * * 输入：n = 14 * 输出：false * 解释：14 不是丑数，因为它包含了另外一个质因数 7 。 * 提示： * * -231 &lt;= n &lt;= 231 - 1 * @param n * @return */ public boolean isUgly(int n) { if(n &lt;= 0) { return false; } while(n % 2 == 0) { n /= 2; } while(n % 3 == 0) { n /= 3; } while(n % 5 == 0) { n /= 5; } return n == 1; } } //leetcode submit region end(Prohibit modification and deletion) 264. 丑数 II class Solution { public int nthUglyNumber(int n) { int i = 1; int[] ugly = new int[n + 1]; int p1 = 1; int p2 = 1; int p3 = 1; int step2 = 1; int step3 = 1; int step5 = 1; while(i &lt;= n) { int min = Math.min(Math.min(step2, step3), step5); ugly[i] = min; i++; if(min == step2) { step2 = 2 * ugly[p1++]; } if(min == step3) { step3 = 3 * ugly[p2++]; } if(min == step5) { step5 = 5 * ugly[p3++]; } } return ugly[n]; } } 378. 有序矩阵中第 K 小的元素 class Solution { /** * 给你一个 n x n 矩阵 matrix ，其中每行和每列元素均按升序排序，找到矩阵中第 k 小的元素。 * 请注意，它是 排序后 的第 k 小元素，而不是第 k 个 不同 的元素。 * * 你必须找到一个内存复杂度优于 O(n2) 的解决方案。 * * 示例 1： * * 输入：matrix = [[1,5,9],[10,11,13],[12,13,15]], k = 8 * 输出：13 * 解释：矩阵中的元素为 [1,5,9,10,11,12,13,13,15]，第 8 小元素是 13 * 示例 2： * * 输入：matrix = [[-5]], k = 1 * 输出：-5 * 提示： * * n == matrix.length * n == matrix[i].length * 1 &lt;= n &lt;= 300 * -109 &lt;= matrix[i][j] &lt;= 109 * 题目数据 保证 matrix 中的所有行和列都按 非递减顺序 排列 * 1 &lt;= k &lt;= n2 * 进阶： * * 你能否用一个恒定的内存(即 O(1) 内存复杂度)来解决这个问题? * 你能在 O(n) 的时间复杂度下解决这个问题吗?这个方法对于面试来说可能太超前了，但是你会发现阅读这篇文章（ this paper ）很有趣。 * @param matrix * @param k * @return */ public int kthSmallest(int[][] matrix, int k) { PriorityQueue&lt;int[]&gt; q = new PriorityQueue&lt;&gt;((a,b) -&gt; { return a[0] - b[0]; }); int n = matrix.length; for(int i = 0; i &lt; n; i++) { q.offer(new int[] {matrix[i][0], i, 0}); } int res = 0; while(!q.isEmpty() &amp;&amp; k &gt; 0) { int[] cur = q.poll(); int i = cur[1]; int j = cur[2]; k--; res = cur[0]; if(j + 1 &lt; n) { q.offer(new int[]{matrix[i][j + 1], i, j + 1}); } } return res; } } 3115. 质数的最大距离 //leetcode submit region begin(Prohibit modification and deletion) class Solution { public int maximumPrimeDifference(int[] nums) { int p1 = -1; // 初始化第一个质数的下标 int p2 = -1; // 初始化最后一个质数的下标 for(int i = 0; i &lt; nums.length; i++) { if(isPrime(nums[i])) { if(p1 == -1) { p1 = i; } p2 = i; } } return p2 - p1; } public boolean isPrime(int num) { if (num &lt; 2) return false; // 小于2的数不是质数 // num 题设限制大于 0 for(int i = 2; i * i &lt;= num; i++) { if(num % i == 0) { return false; } } return true; } } //leetcode submit region end(Prohibit modification and deletion) 373. 查找和最小的 K 对数字 class Solution { public List&lt;List&lt;Integer&gt;&gt; kSmallestPairs(int[] nums1, int[] nums2, int k) { PriorityQueue&lt;int[]&gt; q = new PriorityQueue&lt;&gt;((a, b) -&gt; { return a[0] + a[1] - b[0] - b[1]; }); for(int i = 0; i &lt; nums1.length; i++) { q.offer(new int[]{nums1[i], nums2[0], 0}); } List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); while(!q.isEmpty() &amp;&amp; k &gt; 0) { int[] cur = q.poll(); res.add(Arrays.asList(cur[0], cur[1])); if(cur[2] + 1 &lt; nums2.length) { q.offer(new int[]{cur[0], nums2[cur[2] + 1], cur[2] + 1}); } k--; } return res; } } 206. 反转链表 //leetcode submit region begin(Prohibit modification and deletion) /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { public ListNode reverseList(ListNode head) { if(head == null || head.next == null) { return head; } ListNode last = reverseList(head.next); head.next.next = head; head.next = null; return last; } } //leetcode submit region end(Prohibit modification and deletion) 92. 反转链表 II //leetcode submit region begin(Prohibit modification and deletion) /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { /** * 给你单链表的头指针 head 和两个整数 left 和 right ，其中 left &lt;= right 。请你反转从位置 left 到位置 right 的链表节点，返回 反转后的链表 。 * * 示例 1： * * * 输入：head = [1,2,3,4,5], left = 2, right = 4 * 输出：[1,4,3,2,5] * 示例 2： * * 输入：head = [5], left = 1, right = 1 * 输出：[5] * 提示： * * 链表中节点数目为 n * 1 &lt;= n &lt;= 500 * -500 &lt;= Node.val &lt;= 500 * 1 &lt;= left &lt;= right &lt;= n * 进阶： 你可以使用一趟扫描完成反转吗？ * @param head * @param left * @param right * @return */ public ListNode reverseBetween(ListNode head, int left, int right) { if(left == 1) { return reverseN(head, right); } head.next = reverseBetween(head.next, left - 1, right - 1); return head; } ListNode successor = null; // 后驱节点 // 反转以 head 为起点的 n 个节点，返回新的头结点 // 1 2 3, n = 2 -&gt; 2 1 3 public ListNode reverseN(ListNode head, int n) { if (n == 1) { // 记录第 n + 1 个节点 successor = head.next; return head; } // 以 head.next 为起点，需要反转前 n - 1 个节点 ListNode last = reverseN(head.next, n - 1); head.next.next = head; // 让反转之后的 head 节点和后面的节点连起来 head.next = successor; return last; } } //leetcode submit region end(Prohibit modification and deletion) 234. 回文链表 //leetcode submit region begin(Prohibit modification and deletion) /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { // 快慢指针找到要反转的起始节点 // 翻转后半部分 // 遍历对比 public boolean isPalindrome(ListNode head) { ListNode slow = head; ListNode fast = head; while(fast != null &amp;&amp; fast.next != null) { slow = slow.next; fast = fast.next.next; } if(fast != null) { slow = slow.next; } ListNode last = reverse(slow); while(last != null) { if(last.val != head.val) { return false; } last = last.next; head = head.next; } return true; } public ListNode reverse(ListNode head) { ListNode pre = null; ListNode cur = head; while(cur != null) { ListNode next = cur.next; cur.next = pre; pre = cur; cur = next; } return pre; } } //leetcode submit region end(Prohibit modification and deletion) 25. K 个一组翻转链表 class Solution { public ListNode reverseKGroup(ListNode head, int k) { if(head == null) { return head; } ListNode a = head; ListNode b = head; // 12345 for(int i = 0; i &lt; k; i++) { if(b == null) { return head; } b = b.next; } ListNode newHead = reverse(a, b); a.next = reverseKGroup(b, k); return newHead; } public ListNode reverse(ListNode a, ListNode b) { ListNode pre = null; ListNode cur = a; while(cur != b) { ListNode next = cur.next; cur.next = pre; pre = cur; cur = next; } return pre; } } 88. 合并两个有序数组 //leetcode submit region begin(Prohibit modification and deletion) class Solution { public void merge(int[] nums1, int m, int[] nums2, int n) { int p1 = m - 1; int p2 = n - 1; int i = m + n - 1; while(p1 &gt;= 0 &amp;&amp; p2 &gt;= 0) { if(nums1[p1] &gt; nums2[p2]) { nums1[i--] = nums1[p1--]; } else { nums1[i--] = nums2[p2--]; } } while (p2 &gt;= 0) { nums1[i--] = nums2[p2--]; } } } //leetcode submit region end(Prohibit modification and deletion) ","link":"https://panson.top/post/panson-weekly-032/"},{"title":"Panson-Weekly-031","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 752. 打开转盘锁 class Solution { public int openLock(String[] deadends, String target) { Set&lt;String&gt; deadLocks = new HashSet&lt;&gt;(); for(String str : deadends) { deadLocks.add(str); } Set&lt;String&gt; visited = new HashSet&lt;&gt;(); Deque&lt;String&gt; queue = new ArrayDeque&lt;&gt;(); int step = 0; queue.offer(&quot;0000&quot;); visited.add(&quot;0000&quot;); while(!queue.isEmpty()) { int size = queue.size(); for(int i = 0; i &lt; size; i++) { String cur = queue.poll(); if(deadLocks.contains(cur)) { continue; } if(target.equals(cur)) { return step; } for(int j = 0; j &lt; 4; j++) { String up = plusOne(cur, j); if(!visited.contains(up)) { queue.offer(up); visited.add(up); } String down = minusOne(cur, j); if(!visited.contains(down)) { queue.offer(down); visited.add(down); } } } step++; } return -1; } public String plusOne(String cur, int j) { char[] ch = cur.toCharArray(); if(ch[j] == '9') { ch[j] = '0'; } else { ch[j] += 1; } return new String(ch); } public String minusOne(String cur, int j) { char[] ch = cur.toCharArray(); if(ch[j] == '0') { ch[j] = '9'; } else { ch[j] -= 1; } return new String(ch); } } 82. 删除排序链表中的重复元素 II /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { public ListNode deleteDuplicates(ListNode head) { if(head == null || head.next == null) { return head; } ListNode dummy = new ListNode(-101); ListNode p1 = dummy; ListNode p2 = head; while(p2 != null) { if(p2.next != null &amp;&amp; p2.val == p2.next.val) { while(p2.next != null &amp;&amp; p2.val == p2.next.val) { p2 = p2.next; } p2 = p2.next; if(p2 == null) { p1.next = null; } } else { p1.next = p2; p1 = p1.next; p2 = p2.next; } } return dummy.next; } } ","link":"https://panson.top/post/panson-weekly-031/"},{"title":"Panson-Weekly-030","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 78. 子集 class Solution { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) { backtrack(nums, 0); return res; } public void backtrack(int[] nums, int start) { res.add(new LinkedList&lt;&gt;(track)); for(int i = start; i &lt; nums.length; i++) { track.add(nums[i]); backtrack(nums, i + 1); track.removeLast(); } } } 77. 组合 class Solution { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) { backtrack(n, 1, k); return res; } public void backtrack(int n, int start, int k) { if(k == track.size()) { res.add(new LinkedList&lt;&gt;(track)); } for(int i = start; i &lt;= n; i++) { track.add(i); backtrack(n, i + 1, k); track.removeLast(); } } } 90. 子集 II class Solution { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) { Arrays.sort(nums); backtrack(nums, 0); return res; } public void backtrack(int[] nums, int start) { res.add(new LinkedList&lt;&gt;(track)); for(int i = start; i &lt; nums.length; i++) { if(i &gt; start &amp;&amp; nums[i] == nums[i - 1]) { continue; } track.add(nums[i]); backtrack(nums, i + 1); track.removeLast(); } } } 40. 组合总和 II class Solution { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); int sum = 0; public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target) { Arrays.sort(candidates); backtrack(candidates, 0, target); return res; } public void backtrack(int[] nums, int start, int target) { if(sum == target) { res.add(new LinkedList&lt;&gt;(track)); return; } for(int i = start; i &lt; nums.length; i++) { if(i &gt; start &amp;&amp; nums[i] == nums[i - 1]) { continue; } if(sum + nums[i] &gt; target) { continue; } track.add(nums[i]); sum += nums[i]; backtrack(nums, i + 1, target); sum -= nums[i]; track.removeLast(); } } } 47. 全排列 II //leetcode submit region begin(Prohibit modification and deletion) class Solution { /** * 给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。 * * 示例 1： * * 输入：nums = [1,1,2] * 输出： * [[1,1,2], * [1,2,1], * [2,1,1]] * 示例 2： * * 输入：nums = [1,2,3] * 输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]] * 提示： * * 1 &lt;= nums.length &lt;= 8 * -10 &lt;= nums[i] &lt;= 10 * * @param nums * @return */ // 1 1 1 2 List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); boolean[] used; public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) { used = new boolean[nums.length]; Arrays.sort(nums); backtrack(nums); return res; } public void backtrack(int[] nums) { if(track.size() == nums.length) { res.add(new LinkedList&lt;&gt;(track)); return; } for(int i = 0; i &lt; nums.length; i++) { if(used[i]) { continue; } if(i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i - 1]) { continue; } track.add(nums[i]); used[i] = true; backtrack(nums); track.removeLast(); used[i] = false; } } } //leetcode submit region end(Prohibit modification and deletion) 39. 组合总和 //leetcode submit region begin(Prohibit modification and deletion) class Solution { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); int sum = 0; public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) { backtrack(candidates, 0, target); return res; } public void backtrack(int[] candidates, int start, int target) { if(sum == target) { res.add(new LinkedList&lt;&gt;(track)); return; } if(sum &gt; target) { return; } for(int i = start; i &lt; candidates.length; i++) { sum += candidates[i]; track.add(candidates[i]); backtrack(candidates, i, target); sum -= candidates[i]; track.removeLast(); } } } 111. 二叉树的最小深度 class Solution { public int minDepth(TreeNode root) { if(root == null) { return 0; } ArrayDeque&lt;TreeNode&gt; queue = new ArrayDeque&lt;TreeNode&gt;(); queue.offer(root); int depth = 1; while(!queue.isEmpty()) { int size = queue.size(); for(int i = 0; i &lt; size; i++) { TreeNode node = queue.poll(); if(node.left == null &amp;&amp; node.right == null) { return depth; } if(node.left != null) { queue.offer(node.left); } if(node.right != null) { queue.offer(node.right); } } depth++; } return depth; } } ","link":"https://panson.top/post/panson-weekly-030/"},{"title":"Panson-Weekly-029","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 509. 斐波那契数 class Solution { public int fib(int n) { if(n &lt; 2) { return n; } int dp0 = 0; int dp1 = 1; for(int i = 2; i &lt;= n; i++) { int tmp = dp0; dp0 = dp1; dp1 = dp1 + tmp; } return dp1; } } 322. 零钱兑换 class Solution { int[] memo; public int coinChange(int[] coins, int amount) { memo = new int[amount + 1]; Arrays.fill(memo, -2); return dp(coins, amount); } public int dp(int[] coins, int amount) { if(amount == 0) { return 0; } if(amount &lt; 0) { return -1; } int res = Integer.MAX_VALUE; if(memo[amount] != -2) { return memo[amount]; } for(int coin : coins) { int sub = dp(coins, amount - coin); if(sub == -1) { continue; } res = Math.min(res, sub + 1); } res = res == Integer.MAX_VALUE ? -1 : res; memo[amount] = res; return res; } } class Solution { // dp 数组的定义：当目标金额为 i 时，至少需要 dp[i] 枚硬币凑出。 int coinChange(int[] coins, int amount) { int[] dp = new int[amount + 1]; // 数组大小为 amount + 1，初始值也为 amount + 1 Arrays.fill(dp, amount + 1); // base case dp[0] = 0; // 外层 for 循环在遍历所有状态的所有取值 for (int i = 0; i &lt; dp.length; i++) { // 内层 for 循环在求所有选择的最小值 for (int coin : coins) { // 子问题无解，跳过 if (i - coin &lt; 0) { continue; } dp[i] = Math.min(dp[i], 1 + dp[i - coin]); } } return (dp[amount] == amount + 1) ? -1 : dp[amount]; } } 46. 全排列 class Solution { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) { LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); boolean[] used = new boolean[nums.length]; backtrack(nums, track, used); return res; } public List&lt;List&lt;Integer&gt;&gt; backtrack(int[] nums, LinkedList&lt;Integer&gt; track, boolean[] used) { if(nums.length == track.size()) { res.add(new LinkedList&lt;&gt;(track)); } for(int i = 0; i &lt; nums.length; i++) { if(used[i]) { continue; } track.add(nums[i]); used[i] = true; backtrack(nums, track, used); track.removeLast(); used[i] = false; } return res; } } ","link":"https://panson.top/post/panson-weekly-029/"},{"title":"Panson-Weekly-028","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 27. 移除元素 class Solution { public int removeElement(int[] nums, int val) { if(nums.length == 0) { return 0; } int p1 = 0; int p2 = 0; int n = nums.length; while(p2 &lt;= n - 1) { while(p2 &lt;= n - 1 &amp;&amp; nums[p2] == val) { p2++; } if(p2 &lt;= n - 1) { nums[p1] = nums[p2]; p1++; p2++; } } return p1; } } 283. 移动零 class Solution { public void moveZeroes(int[] nums) { int n = nums.length; int p1 = 0; int p2 = 0; while(p2 &lt;= n - 1) { while(p2 &lt;= n - 1 &amp;&amp; nums[p2] == 0) { p2++; } if(p2 &lt;= n - 1) { nums[p1] = nums[p2]; p1++; p2++; } } while(p1 &lt;= n - 1) { nums[p1++] = 0; } } } 344. 反转字符串 class Solution { public void reverseString(char[] s) { int n = s.length; int p1 = 0; int p2 = n - 1; while(p1 &lt; p2) { char tmp = s[p1]; s[p1] = s[p2]; s[p2] = tmp; p1++; p2--; } } } 5. 最长回文子串 class Solution { public String longestPalindrome(String s) { if(s == null || s.length() &lt;= 1) { return s; } String res = &quot;&quot;; for(int i = 0; i &lt; s.length(); i++) { String palindrome1 = palindrome(s, i, i); String palindrome2 = palindrome(s, i, i + 1); res = palindrome1.length() &gt; res.length() ? palindrome1 : res; res = palindrome2.length() &gt; res.length() ? palindrome2 : res; } return res; } public String palindrome(String s, int i, int j) { while(i &gt;= 0 &amp;&amp; j &lt; s.length() &amp;&amp; s.charAt(i) == s.charAt(j)) { i--; j++; } return s.substring(i + 1, j); } } 83. 删除排序链表中的重复元素 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { public ListNode deleteDuplicates(ListNode head) { if(head == null || head.next == null) { return head; } ListNode dummy = new ListNode(-1); dummy.next = head; ListNode p1 = head; ListNode p2 = head.next; while(p2 != null) { while(p2 != null &amp;&amp; p1.val == p2.val) { p2 = p2.next; } p1.next = p2; p1 = p1.next; }a return dummy.next; } } 104. 二叉树的最大深度 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { public int maxDepth(TreeNode root) { if(root == null) { return 0; } return Math.max(maxDepth(root.left), maxDepth(root.right)) + 1; } } +144. 二叉树的前序遍历 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); public List&lt;Integer&gt; preorderTraversal(TreeNode root) { if(root == null) { return res; } res.add(root.val); preorderTraversal(root.left); preorderTraversal(root.right); return res; } } ","link":"https://panson.top/post/panson-weekly-028/"},{"title":"Panson-Weekly-027","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 26. 删除有序数组中的重复项 class Solution { public int removeDuplicates(int[] nums) { if(nums == null || nums.length == 0) return 0; int n = nums.length; int p1= 0; int p2 = 0; while(p2 &lt; n) { // 找到第一个 while(p2 &lt; n &amp;&amp; nums[p1] == nums[p2]) { p2++; } p1++; if(p2 &lt; n) { nums[p1] = nums[p2]; } } return p1; } } /** * 用队列实现一个栈 * * @author Panson * @create 2024-05-31 */ public class Queue2Stack&lt;T&gt; { private Deque&lt;T&gt; queue; private Deque&lt;T&gt; tmpQueue; public Queue2Stack() { queue = new ArrayDeque&lt;&gt;(); tmpQueue = new ArrayDeque&lt;&gt;(); } public void push(T element) { queue.offer(element); } public T pop() { if(isEmpty()) { throw new RuntimeException(&quot;Queue2Stack is empty&quot;); } while(queue.size() &gt; 1) { tmpQueue.offer(queue.poll()); } T element = queue.poll(); Deque&lt;T&gt; tmp = tmpQueue; tmpQueue = queue; queue = tmp; return element; } public T peek() { if(isEmpty()) { throw new RuntimeException(&quot;Queue2Stack is empty&quot;); } while(queue.size() &gt; 1) { tmpQueue.offer(queue.poll()); } T element = queue.poll(); tmpQueue.offer(element); Deque&lt;T&gt; tmp = tmpQueue; tmpQueue = queue; queue = tmp; return element; } public boolean isEmpty() { return queue.isEmpty(); } } /** * 如何用栈实现一个队列 * @author Panson * @create 2024-05-31 */ public class Stack2Queue&lt;T&gt; { private Deque&lt;T&gt; stackA; private Deque&lt;T&gt; stackB; public Stack2Queue() { stackA = new ArrayDeque&lt;&gt;(); stackB = new ArrayDeque&lt;&gt;(); } public boolean isEmpty() { return stackA.isEmpty(); } public void offer(T element) { stackA.push(element); } public T pop() { if(isEmpty()) { throw new RuntimeException(&quot;Stack2Queue is empty&quot;); } if(stackB.isEmpty()) { while (!stackA.isEmpty()) { stackB.push(stackA.pop()); } } return stackB.pop(); } public T peek() { if(isEmpty()) { throw new RuntimeException(&quot;Stack2Queue is empty&quot;); } if(isEmpty()) { throw new RuntimeException(&quot;Stack2Queue is empty&quot;); } if(stackB.isEmpty()) { while (!stackA.isEmpty()) { stackB.push(stackA.pop()); } } return stackB.peek(); } } ","link":"https://panson.top/post/panson-weekly-027/"},{"title":"Panson-Weekly-026","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 141. 环形链表 public class L0141 { /** * Definition for singly-linked list. * class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */ public class Solution { public boolean hasCycle(ListNode head) { if(head == null || head.next == null) { return false; } ListNode slow = head; ListNode fast = head; while(fast != null &amp;&amp; fast.next != null) { slow = slow.next; fast = fast.next.next; if(slow == fast) { return true; } } return false; } } } 142. 环形链表 II public class L0142 { /** * Definition for singly-linked list. * class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */ public class Solution { public ListNode detectCycle(ListNode head) { if(head == null || head.next == null) { return null; } ListNode slow = head; ListNode fast = head; boolean existCycle = false; while(fast != null &amp;&amp; fast.next != null) { slow = slow.next; fast = fast.next.next; if(slow == fast) { existCycle = true; break; } } if(existCycle) { fast = head; } else { return null; } while(fast != slow) { fast = fast.next; slow = slow.next; } return fast; } } } 160. 相交链表 /** * @author Panson * @create 2024-05-22 */ public class L0160 { /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */ public class Solution { public ListNode getIntersectionNode(ListNode headA, ListNode headB) { if(headA == null || headB == null) { return null; } ListNode pA = headA; ListNode pB = headB; while(pA != pB) { if(pA == null) { pA = headB; } else { pA = pA.next; } if(pB == null) { pB = headA; } else { pB = pB.next; } } return pA; } } } 19. 删除链表的倒数第 N 个结点 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummy = new ListNode(-1); dummy.next = head; ListNode pre = dummy; ListNode cur = dummy; while(n &gt; 0) { cur = cur.next; n--; } while(cur.next != null) { cur = cur.next; pre = pre.next; } pre.next = pre.next.next; return dummy.next; } } 21. 合并两个有序链表 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { public ListNode mergeTwoLists(ListNode list1, ListNode list2) { ListNode head = new ListNode(-1); ListNode dummy = head; while(list1 != null &amp;&amp; list2 != null) { if(list1.val &lt; list2.val) { head.next = list1; list1 = list1.next; } else { head.next = list2; list2 = list2.next; } // -1, -9, 3, head = head.next; } if(list1 != null) { head.next = list1; } if(list2 != null) { head.next = list2; } return dummy.next; } } 23. 合并 K 个升序链表 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { public ListNode mergeKLists(ListNode[] lists) { if(lists == null || lists.length == 0) { return null; } PriorityQueue&lt;ListNode&gt; queue = new PriorityQueue&lt;&gt;(lists.length, (a, b) -&gt; (a.val - b.val)); for(ListNode node : lists) { if(node != null) { queue.offer(node); } } ListNode p = new ListNode(-1); ListNode dummy = p; while(!queue.isEmpty()) { ListNode node = queue.poll(); p.next = node; if(node.next != null) { queue.offer(node.next); } p = p.next; } return dummy.next; } } 86. 分隔链表 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { public ListNode partition(ListNode head, int x) { ListNode dummy1 = new ListNode(-1); dummy1.next = head; ListNode dummy2 = new ListNode(-1); dummy2.next = head; ListNode p1 = dummy1; ListNode p2 = dummy2; while(head != null) { if(head.val &lt; x) { p1.next = head; p1 = p1.next; } else { p2.next = head; p2 = p2.next; } head= head.next; } p2.next = null; p1.next = dummy2.next; return dummy1.next; } } 876. 链表的中间结点 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { public ListNode middleNode(ListNode head) { ListNode dummy = new ListNode(-1); dummy.next = head; ListNode p1 = dummy; ListNode p2 = dummy; while(p2 != null &amp;&amp; p2.next != null) { p1 = p1.next; p2 = p2.next.next; } if(p2 == null) { return p1; } else { return p1.next; } } } 167. 两数之和 II - 输入有序数组 class Solution { public int[] twoSum(int[] numbers, int target) { int n = numbers.length; int p1 = 0; int p2 = n - 1; while(p1 &lt; p2) { if(numbers[p1] + numbers[p2] == target) { return new int[]{p1 + 1, p2 + 1}; } else if(numbers[p1] + numbers[p2] &lt; target) { p1++; } else { p2--; } } return new int[]{-1, -1}; } } ","link":"https://panson.top/post/panson-weekly-026/"},{"title":"042.什么是料箱到人在线理货","content":"在 WMS（仓库管理系统） 和 WES（仓库执行系统） 中，料箱到人在线理货 是指通过料箱运输商品到指定位置，并利用在线系统或设备进行实时的理货操作。理货通常是指根据任务需求将商品进行分类、整理、挑选等操作，确保商品在出库前符合要求，便于后续的配送或销售。 料箱到人在线理货的工作流程： 料箱运输到指定位置： 在仓库中，首先通过自动化设备（如自动化搬运车、AGV等）将料箱或容器运送到指定的理货区域，或者通过人工操作将货物推送到理货区域。 系统分配理货任务： 在理货区域，系统会通过实时数据（通常是通过 WMS 或 WES 系统）分配理货任务。这些任务通常包括对每个料箱中的商品进行整理、挑选、确认等操作。 系统会根据订单需求、商品信息以及仓库布局等因素，指导工作人员进行理货，确保每个料箱内的商品与订单要求一致。 在线系统支持： 在线理货是指在整个理货过程中，操作员实时与系统进行交互，系统会提供实时的任务指令、商品信息、作业进度等。这通常通过 手持设备（如PDA、RF设备等）完成，操作员可以实时更新任务状态。 系统会实时记录每个理货操作，并自动检查商品是否与订单需求匹配，如有异常（例如商品数量不足或错误），系统会发出警告或提示。 理货操作： 根据系统提供的指令，操作员会对料箱中的商品进行检查、分类、整理或挑选。在线理货时，系统通常会进行实时反馈和数据更新，确保操作员跟随最新的任务进度。 如果存在需要变更或重新整理的商品，系统会提示操作员进行调整，确保所有商品在出库前符合要求。 确认和完成任务： 理货完成后，操作员会通过设备或系统确认商品已经理货完毕，理货任务就此完成。仓库系统会记录每个步骤，确保每个商品的处理都符合要求。 完成理货后，商品将会进入下一环节（如分拣、打包或发货等）。 料箱到人在线理货的优点： 提高效率： 在线理货通过系统实时指导，避免了手动查询或频繁的走动，可以大大提高理货效率。 减少错误： 系统自动检查和反馈任务执行情况，有效减少由于人为疏忽而导致的错误，例如商品错误、缺货等。 实时数据更新： 在线理货与系统实时连接，可以即时更新商品信息、库存数据和理货进度，保证仓库操作的实时性和准确性。 增强作业可视化： 操作员通过系统能清晰看到理货任务的具体要求和进度，同时仓库管理人员也可以实时监控整个理货过程，及时调整作业策略。 优化资源分配： 系统通过实时数据分析，可以更精确地安排任务，优化作业员的工作路径和时间分配，从而减少不必要的时间浪费。 适用场景： 仓库分拣： 适用于大型仓库中需要对商品进行多轮分拣和理货的场景，特别是在电商仓库、零售仓库等。 订单处理： 对于订单量大的仓库，料箱到人在线理货可以有效提高订单处理速度，确保按时发货。 多品类商品： 当仓库需要处理多种商品并且需要高效的整理、分类时，在线理货非常适用。 总结： 料箱到人在线理货 是仓库中一种高效的商品整理、挑选和分类方式，通过 WMS 或 WES 系统的实时数据支持，结合手持设备操作，能够减少人为错误、提高作业效率，并确保商品和订单的一致性。这种方法特别适用于大规模的仓储管理和电商、零售等需要高效物流操作的场景。 ","link":"https://panson.top/post/042_-shi-me-shi-liao-xiang-dao-ren-zai-xian-li-huo/"},{"title":"031.什么是料箱到人整箱直接上架","content":"料箱到人整箱直接上架（Case-to-Person Direct Putaway） 是一种仓库管理和拣选模式，主要用于高效管理库存和上架商品。它的基本思路是将商品存放在料箱中，并直接通过自动化或半自动化设备将整箱商品从接收到的货物直接送到目标货架上进行存储。 料箱到人整箱直接上架的流程： 接收货物： 商品通过运输方式送到仓库，通常这些商品会被装在预先准备好的料箱中。每个料箱可能包含多个相同或相似的商品。 料箱传输： 自动化设备（如输送带、AGV机器人等）会将这些装有商品的料箱从接收区域送到仓库的存储区域。这是一个自动化过程，不需要人工干预。 整箱上架： 料箱直接送到目标货架位置，并由系统或者工作人员根据需求进行存储。这个过程是“整箱”存储，即整个料箱（而不是单个商品）被放置在指定的位置。 目标货架管理： 整箱商品上架后，仓库管理系统（WMS）会记录下商品所在的具体货架位置，便于后续的库存管理、拣选及配送。 料箱到人整箱直接上架的优点： 提高上架效率：通过自动化设备将整箱商品直接送到货架，无需人工逐个商品地搬运和放置，提高了上架速度和精度。 减少人工操作：减少了人工干预，降低了劳动强度，减小了操作错误的几率。 提高库存管理效率：上架时，系统会自动记录每个货物的位置，便于后续查找、补货和库存盘点。 节省空间和时间：料箱的使用可以提高仓库空间的利用率，并且整箱上架能够更快速地完成库存存储任务。 适用场景： 大批量商品管理：适用于批量化、大宗商品的管理，比如批发仓库、零售仓库、食品仓库等。 商品种类相对固定：适合商品种类较少、比较统一的环境，尤其是同类商品一起存储的情况下。 高效的存储管理：当仓库需要高效地管理库存并且减少人工干预时，这种方式特别有效。 与其他模式的区别： 料箱到人：在料箱到人模式中，商品通常会按料箱或托盘进行管理，而整箱上架则强调将整个料箱作为一个单位直接存放。 货架到人：货架到人模式更注重将货架上的商品送到操作员，而料箱到人模式侧重于将整箱货物直接送到货架上进行存储。 总结： 料箱到人整箱直接上架 是一种通过自动化手段将装有商品的料箱直接送到指定货架的仓储管理方式，适用于大宗商品、批量订单的高效管理。该模式能够减少人工操作，提高上架速度和库存管理的精确度，同时优化仓库空间利用。 ","link":"https://panson.top/post/031_-shi-me-shi-liao-xiang-dao-ren-zheng-xiang-zhi-jie-shang-jia/"},{"title":"032.什么是料箱到人空箱直接上架","content":"好的，去掉与其他模式的区别后，更新内容如下： 料箱到人空箱直接上架（Case-to-Person Empty Putaway） 是一种仓库管理模式，主要用于管理空的料箱，帮助提高仓库的空间利用率和存储效率。与“料箱到人整箱直接上架”不同，空箱上架的过程并不涉及商品，而是将空的料箱或托盘直接放置在合适的货架位置，供后续使用或存储商品时使用。 料箱到人空箱直接上架的流程： 接收空箱： 空的料箱或托盘被运输或送入仓库。这些空箱一般是在运输商品后留下的空箱，或者是为了后续填充商品而准备的空料箱。 空箱传输： 自动化设备（如输送带、自动导引车（AGV）、机器人等）会将这些空的料箱从接收区域送到仓库的存储区域。这个过程自动化程度较高，无需人工干预。 空箱上架： 自动化设备将这些空的料箱或托盘送到目标货架上，按需要将其存放在合适的存储位置。这些空箱存放在专门的区域，以备后续商品存放时使用。 存储过程中，仓库管理系统（WMS）会记录每个空箱的位置，以便后续能够快速调度使用。 目标货架管理： 上架后的空箱会被系统跟踪，确保它们的存储位置清晰可查。这样，在需要时，系统可以快速调度空箱，减少人工查找和搬运的时间。 料箱到人空箱直接上架的优点： 提高存储效率：通过自动化将空箱直接送到货架，可以减少人工搬运，提高存储效率。 优化空间利用：空箱的存储通常会有专门的区域，能够合理规划存储空间，使仓库布局更为高效。 减少人工操作：通过自动化设备处理空箱的上架，可以减少人工干预，降低劳动强度，提高作业效率。 提高空箱的调度效率：自动化系统可以准确记录每个空箱的位置，确保仓库人员能够在需要时迅速找到空箱，避免浪费时间寻找。 适用场景： 空料箱管理：当仓库需要管理大量空料箱，或者空托盘在仓库中占用较大空间时，这种模式能帮助高效管理空料箱。 标准化商品存储：对于一些商品批量化存储，空箱通常在商品存放前需要先行准备。空箱上架可以确保它们在适当的地方随时待命。 高效的仓库空间管理：适用于空间利用率要求较高的仓库，特别是在商品进出频繁、空箱堆积较多的环境。 总结： 料箱到人空箱直接上架 是一种通过自动化手段将空料箱或空托盘直接送到指定存储位置的仓储管理方式，适用于高效管理空料箱、提高空间利用率和优化仓库布局。通过减少人工干预和自动化管理，空箱的存储、调度和使用变得更加高效。这种模式对于存储和调配空料箱的仓库，特别是在商品存放和拣选频繁的环境中具有重要的意义。 ","link":"https://panson.top/post/032_-shi-me-shi-liao-xiang-dao-ren-kong-xiang-zhi-jie-shang-jia/"},{"title":"033.什么是料箱到人在线指导上架","content":"料箱到人指导上架（Case-to-Person Guided Putaway） 是一种仓库管理模式，通过使用指导系统帮助工作人员将料箱（通常是装有商品的容器）送到正确的存储位置。与传统的手动上架方式不同，这种模式结合了仓库管理系统（WMS）和先进的技术（如条码扫描、RFID、语音指令等）来引导和优化上架过程，确保料箱能够被准确、高效地放置到指定位置。 料箱到人指导上架的流程： 接收商品： 商品或料箱首先进入仓库，通过接收区进行初步处理，确保商品和库存信息准确无误。 指导系统指示： 系统根据库存需求和存储规则生成上架任务，并通过不同的方式（如显示屏、手持设备、语音提示等）将目标位置和相关信息传达给仓库操作员。 操作员收到指示后，开始执行上架任务。 操作员上架： 操作员根据系统提供的引导，使用设备（如扫描枪、语音设备、或平板）查找并扫描每个料箱或托盘，确认商品的准确性。 系统通过实时跟踪上架情况，指导操作员将料箱放置到正确的存储位置。 确认上架： 完成上架后，操作员通过设备扫描或输入信息来确认货物已经上架到指定位置，系统更新库存信息，确保实时同步。 任务完成： 上架完成后，操作员返回仓库控制中心或其他任务区域，等待下一个任务。 料箱到人指导上架的优点： 减少错误率：通过实时引导系统（如条码扫描、语音提示等），可以大大减少人工错误，提高上架准确性。 提高效率：指导系统帮助操作员更快找到正确的存储位置，减少寻找货位的时间，从而提高工作效率。 优化空间利用：系统能够根据库存情况和存储规则，自动为每个商品分配最佳的存储位置，优化仓库空间的利用率。 实时跟踪：系统能够实时追踪上架进度，确保每个料箱的存储情况被准确记录，避免遗漏。 降低培训成本：通过引导系统，新员工能够快速适应工作流程，减少培训时间和成本。 适用场景： 大规模商品存储：在大规模存储和管理商品的仓库，料箱到人指导上架可以帮助操作员高效、准确地完成上架任务。 高频率的货物进出：对于商品进出频繁的仓库，采用指导上架方式可以避免过多的库存堆积，保持高效的工作流。 复杂的库存管理：如果仓库内商品种类繁多，且有多种存储要求，指导上架有助于确保每个商品都被准确存放。 总结： 料箱到人指导上架 是一种结合技术和智能系统，帮助仓库操作员高效、准确地将料箱或商品存放到指定位置的仓库管理模式。通过引导系统，操作员能够减少错误、提高效率，并实现仓库空间的最优利用。这种模式在商品量大、存储复杂的仓库管理环境中尤为有效。 ","link":"https://panson.top/post/033_-shi-me-shi-liao-xiang-dao-ren-zai-xian-zhi-dao-shang-jia/"},{"title":"034.什么是货架到人在线直接上架","content":"货架到人在线直接上架（Shelf-to-Person Online Direct Putaway） 是一种仓库管理模式，指的是在商品到达仓库后，货物从货架上直接被送到人员所在的作业区域进行上架，并且这个过程是实时在线进行的。通过自动化系统的支持，商品上架过程中能够实时监控、控制和调整，确保货物能准确无误地上架到指定位置。 货架到人在线直接上架的流程： 接收商品： 商品或货物到达仓库，经过接收区检查并确认商品信息，记录到仓库管理系统（WMS）中。 分配上架任务： 仓库管理系统（WMS）根据商品的种类、存储要求和当前的库存需求，自动生成上架任务，并为每个任务分配相应的货架和目标存储位置。 实时指引： 在货物到达仓库后，系统通过在线方式，实时指引操作员或自动化设备将货物从货架上取出并进行上架。 系统通过手持设备、条形码扫描器、RFID设备、语音指令等方式为操作员提供指导，确保上架过程中每一步都得到确认。 货物搬运与上架： 操作员根据系统的实时指引，从货架上取下商品或料箱，通过自动化设备（如AGV、输送带等）将其送到指定的存储位置，进行上架操作。 在此过程中，系统实时监控并记录上架操作，确保商品被正确存放。 确认上架： 完成上架后，操作员通过扫描设备或输入信息来确认商品已经放置到目标位置。 系统更新库存信息，确保货物的位置和库存量的实时同步。 完成任务： 上架完成后，系统将自动记录任务的完成状态，操作员继续等待下一个上架任务。 货架到人在线直接上架的优点： 实时监控： 系统能够实时监控商品的上架情况，及时反馈给操作员，以确保上架任务按计划进行，并及时解决问题。 提高效率： 在线直接上架模式消除了人工干预的时间，自动化系统能够减少操作员在货架之间来回走动的时间，从而提高作业效率。 准确性： 通过实时指引，能够确保货物被准确地上架到指定位置，避免误放或遗漏。 优化库存管理： 由于系统对上架过程的实时监控，可以确保仓库库存信息始终保持准确，避免过度存储或缺货现象。 降低人工成本： 通过自动化设备和实时系统指引，减少了人工操作，降低了仓库的劳动成本。 灵活的调整： 在线系统允许根据仓库内存储需求、商品种类等因素灵活调整上架策略，以适应不同的作业需求。 适用场景： 高效仓库管理： 对于商品种类繁多、存储要求复杂的仓库，在线直接上架模式能够确保快速且准确的上架过程。 大型仓储中心： 在大规模的仓库中，货物进出频繁，通过货架到人在线直接上架模式可以有效减少空间浪费，提高库存管理的效率。 电商及零售仓库： 在电商仓库或者零售仓库中，商品的存储与上架要求高度精确，实时在线系统能够确保快速、准确的上架操作。 总结： 货架到人在线直接上架 是一种仓库管理模式，通过结合自动化设备和在线实时系统，为操作员提供精准的上架指导，使得货物从货架到指定存储位置的上架过程更加高效、准确。这种模式能够优化库存管理、提高仓库作业效率，并确保商品存储的准确性，特别适用于大规模商品存储和快速货物流动的仓库环境。 ","link":"https://panson.top/post/034_-shi-me-shi-huo-jia-dao-ren-zai-xian-zhi-jie-shang-jia/"},{"title":"035.什么是货架到人按单指导上架","content":"货架到人按单指导上架（Shelf-to-Person Order Guided Putaway） 是一种仓库管理模式，旨在通过系统指引操作员按订单要求将商品从货架上取出并放置到指定位置。这种方式结合了仓库管理系统（WMS）与自动化技术，通过按订单的需求来引导操作员进行上架操作，从而提高效率、减少错误，并保证库存的准确性。 货架到人按单指导上架的流程： 接收订单和商品： 仓库收到订单，并通过仓库管理系统（WMS）将订单信息处理后生成上架任务。 商品或料箱在接收区进行入库操作，仓库管理系统（WMS）根据商品的种类、存储要求和订单需求生成相应的上架任务。 订单生成上架任务： 根据每个订单的需求，仓库管理系统（WMS）为每个订单自动生成上架任务，指定每个商品的位置及上架优先级。 系统通过条码扫描、RFID、语音指令等技术，向操作员提供每个商品具体的上架位置和任务。 操作员接收上架指令： 操作员通过扫描设备、手持终端或语音设备，接收系统给出的具体上架指令，指示操作员从哪个货架上取出商品，并将其放置到指定位置。 按单上架： 根据订单的要求，操作员将商品按照系统指示从货架上取出，进行上架操作。每个操作员都根据当前的订单任务来上架商品。 如果订单包含多个商品，操作员根据系统提供的优先级和指导，逐一完成每个商品的上架。 确认上架： 完成上架后，操作员通过扫描设备确认商品已经成功上架到指定的存储位置。系统会更新库存信息和上架状态，确保库存数据的实时同步。 系统还会对上架过程进行跟踪，保证每个步骤都按计划执行。 完成任务： 上架任务完成后，操作员可以开始处理其他订单，或者等待新的上架任务。 货架到人按单指导上架的优点： 订单导向性强： 该模式能够根据具体订单需求来指导上架过程，确保每个商品的上架位置、数量等都能精确对应到订单要求。 提高准确性： 系统通过精准的指引，减少了操作员的主观判断，避免了误操作和商品放错位置的情况，确保库存的准确性。 提高效率： 系统为操作员提供明确的上架指导，减少了寻找货物的时间，提高了上架速度，进而提高了整体的仓库作业效率。 减少人工干预： 通过系统自动生成上架任务并指导操作员，减少了人为干预，降低了人为错误的发生率。 灵活的任务分配： 仓库管理系统根据订单的需求灵活分配上架任务，可以动态调整任务优先级，从而更好地满足订单的需求。 实时监控和跟踪： 系统实时监控上架任务的进度，确保每项任务按时完成，同时能够对异常情况进行预警，确保作业的顺利进行。 适用场景： 订单驱动的仓库： 对于以订单为驱动的仓库管理（如电商仓库），通过按单指导上架可以有效提高作业效率，并确保商品的准确存储。 多品类商品存储： 在商品种类繁多、存储要求不同的仓库环境中，按单指导上架能够确保商品按照订单要求准确存放，避免库存积压和错误。 实时性要求高的仓库： 在一些要求高效和快速响应的仓库（如零售和电商仓库）中，按单指导上架能够保证快速、精准地完成商品的上架任务。 总结： 货架到人按单指导上架 是一种基于订单需求的仓库管理模式，操作员根据系统的实时指引，将商品从货架上取出并准确地上架到指定位置。该模式通过仓库管理系统（WMS）的支持，减少人工干预、提高作业效率和库存准确性，非常适用于订单驱动型的仓库和多品类商品存储环境。 ","link":"https://panson.top/post/035_-shi-me-shi-huo-jia-dao-ren-an-dan-zhi-dao-shang-jia/"},{"title":"036.什么是料箱到人在线拣选","content":"料箱到人在线拣选（Box-to-Person Online Picking） 是一种现代化的仓库拣选方式，指的是将商品从料箱中直接送到操作员所在位置，供操作员进行拣选作业的流程。这个过程通常借助仓库管理系统（WMS）和自动化技术，通过在线实时指导操作员，确保商品的拣选过程高效、准确，并且能够实时反馈和调整。 料箱到人在线拣选的流程： 接收订单并生成拣选任务： 仓库管理系统（WMS）接收到客户订单或库存需求后，自动生成拣选任务，指引操作员从仓库中的料箱中拣选所需的商品。 系统根据订单内容、商品位置以及其他因素生成拣选指令，并将任务分配给相应的操作员。 在线指引拣选： 系统实时将拣选任务推送到操作员的终端设备（如手持终端、RFID扫描器、语音指引设备等），并且在线指导操作员进行拣选。 操作员根据指示，系统会告知他们需要从哪个料箱中拣选哪种商品，拣选数量等信息。 自动化设备运输商品： 在某些自动化仓库中，自动化设备（如AGV、输送带、自动搬运车等）将料箱自动送到操作员的工作区域，减少了操作员需要走动的时间和精力，提升了拣选效率。 操作员只需要通过系统指示，拿取正确的商品并放入订单指定的容器中。 实时确认和反馈： 操作员通过扫描条码或使用其他设备进行商品确认，确保从料箱中拣选到正确的商品。 系统会实时更新库存信息，并反馈拣选进度，确保仓库中的库存数据始终保持准确。 拣选完成： 完成拣选后，系统会生成拣选完成的报告，操作员将已拣选的商品放置在指定区域，等待后续的包装、配送或其他处理。 仓库管理系统也会在后台更新库存，确保每个商品的出库操作被准确记录。 料箱到人在线拣选的优点： 提高拣选效率： 自动化设备能够快速将料箱送到操作员，减少了操作员的步行时间。在线拣选指引可以大大提高拣选速度。 准确性高： 通过实时在线指引，系统能够准确地指示操作员从哪一个料箱中拣选哪些商品，减少了人工错误，提高了拣选准确率。 降低劳动强度： 操作员无需频繁走动，系统通过自动化设备将商品送到操作员附近，减少了体力消耗，使得操作员能够专注于拣选工作。 实时监控和调整： 系统能够实时监控拣选进度，若出现拣选错误或偏差，能够及时反馈并调整任务，确保拣选工作顺利进行。 减少库存差异： 系统实时更新库存，确保每个商品的库存状态能够随时被监控，减少了库存错误的发生。 适应高效高频的拣选需求： 这种模式特别适合电商、零售等行业，需要高效快速处理大量订单的环境。 适用场景： 电商仓库： 电商仓库通常会处理大量订单且商品种类繁多，料箱到人在线拣选能够提高拣选效率，减少拣选错误。 分拣中心： 在大规模的分拣中心，通过这种模式可以高效处理订单，及时完成订单的拣选作业。 自动化仓库： 具备自动化设备的仓库，能够通过自动化搬运设备将料箱送到操作员，结合实时在线指导完成高效的拣选。 大宗商品处理： 对于需要处理大量商品的仓库，尤其是大宗商品，料箱到人在线拣选能够大幅提高效率，减少人工负担。 总结： 料箱到人在线拣选 是一种先进的仓库拣选方式，通过自动化设备和实时在线系统指引操作员，从料箱中快速准确地拣选商品。这种模式能有效提高仓库作业效率、准确性，并且减少人工劳动强度，特别适用于电商、零售、自动化仓库等高效需求的仓储环境。 ","link":"https://panson.top/post/036_-shi-me-shi-liao-xiang-dao-ren-zai-xian-jian-xuan/"},{"title":"037.什么是货架到人在线拣选","content":"货架到人在线拣选（Shelf-to-Person Online Picking） 是一种现代化的仓库拣选模式，旨在通过在线系统实时指引操作员从货架上直接拣选商品。这种模式结合了仓库管理系统（WMS）和自动化技术，通过线上指导操作员完成拣选任务，从而提升拣选效率和准确性。 货架到人在线拣选的流程： 接收订单并生成拣选任务： 仓库管理系统（WMS）接收到客户的订单后，会根据订单需求生成具体的拣选任务。 每个拣选任务都包括了需要从仓库货架上拣选的商品以及相关的拣选数量。 在线指导拣选： 系统通过设备（如手持终端、扫描枪、语音指引系统等）向操作员实时推送拣选任务和指导。 操作员根据系统提供的拣选指引，依次从货架上取下需要的商品，通常系统会显示商品所在的货架位置和拣选数量，确保拣选准确。 确认商品和实时更新： 操作员会扫描商品的条形码或RFID标签，系统会根据扫描结果实时确认拣选的商品是否正确。 每当商品被拣选并确认后，系统会更新库存信息，确保库存数据的准确性。 拣选完成： 当操作员完成订单中所有商品的拣选后，他们会把拣选的商品放入指定的容器中或送往包装区。 系统会记录拣选的完成情况，并通知下一个工作环节准备进行打包和发货。 货架到人在线拣选的优点： 高效性： 操作员根据系统提供的实时指引进行拣选，减少了人工判断的时间和误差。 系统优化了拣选路径，减少了操作员在仓库中走动的时间，从而提高了拣选效率。 准确性： 系统通过实时确认和监控拣选过程，确保商品的准确性。每当商品被拣选时，都会通过扫描确认，避免了拣错商品的情况。 实时更新库存： 系统实时跟踪每个商品的拣选状态，并且及时更新库存数据，保证库存信息始终准确。 减少人工干预： 货架到人在线拣选通过自动化和系统化的方式降低了人工操作错误，减少了人工干预的需求，提升了工作效率。 灵活应对多种订单类型： 无论是小订单还是大订单，货架到人在线拣选都能高效完成，适用于多种类型的订单处理需求。 提高库存管理水平： 由于系统实时反馈，仓库能够更好地管理库存，减少库存差异，保证库存精确性。 适用场景： 电商仓库： 电商仓库通常需要处理大量的小批量订单，货架到人在线拣选能够快速、准确地完成商品拣选，提高订单处理效率。 高频次商品的仓库： 对于那些订单频繁、商品种类繁多的仓库，货架到人在线拣选能够有效提高仓库的作业效率，并确保商品拣选的准确性。 需要高准确性的仓库： 该模式适用于需要高准确性和精确库存管理的仓库，如食品、医药等行业，能够减少错误并提高订单配送的准确率。 多品类仓库： 当仓库中的商品种类多，且每个商品的存放位置都不同，货架到人在线拣选能够通过系统引导操作员，确保每个商品的准确拣选。 总结： 货架到人在线拣选 是通过仓库管理系统（WMS）结合自动化技术，实时指导操作员从货架上准确拣选商品的一种方式。它通过在线指引和实时监控，提高了拣选效率和准确性，并减少了人工错误，特别适用于电商仓库、分拣中心以及高频次订单的仓库环境。 ","link":"https://panson.top/post/037_-shi-me-shi-huo-jia-dao-ren-zai-xian-jian-xuan/"},{"title":"038.什么是料箱到人空箱出库","content":"料箱到人空箱出库（Tote-to-Person Empty Tote Outbound） 是一种在仓库管理和物流流程中使用的作业模式，特别适用于从仓库中出库空料箱的情况。该模式通常结合自动化设备和仓库管理系统（WMS）来实现物料的高效出库操作，确保操作员能够快速准确地处理空箱的出库任务。 料箱到人空箱出库的工作原理： 接收空料箱出库任务： 系统（通常是仓库管理系统WMS）会根据出库需求生成空料箱的出库任务。 该任务会指定需要出库的空料箱类型、数量以及相关的出库目标位置。 自动化设备调度空料箱： 自动化设备（如自动搬运车、机器人、输送带等）将空的料箱从仓库的储存区域或货架区域送到操作员所在的工作区。 操作员根据系统的指导，准备好处理这些空料箱，通常在搬运过程中，系统会实时更新空料箱的状态和位置。 在线指导操作员进行空箱出库： 在空箱到达操作员所在的工作区域后，系统通过手持终端、扫描枪、语音指引等方式实时指导操作员完成出库任务。 操作员根据系统的指示，取出空料箱并按要求进行相关的出库操作。 确认空箱出库： 操作员会扫描空料箱的条形码或RFID标签，系统会实时验证空箱是否正确，并确认出库信息。 一旦确认无误，系统会标记该空料箱为已出库，自动更新库存数据。 空料箱运送到指定位置： 确认出库后，空料箱将被送往目的地，如再利用区域、运输区等，或者准备重新利用。 库存更新： 系统会及时更新空料箱的库存状态，确保仓库的库存信息始终准确。 料箱到人空箱出库的优点： 高效性： 自动化设备能够将空料箱快速送到操作员所在的位置，减少了操作员的步行时间，提升了操作效率。 系统的在线指导能够提高空箱出库的准确性和速度，减少了人工操作的错误和延误。 减少人工干预： 通过自动化设备和系统的结合，减少了人工干预和人工失误，提高了出库操作的自动化水平。 准确性： 系统实时监控和确认空料箱出库，确保每个出库任务的执行准确无误，减少了空箱丢失或错放的风险。 灵活性： 适用于需要管理和运输空料箱的仓库，尤其是在处理大批量货物时，空料箱的管理和出库同样重要，能够灵活应对不同的任务需求。 节省空间： 通过空料箱的出库和管理，可以腾出更多仓库空间用于存储其他物品或货物，从而优化仓库的空间使用。 库存更新及时： 出库操作一旦完成，系统会即时更新库存数据，确保仓库中的空料箱数量和状态准确无误，避免库存失误。 适用场景： 物流仓库： 适用于需要管理大量空料箱的物流仓库，特别是当空料箱需要频繁进行出库和再利用时。 配送中心： 在需要频繁出库空料箱来准备再利用的配送中心，能够通过这种模式高效管理空料箱，提升整体运营效率。 制造业仓库： 在制造业中，空料箱可能需要从仓库中取出并重新分配给其他生产线或存储区域，料箱到人空箱出库模式能够有效处理这些需求。 电商仓库： 在电商仓库中，尤其是在订单量大的情况下，空料箱的处理也是仓库管理的一部分，空箱出库能够更高效地进行空间管理和物料周转。 总结： 料箱到人空箱出库 是一种基于自动化设备和系统指导的仓库出库操作模式，适用于仓库中需要管理空料箱并进行出库处理的场景。通过这种模式，仓库能够更高效地处理空料箱的出库，提升操作效率，减少人工干预，确保库存准确性，并且优化仓库空间利用率。 ","link":"https://panson.top/post/038_-shi-me-shi-liao-xiang-dao-ren-kong-xiang-chu-ku/"},{"title":"039.什么是料箱到人在线盘点","content":"料箱到人在线盘点（Tote-to-Person Online Inventory Counting） 是一种结合自动化设备和仓库管理系统（WMS）进行仓库库存盘点的作业模式。此模式通常应用于物品和库存管理，目的是提高盘点效率和准确性，减少人工操作失误，并能够实时更新仓库的库存状态。 料箱到人在线盘点的工作原理： 生成盘点任务： 仓库管理系统（WMS）根据库存管理需求，生成盘点任务，可能是某一类商品或某一批次的物品。系统会根据盘点任务要求，自动指派和调度需要盘点的区域或者货架。 调度料箱： 系统根据盘点任务要求，自动调度料箱并通过自动化设备（如AGV、小车、输送带等）将料箱送到盘点操作员所在的工作区。 在线指导操作员盘点： 料箱到达操作员工作区域后，操作员通过手持设备（如PDA、扫描枪等）或视觉显示设备，系统会通过屏幕或语音等方式给出盘点指导。操作员根据系统的提示，扫描料箱中的物品，进行数量核对。 扫描核对： 操作员扫描料箱中的每一件商品或物品，通过系统对比实时库存数据和实际盘点数据。如果发现差异，系统会自动提示并进行记录，帮助操作员调整并纠正错误。 实时更新库存： 在盘点过程中，系统会实时更新库存信息，确保每次扫描、每次盘点的结果都会立刻反映到仓库管理系统中。 完成盘点： 操作员完成盘点任务后，系统会自动统计盘点结果，生成盘点报告，并且更新仓库库存数据。这样，仓库的库存信息始终是最新的。 料箱到人在线盘点的优势： 提高盘点效率： 料箱到人在线盘点结合自动化设备，可以减少人工走动和繁琐的操作过程，极大提高盘点的速度。自动化设备将盘点任务中的料箱快速送到操作员处，节省了时间和劳动力。 减少人工错误： 系统提供实时指导并且操作员只能按照系统指引进行盘点，减少了因人工疏忽或者操作错误造成的盘点失误。 实时库存更新： 盘点结果能够实时更新，仓库管理系统（WMS）会立刻反映盘点数据，避免了传统人工盘点后再更新库存的延迟，确保库存数据的准确性和及时性。 自动化和精准性： 通过扫描和自动记录，系统能够精确地核对库存，自动记录盘点数据，避免了手动输入带来的错误，确保数据的一致性和准确性。 减少人工干预： 操作员只需扫描和确认信息，系统自动化程度高，减少了人工干预，提高了盘点的自动化和智能化水平。 灵活的盘点模式： 这种模式可以根据实际需要，灵活选择不同的盘点区域或货架，进行定期盘点、循环盘点等多种盘点方式，灵活应对不同的库存需求。 适用场景： 高频次库存盘点的仓库： 适用于需要频繁进行库存盘点的仓库，例如电商仓库、物流中心等，这些仓库的商品量大且种类繁多，定期盘点对确保库存准确性非常重要。 自动化仓库： 适用于自动化程度较高的仓库，尤其是在高度依赖自动化设备（如AGV、自动搬运车等）的环境中，料箱到人在线盘点可以高效完成库存核对。 大型分拣中心或配送中心： 在这些中心，货物品种繁多且动态变化，料箱到人在线盘点能够帮助仓库及时校准库存数据，确保各类商品的库存信息准确无误。 制造业仓库： 对于制造业来说，料箱到人在线盘点能够有效管理和核对生产物料库存，确保生产线所需物料的数量与仓库库存保持一致。 总结： 料箱到人在线盘点 是一种结合自动化设备和仓库管理系统的库存盘点模式，具有提高盘点效率、减少人工错误、实时更新库存等优点。通过料箱自动调度到操作员的工作区，操作员按系统指引扫描盘点，实现了高效、精准的库存核对。这种模式非常适合高频次盘点的仓库、自动化程度较高的仓库及其他需要精确库存管理的场景。 ","link":"https://panson.top/post/039_-shi-me-shi-liao-xiang-dao-ren-zai-xian-pan-dian/"},{"title":"040.什么是货架到人在线盘点","content":"货架到人在线盘点（Shelf-to-Person Online Inventory Counting） 是一种结合自动化设备和仓库管理系统（WMS）进行仓库库存盘点的作业模式。在这种模式下，盘点任务不再由操作员主动走到货架去进行盘点，而是由自动化设备（如AGV、自动搬运车、输送带等）将货架上的物品或货架本身送到操作员所在的位置，操作员只需进行扫描、核对，并实时更新库存信息。 货架到人在线盘点的工作原理： 生成盘点任务： 仓库管理系统（WMS）根据库存管理需求，生成盘点任务，通常包括对某一类商品或某一批次的物品进行盘点。系统会指定需要盘点的区域、货架或物品。 自动化设备调度货架： 系统调度自动化设备（如AGV或自动搬运车），将需要盘点的货架从仓库的存储区域或货架区运送到操作员工作区。这样，操作员无需步行到货架去取货或盘点。 在线指导操作员盘点： 当货架到达操作员工作区域后，系统通过手持设备（如PDA、扫描枪等）或屏幕显示，实时提供盘点指导。操作员根据系统的提示，扫描货架上的物品进行核对。 扫描核对： 操作员扫描货架上的每个物品的条形码或RFID标签，系统会自动与库存数据进行对比。操作员需要确认物品数量是否匹配，如果出现差异，系统会自动记录并标记为异常，提醒操作员处理问题。 实时更新库存： 盘点过程中，系统会实时更新库存数据。当操作员确认某项物品的盘点数量时，库存数据会立刻在系统中更新，保证库存信息的准确性。 完成盘点： 当所有物品的盘点完成后，系统生成盘点报告，并完成库存更新。盘点任务结束后，操作员可以将货架返回到原存储区域。 货架到人在线盘点的优势： 提高盘点效率： 自动化设备将货架送到操作员工作区，减少了操作员走动的时间，操作员仅需扫描和确认数据。整个盘点过程大大提高了效率。 减少人工错误： 系统提供实时指导，减少了因操作员手动记录、疏忽或误操作而导致的错误，从而提高了盘点的准确性。 实时库存更新： 盘点结果会实时反馈到仓库管理系统中，库存数据得到实时更新，避免了传统盘点方式中手动更新库存数据带来的延迟问题。 自动化与精准性： 自动化设备的使用减少了人工干预，操作员的盘点工作变得更加精准、快速。通过扫描和自动记录，系统能够确保每个物品盘点无误。 节省空间和时间： 操作员不需要走动到货架进行盘点，减少了空间的浪费和时间的消耗。盘点任务变得更加集约化和高效化。 灵活的盘点方式： 该模式可以进行定期盘点、周期性盘点或循环盘点，适应不同仓库的盘点需求。仓库可以在不干扰日常操作的情况下进行盘点，确保库存信息的实时准确性。 适用场景： 高频次库存盘点的仓库： 适用于需要频繁盘点的仓库，特别是物品种类繁多，库存波动较大的电商仓库、物流仓库等。 自动化仓库： 在自动化程度较高的仓库中，自动化设备已经广泛应用于物料搬运和货物存取，货架到人在线盘点模式能够进一步提升盘点效率。 大型分拣中心或配送中心： 在这些中心中，盘点的任务通常量大且时间紧迫，采用货架到人在线盘点能够减少人工劳动，提高盘点的速度和准确性。 制造业仓库： 制造业中的仓库通常有大量物料需要管理，货架到人在线盘点帮助确保物料库存准确，确保生产线的顺畅运行。 总结： 货架到人在线盘点 是一种结合自动化设备和仓库管理系统的库存盘点模式，操作员不再需要走动到货架进行盘点，而是通过自动化设备将货架送到操作员面前，操作员进行扫描和核对。通过这种模式，仓库能够提高盘点效率，减少人工干预，确保库存数据实时、准确，尤其适用于高频次盘点和自动化仓库等场景。 ","link":"https://panson.top/post/040_-shi-me-shi-huo-jia-dao-ren-zai-xian-pan-dian/"},{"title":"041.什么是复盘单","content":"在 WES（仓库执行系统） 或 WMS（仓库管理系统） 中，复盘单 是一种用来处理库存差异并决定是否需要进行二次盘点的单据。当系统在库存管理过程中发现实际库存与理论库存之间存在差异时，可能会触发复盘单的生成。复盘单的主要作用是进行库存差异的确认、分析，并决定是否需要再次盘点以校准库存数据。 复盘单的工作流程： 触发库存差异： 在正常的库存管理过程中，系统会定期或者在操作过程中对库存进行盘点。若在盘点过程中发现某一商品的实际库存与系统中的理论库存不一致，就会产生库存差异。 生成复盘单： 系统自动根据库存差异生成复盘单，并将其提交给相关人员进行处理。复盘单通常会记录差异商品的信息、差异的数量以及差异的可能原因。 决定是否进行二次盘点： 复盘单中可能会根据差异的情况建议进行二次盘点。二次盘点是为了进一步确认库存差异是否属实，以及找到造成差异的根本原因。 如果差异较大，或者经过初步调查无法解释差异原因，复盘单可能会触发二次盘点任务。 二次盘点： 复盘单生成后，仓库管理人员或操作员会根据复盘单指示的商品和数量进行二次盘点。二次盘点的目的是确认库存的准确性，确保库存数据的正确性。 二次盘点完成后，系统会更新库存数据，确保仓库中的库存信息与实际情况一致。 处理盘点差异： 如果二次盘点后发现库存差异仍然存在，可能需要进一步调查，了解是系统故障、操作错误，还是其他原因导致的差异。复盘单的结果可以用来指导后续的库存调整、报废处理等。 复盘单的作用与意义： 确保库存准确性： 复盘单帮助仓库管理人员发现并处理库存差异，确保库存数据的准确性。库存差异可能会影响后续的订单处理、出库作业和库存管理，因此及时发现和解决库存差异至关重要。 提供差异分析和整改依据： 复盘单不仅记录差异，还可以帮助分析差异的原因（如操作错误、系统故障、搬运过程中的问题等），为整改和优化提供依据。 规范库存管理： 通过复盘单和二次盘点，仓库能够规范库存管理流程，减少库存管理中的失误和漏洞。 减少库存损失： 通过复盘单及时纠正库存差异，可以减少库存损失，确保库存信息的真实、可靠，为后续的库存调整、补货等操作提供准确数据。 复盘单的常见信息： 差异商品信息： 包括商品的名称、编码、数量、规格等信息。 库存差异： 理论库存与实际库存之间的差异。 原因分析： 系统可能会记录初步的差异原因，例如系统错误、操作错误、拣选错误等。 盘点时间： 系统盘点时间，以及差异发现的具体时间。 操作员信息： 处理复盘单的人员或操作员的信息。 处理意见： 是否需要进行二次盘点、库存调整，或其他操作。 总结： 复盘单 在 WMS 或 WES 系统中是一个非常重要的工具，用于处理库存差异问题。它帮助仓库管理人员发现和确认库存差异，决定是否进行二次盘点，并确保库存数据的准确性。通过复盘单，仓库能够规范库存管理流程、减少差异，提高库存管理效率和准确性。 ","link":"https://panson.top/post/041_-shi-me-shi-fu-pan-dan/"},{"title":"043.什么是货架到人在线理货","content":"货架到人在线理货 是一种仓库管理方式，主要应用于 WMS（仓库管理系统） 或 WES（仓库执行系统） 中，它将商品从货架直接送到操作员进行理货（整理、挑选、分类等）操作，而不是将操作员带到货架位置。这种方式提高了仓库操作的效率，减少了不必要的移动，并且能够实时获取数据反馈。 货架到人在线理货的工作流程： 商品从货架移动到作业区： 在货架到人模式下，商品并不是由操作员到货架上进行寻找和挑选，而是系统将商品从货架上自动或通过AGV（自动引导车）等设备运输到指定位置，或者通过其他搬运工具送到操作员的工作区域。 系统分配任务： WMS/WES系统会根据订单需求、商品种类、存放位置等因素，自动生成理货任务，并实时将任务分配给工作人员。系统会指导操作员进行商品的整理、挑选和分类。 在线理货支持： 在线理货意味着操作员在理货过程中始终与系统进行交互，系统会实时提供任务指令、商品信息、实时进度等。操作员通过手持设备（如PDA或RF设备）扫描商品条码，系统实时更新商品的理货状态。 如果商品不符合订单要求（例如商品种类、数量不对），系统会及时反馈并给出调整建议。 商品理货： 操作员根据系统提供的信息，对从货架上送来的商品进行整理、挑选和分类，确保每个订单的商品符合要求。这个过程通常是精细化的，可能包括挑选正确的数量、规格等。 确认并更新库存： 理货完成后，操作员通过设备确认任务完成，并将理货结果反馈到系统中。系统会根据确认的数据更新库存信息、订单状态等。 如果理货任务涉及到错误商品、缺货等问题，系统会发出警告或提示，操作员可以根据系统提示进行调整。 继续下一步流程： 完成理货后，商品进入仓库的下一环节，可能是分拣、打包或出库等操作。 货架到人在线理货的优点： 提高作业效率： 通过减少操作员到货架位置的移动，节省了时间和精力，操作员只需专注于理货任务，能够更快地完成工作，提高仓库作业效率。 减少错误率： 系统会实时监控理货过程，如果操作员的操作与任务不符，系统会提供反馈，从而减少商品挑选错误的几率。通过实时在线操作，能够有效避免手工错误、遗漏或重复作业。 实时数据更新： 在线理货能够实时更新库存、任务进度等信息，仓库管理人员可以随时掌握理货过程中的实时数据，并根据情况及时调整作业计划。 作业路径优化： 货架到人模式能够避免不必要的步行或寻找，仓库内部的作业路径得到优化，使得工作流程更加顺畅。 提高灵活性和可扩展性： 随着订单需求的变化，系统能够灵活地调整理货任务，提高仓库运营的适应性。尤其是在订单量大的情况下，能够保持高效的操作。 减少人员劳动强度： 操作员不需要频繁地走动、寻找商品，从而减少了身体上的疲劳，提高了工作效率和舒适度。 适用场景： 电商仓库： 在电商行业，订单数量大且变化快，货架到人在线理货能够提高订单处理效率，确保快速准确地完成分拣和挑选任务。 零售仓库： 零售仓库中商品种类多样且存放在不同的货架上，货架到人理货能够简化操作流程，减少人力成本，提高处理速度。 大型仓储中心： 在大型仓库中，货架到人模式特别适用，能够帮助操作员提高工作效率，快速完成理货任务。 总结： 货架到人在线理货 是一种基于 WMS 或 WES 系统的高效仓储管理方式。它通过将商品从货架上自动或通过设备运输到操作员工作区域，同时利用在线系统指导操作员进行实时的商品整理、挑选和分类。通过这种方式，仓库可以显著提高作业效率，减少操作错误，确保库存和订单数据的准确性。这种方式适用于各种需要高效作业的仓库环境，特别是电商、零售等领域。 ","link":"https://panson.top/post/043_-shi-me-shi-huo-jia-dao-ren-zai-xian-li-huo/"},{"title":"044.什么是库区","content":"库区（Storage Area）是什么？ 库区 是指 仓库内部按照特定规则划分的存储区域，用于管理不同类型的商品、货物或作业流程。库区的划分可以基于 商品特性、存储需求、作业流程、货位管理 等因素，以提高仓库管理的 效率、准确性和灵活性。 库区的作用 优化仓库管理：通过库区划分，可以更好地规划存储空间，减少混乱，提高拣选和存储的效率。 提高拣选效率：根据商品特性将其存放在特定库区，可以减少拣选时间，提高作业效率。 降低货损风险：易碎品、危险品等特殊商品可以单独存放，避免损坏或安全事故。 支持不同作业模式：不同作业流程（如收货、拣货、补货、盘点）可以在不同库区进行，提升整体运营效率。 精准库存管理：库区划分使得库存管理更加精细化，便于追踪商品的存放位置和状态。 常见库区类型 1. 存储类库区 常温库区：用于存放对温湿度要求不高的商品，如普通日用品、服装等。 冷藏/冷冻库区：存放对温度有严格要求的商品，如食品、药品等。 保税库区：用于存放需要关税监管的进出口商品。 超大件库区：专门存放大型商品，如家具、电器等。 2. 作业类库区 收货库区：用于仓库接收新到货物的临时存放区域，通常靠近入库口。 退货库区：专门用于存放退回商品，便于后续检验和处理。 质检库区：用于存放需要进行质量检验的货物，合格后才能正式入库。 盘点库区：用于存放需要进行盘点的商品，确保账物相符。 3. 特殊功能库区 贵重品库区：存放高价值商品，如珠宝、奢侈品、电子产品等，需要额外的安全措施。 危险品库区：存放化学品、易燃品等危险物品，需符合安全管理标准。 异常品库区：存放有问题的商品，如包装破损、标签错误的货物，以便后续处理。 库区与库位的关系 库区（Storage Area）：仓库内的大区域划分，是管理库存的基础单位，如冷藏区、存储区等。 库位（Storage Location）：库区下的具体存放位置，通常指货架上的某个格子、货位编号等。 示例： 库区：A区（存储库区） 库位：A01-01（第一排第一列的存放点） 库区管理在 WMS/WES 系统中的应用 在 WMS（仓库管理系统） 或 WES（仓库执行系统） 中，库区管理主要涉及： 库区划分与规则设定：系统内设定不同库区的属性，如温控、作业模式等。 入库分配：根据商品属性自动分配合适的库区存放。 库存管理：实时跟踪不同库区的库存状态。 出库优化：系统根据库区信息优化拣选路径，提高出库效率。 总结 库区是仓库管理中的核心概念，它通过合理划分存储区域，提升仓库的存储效率、作业效率和库存管理精度。不同的库区类型适用于不同商品特性和业务需求，在 WMS/WES 系统 中，库区管理能极大提高仓库运营效率，是现代仓储物流不可或缺的一部分。 ","link":"https://panson.top/post/044shi-me-shi-ku-qu/"},{"title":"045.什么是货架与库位","content":"货架（Shelf）和库位（Storage Location）是什么？ 在 WMS（仓库管理系统） 或 WES（仓库执行系统） 中，货架 和 库位 是仓库管理的基本单元，负责存储和定位商品，提高仓库运营效率。 1. 什么是货架（Shelf）？ 货架 指的是 仓库中用于存放商品的架子或存储设备，通常由多个层级（货架层）组成，以便分类存放不同的货物。 货架的作用 最大化利用仓库空间，提高存储密度。 提高拣选效率，减少人工找货时间。 确保货物安全，避免堆放导致损坏。 支持自动化作业，如 AGV（自动搬运车）、机械臂等设备取货。 常见货架类型 横梁式货架：常见的标准货架，适用于托盘存储。 贯通式货架：适用于存储大量同类型商品（如冷库）。 重力式货架：利用重力滑动货物，提高拣选效率。 自动化立体库货架：与自动存取设备结合，实现智能化仓储。 悬臂式货架：适用于存放长条状物品，如管材、木材等。 流利式货架：利用滚筒式设计，方便先进先出的存储模式。 2. 什么是库位（Storage Location）？ 库位 指的是 货物在仓库中的具体存放位置，它是仓库管理中的最小存储单元。 库位的作用 精确定位商品，减少查找时间。 提高库存管理的精确度，避免错放或丢失。 优化仓库空间利用，合理规划存储区域。 支持智能化仓储，结合 WMS/WES 系统进行智能调度。 库位的编号规则 通常，库位的编号采用 “库区-货架-层-列” 的方式，例如： A01-03-02 A01：库区编号 03：货架编号 02：货架的第 2 层 这个库位对应某个具体的存储空间 3. 货架与库位的关系 货架 是存储货物的整体结构，一个货架上可以有多个 库位。 库位 是具体存放商品的物理位置，每个库位通常对应一个 SKU（商品最小管理单元）。 示例 货架编号：A01 库位 1：A01-01-01（第 1 层） 库位 2：A01-01-02（第 2 层） 库位 3：A01-01-03（第 3 层） 在 WMS 系统中，库存管理时会精确到库位级别，确保商品存放、移动、拣选都能准确无误。 4. 货架与库位在 WMS/WES 系统中的应用 入库管理：系统根据商品属性分配合适的库位存放。 库存管理：实时更新每个库位的库存信息，避免库存错乱。 拣选作业：系统提供拣选路径，优化取货效率。 智能仓储：与自动化设备结合（如自动立库、AGV），提高作业效率。 总结 货架 是存储货物的架子，可以有多个层级。 库位 是具体的存储位置，每个库位唯一标识一个存放点。 WMS/WES 系统 通过管理货架和库位，实现精准的库存管理，提高仓库运作效率。 这样一来，仓库中的货物存放和流转都能有条不紊地进行，提高作业效率并减少错误率。 ","link":"https://panson.top/post/045shi-me-shi-huo-jia-yu-ku-wei/"},{"title":"046.什么是 AGV","content":"AGV（Automated Guided Vehicle）是什么？ AGV（自动导引运输车），即自动搬运机器人，是一种能够沿预设路径或自主导航完成货物运输的无人驾驶设备。AGV 主要用于仓储、物流、制造、医疗等行业，用于提升运输效率和降低人工成本。 1. AGV 的核心特点 无人驾驶：不需要人工操作，可自动完成搬运任务。 路径导航：通过磁条、激光、视觉、惯性导航等方式自主行驶。 智能调度：可接入 WMS（仓库管理系统）/WCS（仓库控制系统），进行任务分配和路径优化。 安全性高：配备避障传感器，可自动检测并规避障碍物，确保运行安全。 充电自主化：可在电量低时自动返回充电站补充电量。 2. AGV 的工作原理 AGV 依赖多种导航和控制技术，实现自动搬运： 导航方式 磁条导航（Magnetic Tape）：AGV 沿地面磁条行驶，简单稳定，适用于固定路线搬运。 激光导航（Laser）：利用激光反射标识定位，路径灵活，可动态调整路线。 惯性导航（Inertial）：利用陀螺仪与加速度计进行定位，适用于复杂环境。 视觉导航（Vision）：使用摄像头识别环境特征点，自主调整路线，适合动态仓库环境。 SLAM（同步定位与建图）：结合激光、视觉等技术，实现自主导航，无需预设路径。 3. AGV 在仓储和物流中的应用 （1）仓库物流 料箱搬运：将料箱从存储区运输到拣选站，适用于“料箱到人”系统。 托盘搬运：将整托货物从存储区运送到生产线或发货区。 自动补货：AGV 在库存低时自动将货物补充到相应区域。 （2）制造工厂 生产线物料配送：AGV 负责将原材料从仓库运送到生产线，提高生产效率。 成品运输：将生产完成的产品运送到质检区或仓库。 （3）电商 &amp; 物流中心 拣选与打包：AGV 在大规模电商仓库中用于拣选订单，提高订单处理速度。 快递分拣：AGV 搬运包裹至不同分拣站点，提高快递分拣效率。 4. AGV 与 AMR（自主移动机器人）的区别 对比项 AGV（Automated Guided Vehicle） AMR（Autonomous Mobile Robot） 导航方式 依赖磁条、激光等固定路径 具备自主路径规划能力 灵活性 受限于预设路径，调整较困难 可根据环境动态调整路线 应用场景 适用于规则化仓储 适用于复杂动态环境 避障能力 主要依赖传感器，避障能力有限 具备更高级的环境感知和避障能力 5. AGV 的优缺点 ✅ 优势 减少人工成本，减少人工作业，提高自动化水平。 提高运输效率，减少人工搬运时间。 提升安全性，减少人工搬运中的事故风险。 可 24/7 运行，不断优化仓储和生产效率。 ❌ 劣势 初期投资较高，包括设备、软件及基础设施建设。 灵活性有限，传统 AGV 需要固定路径导航，不易变更路线。 维护成本，AGV 需要定期维护传感器、电池、轮子等部件。 6. AGV 在智能仓储中的发展趋势 向 AMR（自主移动机器人）发展，具备更强的自主导航能力。 结合 AI 和大数据，优化任务调度，提高仓库运营效率。 多机器人协同作业，提升仓库吞吐量，满足大规模订单需求。 无缝对接 WMS/WCS 系统，智能调度 AGV 任务，实现自动化仓储管理。 7. 结论 AGV 在现代智能仓储和物流体系中扮演着关键角色，能够替代人工搬运，提高仓库自动化程度。随着AI、5G、视觉导航等技术的发展，AGV 逐步向更智能的 AMR 方向演进，为未来智慧物流和智能制造提供更高效的解决方案。 ","link":"https://panson.top/post/046shi-me-shi-agv/"},{"title":"047.什么是作业地图","content":"作业地图是什么？ 作业地图是WMS（仓库管理系统）或 WES（仓库执行系统）中用于可视化管理仓库作业流程和资源分布的工具。它提供了仓库布局、库存位置、任务执行状态、设备（如 AGV、机器人）实时位置等信息，帮助仓库运营人员优化作业路径，提高效率。 1. 作业地图的核心功能 作业地图的主要作用是直观呈现仓库作业情况，优化仓库资源调度，常见功能包括： 仓库布局可视化 展示仓库的区域划分，如库区、货架、库位、输送线等。 实时显示库存的存放位置，辅助拣选、补货作业。 任务执行跟踪 显示订单拣选、补货、上架、盘点等任务的执行状态。 监控任务进度，发现异常任务（如任务滞留、库存差异等）。 设备与人员管理 追踪 AGV（自动导引运输车）、机械臂、叉车等设备的位置及运行状态。 监控操作人员的作业区域，优化作业路径，减少重复行走。 路径规划 计算并推荐最优拣选、补货、盘点路径，提高作业效率。 支持动态调整路径，避开拥堵区域。 数据统计与分析 记录作业效率数据（如拣选时间、设备利用率等）。 结合 AI 预测瓶颈区域，优化仓库布局。 2. 作业地图的应用场景 “货到人”系统 监控料箱、货架的移动情况，优化机器人调度。 智能拣选 结合电子标签、PDA 设备，实现可视化拣选作业。 盘点作业 显示库存盘点任务的分布，辅助操作员快速盘点。 AGV 调度 实时调整 AGV 路线，避免交通堵塞，提高搬运效率。 3. 作业地图的优势 ✅ 提高作业效率：直观展示任务分布，优化作业路径。 ✅ 降低错误率：减少人工查找货位、拣选错误。 ✅ 优化资源利用：合理调度人力、设备，减少空跑和重复作业。 ✅ 提升仓库可视化管理能力：实时掌握库存动态，提高响应速度。 总结 作业地图是现代智能仓储系统的重要组成部分，结合WMS/WES、AI 计算、实时定位技术，可以优化仓库作业流程，提高运营效率，减少人工成本。 ","link":"https://panson.top/post/047shi-me-shi-zuo-ye-di-tu/"},{"title":"048.什么是商品热度","content":"商品热度是什么？ 商品热度通常指某个商品在一定时间内的销售、浏览、查询、拣选等行为的综合活跃度。在 WMS（仓库管理系统） 和 WES（仓库执行系统） 中，商品热度主要用于优化库存布局、拣选路径、补货策略，以提升仓库运营效率。 1. 商品热度的衡量指标 商品热度通常由以下几个核心指标决定： 销量 📈 一段时间内的销售数量（如日、周、月销量）。 高销量商品一般具有较高热度。 订单频次 🛒 该商品在订单中出现的次数。 订单量越多，说明该商品需求量大。 拣选次数 🚀 该商品在仓库内被拣选的频率。 拣选频次高的商品需要放在易于取用的位置。 补货频率 🔄 该商品因库存不足被补货的次数。 频繁补货的商品通常为热销品。 库存周转率 🔄 商品库存的更替速度，计算方式： 库存周转率 = 一段时间内的销售数量 / 平均库存量 周转率高的商品通常热度较高，需要更快补货。 浏览/查询次数 👀（适用于电商和前端系统） 该商品在系统中被用户查询、浏览的次数。 2. 商品热度的应用场景 在 WMS 和 WES 系统中，商品热度可用于以下场景： (1) 库存优化 高热度商品放在拣选路径最近、最易拿取的库位，减少拣选时间，提高效率。 低热度商品放在库位较远或高处，以优化仓库空间利用率。 (2) 订单拣选优化 波次拣选（Batch Picking）： 根据商品热度，把常见组合的商品分配到同一波次，提高拣选效率。 智能路径规划： 拣选系统可优先安排高热度商品，减少拣选员的移动距离。 (3) 补货策略 高热度商品设置较高的安全库存，避免缺货。 提前预警补货，防止因销量激增导致库存不足。 (4) 促销与策略调整 结合商品热度数据，电商或仓库管理可： 制定促销策略，推动低热度商品销售。 调整采购计划，确保热销商品有充足供应。 3. 商品热度的计算方式 不同系统可以有不同的计算方法，常见公式： 热度评分 = (销量 × 权重1) + (拣选次数 × 权重2) + (补货频率 × 权重3) + ... 例如： 最近 7 天销量占比 50%，拣选次数占比 30%，补货次数占比 20%： 热度 = (销量 × 0.5) + (拣选次数 × 0.3) + (补货次数 × 0.2) 4. 总结 ✅ 商品热度衡量商品的销售和拣选活跃度，帮助优化仓库管理。 ✅ 高热度商品应放在拣选路径最优的位置，减少人工移动，提高拣选效率。 ✅ 结合补货频率、库存周转率，制定智能库存管理策略，避免缺货或积压。 ✅ 适用于 WMS/WES、仓储优化、电商平台等场景，提高仓库运作效率与服务质量。 ","link":"https://panson.top/post/048shi-me-shi-shang-pin-re-du/"},{"title":"049.什么是热度移位","content":"热度移位是什么？ 热度移位是指根据商品的热度变化（如销量、拣选次数、订单频次等）动态调整商品的存储位置，以优化仓库管理，提高拣选和补货效率。 在 WMS（仓库管理系统） 和 WES（仓库执行系统） 中，热度移位主要用于减少拣选人员或机器人移动距离，提高仓库运作效率。 1. 热度移位的核心逻辑 当商品热度发生变化时，系统自动或手动调整其库位： 高热度商品 → 移动到前排/黄金拣选区 例如，销量上升的商品从远端库位调整到拣选路径更优的位置。 方便拣选员/机器人快速获取，减少拣选时间。 低热度商品 → 移动到后排/远端库位 例如，销量下降的商品可移至较远或高层库位，以优化仓库空间。 季节性商品 → 季节变更时移位 例如，冬季商品在秋末前移到前端库位，夏季商品则移到后排。 2. 热度移位的应用场景 (1) 订单拣选优化 减少人工或机器人拣选路径，提升拣选效率。 降低订单处理时间，加快物流周转。 (2) 仓库空间优化 高价值库位分配给热销商品，提高库位利用率。 减少低热度商品占据核心库区，避免资源浪费。 (3) 补货 &amp; 波次拣选 高热度商品靠近出货区，减少补货频率。 结合订单数据，智能调整商品位置。 3. 热度移位的触发机制 (1) 规则驱动（定期分析 &amp; 批量调整） 例如，每周系统自动分析商品热度，并推荐移位操作。 (2) 实时动态调整 结合 AI/大数据分析，实时感知订单趋势，自动调整库位。 (3) 手动触发 仓库管理人员可基于业务需求进行人工调整。 4. 总结 ✅ 热度移位 = 依据商品热度，调整存储位置，提高仓库拣选效率。 ✅ 高热度商品前移，低热度商品后移，优化库位资源。 ✅ 适用于 WMS/WES 系统，适配电商、零售、制造业仓储。 ✅ 结合 AI/大数据，支持自动或手动调整，实现智能仓储管理。 ","link":"https://panson.top/post/049shi-me-shi-re-du-yi-wei/"},{"title":"050.什么是缺拣","content":"缺拣（Short Picking）是什么？ 缺拣是指订单拣选过程中，由于库存不足或操作失误，导致未能按订单要求拣选到足够的商品。 在 WMS（仓库管理系统） 和 WES（仓库执行系统） 中，缺拣通常会触发补货、库存调整或异常处理，以保证订单履约率。 1. 缺拣的常见原因 (1) 实际库存 ≠ 系统库存 库存账实不符（例如：数据错误、漏盘点、盘亏）。 系统显示有库存，但实际无货（如库存损耗、商品丢失）。 (2) 订单需求 &gt; 可用库存 库存不足，无法满足订单全部需求。 部分商品刚被其他订单拣选，导致剩余库存不足。 (3) 货位或库存异常 商品存放位置错误，导致拣选员找不到。 库存破损或质量问题，无法拣选。 (4) 拣选员或机器人操作失误 人工拣选错误，未能拿足所需数量。 自动拣选设备故障，未能正确拣货。 2. 缺拣的应对措施 (1) 触发系统补货 系统发现库存不足，自动创建补货任务。 优先从其他库位、其他仓库或供应商调货。 (2) 调整订单履约策略 缺拣商品不足时，拆分订单（部分发货）。 若完全缺货，则通知客户，提供替代商品或退款。 (3) 盘点 &amp; 纠正库存 定期盘点，确保账实库存一致。 使用 RFID、PDA 扫码等方式减少人为失误。 (4) 订单优先级调整 优先满足高优先级订单（如 VIP 客户）。 对于低优先级订单，系统可建议推迟发货或拆单处理。 3. 缺拣的影响 ✅ 影响订单履约率，可能导致客户投诉或取消订单。 ✅ 增加仓库额外工作量，如补货、盘点、异常处理。 ✅ 可能影响供应链管理，如导致后续生产或采购计划调整。 4. 总结 📌 缺拣 = 订单商品未能完全拣选，通常因库存不足、拣选错误或数据不准。 📌 WMS/WES 可通过补货、库存调整、订单优化等方式降低缺拣影响。 📌 优化库存管理、提高拣选准确率，可减少缺拣率，提高订单履约能力。 ","link":"https://panson.top/post/050shi-me-shi-que-jian/"},{"title":"051.什么是绑箱","content":"在 WMS（仓库管理系统）中，“出库绑箱”是指在出库过程中，将拣选好的商品按照一定规则打包进箱（或托盘）并进行绑定操作，以便后续发货、追踪和核对的一种操作流程。 具体来说，“出库绑箱”包含以下几个关键点： ✅ 1. 拣货完成 拣货员将订单需要的商品从仓库中拣出。 ✅ 2. 进行“绑箱”操作 拣完的商品被打包到箱子中，然后通过系统操作，将商品和箱号绑定。 系统中记录：箱号 → 包含哪些商品、哪些订单、数量等信息。 一般会贴上箱码（如二维码或条形码），用于后续扫描识别。 ✅ 3. 后续流程使用 复核发货：发货时通过扫描箱码即可快速核对是否正确。 物流追踪：箱码可作为物流追踪号的一部分。 客户收货对账：箱内物品可通过系统记录追溯。 举个例子： 一个客户下了两个订单，共10件商品。 仓库拣货人员将这10件商品拣出。 系统指示这些商品要装入两个箱子：箱 A 装 6 件，箱 B 装 4 件。 操作人员将商品装箱，并在系统中进行“出库绑箱”： 将箱 A 绑定为包含商品1×3件，商品2×3件。 将箱 B 绑定为商品3×4件。 每个箱子贴上一个箱码，后续发货扫描即可。 ","link":"https://panson.top/post/051shi-me-shi-bang-xiang/"},{"title":"022.什么是货架到人离线直接上架","content":"货架到人离线直接上架（Shelf-to-Person Offline Direct Shelving） 货架到人离线直接上架 是一种仓库作业方式，通常用于 WMS（仓库管理系统） 中，结合 货架管理 和 上架作业，旨在 提高商品入库的效率 和 减少人为错误。具体来说，这个过程是指在商品入库时， 商品直接从货架上进行分类、整理，并通过手动或机械化方式直接上架，无需经过中间的存储和排序过程。 核心概念 货架到人：与传统的“人到货架”不同，货架到人意味着 商品已经放置在指定的货架位置，操作员不需要去找货品，而是 直接从货架上选择商品并进行上架。 离线直接上架：指的是上架操作是在没有实时系统支持的情况下完成的，可能使用纸质清单或手持设备进行商品上架，且没有即时与系统交互（离线作业）。 工作流程 1. 商品入库： 商品到达仓库后，先经过检验、验收，确保无误。 将商品直接放置到事先规划好的货架区域。 2. 离线作业： 操作员根据订单、货架规划或手持设备，从货架上直接选择商品。 操作员可以使用手动操作或机械设备（如叉车、AGV等）来处理商品。 3. 直接上架： 商品被整理、打包或分类后，直接放到货架或指定的储物位置，等待后续的订单拣选。 特点与优势 减少人为错误：通过货架直接上架，避免了库存数据不准确的情况，减少了中间环节可能出现的错误。 提高上架效率：避免了传统上架方式中的多次搬运，可以减少商品在仓库内的流动，节省时间。 简化操作流程：通过合理的货架规划，员工只需将商品放到货架上，而不需要多次扫描、移动或处理。 适用于高频商品：这种方式适合一些较为常见且高频入库的商品，能够加速整个上架过程。 离线操作简便：不依赖系统实时操作，能在网络不稳定或临时无法连接时进行操作。 适用场景 传统仓库作业：适用于一些传统仓库，特别是那些不需要频繁在线同步的环境。 入库高频商品：对于一些商品批量入库且不需要精细存放的情形，能够提高仓库的入库速度。 小型仓库或低技术要求的仓库：无需大量依赖高端技术和设备的仓库作业。 总结 货架到人离线直接上架 是一种简单、高效的仓库作业方式，旨在通过直接将商品从货架上整理并上架，减少不必要的存储、移动和误差。 这种方式通常适用于入库高频商品、低技术要求的仓库，并且不依赖系统实时操作，有助于提高入库效率和降低出错率。 ","link":"https://panson.top/post/022_-shi-me-shi-huo-jia-dao-ren-chi-xian-zhi-jie-shang-jia/"},{"title":"023.什么是货架到人离线整托上架","content":"货架到人离线整托上架（Shelf-to-Person Offline Pallet Shelving） 货架到人离线整托上架 是一种仓库操作模式，结合了 货架管理 和 整托商品的上架，主要用于 大宗商品 或 高效仓储管理。其基本思想是将商品按整托形式直接从货架取出并上架，无需进行商品拆分或重新分配。这种方式主要是为了提高上架效率并减少中间环节，特别适用于需要集中管理和快速入库的商品。 核心概念 货架到人：传统仓库作业一般是人到货架取货，而货架到人则是商品已经预先被放置到指定货架，工作人员根据需求直接从货架上取出商品并进行处理。 离线操作：指操作人员在没有实时系统交互的情况下执行任务，可能通过手持设备、纸质清单等进行作业。 整托上架：指整托（整盘）商品直接被搬运并放到指定位置或货架上，不需要拆解或重新包装。与单件商品不同，整托商品作为一个单位进行上架操作。 工作流程 1. 商品入库 商品按照整托的形式送达仓库，并经过入库验收。 商品保持原有包装和托盘形式，准备直接上架。 2. 离线整托上架 操作员根据离线任务单或手持设备的指引，从货架上取下整托商品。 商品无需拆解，整托商品直接放到仓库指定的货架或存储位置。 3. 上架管理 上架完成后，整托商品就位，可以等待拣选、分配或配送。 在没有实时数据反馈的情况下，系统通常会在稍后的时间进行库存更新或批量处理。 特点与优势 高效操作：通过整托上架，避免了逐个商品的拆分和操作，提高了上架效率。 减少操作环节：离线整托上架减少了人工拆分、重新包装的环节，节省了时间和人力成本。 节省空间：整托商品可直接上架并合理利用仓库空间，不需要复杂的货架调整。 适用于大宗商品：尤其适用于商品量大、品种单一且不需要频繁调整的仓库管理，减少了库存管理的复杂度。 简化管理流程：操作员只需根据任务指引直接取出整托商品，减少了误差和人工操作失误。 适用场景 大宗商品仓库：例如，零售仓库、大型制造业的零部件存储中心、批发市场等，适合大量的整托商品管理。 高频商品管理：对于需要高频次补货或大量配送的商品，使用整托上架可以加速上架速度。 低复杂度的仓储系统：对于需要简单和直接管理的大宗商品，适合离线整托上架。 大宗配送：例如，大型零售商的配送中心可以使用该方式进行高效的商品上架和出货。 示例 零售商品仓库：例如，家电、电器类商品，商家在上架时可能直接将整托商品（如多个电视机、冰箱等）按种类放到货架上，避免拆解商品。 批发仓库：例如，一些批发商或制造商接收到的大宗原材料货物，可能直接以整托形式上架。 总结 货架到人离线整托上架 是一种高效的仓库管理方式，适合于大量商品以整托形式入库并直接上架的场景。 通过减少人工拆分和重新包装的环节，可以提高上架效率，简化管理流程，特别适用于大宗商品或高频次入库的仓库。 这种方式尤其适用于大宗商品的管理、低复杂度的仓库环境，并能帮助仓库减少误差、提高效率。 ","link":"https://panson.top/post/023_-shi-me-shi-huo-jia-dao-ren-chi-xian-zheng-tuo-shang-jia/"},{"title":"024.什么是库存调整单","content":"库存调整单（Inventory Adjustment Order） 库存调整单 是一种记录和管理仓库库存变动的单据。在仓储和库存管理中，库存调整单用于记录实际库存与系统库存不符时的调整操作。例如，当库存发生误差时，管理人员可以通过库存调整单来进行修正。这种操作通常发生在 库存盘点 后，或者在发生 库存损耗、破损、丢失 或 其他异常 的情况下。 库存调整单的作用 修正库存差异：当实际库存与系统库存不一致时，库存调整单用于调整系统记录，确保仓库的库存数据准确。 记录库存变动：库存调整单能够清晰记录每次库存变动的原因、数量、日期等关键信息，帮助管理者追踪库存的变化。 防止库存积压或短缺：定期调整库存可以避免因为错误数据导致的积压或短缺，优化库存管理。 确保财务准确：库存调整单帮助保证仓库数据与财务数据一致，尤其是在盘点后确保账目和实际物资数量相符。 库存调整单的主要内容 库存调整单通常包含以下内容： 调整类型：可以是 增加（如系统库存低于实际库存）或 减少（如系统库存高于实际库存）。 商品名称：需要进行库存调整的商品名称或编号。 调整数量：调整的商品数量。 调整原因：为什么需要调整库存（如盘点、损坏、丢失等）。 调整时间：进行调整的时间。 库存位置：商品所在的货架或仓库位置。 调整后库存：调整完成后的新库存数量。 操作人员：进行调整操作的人员信息。 审批流程：在某些系统中，库存调整单需要管理人员或仓库主管的审批。 库存调整单的处理流程 盘点或库存检查：定期进行库存盘点，核对系统记录与实际库存。 发现差异：在盘点或日常检查中，如果发现库存数量与系统记录不符，就需要创建库存调整单。 生成调整单：根据盘点结果或差异原因填写库存调整单，记录需要增加或减少的库存数量及原因。 审批流程：在一些企业中，库存调整单可能需要管理人员或仓库主管审批，以确保调整是合规和合理的。 执行调整：经过审批后，库存管理人员根据调整单进行系统更新，修改库存数量。 记录存档：完成库存调整后，库存调整单会被存档以备后续审核和查询。 适用场景 盘点后的差异调整：例如，在定期库存盘点时，发现实际库存数量与系统记录不符，需要进行库存调整。 库存损耗/损坏：商品在仓储过程中可能会出现损坏或丢失，这时需要通过库存调整单来减少库存数量。 过期商品：对于有有效期的商品，若商品过期无法销售，需要进行库存减少调整。 错误录入：在入库或出库过程中，可能会因人为错误导致库存数量不准确，这时需要通过库存调整单来修正。 退货/调拨：商品从其他仓库调拨过来或因退货从客户处返回时，需要做库存调整以更新数据。 库存调整单的管理与控制 审批权限：对于库存调整单，通常会设定审批权限，确保库存变动合法合规，防止人为的库存调整错误或欺诈行为。 调整限制：部分公司可能设定库存调整的数量和金额上限，以确保不会发生过大的调整。 审计与跟踪：库存调整单会被记录和存档，以便后续审计和分析，确保库存管理的透明性和可追溯性。 总结 库存调整单 是仓库管理中用于修正库存差异的工具。当实际库存和系统记录之间存在差异时，管理人员可以通过库存调整单记录并执行必要的库存调整操作。这不仅有助于确保库存的准确性，还能帮助管理人员追踪库存的变动原因，优化库存管理流程，并确保财务和库存数据一致。 ","link":"https://panson.top/post/024_-shi-me-shi-ku-cun-diao-zheng-dan/"},{"title":"025.什么是批次调整单","content":"批次调整单（Batch Adjustment Order） 批次调整单 是一种记录和管理仓库库存批次变动的单据，用于在库存管理过程中调整某一批次商品的库存数量或状态。通常情况下，批次调整单用于处理和修正某一批次商品的库存差异、损失、报废、过期、库存更新等情况。 批次调整单与普通的库存调整单类似，但其特殊之处在于，它关注的是特定批次的商品，而不仅仅是单件商品。批次调整通常用于大宗商品、具有生产日期或保质期的商品、或是以批次管理的商品，例如药品、食品、化妆品、生产线中的原材料等。 批次调整单的作用 修正库存差异：当商品的实际库存与系统记录存在差异时，可以通过批次调整单来调整某个特定批次商品的库存。 库存状态更新：处理商品损坏、过期、失效等原因，更新特定批次商品的库存状态。 确保库存数据准确性：在进行库存盘点后，若发现某批次商品的库存与记录不符，可以使用批次调整单进行修正，保持库存信息的准确。 提升库存管理的透明度：通过批次调整单的记录，可以清晰地追踪每个批次商品的库存变动和调整原因。 批次调整单的主要内容 批次调整单一般包含以下内容： 批次号：商品的批次编号或批次信息，确保调整操作发生在正确的商品批次上。 调整类型：增加库存或减少库存，通常根据实际情况选择适当的调整类型。 商品名称：需要进行调整的商品名称。 调整数量：需要增加或减少的数量，记录调整后商品的实际库存。 调整原因：说明为何要进行调整（例如：过期、损坏、盘点差异、生产批次错误等）。 调整时间：进行批次调整的日期和时间。 批次状态：调整前后该批次商品的状态，如过期、损坏、待检等。 操作人员：进行批次调整操作的人员信息。 审批流程：一些系统可能要求经过审批才能执行批次调整，审批人和审批时间等信息。 备注：其他补充说明或特殊情况的备注信息。 批次调整单的处理流程 库存盘点或发现差异：在进行盘点、检查时，如果发现某个商品批次存在库存差异或状态不符（如损坏、过期、缺货等），需要进行批次调整。 创建批次调整单：根据实际情况，创建批次调整单，填写相关商品批次的调整信息。 审批流程：若公司内部有审批流程，批次调整单需要经过管理人员的审核和批准。 执行调整：经过审批后，相关仓库人员根据调整单内容执行库存更新，系统中的批次库存数量会被调整。 记录存档：批次调整完成后，批次调整单会被存档并用于后续的查询、审计或分析。 批次调整单的适用场景 过期商品：在食品、药品、化妆品等行业中，商品有生产日期或有效期。如果某个批次商品过期无法使用或出售，就需要进行库存调整。 损坏商品：如果某批次商品由于运输、储存或其他原因受损，必须通过批次调整单调整库存。 库存盘点差异：在库存盘点过程中，发现某批次商品的库存与系统记录不符，需要进行批次调整来修正差异。 批次管理商品：对于需要进行批次管理的商品（如电子产品、药品、化工产品等），批次调整单可以确保库存的精确管理。 库存优化：某些批次商品可能因为销售低迷或生产计划调整，导致需要调整库存，例如将库存调整到不同的仓库或减少某些批次商品的库存量。 批次调整单的管理与控制 审批机制：为防止库存操作不当，批次调整单通常需要经过审批流程，确保调整行为合法且有依据。 限定调整权限：一些系统中会设定权限管理，只有特定角色（如仓库管理员、财务人员）才能创建和审批批次调整单。 审计与跟踪：批次调整单通常会被记录在系统中，确保库存操作可追溯，便于后期审计。 库存报告与分析：批次调整单提供了库存变动的重要数据，有助于仓库管理人员分析库存变化的趋势和原因，进行有效的库存控制。 总结 批次调整单 是用于修正特定批次商品库存差异的单据，主要适用于那些需要进行批次管理的商品。它有助于确保库存数据的准确性，处理库存损坏、过期、丢失或盘点差异等问题。通过批次调整单，仓库可以精确跟踪每个批次的库存变动，保证库存管理的透明性、合规性和效率。 ","link":"https://panson.top/post/025_-shi-me-shi-pi-ci-diao-zheng-dan/"},{"title":"026.什么是货权调整单","content":"货权调整单（Ownership Adjustment Order） 货权调整单 是一种用于调整和记录商品所有权变更的单据。它通常在物流、仓储和供应链管理中使用，当商品的所有权发生变化时，需要通过货权调整单来进行相应的调整和记录。货权调整单通常涉及到商品的所有者、承运人、仓库、客户等多方角色，特别是在商品从一个实体转移到另一个实体时。 货权调整单的作用 记录所有权变更：当商品的所有权发生变更时，通过货权调整单进行记录，确保所有相关方都清楚谁是商品的合法所有者。 确保财务和账务准确：在商品所有权变更时，货权调整单有助于确保财务系统中商品的所有权状态与实际情况一致。 提高供应链透明度：货权调整单有助于提高供应链中的透明度，确保各方在交易和交付过程中对商品所有权的认知一致。 防止纠纷：明确的货权记录和调整有助于减少因所有权不清而产生的纠纷，特别是在跨公司或跨国的交易中。 货权调整单的主要内容 货权调整单通常包含以下主要信息： 商品信息：包括商品名称、数量、规格、批次号等，用于标明调整的商品。 原所有者：商品在调整前的原所有者（例如供应商、仓库等）。 新所有者：商品调整后的新所有者（例如客户、承运商、仓库等）。 调整原因：说明为什么需要进行货权调整（如商品出售、退货、转移、损失等）。 调整日期：进行货权调整的日期。 调整数量：涉及到的商品数量或金额。 操作人员：负责操作和处理货权调整单的人员信息。 审批信息：在某些情况下，货权调整单可能需要经过相关主管或管理层的审批。 备注：其他说明或特殊情况的备注信息。 货权调整单的处理流程 发生货权变更事件：例如，客户购买商品后，商品的所有权会从供应商转移到客户。 创建货权调整单：相关方（如仓库、财务、物流部门）根据实际情况创建货权调整单，记录所有权变更的具体信息。 审批流程：如果需要，货权调整单会经过相应的审批流程，以确保所有权变更的合法性和合规性。 执行调整：审批通过后，商品的所有权记录会在系统中进行调整，并通知所有相关方（例如财务、物流、仓库等）。 存档记录：完成货权调整后，货权调整单会被存档，以备后续查询、审计或验证。 货权调整单的适用场景 商品交易：当商品从卖方转移到买方时，需要进行货权调整，以确保买方成为商品的合法所有者。 退货和换货：在客户退货或换货时，商品的所有权需要从客户回到卖方或供应商。 委托代销：在一些情况下，商品的所有权可能由委托方转移给代理商或经销商，这时也需要货权调整单。 物流配送：在物流过程中，商品的所有权可能在运输过程中发生转移，需要使用货权调整单进行记录。 库存调拨：商品从一个仓库转移到另一个仓库时，可能涉及所有权的变更，特别是在多个公司或实体之间调拨商品时。 货权调整单的管理与控制 审批流程：为了防止错误或不合规的操作，货权调整单通常需要经过相关主管或管理人员的审批。 权限管理：通常只有特定角色（如财务人员、仓库管理员或高层管理人员）才能创建、审批或执行货权调整操作。 审计与跟踪：货权调整单会被系统记录并存档，以便后续审计、查询和跟踪。系统会记录每一笔调整的详细信息，确保可追溯性。 财务对账：财务部门会根据货权调整单对账务进行调整，确保商品的所有权在账务系统中得到准确反映。 总结 货权调整单 是用于记录和管理商品所有权变更的单据，确保当商品的所有权发生转移时，相关方（如仓库、财务、客户等）能够及时更新记录，确保供应链的透明度和准确性。通过货权调整单，仓库和财务管理能够清楚掌握商品的流转和所有权变动，减少纠纷和错误，提升整体管理效率。 ","link":"https://panson.top/post/026_-shi-me-shi-huo-quan-diao-zheng-dan/"},{"title":"027.什么是集合单","content":"集合单（Collection Order） 集合单 是指在仓储管理、物流或供应链系统中，用于统一收集、整理、处理多个订单或商品的单据。它通常用于将多个客户或多个订单的货物集合在一起，以便进行统一的操作、分拣、打包或发货。 集合单的主要作用是帮助仓库或物流中心更高效地管理、整理多个订单或商品，减少操作复杂度，提高工作效率，特别是在处理大量商品或多订单的情况下。 集合单的作用 集货操作：集合单可以将多个订单或商品集合在一起，方便进行集货操作，比如将来自不同客户或订单的商品统一收集到一个区域，进行打包或发货。 提高效率：通过集合单，仓库人员可以一次性处理多个订单，减少每个订单单独处理的时间和成本，提升作业效率。 集中管理：在仓库中，集合单帮助工作人员在一个集合点集中处理多个订单或商品，确保商品能及时、准确地进行分拣和发货。 减少错误：通过集合单统一管理多个订单的商品，可以减少错误和遗漏，避免因为分拣混乱或漏单造成的发货错误。 集合单的常见场景 多订单合并：当多个订单的商品来自同一仓库或同一拣货区域时，仓库管理人员可以使用集合单来将多个订单的商品集合到一起，方便一并拣货、打包。 分拣操作：在订单分拣过程中，集合单帮助工作人员将来自不同客户的商品归集到一个集合区域，进行后续的打包或发货。 发货管理：对于多个订单的商品，使用集合单可以帮助仓库根据出库要求，将所有商品汇总并准备发货，减少操作环节。 生产与出货：在一些制造业和仓储操作中，集合单用于汇总生产或出货订单，帮助物流人员进行集中的处理和发运。 集合单的主要信息 一个集合单通常包含以下主要信息： 集合单编号：唯一标识该集合单的编号。 订单信息：集合单涉及的订单编号、客户信息等。 商品信息：集合单中包含的商品种类、数量、规格等。 仓库信息：集合单所在的仓库信息，或者涉及的多个仓库信息。 处理状态：集合单的当前处理状态，如已生成、已集合、已发货等。 处理人员：负责处理该集合单的工作人员信息。 集合时间：集合单创建的时间和处理的时间。 集合单的处理流程 生成集合单：当仓库或物流中心收到多个订单或商品需要集中的任务时，会生成集合单。 商品集合：按照集合单的要求，仓库工作人员将多个订单中的商品集合到指定区域。 分拣与打包：在集合点进行商品分拣和打包，确保每个订单的商品都齐全。 发货：集合完商品后，集合单上的商品会根据发货要求进行统一发货操作。 记录与追踪：集合单完成后，系统会更新集合单的状态，并记录相关操作，便于追踪和审计。 集合单的优势 提高操作效率：通过将多个订单或商品集合到一起，可以一次性完成拣货、打包和发货操作，减少操作时间。 降低操作成本：集合单减少了每个订单的单独操作，降低了物流和仓储的处理成本。 减少错误：通过集中管理和处理多个订单，可以减少因分拣错误、遗漏等导致的发货问题。 灵活性：集合单可以根据订单量、商品类型和仓库实际情况进行灵活操作，适应不同的业务需求。 总结 集合单 是在物流、仓储或供应链管理中用于集中的处理多个订单或商品的单据。它帮助仓库和物流中心更加高效地管理订单、商品的集合、分拣、打包和发货。通过使用集合单，可以提升工作效率、降低成本、减少错误，并提高整体的运营效率。 ","link":"https://panson.top/post/027_-shi-me-shi-ji-he-dan/"},{"title":"028.什么是料箱到人","content":"料箱到人（Case-to-Person） 料箱到人（Case-to-Person） 是一种自动化的仓储作业方式，属于仓储拣选系统的一种。其基本思路是将商品存储在料箱中，并通过自动化设备将货物从储存位置送到操作人员所在的拣选工作站。操作员只需要在工作站执行拣选任务，而不需要在仓库中来回走动去寻找商品，极大提高了仓库拣选效率。 基本原理 在“料箱到人”模式下，商品被存放在固定的货架或料箱中，当有订单需要拣选时，自动化设备（如AGV、传送带、自动堆垛机等）会把对应的货物从储存位置运送到操作人员所在的工作台或拣选站。操作员接收到货物后，直接完成拣选和包装，而不需要亲自走到仓库的其他地方寻找商品。 关键特点 自动化设备：料箱到人系统通常依赖自动化设备（如传送带、堆垛机、机器人等）来将商品送到拣选工作站，减少人工搬运时间。 减少步行：与传统的人工拣选方式相比，料箱到人的方式大大减少了工作人员的步行距离，从而提高工作效率。 提高准确性：自动化系统能够准确将商品送到指定位置，减少人工操作中的错误和遗漏。 灵活性：可以在多种环境下使用，如自动化仓库、零售仓储等。 料箱到人的优势 提高拣选效率：操作员无需走动寻找商品，节省时间，拣选效率显著提高。 减少人工成本：通过自动化设备替代大量人工操作，降低人工成本。 精准操作：自动化系统能够精确地执行任务，避免了人工拣选过程中可能发生的错误和遗漏。 减少劳动强度：操作员的体力劳动减少，能够集中精力完成更高效的工作。 适应高频次、复杂订单的需求：适用于处理小批量、高频次的订单，对于快速出库的环境非常适用。 料箱到人的应用场景 电商仓库：电商平台的订单通常有很高的处理频率和复杂度，料箱到人可以显著提升订单处理速度和准确性。 零售业：超市、零售商等需要进行频繁商品拣选的地方，料箱到人模式能够帮助提高商品的出库效率。 食品行业：对于大批量、小商品种类的拣选需求，料箱到人也能有效提高库存管理和订单拣选速度。 批发分销：批发商和分销商往往处理大量商品，料箱到人系统能够优化拣选过程，节省人工和时间。 料箱到人和人到货的区别 人到货（Person-to-Goods）：操作员走到仓库的货架或储存位置，挑选商品并将其搬到工作站进行包装或处理。这是传统的拣选模式。 料箱到人（Case-to-Person）：自动化设备将商品从储存位置运送到操作员所在的工作站，操作员只需要进行简单的接收和包装工作。 相比之下，料箱到人 能够显著减少操作员的步行时间，减少人力资源的消耗，提升拣选效率和准确度。 总结 料箱到人 是一种高效、自动化的仓储拣选方式，它通过自动化设备将商品送到操作员所在的工作站，减少人工拣选时的时间消耗和错误。它在电商、零售、食品及批发行业等具有广泛的应用，能够大大提高拣选效率，降低成本，提升仓储作业的整体性能。 ","link":"https://panson.top/post/028_-shi-me-shi-liao-xiang-dao-ren/"},{"title":"029.什么是货架到人","content":"货架到人（Shelf-to-Person） 货架到人（Shelf-to-Person） 是一种现代化的仓储拣选方式，通常依赖自动化系统和机器人技术来将商品从存储货架自动运送到操作员所在的工作站。与传统的“人到货”（即操作员自己去货架上挑选商品）不同，货架到人模式大大减少了操作员的步行时间，提升了拣选效率。 基本原理 在货架到人模式中，商品被存储在固定的货架或存储位置。当有订单需要拣选时，自动化设备（例如：自动引导车（AGV）、自动传送带、堆垛机、机器人等）会将存储在货架上的商品自动运送到指定的工作站。操作员只需在工作站接收商品并进行分拣或打包，而不需要走到仓库的其他区域去挑选商品。 关键特点 自动化运送：货架上的商品通过自动化设备（如机器人、传送带）送到操作员的工作站，避免人工搬运。 减少步行距离：操作员无需走到货架上挑选商品，只需在工作站执行拣选任务，大大减少了步行时间和体力消耗。 提高效率：自动化设备可以快速、精准地将商品送到工作站，减少等待时间，提升整体作业效率。 减少错误：自动化系统通过精准的路径规划和任务执行，减少了人工拣选过程中可能出现的错误。 货架到人的优势 提高拣选效率：自动化系统能迅速将商品送到工作站，操作员的工作效率大幅提升。 降低劳动强度：操作员不再需要走动、搬运商品，体力消耗大大降低，避免了重复的体力劳动。 提高准确性：自动化设备减少了人为错误，确保了商品准确无误地送到操作员手中，减少了漏拣和错误拣选的情况。 优化仓库空间：自动化设备可以更高效地使用仓库空间，特别是在高密度存储区域，通过减少操作员步行，可以更紧凑地安排存储。 提高灵活性：适用于快速变化的订单和高频次的操作，能够快速响应仓库中的各种需求。 货架到人的应用场景 电商仓库：电商仓库通常需要高效处理大量小订单，货架到人模式帮助仓库快速处理高频次、小批量订单，提升了作业效率。 零售仓库：大型零售商的仓库需要快速、准确地拣选商品以应对不断变化的市场需求，货架到人模式能够有效提高库存管理效率。 食品和日用消费品仓库：这些行业的商品种类繁多，货架到人模式能够有效地提高仓库的处理能力，减少操作员的疲劳。 分销中心：分销商需要快速、高效地从货架上取货并发货，货架到人模式能大大提高分销效率。 货架到人和料箱到人对比 货架到人（Shelf-to-Person）：商品存储在货架上，自动化设备将货物从货架送到操作员的工作站，适用于存储量大且种类繁多的商品。 料箱到人（Case-to-Person）：商品通常存储在料箱或集装箱中，自动化设备将商品从料箱送到操作员的工作站，通常用于较为标准化和批量的商品管理。 区别： 适用场景：货架到人更适合存储种类多、变化快的商品，而料箱到人则适用于高频次、标准化的商品存储。 拣选方式：货架到人更依赖商品的存储位置和数量，而料箱到人则更多依赖于自动化系统进行物品集合。 总结 货架到人 是一种依靠自动化设备将商品从货架运送到操作员工作站的仓储作业方式。这种方式减少了操作员在仓库中走动的时间，降低了劳动强度，提升了拣选效率和准确性。它适用于电商、零售、食品等行业，能够有效提高仓库的运营效率和灵活性。 ","link":"https://panson.top/post/029_-shi-me-shi-huo-jia-dao-ren/"},{"title":"030.货架到人和料箱到人的区别","content":"货架到人（Shelf-to-Person）与料箱到人（Case-to-Person）的区别 货架到人（Shelf-to-Person） 和 料箱到人（Case-to-Person） 都是现代仓库中的自动化拣选模式，但它们的工作原理、适用场景、以及操作流程有一些关键区别。 1. 存储方式的不同 货架到人： 商品通常是单独存储在货架上的，每个货架上可能有一个或多个商品，商品根据类型、大小、重量等因素被放置在不同的货架位置。 这种方式适用于存储种类繁多、尺寸不一的商品，商品之间没有固定的集装箱或托盘。 料箱到人： 商品通常是存储在料箱（箱子、托盘）中，每个料箱可以存储同一类商品，或者某些商品的组合。 料箱到人模式一般用于存储具有较高标准化的商品，或在一定时间内保持相同的货物分配，如批量订单。 2. 商品获取的方式 货架到人： 自动化设备（如机器人、传送带、自动堆垛机等）将单个货架上的商品送到操作员的工作站。 操作员站在工作站接收商品，进行拣选或打包。每次送到的可能是单个商品或多个商品，视具体的商品存储方式和拣选需求而定。 料箱到人： 自动化设备将存储在料箱中的商品送到操作员所在的工作站。每个料箱里可能包含多种商品或某类商品，操作员从料箱中进行拣选。 操作员通过收到一个预装箱的商品来进行拣选，通常会收到的是一箱商品，不需要一件一件地从货架上挑选。 3. 适用场景的不同 货架到人： 适用于商品种类繁多且大小不一的仓库，商品在货架上单独存放。例如，零售仓库、电商仓库等，订单可能需要从多个货架上提取少量商品。 商品数量相对较小，商品种类更复杂，操作员通常需要根据不同的商品类型、形状和尺寸进行操作。 料箱到人： 适用于商品相对较为标准化的仓库，尤其是当订单数量较大时，采用料箱将多个商品组合在一起送到操作员。比如，批量订单的处理和库存管理较为规范的商品（如饮料、食品、配件等）。 商品的存储和配送模式较为统一，一般是为节省空间和提高效率而将同类商品组合到一个料箱中。 4. 拣选效率的区别 货架到人： 因为是从各个货架上拣选单个商品，操作员可能需要处理不同的商品类型，拣选较为分散，适合多品种、小批量的拣选任务。 优点：适合需要频繁更新、存储不规则、商品种类多的环境。 缺点：可能需要多次拣选才能完成一个订单。 料箱到人： 由于每个料箱存储的是同类商品或者已经组合好的商品，拣选任务相对较简单，适合单一品类或大批量的订单处理。 优点：适用于大宗商品的拣选，能够快速完成单品类、批量化的拣选任务。 缺点：不适合多品种订单的处理，因为每次拣选的料箱可能包含多个商品而不满足个性化需求。 5. 仓库空间利用的差异 货架到人： 仓库的空间布局可以更加灵活，货架可以根据商品的形状和大小进行定制。通常不需要事先安排好料箱的大小，较为适合存储体积不一的商品。 料箱到人： 由于商品是统一存储在料箱或托盘中的，仓库空间的规划相对固定。为了节省空间，货物的摆放通常需要合理规划以便最大化存储。 存储空间利用效率相对较高，但对于多种类商品的存储可能不如货架到人灵活。 总结： 特性 货架到人（Shelf-to-Person） 料箱到人（Case-to-Person） 存储方式 商品存放在货架上，按种类和大小分类 商品存放在料箱中，一般为同类商品或按批次存储 拣选方式 自动化设备将单个货架商品送到操作员 自动化设备将整个料箱送到操作员，操作员从中拣选 适用场景 适用于商品种类繁多、个体差异较大的环境，如电商、零售仓库 适用于大宗商品或批量订单的处理，如食品、批发仓库等 拣选效率 适合多品种、小批量的拣选，拣选任务较为分散 适合单品类、大批量拣选，任务较为集中 空间利用 仓库空间较为灵活，适合体积不一的商品 仓库空间利用效率高，适合相对规则的商品存储 总结： 货架到人 是适用于商品种类多且变化较快的环境，能够更灵活地处理不同类型和大小的商品拣选任务。 料箱到人 适合存储和处理批量商品的仓库，能够高效地进行大量同类商品的拣选，但对多品种、小批量的订单处理效率较低。 ","link":"https://panson.top/post/030_-huo-jia-dao-ren-he-liao-xiang-dao-ren-de-qu-bie/"},{"title":"009.什么是工作站","content":"在 WMS（Warehouse Management System，仓库管理系统） 中，工作站（Workstation） 是指用于执行仓库任务的物理或虚拟位置，通常是操作员与仓库管理系统交互的地方。工作站可能是指某个特定区域中的设备（如扫描枪、电脑、终端等），也可能是一个具体的操作流程节点。工作站的设计目的是为了提高操作效率、减少错误并优化库存管理。 工作站的主要功能和类型 接收和入库工作站（Receiving Station） ○ 负责接收货物、验收物品、登记入库信息。操作员扫描条形码或二维码，确认商品的接收情况，并将物品入库到指定位置。 ○ 任务：验收商品、登记货物信息、入库操作。 拣货工作站（Picking Station） ○ 负责从仓库中拣取订单中所需的商品。拣货工作站可能与拣货策略（如单品拣货、批量拣货、波次拣货等）相关联。 ○ 任务：选择正确的商品、核对订单、将商品准备好。 包装工作站（Packing Station） ○ 负责将已拣选的商品打包为客户订单的最终形态。工作站可能配备扫描枪、打印机等设备，确保每个包裹的内容和信息准确无误。 ○ 任务：检查商品数量、包装商品、打印运单和标签。 出库工作站（Shipping Station） ○ 负责将完成包装的商品准备发运。可能涉及到货物分拣、装车等操作。出库工作站通常会与物流公司对接，生成运输标签、准备装车信息。 ○ 任务：分配运输方式、装车、打印运输单据。 盘点工作站（Inventory Counting Station） ○ 用于执行库存盘点任务。盘点工作站通常涉及扫描库存中的商品，核对系统数据和实际库存，进行差异分析。 ○ 任务：库存盘点、库存调整、数据同步。 退货工作站（Returns Station） ○ 专门用于处理客户退货的商品。通常包括商品检查、质量检测、再入库或销毁等流程。 ○ 任务：退货商品检查、分类、更新库存。 工作站的硬件设备 工作站通常由一组硬件设备组成，包括但不限于： ● 扫描枪/扫描器：用于扫描条形码或二维码，识别商品信息。 ● 计算机/平板电脑：显示操作界面，供操作员执行任务。 ● 打印机：用于打印标签、发货单等单据。 ● 称重设备：用于检测商品重量（特别是在包装和出库过程中）。 ● RFID 设备：用于更高效的库存管理和商品追踪。 工作站的作用和意义 提高效率：通过设置专门的工作站，每个操作员可以集中精力执行特定任务，避免任务切换带来的效率损失。 降低错误率：每个工作站都有明确的操作流程，通过系统提示、扫码等方式，减少人为错误。 优化流程：通过自动化设备（如条形码扫描、称重、打印等），可以大幅度提升仓库作业的自动化水平，减少人工操作的时间和误差。 集中管理：工作站通常由 WMS 系统集中管理，能够实时监控工作进度、任务完成情况和资源利用率。 WMS 中的工作站配置 在 WMS 中，工作站的配置通常包括以下内容： ● 工作站类型：配置工作站的种类，定义不同任务对应的工作站。 ● 工作站设备：为每个工作站指定所需的硬件设备，如扫描枪、打印机等。 ● 任务分配：根据工作站类型和仓库作业流程，将任务动态分配到相应的工作站。 ● 工作站参数：设置工作站的相关参数，如优先级、作业时间、作业顺序等。 总结 在 WMS 系统中，工作站是各项仓库操作任务的执行地点和关键环节，设计合理的工作站配置可以有效提升仓库的作业效率、减少错误，并优化整个仓库的管理和物流流转。通过合理划分不同的工作站，仓库管理可以更加细化和精确，帮助实现高效的库存管理和订单处理。 ","link":"https://panson.top/post/009_-shi-me-shi-gong-zuo-zhan/"},{"title":"008.什么是料箱容器","content":"料箱业务中的容器信息维护 在料箱业务中，需要维护容器信息，包括：容器类型、容器具体信息、料格类型、料格信息。 容器用于存储商品，容器可以分格，每一个料格也都可以用于存储商品。 1. 容器信息 基本信息 仓库名称：容器所属仓库的名称。 仓库编码：容器所属仓库的编码。 容器编码：容器的唯一编码信息。 容器类型名称：容器所属类型的名称。 容器种类：容器所属类型的种类，分为托盘/料箱。 容器数字码：容器的数字码信息。 容器类型编码：容器所属类型的编码。 库位：如果容器在库内，显示容器当前所在的库位信息。 其他属性 是否启用料格：容器所属类型是否启用料格（是/否）。 料箱移位属性（预留字段）：目前无意义。 是否预出库（预留字段）：目前无意义。 料箱所属库区（预留字段）：目前无意义。 空满标记（预留字段）：目前无意义。 有效状态：容器是否有效（有效/无效）。 2. 容器类型信息 容器类型编码：容器类型的唯一编码信息。 容器类型名称：容器类型的名称信息。 容器种类：区分容器是料箱还是托盘。 长：容器的长度，记录准确数值。 宽：容器的宽度，记录准确数值。 高：容器的高度，记录准确数值。 有效状态： 有效：可用于创建容器。 无效：不可用于创建容器。 是否识别容器号：是否在业务操作中记录和校验容器编码（默认：否）。 叉孔高度：全向车叉孔高度（默认：0，无需修改）。 叉孔底部高度：全向车叉孔底部高度（默认：0，无需修改）。 材质类型：记录该容器类型的材料信息。 ","link":"https://panson.top/post/008_-shi-me-shi-liao-xiang-rong-qi/"},{"title":"007.什么是商品","content":"在 WMS 和 WES 中，商品是什么？ 在 WMS（仓库管理系统） 和 WES（仓库执行系统） 中，商品（Product 或 SKU）是指仓库内存储和管理的物品，通常以唯一标识（如 SKU、条码）进行追踪，并涉及存储、拣选、运输、包装等操作。 1. 商品（Product）在 WMS/WES 中的定义 在 WMS 和 WES 中，商品不仅仅是普通的商品，而是一个数据实体，通常包括以下关键信息： 字段 说明 SKU（库存单位） 商品的唯一标识代码，如 &quot;ABC123&quot; 条码（Barcode） 扫描识别商品的编码，如 EAN-13、UPC 名称（Product Name） 商品名称，如 &quot;iPhone 15 256GB&quot; 商品分类（Category） 例如 &quot;电子产品&quot;、&quot;服装&quot;、&quot;食品&quot; 单位（Unit of Measure, UOM） 例如 &quot;箱&quot;、&quot;件&quot;、&quot;公斤&quot; 包装规格（Pack Size） 例如 &quot;1 箱 = 12 罐&quot; 重量/体积（Weight/Volume） 物流计算使用，如 &quot;2kg/0.01m³&quot; 批次（Batch Number） 生产批次管理，如 &quot;20240301A&quot; 保质期/有效期（Expiry Date） 适用于食品、药品，如 &quot;2025-01-01&quot; 存储规则（Storage Rules） 例如 &quot;需冷藏（2-8°C）&quot;、&quot;危险品存储&quot; 库存状态（Inventory Status） 例如 &quot;可售&quot;、&quot;待检&quot;、&quot;退货&quot; 2. WMS（仓库管理系统）中的商品 WMS 主要关注商品的存储、库存和移动管理，确保商品在仓库中的准确存放、补货和拣选。 在 WMS 中，商品会被关联到仓库中的具体存储位置（货架、库位），并受到各种规则的影响，如： 存储规则：某些商品需要存放在特定温度区域（如冷链仓库）。 批次管理：同一 SKU 可能有不同生产批次，需要按**先进先出（FIFO）**出库。 库存管理：商品可能处于不同状态（可售库存、待检库存等）。 ✅ 示例： 一家电商仓库中的 iPhone 15（SKU: IP15-256-BLACK），WMS 需要管理： 存储在哪个货架、库位？ 是否还有库存？补货情况？ 是否有多个批次？需要优先出库哪个批次？ 3. WES（仓库执行系统）中的商品 WES 主要关注商品在仓库中的自动化处理，如拣选、分拣、包装和出库，确保订单高效执行。 在 WES 中，商品信息用于： 机器人拣选：自动分拣设备通过条码或RFID识别商品，执行拣选任务。 订单合并：同一订单的商品如何高效合并。 分波处理：按订单优先级和路线优化出库顺序。 ✅ 示例： 在京东智能仓库，iPhone 15（SKU: IP15-256-BLACK） 需要： 机器人从货架上拣选该商品，并放入订单拣选箱。 自动输送带将商品送往包装区进行贴单、称重。 按快递区域进行分拣，并装车出库。 总结 在 WMS 和 WES 中，商品不仅仅是一个产品，而是一个数据实体，涉及库存管理、批次追踪、存储规则、拣选执行等多个环节。 WMS 侧重于 库存存储、管理，确保库存信息准确。 WES 侧重于 自动化执行（拣选、分拣、包装），提高订单履行效率。 最终，二者协同工作，确保仓库内的商品能够高效管理和流转。 ","link":"https://panson.top/post/007_-shi-me-shi-shang-pin/"},{"title":"006.什么是商品条码","content":"商品条码（Product Barcode）是什么？ 商品条码（Product Barcode）是一种用于唯一标识商品的编码，通常由一串数字和对应的条形码或二维码组成，便于自动化识别、库存管理和销售追踪。 在 WMS（仓库管理系统） 和 WES（仓库执行系统） 以及 POS（销售点终端） 中，商品条码是商品追踪和管理的核心标识。 商品条码的组成 商品条码一般由数字编码和条形码图像组成： 数字编码：通常由 不同位数的数字组成，每部分表示不同的信息（如厂商、产品类别、校验码）。 条形码：将数字编码转换为可扫码的黑白条图像，可通过扫码枪或智能设备识别。 常见的商品条码类型 1. EAN（欧洲商品编号） EAN-13（13 位）：全球通用，超市、零售行业最常见（如食品、日用品）。 EAN-8（8 位）：用于小商品（如口香糖、小瓶装商品）。 结构示例（EAN-13）：6 90 12345 67890 5 | | | | | | | | | 校验码 | | | 商品代码 | | 制造商代码 | 国家代码（前两位） **示例：**超市中的牛奶、面包、饮料通常带有 EAN-13 条码。 2. UPC（通用商品代码） UPC-A（12 位）：美国和加拿大常用，类似于 EAN-13。 UPC-E（6 位）：缩短版，用于小商品。 **示例：**美国超市的食品、电子产品常见。 3. Code 128（128 码） 用于物流、仓储、运输行业。 支持字母 + 数字 + 特殊字符，信息量大。 **示例：**快递单号、仓储货架标签。 4. QR Code（二维码） 可存储更多信息，支持网址、文本、产品说明等。 **示例：**支付二维码、产品追溯码（如化妆品防伪码）。 商品条码的作用 作用 说明 商品识别 每个商品有唯一条码，方便快速扫描录入 库存管理 WMS/WES 通过条码跟踪库存数量、位置 销售管理 POS 系统扫码识别商品，完成结账 防伪追溯 结合二维码，追踪产品来源、生产批次 供应链追踪 在供应链环节中扫描条码，监控物流状态 总结 商品条码是唯一标识商品的编码，广泛用于零售、仓储、物流、供应链等领域，主要包括 EAN、UPC、Code 128、QR Code 等不同格式，帮助企业实现自动化管理和追踪商品。 ","link":"https://panson.top/post/006_-shi-me-shi-shang-pin-tiao-ma/"},{"title":" 004.什么是出库","content":"在 WMS（仓库管理系统） 中，出库 指的是从仓库中将货物发放到外部的过程。它是仓库管理的重要环节之一，通常包括从订单生成到货物最终出库的所有操作，确保货物能够准确、高效地送达客户或下游环节。 出库的主要流程 订单生成： 客户创建订单或系统接收到销售订单/出库指令。 系统生成出库任务。 库存分配： 根据订单需求，分配对应的货品和库存位置。 确保库存足够，并检查是否需要调拨或补货。 拣货： 仓库工作人员按照系统的指引，到指定库位拣选货物。 有时会使用 手持终端（PDA） 或其他扫描设备来确认货物和数量的准确性。 复核： 拣货完成后，进行复核，确保货物的品类、数量和质量符合要求。 包装： 根据订单需求对货物进行包装。 包括贴标、打包、加固等操作。 出库确认： 将货物从仓库正式转移到配送环节。 系统中记录出库状态，库存数据实时更新。 物流对接： 根据客户要求，安排运输方式（快递、物流货车等）。 打印发货单或物流单号，与物流公司交接。 出库的类型 销售出库：因客户订购而发货，比如电商订单。 调拨出库：把货物从一个仓库调拨到另一仓库。 退货出库：客户退货后重新发货。 其他出库：如样品发送、生产领料等。 出库的重点 精确性：确保货物品类、数量与订单一致。 时效性：按时发货，满足客户需求。 效率：优化拣货和发货流程，节省时间。 质量：货物在出库前需确认完好，避免运输中的损坏。 总之，出库是保证货物从仓库到客户手中流转的关键环节，对仓库管理的服务质量和效率有着重要影响。 ","link":"https://panson.top/post/004_-shi-me-shi-chu-ku/"},{"title":"003.什么是出库单","content":"在 WMS（Warehouse Management System，仓库管理系统） 中，出库单是一个非常重要的业务单据和操作流程节点，用于实现货物出库管理的数字化和精细化操作。相比传统的纸质或手工管理，WMS 中的出库单与系统的各个模块紧密联动，不仅记录货物出库的情况，还直接驱动系统内的出库作业流程。 以下是出库单在 WMS 中的详细说明： 1. 出库单的定义 在 WMS 系统中，出库单是描述货物出库任务的核心单据，它从系统的上游（如订单、计划）生成，指导仓库的出库操作。通过出库单，WMS 能够明确仓库中的货物需要出库的内容、数量、优先级和目的地。 2. 出库单的来源 在 WMS 中，出库单通常由上游系统或业务产生，具体来源包括： 销售订单：客户下单后，WMS 根据销售订单生成出库单。 调拨计划：企业内部的跨仓库调拨需求，生成调拨出库单。 生产领料单：生产部门从仓库领取原材料，生成领料出库单。 退货单：客户退货后重新发货，生成退货出库单。 其他业务需求：如赠品发放、盘亏处理等。 备注：在 WMS 中，出库单通常是上游业务单据的执行指令，或者通过接口从 ERP、OMS（订单管理系统）等系统中同步生成。 3. 出库单的内容 出库单在 WMS 系统中包含更全面、结构化的数据，具体字段可能包括： 基本信息 出库单编号：系统自动生成的唯一标识编号。 出库单类型：标明出库的业务场景，如销售出库、调拨出库、领料出库等。 创建时间：出库单生成的时间。 优先级：出库任务的优先级（用于调度时排序）。 货物信息 物品编码：货物的唯一标识（SKU 或条码）。 物品名称：货物的名称。 规格型号：货物的规格、尺寸等信息。 单位：如件、箱、公斤等。 出库数量：计划出库的数量。 批次号：货物的批次信息，特别是需要追溯或存在保质期的货物。 库位信息：物品的存储位置（如货架号、库区等）。 关联信息 关联订单编号：与该出库单相关联的上游业务单据编号（如销售订单号、调拨单号）。 客户信息：发货的客户名称、地址等。 承运信息：物流方式、承运商、运单号等。 操作信息 制单人：生成出库单的人员或系统。 审核人：负责审核出库单的人员。 操作状态：当前出库单的处理状态（如已创建、拣货中、已复核、已发货等）。 备注：特殊说明或补充信息。 4. 出库单在 WMS 中的操作流程 WMS 中的出库单不仅是一个记录工具，还驱动了整个出库业务流程。典型的出库流程如下： (1) 出库单生成 自动生成：由上游系统（如 ERP、OMS）通过接口推送，或根据规则自动生成。 手动创建：由仓库管理员在 WMS 系统中手动创建（如紧急订单）。 (2) 出库任务分解 WMS 将出库单分解为具体的操作任务，包括： 拣货任务：根据库存位置和出库单的需求生成拣货任务。 分拣任务：将拣货后的货物按照订单或客户要求进行分类。 复核任务：核对出库的货物是否与订单要求一致。 包装任务：对出库货物进行包装。 发货任务：将货物装车并交接给物流公司。 (3) 库存分配 在出库任务生成后，WMS 会检查库存情况并进行库存分配： 根据 先进先出（FIFO）、批次优先 等规则分配库存。 锁定对应的货位和库存数量，防止冲突。 (4) 拣货作业 系统通过 无线终端（PDA） 或打印拣货单，指导仓库人员到指定货位拣货。 拣货完成后，更新系统库存，记录拣货的实际操作数据。 (5) 复核与包装 拣货完成后，进行复核，确保物品、数量、批次等信息正确无误。 根据需要，将货物进行包装并贴上标签（如发货标签、物流单号）。 (6) 发货确认 出库货物装车后，通过系统完成发货确认。 系统生成物流信息，并向上游业务系统反馈出库完成状态。 5. 出库单的状态流转 在 WMS 中，出库单通常会经历以下状态： 创建：出库单生成后，处于初始状态。 分配库存：系统根据规则锁定库存，更新状态。 拣货中：拣货任务开始执行。 复核中：货物核对中。 已发货：货物完成出库并交接给物流。 6. 出库单的作用 在 WMS 中，出库单的作用更加细化，主要包括： 作业指令：指导仓库操作人员完成拣货、复核、发货等任务。 库存管理：实时调整库存数据，反映库存减少情况。 流程追溯：记录每个出库环节的信息，便于后续追溯和审计。 对账依据：为财务和物流提供准确的出库数据和凭证。 效率提升：通过系统化的流程和任务分配，提高仓库运作效率。 7. 出库单的与其他单据的关系 在 WMS 中，出库单与其他单据和模块紧密关联： 与销售订单：销售订单是出库单的上游来源，出库单是销售订单的执行指令。 与库存调整单：出库单触发库存减少，影响库存调整记录。 与发货单：发货单是出库单完成后的下游单据，面向客户和物流使用。 与调拨单：调拨单可能生成两个出库单（出库仓）和入库单（入库仓），实现调拨的闭环。 总结 在 WMS 中，出库单不仅是记录出库操作的单据，更是整个出库流程的核心驱动工具。它通过数字化系统连接上游订单和下游物流，细化并优化每个出库环节，从而提升库存管理的精准性和仓库运作的效率。 ","link":"https://panson.top/post/003_-shi-me-shi-chu-ku-dan/"},{"title":"002.什么是入库","content":"在 WMS（Warehouse Management System，仓库管理系统） 中，入库 是指商品、原材料或货物从外部进入仓库并被系统记录和管理的过程。入库是仓储管理的一个核心环节，确保仓库能够准确地接收、登记和存储货物。 入库的主要流程： 入库通知： 仓库接收到采购订单、退货订单或其他入库需求（如生产入库、调拨入库）的通知。 通知单中通常会包含入库的货物种类、数量和特殊要求。 货物到达： 供应商或运输方将货物运送到仓库。 仓库人员确认货物到达后进行初步核对。 验收： 仓库工作人员核对货物数量、质量、规格等是否与入库单一致。 如果发现问题（如数量不符、质量不合格），需要记录异常并处理。 上架或存放： 验收合格的货物按照系统指引分配到指定的存储位置（货架、库区等）。 WMS 系统会记录货物的存储位置，方便后续查询和调度。 入库确认： 仓库人员在 WMS 系统中完成入库操作，录入相关信息（如货物类别、数量、存储位置等）。 系统更新库存数据，反映最新的库存状态。 入库的类型： 根据不同的业务需求，入库可以分为以下几种类型： 采购入库：供应商交付的货物入库。 生产入库：生产完成的成品或半成品入库。 退货入库：客户退货后重新入库。 调拨入库：从其他仓库调拨过来的货物入库。 其他入库：如赠品、临时物资等入库。 入库在 WMS 系统中的意义： 库存准确性：入库环节确保仓库库存数据的更新和准确。 优化仓储空间：通过合理分配存储位置，提高仓库的利用率。 便捷后续操作：入库完成后，货物的后续操作（如拣货、发货）会更高效。 入库常见的技术支持： 条形码/RFID：通过扫描条形码或 RFID 标签快速记录货物信息。 自动化设备：如传送带、自动分拣机等，提升入库效率。 移动终端/PDA：仓库人员使用手持设备操作入库，实时上传数据。 通过 WMS 系统的支持，入库流程变得更加高效和精准，同时提升了仓储管理的整体水平。 ","link":"https://panson.top/post/002_-shi-me-shi-ru-ku/"},{"title":"005.什么是商品容量","content":"在 WMS（Warehouse Management System，仓库管理系统） 和 WES（Warehouse Execution System，仓库执行系统） 中，商品容量（Product Capacity）通常指的是单位存储空间内可容纳的商品数量，或者指商品本身在存储和操作过程中的容量属性。具体而言，商品容量的概念可以分为以下几个方面： 1. 存储容量（Storage Capacity） 指 某种商品在仓库中的单位存储空间可容纳的最大数量。 例如，一个货架上的某个存储单元（Bin）可以存放 100 盒某种产品，那么这个存储单元的商品容量就是 100 盒。 在 WMS 中，存储容量用于优化库存分配和仓位管理，确保空间利用最大化。 2. 运输/拣选容量（Handling Capacity） 指 商品在拣选或运输时的最大处理量。 例如，一个料箱（Tote）可以容纳 20 件产品，或者一个托盘（Pallet）可以承载 500kg 的货物，那么这个容器的商品容量就是其最大承载量。 在 WES 中，这个指标用于优化拣选路径、计算机器人或输送带的负载能力。 3. 单位包装容量（Unit Packaging Capacity） 指 单个包装（如箱、托盘）能容纳的商品数量。 例如： 一箱苹果汁包含 24 瓶（1 箱 = 24 瓶）。 一个托盘纸巾包含 1000 包（1 托盘 = 1000 包）。 这个数据在 WMS 和 WES 中用于订单拆分、装载优化和补货计算。 4. 体积与重量限制（Volume &amp; Weight Capacity） 有些 WMS 还会将体积和重量作为商品容量的重要指标： 例如，一个仓库货架的某个存储位置最多可以承载 500kg 的货物，或容纳 1 立方米的产品。 这些数据用于存储规划，确保不会因超载而影响仓库运营。 在 WMS 和 WES 中的应用 商品容量类型 作用 存储容量 确定每个仓位可存放多少商品，优化库存布局 运输/拣选容量 计算拣选容器、自动化系统（如 AGV、输送带）的负载能力 单位包装容量 影响订单拆分、补货计算 体积 &amp; 重量容量 确保货架、设备、存储单元的承载能力不超标 总结 在 WMS 和 WES 系统中，商品容量的概念主要涉及存储、拣选、包装、体积和重量等维度，用于优化仓储管理和物流执行。不同的仓储系统可能会根据业务需求对商品容量的计算方式有所调整。 ","link":"https://panson.top/post/005_-shi-me-shi-shang-pin-rong-liang/"},{"title":"001.什么是入库单","content":"在 WMS（仓库管理系统） 中，入库单是一种用于管理和追踪物料、商品进入仓库的数字化单据。它是 WMS 系统核心功能之一，贯穿于仓库的入库流程，确保从物料接收到正式入库的整个过程可视化、可追踪、规范化。 WMS 中入库单的作用 信息记录： 记录入库商品的详细信息（如品名、规格、数量、供应商来源等），以实现精准的库存管理。 流程控制： 从物料到货、验收、上架到正式入库的全过程都由入库单驱动，保证流程有序。 与其他系统对接： 入库单与采购系统、ERP 系统、财务系统等关联，实现业务协同。 库存动态更新： 入库单完成后，WMS 系统会实时更新库存数量和位置，确保库存数据准确。 WMS 中入库单的类型 根据业务场景，WMS 中的入库单可以有以下类型： 采购入库单： 由采购订单生成，用于记录采购商品入库的情况。 生产入库单： 工厂生产的成品、半成品完成后进入仓库时生成的入库单。 退货入库单： 客户或门店退回的商品重新入库时生成的单据。 调拨入库单： 从其他仓库或分拣中心调拨过来的物品入库时使用。 其他入库单： 例如赠品入库、盘盈入库、报废物资回收入库等。 WMS 中入库单的核心字段 入库单在 WMS 系统中通常包含以下信息： 字段名称 描述 单据编号 入库单的唯一标识，用于追踪。 入库时间 记录物料入库的时间。 供应商名称 入库商品的供应商信息（如采购时）。 物料信息 商品名称、规格型号、批次号、数量、单位等。 仓库/库位 入库的仓库及具体存放库位。 操作人员 负责物料验收、入库操作的人员信息。 关联单据 关联的采购单号、调拨单号或其他业务单据编号。 备注 其他需要说明的信息。 WMS 入库单的流程 创建入库单： 系统根据采购订单或其他来源自动生成入库单，或由操作人员手动录入。 收货登记： 物料到达仓库，操作人员扫描条码（或录入信息），核对数量和质量。 质检验收（可选）： 如果需要质检，系统会记录质检结果（合格或不合格）并更新入库单状态。 上架操作： 系统根据库存规则或人工指定，将商品分配到具体库位，并生成上架任务。 入库确认： 上架完成后，系统更新入库单状态为“已完成”，并同步更新库存。 WMS 入库单与其他模块的关系 与采购模块： 从采购订单生成入库单，确保采购的商品及时入库。 与库存模块： 入库单完成后，库存数量和库位信息实时更新。 与财务模块： 入库单完成后，可用于核算采购成本、库存价值等。 与质检模块： 部分商品入库前需要质检，质检结果会影响入库单状态。 WMS 入库单的优点 数字化管理： 减少人工录入错误，数据实时同步，提高效率。 库存精准性： 通过入库单驱动库存更新，确保库存数据准确无误。 操作规范化： 入库全流程可追溯，提升仓库管理的透明度和合规性。 高效协同： 入库单与其他业务系统联动，提升整体供应链效率。 通过 WMS 系统中的入库单，企业可以实现仓库管理的流程化和精细化，为供应链的高效运转提供有力支持。 ","link":"https://panson.top/post/001_-shi-me-shi-ru-ku-dan/"},{"title":"012.什么是料格电子标签","content":"料格电子标签是现代仓储系统中一种高效的辅助工具，主要用于标识货架或料格中的物品信息，以及实现高效的仓储管理。 料格电子标签的功能 物品标识 每个料格对应一个电子标签，用于显示该料格中存放物品的基本信息（如名称、规格、数量、批次等）。 动态更新 电子标签的信息可以通过仓储管理系统（WMS）实时更新，无需人工更换纸质标签，减少人为错误。 库存管理 当库存发生变化时，电子标签会同步更新库存数量，方便精准管理。 操作指引 在拣货、补货或盘点时，系统可以点亮特定料格的电子标签，指引操作人员快速找到目标货品。 扫码交互 许多电子标签支持扫码功能，与移动设备或扫描枪交互，进一步简化操作。 料格电子标签的特点 低功耗设计 通常采用电子墨水屏（E-Ink）或液晶屏（LCD），耗电量低，使用寿命长。 无线控制 支持无线通讯（如 Wi-Fi、ZigBee、蓝牙等），实现远程配置和更新。 高可视性 标签通常具备高对比度，方便操作人员快速读取信息。 模块化设计 可根据不同的货架或料格尺寸定制，灵活适配各种仓储场景。 耐用性 具有抗震、防尘、防水能力，适合复杂的仓储环境。 料格电子标签的应用场景 电商仓库 大量 SKU（库存单位）的管理需要高效的拣货指引和库存更新。 制造业仓库 在生产线的物料管理中使用电子标签，实现物料的高效进出库。 冷链仓储 在低温环境下，电子标签可以正常工作，实时显示货物信息。 医药仓库 对批次和有效期管理要求严格，电子标签可精准标识和提醒。 零售仓库 快速补货和商品调拨时，电子标签能显著提高效率。 料格电子标签的优势 提高效率 减少人工操作和纸质标签更换的时间，提高操作效率。 降低出错率 实时更新信息，避免因信息滞后导致的拣货或补货错误。 节约成本 长期使用可以节省打印纸质标签的成本。 数据集成 与 WMS、ERP 等系统集成，便于数据同步和分析。 技术实现 1. 硬件部分 电子标签屏幕（电子墨水屏或 LCD）。 无线通讯模块（如 Wi-Fi 或 ZigBee）。 电池或供电模块。 2. 软件部分 与仓储管理系统（WMS）的对接。 标签信息的编辑、下发和更新。 操作指引的逻辑控制。 3. 通讯方式 常见的无线通讯方式包括 Wi-Fi、RFID、蓝牙、ZigBee 等，具体选择取决于仓库规模和应用需求。 未来发展趋势 智能化 结合 AI 和大数据分析，实现更精准的库存预测和自动化管理。 多功能化 未来的电子标签可能集成更多功能（如温湿度监控、扫码器等）。 高集成性 与更多的智能设备（如 AGV、机器人）联动，打造智能化仓储。 绿色低碳 进一步降低能耗，推动可持续发展。 总结 料格电子标签是现代仓储系统的重要技术工具，为提高仓储管理效率、降低错误率、节省成本提供了有效的解决方案。在物流、电商、制造业等领域的智能化仓储中，料格电子标签正逐步成为不可或缺的关键设备。 ","link":"https://panson.top/post/012_-shi-me-shi-liao-ge-dian-zi-biao-qian/"},{"title":"013.什么是智能仓储","content":"智能仓储 是指通过引入自动化设备、物联网（IoT）、大数据分析、人工智能（AI）、云计算等技术，实现仓储作业的高效、精准和自动化管理的一种现代化仓储模式。它是传统仓储与现代信息技术深度融合的产物，旨在提升仓储管理效率、优化资源利用、降低运营成本，同时提高供应链的灵活性和响应能力。 智能仓储的特点 自动化设备 智能仓储通常配备自动化设备，如自动化立体库（AS/RS）、AGV（自动导引车）、机器人分拣系统、传送带等，大幅减少人工作业的参与。 信息化管理 使用仓库管理系统（WMS）和仓库控制系统（WCS）来协调人、设备和资源，实时监控仓储流程中的每个环节。 数据驱动 通过传感器、RFID、条形码等技术，采集库存数据并实时上传至系统，利用大数据分析进行库存预测、作业优化和智能决策。 智能调度 依靠 AI 算法和智能调度系统，优化仓储作业路径、资源分配和任务调度，提高整体效率。 协同高效 智能仓储与供应链的上下游系统无缝集成，实现从生产、运输到销售的全链条可视化管理。 智能仓储的核心功能 库存管理 实现精准的库存实时更新，支持库存分区、批次管理、保质期跟踪等功能。 提供库存可视化，随时掌握货物位置、状态及数量。 入库管理 自动验货、扫码、分拣及上架。 结合自动化设备，优化货物摆放位置（如 ABC 分类）。 出库管理 根据订单智能分拣、打包和发货。 优化拣货路径，减少作业时间。 盘点管理 利用 RFID 或无人机实现全自动盘点。 提供库存差异分析，减少人工参与。 设备与任务调度 协调自动化设备（如 AGV、机器人）的任务分配和路径规划。 监控设备状态，提升使用效率。 智能预测 利用历史数据和 AI 算法预测库存需求，优化补货和生产计划。 智能仓储的核心技术 物联网（IoT） 使用传感器、RFID 等技术，实时采集仓库环境（如温湿度）和货物状态信息。 实现设备、货物和系统之间的互联互通。 人工智能（AI） 应用于任务调度、路径规划、库存预测等场景，提高仓储管理智能化水平。 自动化设备 包括自动化立体库、输送系统、机器人分拣系统、无人叉车等。 大数据分析 分析作业历史、库存数据、订单信息，为管理决策提供依据。 云计算 提供仓储管理系统的高效部署和扩展，支持跨地区的协同管理。 数字孪生 构建仓库的虚拟模型，实现仓储作业的可视化、模拟和优化。 智能仓储的应用场景 电商仓储 快速响应高频订单需求，提升订单处理效率。 支持海量 SKU（库存单位）的精准管理。 零售行业 实现门店和仓库之间的无缝补货和调拨。 提升库存周转率，减少库存积压。 制造业 支持原材料和成品的自动化管理。 提供生产线与仓库的高效对接。 冷链物流 实现温控环境下的高效仓储管理。 提供冷链全程的可视化监控。 医药行业 支持药品的批次管理和保质期跟踪。 满足医药行业对高精度、高安全性的要求。 智能仓储的优势 效率提升 自动化和智能化设备减少人工作业时间，提升作业效率。 准确性提高 减少人为错误，保证库存数据与实际情况的一致性。 成本节约 降低人工成本，减少货物损耗和仓储面积浪费。 可视化和预测 实现库存动态可视化，并通过预测优化仓储管理策略。 柔性化管理 适应多样化订单需求，实现仓储系统灵活调整。 智能仓储是现代供应链中不可或缺的环节，通过科技赋能，它能够显著提高仓库运作效率、降低成本并增强企业竞争力。 ","link":"https://panson.top/post/013_-shi-me-shi-zhi-neng-cang-chu/"},{"title":"014.什么是理货单","content":"理货单是仓库管理中用于指导和记录理货作业的单据或任务清单，是仓库管理系统（WMS）中重要的操作工具之一。它详细列出了需要整理、归位或调整的货物信息，帮助仓库工作人员高效完成理货工作。 理货单的作用 指导理货操作： 理货单明确列出需要理货的货物清单，包括货物的种类、规格、数量、批次、储位等信息，为工作人员提供清晰的作业指引。 记录理货结果： 在理货完成后，工作人员可以在理货单上记录实际的作业结果（如货物数量、异常情况等），用于系统更新和后续处理。 辅助库存调整： 理货单可以帮助发现库存问题，例如货物错位、差异数量等，并为库存的修正和优化提供依据。 任务分配： 在WMS中，理货单通常是系统生成的任务清单，通过分配给不同的仓库工作人员，确保理货工作有序进行。 理货单的主要内容 理货单的具体内容会因企业和WMS系统的设计不同而有些差异，但一般会包括以下信息： 信息项 说明 单据编号 理货单的唯一标识，用于跟踪和管理任务。 货物信息 包括货物名称、编号、规格、批次号、保质期（如适用）等。 计划数量 系统记录的库存数量，作为理货时的对照标准。 实际数量 理货后实际清点的货物数量。 货位信息 货物当前所在的储位或目标储位位置。 理货原因 理货任务的触发原因，如库存调整、货物错放、定期整理、分区优化等。 异常记录 在理货过程中发现的异常情况（如短缺、错位、损坏等）。 操作人员 理货任务的执行人或负责人。 任务时间 理货任务的生成时间和完成时间。 理货单的类型 根据不同的业务场景，理货单可以分为以下几种类型： 定期理货单： 用于仓库的日常维护，按照固定周期生成，进行常规整理和盘点。 异常理货单： 当发现库存异常（如数量不符、货物错位）时，生成的任务清单。 入库理货单： 在货物入库时，需要对货物进行整理、分类、归位时生成的理货单。 出库理货单： 在发货前对货物进行验证、整理、补货等操作时生成的理货单。 库位调整理货单： 当需要优化货位布局，例如根据货物周转率调整存放位置时生成的任务。 理货单在WMS系统中的流程 任务生成： WMS系统根据库存状态、操作需求或异常情况，自动生成理货单。 管理人员也可以手动创建理货单。 任务分配： 理货单分配给仓库工作人员，明确任务范围和要求。 货物整理： 工作人员根据理货单的信息（例如货位编号、货物名称等），完成货物的清点、整理、归位或调整操作。 结果记录： 将理货结果（如实际数量、异常情况等）填写到理货单中，并更新到WMS系统。 数据更新： 系统根据理货单的结果修正库存数据，完成任务闭环。 理货单的重要性 提高作业效率：提供标准化的作业指引，减少人工判断和错误。 保证库存准确性：及时发现并修正库存差异，确保系统数据与实际库存一致。 优化仓库布局：通过理货单的任务执行，实现货位的合理调整，提升仓库整体运营效率。 支持后续操作：理货单的信息可以作为盘点、补货或发货的依据。 理货单与其他单据的区别 单据类型 功能 理货单 用于指导货物整理、归位、调整，确保货物有序存放。 盘点单 用于核实库存数据的准确性，通常是对全仓或部分库存的全面清点。 入库单 用于记录货物入库的详细信息，并作为库存增加的依据。 出库单 用于记录货物出库的详细信息，并作为库存减少的依据。 总结来说，理货单是仓库管理中必不可少的一种单据，用于规范理货操作、记录理货结果和优化库存管理。通过WMS系统生成和管理理货单，可以显著提升仓库的运营效率和库存准确性。 ","link":"https://panson.top/post/014_-shi-me-shi-li-huo-dan/"},{"title":"015.什么是理货","content":"在 WMS（仓库管理系统）中，理货是指对仓库中的货物进行整理、清点、分类和优化摆放的一项重要工作，目的是确保货物在仓库内有序存放，便于后续的拣货、盘点、发货等操作。这是仓储管理中不可或缺的环节，直接影响仓库的运行效率和库存的准确性。 理货的主要内容 货物整理： 对货物进行重新分类、归位，确保货物按照既定的存储规则摆放整齐。 清除过期、损坏或多余的货物，优化仓库空间使用。 货物清点： 通过手动或系统扫描，对货物的数量、批次、规格等信息进行核实，确保与系统记录一致。 货物分类： 按照货物的属性（如种类、批次、保质期等），将货物分门别类摆放在相应的储位上。 储位优化： 根据仓库的实际情况，对货物的存放位置进行调整，例如将周转率高的商品放在靠近出入口的位置，以减少拣货时间。 异常处理： 处理在理货过程中发现的问题，如缺货、错放、货物损坏等，并及时更新系统库存。 理货的意义 提高仓库效率：通过理货，货位更加有序，拣货和盘点变得更加快速和准确。 降低差错率：理货可以及时发现库存和系统记录的差异，防止发货错误。 优化空间利用率：合理摆放货物，避免仓库空间浪费。 保障货物质量：及时处理过期、损坏的货物，减少因货物问题带来的损失。 理货在 WMS 系统中的实现 在现代的 WMS 系统中，理货通常依赖于系统功能来辅助完成。例如： 扫描设备：通过扫描条码或 RFID 标签，快速识别和核对货物信息。 任务分配：系统可以根据货物堆放情况，生成理货任务并分配给仓库员工。 库存调整：通过系统实时更新货位信息，确保库存数据的准确性。 优化建议：部分 WMS 系统能根据数据分析，提供货物摆放优化建议（如 ABC 分类法）。 理货与其他仓储作业的关系 与盘点的区别：盘点主要是对库存数量和状态的全面核对，而理货是对货物的整理与优化。 与拣货的联系：理货通常是拣货的前置工作，确保货物在正确的位置，以提高拣货效率。 总结来说，理货是仓库管理中不可忽视的环节，借助 WMS 系统，可以更高效地完成理货工作，为仓库运营打下坚实基础。 ","link":"https://panson.top/post/015_-shi-me-shi-li-huo/"},{"title":" 016.什么是盘点单","content":"在 WMS（仓库管理系统） 中，盘点单 是一种用于记录和管理仓库库存盘点的操作单据，其主要目的是确保系统中记录的库存数量与实际库存数量保持一致。盘点单在仓库管理中的作用非常重要，是库存准确性的重要保障。 盘点单的核心内容 基本信息 盘点单编号（唯一标识盘点单的编号）。 仓库信息（指定盘点的仓库或区域）。 盘点时间（盘点开始和结束的时间）。 创建人和审核人（记录负责盘点的人员）。 状态（如未开始、进行中、已完成、已作废等）。 盘点明细 物料/商品编号：需要盘点的具体物料或商品。 批次号：区分相同商品不同批次的库存。 货位信息：商品所在的具体库位或区域。 系统库存数量：系统记录的理论库存数量。 实际库存数量：盘点过程中实际统计的库存数量。 差异数量：实际库存数量与系统库存数量的差异。 盘点单的主要功能和流程 创建盘点单 系统根据库存情况自动生成盘点单（例如定期盘点或触发的临时盘点）。 人工创建盘点单，根据特定的商品、批次或货位范围指定盘点任务。 盘点任务分配 将盘点任务分配给仓库工作人员或设备（如使用手持终端 PDA）。 支持分区盘点或全仓盘点。 执行盘点 工作人员根据盘点单的任务逐一对商品进行清点，并记录实际库存数量。 支持手动输入或使用条码扫描设备快速记录数据。 差异处理 系统对比实际库存和系统库存，标记出差异项。 对差异进行分析（如漏报、账实不符等），并生成差异调整建议。 审核与调整 盘点结果需由管理员或相关负责人审核。 如果确认差异为真实情况，可以通过库存调整单进行账面库存的更新。 归档 盘点完成后，盘点单归档以供后续查询和审计。 盘点单的分类 定期盘点单 定期生成，覆盖全部库存，通常用于月末或季度盘点。 动态盘点单 随时触发，针对某些特定商品、货位或区域进行盘点（如抽样盘点）。 循环盘点单 将仓库划分为多个区域，分阶段逐步进行盘点，以减小对日常运营的影响。 临时盘点单 针对特殊事件（如商品破损、丢失或异常）引发的盘点。 盘点单的意义 提高库存准确性：发现并修正账实不符的库存差异。 降低运营风险：及时发现库存错误，避免因缺货或多货导致的业务问题。 优化仓库管理：通过盘点结果分析，发现并改进仓库管理流程中的问题。 合规性要求：满足审计和监管对库存管理的要求。 盘点单在系统中的表现 在 WMS 系统中，盘点单通常以电子单据的形式存在，支持以下功能： 盘点单据生成和跟踪。 与移动设备（PDA）联动，提高盘点效率。 实时差异分析和调整。 盘点历史的可追溯性，便于后续复查和审计。 通过盘点单，WMS 能够更好地支持仓库的高效管理，并提升库存数据的准确性和可靠性。 ","link":"https://panson.top/post/016_-shi-me-shi-pan-dian-dan/"},{"title":"017.什么是盘点","content":"在 WMS（仓库管理系统） 中，盘点 是指对仓库中的库存进行核查和清点的过程。这是为了确保系统记录的库存数量与实际库存数量保持一致，从而提高库存管理的准确性和效率。 盘点的主要目的 核实库存准确性 核对实际库存数量与系统中的记录是否一致。 发现并纠正差异 通过盘点找出库存差异（如丢失、损坏、数据错误等），并及时调整系统数据。 预防问题 通过定期盘点，可以及时发现潜在问题（如货物过期、库存短缺、积压等）。 支持决策 盘点可以为库存优化、采购计划和运营决策提供可靠的数据支持。 盘点的类型 定期盘点 在固定的时间周期内（如每月、每季度）对库存进行全面盘点。 循环盘点 按照特定的计划，对部分库存进行不定期或日常性的清点，常用于动态库存管理。 随机盘点 针对某些特定货物或特定区域进行临时盘点，通常是为了确认某些异常情况。 年度盘点 通常在财务年终时进行全面的库存清点，配合财务审计。 盘点的流程 准备工作 制定盘点计划（包括时间、范围、人员分工等）。 准备盘点工具（如扫描枪、盘点表等）。 清理盘点区域，确保货物按区域或批次存放。 实际盘点 仓库人员按照指定区域对库存逐一清点。 使用条码扫描器或手动记录货物实际数量。 数据比对 将盘点数据与WMS中的库存记录进行对比，发现差异。 差异处理 查明差异原因（如漏记、货物损坏、扫描错误等）。 更新系统库存数据，必要时调整账面记录。 盘点总结 生成盘点报告，分析库存差异及原因。 提出改进方案，优化库存管理流程。 盘点的工具和技术 条码扫描器：快速记录货物信息，减少人工错误。 RFID 技术：高效读取大量库存信息，适用于大型仓库。 移动设备：通过移动终端直接与WMS集成，实现实时数据更新。 WMS 系统支持：自动生成盘点计划、记录差异并生成报告。 盘点的意义 盘点在仓库管理中至关重要，它不仅能反映仓库运营的真实情况，还能帮助企业减少库存浪费、优化供应链，同时提升客户满意度和企业利润。 ","link":"https://panson.top/post/017_-shi-me-shi-pan-dian/"},{"title":"018.什么是货主","content":"什么是货主？ 货主（Owner）是指在供应链、仓储或物流系统中，拥有商品所有权并负责管理库存的企业或个人。在 WMS（仓库管理系统） 和 WES（仓库执行系统） 中，货主通常指的是仓库内存储的商品的真正所有者，可能是品牌商、供应商、零售商或第三方电商商家。 货主的主要特征 商品所有权：货主对其库存商品具有法律和经济上的所有权。 库存管理：货主在仓库中存储的库存受其自身管理，可能涉及独立的库存控制、批次管理、补货策略等。 订单履行：货主可以通过WMS/WES 来管理订单的拣选、打包和出库流程。 财务结算：在第三方物流（3PL） 场景下，货主可能需要与仓库运营方结算存储费、操作费、配送费等。 货主的应用场景 1. 传统企业仓库 在制造业或零售企业的自营仓库中，货主通常是企业自己，如： 某家服装品牌自营仓库存放的是该品牌的库存，货主即该品牌公司本身。 2. 第三方物流（3PL）仓库 在第三方物流仓库（如京东、顺丰等），仓库可能为多个货主提供存储和发货服务，常见货主包括： 品牌商（如耐克、阿迪达斯） 电商商家（如淘宝/拼多多店铺卖家） 分销商（如代理商） ✅ 示例： 京东物流的仓库可能存储多个品牌的商品： 耐克（Nike）是一个货主，存放耐克的鞋子和服饰。 小米（Xiaomi）是另一个货主，存放小米的手机和家电。 京东自营商品也可能作为独立货主存在。 每个货主的库存相互独立，不能混合管理。 货主在 WMS/WES 中的作用 在 WMS/WES 系统中，货主通常用于： 区分不同品牌或商家的库存 控制订单流转（避免错误调拨其他货主的库存） 财务结算（计算存储费、操作费等） 货主相关的数据字段 字段 说明 货主名称 货主的企业名称，如 &quot;耐克中国&quot; 货主编码 货主的唯一编码，如 &quot;OWN12345&quot; 货主类型 可能是品牌商、电商商家、分销商等 库存归属 该货主在仓库中的库存归属 订单归属 该货主的订单信息 结算方式 货主与仓库的结算方式（按存储费/操作费等） 总结 货主 是拥有库存所有权的企业或个人，可能是品牌商、电商商家或分销商。 在 WMS/WES 中，货主用于区分库存、管理订单和进行财务结算。 在 3PL 物流仓库中，不同货主的库存独立存储，不得混合使用。 ","link":"https://panson.top/post/018_-shi-me-shi-huo-zhu/"},{"title":"019.什么是组箱","content":"什么是组箱？ 组箱（Cartonization / Box Grouping） 是指在 WMS（仓库管理系统）或 WES（仓库执行系统） 中，按照一定规则将多个商品组合到一个或多个包装箱中，以优化包装、运输和配送的过程。 组箱的核心作用 提高包装效率：自动计算最佳装箱方案，减少人工判断。 节省包装成本：避免过多使用箱子或填充材料，提高空间利用率。 优化物流配送：减少运输中的箱子数量，降低物流成本。 提升拣选效率：减少拣选和打包过程中因不合理装箱导致的返工。 组箱的应用场景 1. 电商仓库 多个商品打包成一个快递包裹，减少运输成本。 如：京东、淘宝、亚马逊等电商订单发货时，WMS 自动计算如何最合理地装箱。 ✅ 示例： 用户下单了 1 部手机、1 个充电器、1 副耳机 如果仓库有合适的小箱子，则系统会建议使用 1 个小箱装所有商品。 如果手机盒较大，可能需要 2 个箱子 分开装。 2. 线下门店补货 仓库给门店配送商品时，WMS 根据门店订单自动计算合理的组箱方案。 如：超市订货，系统会计算如何用尽可能少的箱子装下所有商品。 3. B2B 订单（企业采购） 企业客户批量采购，仓库根据商品体积、重量、订单要求等进行组箱。 如：工厂原材料配送，WMS 计算最优组箱方式，减少运输成本。 组箱的计算逻辑 WMS/WES 在进行组箱时，通常会考虑以下因素： 商品体积、重量：避免超重或超大商品放在同一个箱子。 商品类别：易碎品单独打包，液体与固体分开等。 客户要求：某些客户要求不同商品分箱。 运输方式：航空件 vs. 陆运，箱子尺寸/重量可能有不同限制。 包装材料：选择合适的箱型、填充物，以保证安全运输。 ✅ 示例计算 订单包含：10 瓶红酒、5 包大米、2 台微波炉 WMS 可能这样分箱： 箱 1：5 瓶红酒（带缓冲材料） 箱 2：5 瓶红酒（带缓冲材料） 箱 3：5 包大米 箱 4：2 台微波炉（避免与液体混装） 组箱 vs. 波次 vs. 拣选 概念 定义 组箱（Cartonization） 计算如何最优地把商品装入箱子 波次（Wave Picking） 根据订单批量优化拣选路径 拣选（Picking） 从仓库货架上取出订单商品 📌 组箱通常发生在：订单拣选后，包装前。 总结 组箱（Cartonization） 是根据订单商品特点，计算最优的装箱方案，以减少成本、提高效率、优化运输。 组箱时，系统会考虑体积、重量、商品类别、客户要求、运输方式等因素。 组箱广泛应用于 电商仓库、门店补货、B2B 采购 等场景。 智能组箱 能帮助仓库减少人工决策，提升出库效率，优化物流成本。 ","link":"https://panson.top/post/019_-shi-me-shi-zu-xiang/"},{"title":"020.什么是取消组箱","content":"取消组箱（Uncartonization） 取消组箱（Uncartonization） 是指撤销已完成的组箱操作，将已分配到包装箱中的商品释放回订单状态，以便重新打包或调整装箱方案。 取消组箱的常见场景 订单变更：客户修改订单，需要调整商品或箱规。 拣选/包装错误：商品被错误地分配到某个箱子，需要重新调整。 箱子超重或超大：实际装箱后发现不符合物流要求，需要拆箱重组。 物流要求变化：原本要合箱运输，但客户要求分箱，或者不同快递渠道需要不同包装方式。 取消订单：订单被取消，需要将商品恢复至库存或重新拣选。 取消组箱的流程 1. 在 WMS/WES 系统中执行取消组箱操作 找到已组箱的订单或波次 选择“取消组箱”或“解除装箱” 2. 释放商品 商品从已分配的箱子中释放，回到待包装状态 可能需要重新打印标签或调整物流信息 3. 重新进行组箱（如有需要） 重新计算最优装箱方案 重新进行拣选、包装、贴标 取消组箱 vs. 重新组箱 操作 作用 取消组箱 撤销当前的装箱，将商品恢复到未打包状态 重新组箱 取消组箱后，按照新的规则重新计算装箱方案 示例 ✅ 场景 1：订单修改 原计划：客户下单 3 个商品，系统自动分配到 1 个箱子。 问题：客户临时取消其中 1 个商品。 解决：取消组箱后，重新计算箱子大小，只装 2 个商品。 ✅ 场景 2：拣选错误 原计划：订单 A 组箱 2 件衣服 + 1 双鞋 问题：拣选员误将错误尺码的鞋装入 解决：取消组箱，将错误商品退回拣选，重新装箱。 ✅ 场景 3：物流调整 原计划：系统自动将 5 个商品装入 1 个箱子发顺丰 问题：客户要求分成 2 箱发 2 个地址 解决：取消组箱后，拆分订单，重新装箱。 总结 取消组箱（Uncartonization） 允许撤销已完成的装箱操作，以便调整包装方案。 常见于订单修改、拣选错误、物流要求变更等场景。 取消组箱后，商品将回到待包装状态，可重新计算组箱方案。 在 WMS/WES 系统中，通常提供取消组箱选项，帮助操作员快速调整订单。 ","link":"https://panson.top/post/020_-shi-me-shi-qu-xiao-zu-xiang/"},{"title":"021.什么是 PDA","content":"PDA（Personal Digital Assistant，个人数字助理） 在 WMS（仓库管理系统）或 WES（仓库执行系统） 中，PDA 指的是一种 手持终端设备，用于扫描条码、执行库存管理、拣货、盘点等仓库作业。 PDA 的核心作用 扫描条码：识别商品、货位、订单等信息，确保数据准确。 拣货 &amp; 复核：引导拣货员按最优路径拣货，并进行核对。 库存盘点：扫描货架上的条码，快速记录库存信息。 入库 &amp; 出库：扫码确认货物的入库和出库，提高效率。 实时数据传输：PDA 连接 WMS，确保仓库数据实时更新。 PDA 在仓库管理中的应用 应用场景 PDA 作用 入库 扫描供应商送货条码，记录入库位置 拣货 按订单指引路径拣货，减少错误 复核 确认商品正确无误，避免错发 盘点 扫描货位，记录库存数据 出库 扫描订单信息，核对出库商品 PDA 设备的特点 带扫描功能（支持 一维码、二维码） 无线连接（Wi-Fi / 4G / 5G，实时与 WMS 交互） 坚固耐用（适应仓库环境，防水防摔） 长续航（支持长时间作业） PDA 示例 ✅ 电商仓库：拣货员用 PDA 扫描订单，按系统指引拣选商品。 ✅ 超市配送中心：PDA 扫描 商品条码，快速进行盘点。 ✅ 工厂物料管理：入库时 PDA 扫码录入 物料信息，确保精准管理。 总结 PDA 是仓库管理的重要工具，用于 扫码、拣货、盘点、出入库 等操作。 与 WMS/WES 实时连接，确保库存数据准确、订单处理高效。 适用于 电商、物流、零售、制造业 等多种场景，提高仓储效率。 ","link":"https://panson.top/post/021_-shi-me-shi-pda/"},{"title":"011.什么是批次","content":"由于不同批次的产品，在具体的属性上有区别，或出于保质期、质量追溯、库存精准管理等原因，需要对同一商品、不同批次编号，以此来进行区别。 入库时按照一定的规则生成商品批次，确定后打印带批次商品条码，贴在商品上，通过扫码枪扫码入库。出库时按照仓库需求(一般是新进先出或者近效期先出)，扫码批次商品条码出库，这个过程就叫批次管理。 参考资料 电商后台：商品库存管理之批次管理 ","link":"https://panson.top/post/011_-shi-me-shi-pi-ci/"},{"title":"010.什么是库存","content":"在 WMS（Warehouse Management System，仓库管理系统） 中，库存（Inventory）是指存放在仓库中的所有物品、材料或产品的数量和状态。库存管理是 WMS 的核心功能之一，用于记录、追踪和优化仓库中的物品流动和存储。 库存的主要内容 在 WMS 中，库存通常包括以下几个重要方面： 库存数量： 每种物品的实际数量（如件数、重量、体积等）。 分为 可用库存（可以分配给订单的库存）、占用库存（已被订单锁定但未发出的库存）和 安全库存（为应对突发需求而保留的最低库存量）。 库存位置： 明确物品在仓库中的存储位置（如货架编号、库区、库位等）。 通过库位管理，可以快速找到物品，提升拣货效率。 库存状态： 描述库存的可用性和品质，比如 正常库存、待检库存、损坏库存 或 冻结库存。 库存类型： 区分不同种类的库存，例如原材料库存、成品库存、退货库存等。 库存周转： 跟踪库存的流转频率（例如哪些物品是高频出入库的，哪些是滞销的）。 库存管理在 WMS 中的重要性 精准记录： 确保库存的数量和状态与实际情况一致，减少差异和错误。 提高效率： 帮助仓库人员快速找到物品，优化拣货、补货和盘点流程。 减少成本： 通过优化库存水平，避免过多的存货占用资金或因缺货导致的损失。 支持决策： 提供实时的库存数据，帮助企业进行采购计划、生产安排和销售策略制定。 WMS 中库存管理的功能 库存查询： 实时查看库存的数量、位置和状态。 库存盘点： 定期核实系统记录的库存是否与实际一致。 库存调整： 当发现差异时，调整库存数据以保持准确性。 库存追踪： 通过批次号、序列号、条码等追踪库存的来源和去向。 库存预警： 当库存低于安全库存或高于最大库存时，触发预警机制。 总结 库存在 WMS 中是核心管理对象，准确的库存管理能帮助企业优化供应链流程、提升客户满意度并降低运营成本。通过 WMS 系统的功能，企业可以对库存进行高效、精细化的管控。 ","link":"https://panson.top/post/010_-shi-me-shi-ku-cun/"},{"title":"开篇：供应链及其系统","content":" 供应链是围绕核心企业，通过对信息流、物流、资金流的控制，从采购原材料开始，支撑中间产品及最终产品，最后通过销售网络把产品送到消费者手中，并将供应商、制造商、分销商、零售商直到最终用户连成一个整体的网络结构和模式。 供应链子系统： 采购管理系统 中央库存系统 仓储管理系统 订单履约系统 配送管理系统 门店管理系统 供应商管理系统 商家发货系统 售后系统 统一权限系统 ","link":"https://panson.top/post/gong-ying-lian-xi-tong/"},{"title":"Panson-Weekly-024","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 53. 最大子数组和 class Solution { public int maxSubArray(int[] nums) { if(nums.length == 1) { return nums[0]; } int[] dp = new int[nums.length]; dp[0] = nums[0]; for(int i = 1; i &lt; nums.length; i++) { dp[i] = Math.max(nums[i], nums[i] + dp[i - 1]); } int ret = dp[0]; for(int i = 1; i &lt; dp.length; i++) { ret = Math.max(dp[i], ret); } return ret; } } ","link":"https://panson.top/post/panson-weekly-024/"},{"title":"Panson-Weekly-023","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 141. 环形链表 public class L0141 { /** * Definition for singly-linked list. * class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */ public class Solution { public boolean hasCycle(ListNode head) { if(head == null || head.next == null) { return false; } ListNode slow = head; ListNode fast = head; while(fast != null &amp;&amp; fast.next != null) { slow = slow.next; fast = fast.next.next; if(slow == fast) { return true; } } return false; } } } ","link":"https://panson.top/post/panson-weekly-023/"},{"title":"Panson-Weekly-022","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 237. 删除链表中的节点 class Solution01 { public void deleteNode(ListNode node) { ListNode last = node; while(node.next != null) { node.val = node.next.val; last = node; node = node.next; } last.next = null; } } class Solution02 { public void deleteNode(ListNode node) { node.val = node.next.val; node.next = node.next.next; } } ","link":"https://panson.top/post/panson-weekly-022/"},{"title":"Panson-Weekly-021","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 51. N 皇后 class Solution { public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) { List&lt;List&lt;String&gt;&gt; res = new ArrayList&lt;&gt;(); List&lt;String&gt; board = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; n; i++) { StringBuilder stb = new StringBuilder(); for (int j = 0; j &lt; n; j++) { stb.append(&quot;.&quot;); } board.add(stb.toString()); } backTrack(board, 0, res); return res; } public void backTrack(List&lt;String&gt; board, int row, List&lt;List&lt;String&gt;&gt; res) { int n = board.get(0).length(); if (row == board.size()) { res.add(new ArrayList&lt;&gt;(board)); return; } for (int col = 0; col &lt; n; col++) { if (!valid(board, row, col)) { continue; } StringBuilder cur = new StringBuilder(board.get(row)); cur.setCharAt(col, 'Q'); board.set(row, cur.toString()); backTrack(board, row + 1, res); cur.setCharAt(col, '.'); board.set(row, cur.toString()); } } public boolean valid(List&lt;String&gt; board, int row, int col) { int n = board.size(); // 检查列是否有皇后互相冲突 for (int i = 0; i &lt;= row; i++) { if (board.get(i).charAt(col) == 'Q') return false; } // 检查右上方是否有皇后互相冲突 for (int i = row - 1, j = col + 1; i &gt;= 0 &amp;&amp; j &lt; n; i--, j++) { if (board.get(i).charAt(j) == 'Q') return false; } // 检查左上方是否有皇后互相冲突 for (int i = row - 1, j = col - 1; i &gt;= 0 &amp;&amp; j &gt;= 0; i--, j--) { if (board.get(i).charAt(j) == 'Q') return false; } return true; } } 52. N 皇后 II class Solution { int res = 0; public int totalNQueens(int n) { List&lt;String&gt; board = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; n; i++) { StringBuilder stb = new StringBuilder(); for (int j = 0; j &lt; n; j++) { stb.append(&quot;.&quot;); } board.add(stb.toString()); } backTrack(board, 0); return res; } public void backTrack(List&lt;String&gt; board, int row) { int n = board.get(0).length(); if (row == board.size()) { res++; return; } for (int col = 0; col &lt; n; col++) { if (!valid(board, row, col)) { continue; } StringBuilder cur = new StringBuilder(board.get(row)); cur.setCharAt(col, 'Q'); board.set(row, cur.toString()); backTrack(board, row + 1); cur.setCharAt(col, '.'); board.set(row, cur.toString()); } } public boolean valid(List&lt;String&gt; board, int row, int col) { int n = board.size(); // 检查列是否有皇后互相冲突 for (int i = 0; i &lt;= row; i++) { if (board.get(i).charAt(col) == 'Q') return false; } // 检查右上方是否有皇后互相冲突 for (int i = row - 1, j = col + 1; i &gt;= 0 &amp;&amp; j &lt; n; i--, j++) { if (board.get(i).charAt(j) == 'Q') return false; } // 检查左上方是否有皇后互相冲突 for (int i = row - 1, j = col - 1; i &gt;= 0 &amp;&amp; j &gt;= 0; i--, j--) { if (board.get(i).charAt(j) == 'Q') return false; } return true; } } ","link":"https://panson.top/post/panson-weekly-021/"},{"title":"Panson-Weekly-020","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 239. 滑动窗口最大值 public int[] maxSlidingWindow(int[] nums, int k) { int n = nums.length; int[] res = new int[n - k + 1]; Deque&lt;Integer&gt; q = new ArrayDeque&lt;&gt;(); int index = 0; for(int i = 0; i &lt; n; i++) { while(!q.isEmpty() &amp;&amp; nums[q.peekLast()] &lt;= nums[i]) { q.pollLast(); } while(!q.isEmpty() &amp;&amp; i - q.peekFirst() &gt;= k) { q.pollFirst(); } q.offerLast(i); if(i &gt;= k - 1) { res[i - k + 1] = nums[q.peekFirst()]; } } return res; } 1438. 绝对差不超过限制的最长连续子数组 class Solution { public int longestSubarray(int[] nums, int limit) { int n = nums.length; Deque&lt;Integer&gt; max = new ArrayDeque&lt;&gt;(); Deque&lt;Integer&gt; min = new ArrayDeque&lt;&gt;(); int l = 0; int res = 0; for(int i = 0; i &lt; n; i++) { while(!max.isEmpty() &amp;&amp; nums[max.peekLast()] &lt; nums[i]) { max.pollLast(); } while(!min.isEmpty() &amp;&amp; nums[min.peekLast()] &gt; nums[i]) { min.pollLast(); } max.offerLast(i); min.offerLast(i); while(Math.abs(nums[max.peekFirst()] - nums[min.peekFirst()]) &gt; limit) { l++; if(max.peekFirst() &lt; l) { max.pollFirst(); } if(min.peekFirst() &lt; l) { min.pollFirst(); } } res = Math.max(res, i - l + 1); } return res; } } 46. 全排列 class Solution { public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); int n = nums.length; backTrace(res, nums, new ArrayList&lt;&gt;()); return res; } public void backTrace(List&lt;List&lt;Integer&gt;&gt; res, int[] nums, List&lt;Integer&gt; tmpList) { if(tmpList.size() == nums.length) { res.add(new ArrayList&lt;&gt;(tmpList)); } else { for(int i = 0; i &lt; nums.length; i++) { if(tmpList.contains(nums[i])) { continue; } tmpList.add(nums[i]); backTrace(res, nums, tmpList); tmpList.remove(tmpList.size() - 1); } } } } // 使用布尔数组优化 class Solution { public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); int n = nums.length; boolean[] used = new boolean[n]; backTrack(res, nums, new ArrayList&lt;&gt;(), used); return res; } public void backTrack(List&lt;List&lt;Integer&gt;&gt; res, int[] nums, List&lt;Integer&gt; tmpList, boolean[] used) { if(tmpList.size() == nums.length) { res.add(new ArrayList&lt;&gt;(tmpList)); return; } for(int i = 0; i &lt; nums.length; i++) { if(used[i]) { continue; } used[i] = true; tmpList.add(nums[i]); backTrack(res, nums, tmpList, used); used[i] = false; tmpList.remove(tmpList.size() - 1); } } } ","link":"https://panson.top/post/panson-weekly-020/"},{"title":"Panson-Weekly-019","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 496. 下一个更大元素 I class Solution { public int[] nextGreaterElement(int[] nums1, int[] nums2) { int[] memory = nextGreaterElement(nums2); Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for(int i = 0; i &lt; nums2.length; i++) { map.put(nums2[i], memory[i]); } int[] res = new int[nums1.length]; for(int i = 0; i &lt; nums1.length; i++) { res[i] = map.get(nums1[i]); } return res; } public int[] nextGreaterElement(int[] nums) { int n = nums.length; int[] res = new int[n]; Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); for(int i = n - 1; i &gt;= 0; i--) { while(!stack.isEmpty() &amp;&amp; stack.peek() &lt;= nums[i]) { stack.pop(); } res[i] = stack.isEmpty() ? -1 : stack.peek(); stack.push(nums[i]); } return res; } } 739. 每日温度 class Solution { public int[] dailyTemperatures(int[] temperatures) { int n = temperatures.length; int[] res = new int[n]; Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); for(int i = n - 1; i &gt;= 0; i--) { while(!stack.isEmpty() &amp;&amp; temperatures[stack.peek()] &lt;= temperatures[i]) { stack.pop(); } res[i] = stack.isEmpty() ? 0 : stack.peek() - i; stack.push(i); } return res; } } 503. 下一个更大元素 II class Solution { public int[] nextGreaterElements(int[] nums) { int n = nums.length; int[] res = new int[n]; Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); for (int i = 2 * n - 1; i &gt;= 0; i--) { while(!stack.isEmpty() &amp;&amp; stack.peek() &lt;= nums[i % n]) { stack.pop(); } res[i % n] = stack.isEmpty() ? -1 : stack.peek(); stack.push(nums[i % n]); } return res; } } 1019. 链表中的下一个更大节点 class Solution { public int[] nextLargerNodes(ListNode head) { ListNode p1 = head; int n = getLength(p1); int[] res = new int[n]; ListNode cur = head; // 栈顶是最小的元素数组映射，int[0] 为链表元素值，int[1] 为链表下标索引 Deque&lt;int[]&gt; stack = new ArrayDeque&lt;&gt;(); int i = 0; while(cur != null) { while(!stack.isEmpty() &amp;&amp; stack.peek()[0] &lt; cur.val) { int[] min = stack.pop(); res[min[1]] = cur.val; } stack.push(new int[]{cur.val, i}); i++; cur = cur.next; } return res; } public int getLength(ListNode p) { int res = 0; while(p != null) { p = p.next; res++; } return res; } } 239. 滑动窗口最大值 class Solution { public int[] maxSlidingWindow(int[] nums, int k) { // 使用大根堆，每一个元素为 &lt;index, num&gt; PriorityQueue&lt;int[]&gt; priorityQueue = new PriorityQueue&lt;&gt;((a, b) -&gt; b[1] - a[1]); int n = nums.length; int[] res = new int[n - k + 1]; int index = 0; int i = 0; while(i &lt; k) { priorityQueue.offer(new int[] {i, nums[i]}); i++; } res[index++] = priorityQueue.peek()[1]; while(i &lt; n) { priorityQueue.offer(new int[] {i, nums[i]}); while(i - priorityQueue.peek()[0] &gt;= k) { priorityQueue.poll(); } res[index++] = priorityQueue.peek()[1]; i++; } return res; } } ","link":"https://panson.top/post/panson-weekly-019/"},{"title":"Panson-Weekly-018","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 187. 重复的DNA序列 class Solution { public List&lt;String&gt; findRepeatedDnaSequences(String s) { int n = s.length(); Map&lt;String, Integer&gt; count = new HashMap&lt;&gt;(); List&lt;String&gt; ret = new ArrayList&lt;&gt;(); for(int i= 0; i + 10 &lt;= n; i++) { String cur = s.substring(i, i + 10); Integer curCount = count.getOrDefault(cur, 0); if(curCount == 1) { ret.add(cur); } count.put(cur, curCount + 1); } return ret; } } 1838. 最高频元素的频数 class Solution { public int maxFrequency(int[] nums, int k) { Arrays.sort(nums); int n = nums.length; long total = 0; int l = 0, res = 1; for (int r = 1; r &lt; n; ++r) { total += (long) (nums[r] - nums[r - 1]) * (r - l); while (total &gt; k) { total -= nums[r] - nums[l]; ++l; } res = Math.max(res, r - l + 1); } return res; } } ","link":"https://panson.top/post/panson-weekly-018/"},{"title":"Panson-Weekly-025","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 141. 环形链表 public class L0141 { /** * Definition for singly-linked list. * class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */ public class Solution { public boolean hasCycle(ListNode head) { if(head == null || head.next == null) { return false; } ListNode slow = head; ListNode fast = head; while(fast != null &amp;&amp; fast.next != null) { slow = slow.next; fast = fast.next.next; if(slow == fast) { return true; } } return false; } } } ","link":"https://panson.top/post/panson-weekly-025/"},{"title":"Panson-Weekly-017","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 1450. 在既定时间做作业的学生人数 class Solution { public int busyStudent(int[] startTime, int[] endTime, int queryTime) { int[] dif = new int[1001]; int n = startTime.length; for(int i = 0; i &lt; n; i++) { dif[startTime[i]]++; dif[endTime[i] + 1]--; } int sum = 0; for(int i = 0; i &lt; queryTime; i++) { sum += dif[i]; } return sum; } } 1094. 拼车 class Solution { public boolean carPooling(int[][] trips, int capacity) { int[] timestamp = new int[1001]; // 1001是因为题目给定了时间范围为 [0, 1000] // 记录每个时间点上的乘客数量变化 for (int[] trip : trips) { timestamp[trip[1]] += trip[0]; // 上车点增加乘客数量 timestamp[trip[2]] -= trip[0]; // 下车点减少乘客数量 } // 遍历每个时间点，检查容量是否足够 int currentCapacity = 0; for (int number : timestamp) { currentCapacity += number; if (currentCapacity &gt; capacity) { return false; } } return true; } } ","link":"https://panson.top/post/panson-weekly-017/"},{"title":"Panson-Weekly-016","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 995. K 连续位的最小翻转次数 class Solution01 { public int minKBitFlips(int[] nums, int k) { // 使用模拟暴力求解 int n = nums.length; int count = 0; for(int i = 0; i &lt; n; i++) { if(nums[i] == 0) { // 倒数第 k - 1 位为0 if(i + k &gt; n) { return -1; } for(int j = i; j &lt; i + k; j++) { nums[j] ^= 1; } count++; } } return count; } } class Solution02 { public int minKBitFlips(int[] nums, int k) { int n = nums.length; int[] diff = new int[n + 1]; int ans = 0, revCnt = 0; for (int i = 0; i &lt; n; ++i) { revCnt += diff[i]; // 若 nums[i]+revCnt 是偶数，则说明当前元素的实际值为 0 if ((nums[i] + revCnt) % 2 == 0) { if (i + k &gt; n) { return -1; } ++ans; ++revCnt; --diff[i + k]; } } return ans; } } 1109. 航班预订统计 class Solution { public int[] corpFlightBookings(int[][] bookings, int n) { int[] dif = new int[n + 1]; for(int[] booking : bookings) { int l = booking[0] - 1; int r = booking[1] - 1; dif[l] += booking[2]; dif[r + 1] -= booking[2]; } int[] ret = new int[n]; ret[0] = dif[0]; for(int i = 1; i &lt; n; i ++) { ret[i] = ret[i - 1] + dif[i]; } return ret; } } ","link":"https://panson.top/post/panson-weekly-016/"},{"title":"Panson-Weekly-015","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) +1094. 拼车 class Solution { public boolean carPooling(int[][] trips, int capacity) { int[] timestamp = new int[1001]; // 1001是因为题目给定了时间范围为 [0, 1000] // 记录每个时间点上的乘客数量变化 for (int[] trip : trips) { timestamp[trip[1]] += trip[0]; // 上车点增加乘客数量 timestamp[trip[2]] -= trip[0]; // 下车点减少乘客数量 } // 遍历每个时间点，检查容量是否足够 int currentCapacity = 0; for (int number : timestamp) { currentCapacity += number; if (currentCapacity &gt; capacity) { return false; } } return true; } } ","link":"https://panson.top/post/panson-weekly-015/"},{"title":"Panson-Weekly-014","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 151. 反转字符串中的单词 class Solution { public String reverseWords(String s) { s = s.trim(); int r = s.length() - 1; int l = r; StringBuilder str = new StringBuilder(); while (l &gt;= 0) { while (l &gt;= 0 &amp;&amp; s.charAt(l) != ' ') { l--; } str.append(s.substring(l + 1, r + 1)).append(&quot; &quot;); while (l &gt;= 0 &amp;&amp; s.charAt(l) == ' ') { l--; } r = l; } return str.toString().trim(); } } 48. 旋转图像 class Solution { public void rotate(int[][] matrix) { int n = matrix.length; // 对角线翻转 for(int i = 0; i &lt; n; i++) { for(int j = i; j &lt; n; j++) { int tmp = matrix[i][j]; matrix[i][j] = matrix[j][i]; matrix[j][i] = tmp; } } // 翻转每一行 for(int i = 0; i &lt; n; i++) { for(int j = 0; j &lt; n / 2; j++) { int tmp = matrix[i][j]; matrix[i][j] = matrix[i][n - 1 - j]; matrix[i][n - 1 - j] = tmp; } } } } 54. 螺旋矩阵 ","link":"https://panson.top/post/panson-weekly-014/"},{"title":"RocketMQ 事务消息源码阅读","content":" 01 总体概述 这里我将以「RocketMQ 5.1.2」版本为主，通过「场景驱动」的方式带大家一点点的对 RocketMQ 源码进行深度剖析 02 事务消息使用场景 2.1 单体架构下的事务 在单体系统的开发过程中，假如某个场景下需要对数据库的多张表进行操作，为了保证数据的一致性，一般会使用事务，将所有的操作全部提交或者在出错的时候全部回滚。 这里以创建订单为例，假设下单后需要做两个操作： 在订单表生成订单。 在积分表增加本次订单增加的积分记录。 在单体架构下只需使用 @Transactional 开启事务，就可以保证数据的一致性： @Transactional public void order() { String orderId = UUID.randomUUID().toString(); // 生成订单 orderService.createOrder(orderId); // 增加积分 creditService.addCredits(orderId); } 然而现在越来越多系统开始使用分布式架构，在分布式架构下，「订单系统」和「积分系统」可能是两个独立的服务，此时就不能使用上述的方法开启事务了，因为它们不处于同一个事务中，在出错的情况下无法进行全部回滚，只能对当前服务的事务进行回滚，所以就有可能出现「订单生成成功」但是「积分服务增加积分失败」的情况，此时数据处于不一致的状态。 2.2 分布式架构下的事务 分布式架构下如果需要「保证事务一致性」，需要使用分布式事务，分布式事务的实现方式有多种，这里我们先看通过 RocketMQ 事务的实现方式。 同样以下单流程为例，在分布式架构下的处理流程如下： 订单服务生成订单。 发送订单生成的 MQ 消息，积分服务订阅消息，有新的订单生成之后消费消息，增加对应的积分记录。 2.2.1 普通MQ事务消息存在的问题 如果使用 [@Transactional + 发送普通MQ](http://xn--transactional + mq-1q41bp14yehrkvsa/) 的方式，看下存在的问题： 假如订单创建成功，MQ 消息发送成功，但是 order 方法在返回的前一刻服务突然宕机，由于开启了事务，事务还未提交（方法结束后才会正常提交），所以订单表并未生成记录，但是 MQ 却已经发送成功并且被积分服务消费，此时就会存在订单未创建但是积分记录增加的情况。 假如先发送 MQ 消息再创建订单呢，此时问题就更明显了，如果 MQ 消息发送成功，创建订单失败，那么同样处于不一致的状态。 @Transactional public void order() { String orderId = UUID.randomUUID().toString(); // 创建订单 Order order = orderService.createOrder(orderDTO.getOrderId()); // 发送订单创建的MQ消息 sendOrderMessge(order); return; } 要彻底解决上述问题的方式就是使用 RocketMQ 事务消息。 2.2.2 RocketMQ 事务消息 使用「事务消息」需要实现「自定义的事务监听器」： TransactionListener 提供了「本地事务执行」和「状态回查」的接口。 executeLocalTransaction 方法用于执行「本地事务」。 checkLocalTransaction 是一种补偿机制，在异常情况下如果未收到事务的提交请求，会调用此方法进行事务状态查询，以此决定是否将事务进行提交/回滚。 public interface TransactionListener { /** * 执行本地事务 * * @param msg Half(prepare) message half消息 * @param arg Custom business parameter * @return Transaction state */ LocalTransactionState executeLocalTransaction(final Message msg, final Object arg); /** * 本地事务状态回查 * * @param msg Check message * @return Transaction state */ LocalTransactionState checkLocalTransaction(final MessageExt msg); } 这里我们实现自定义的事务监听器 OrderTransactionListenerImpl: [executeLocalTransaction](http://executelocaltransaction /) 方法中创建订单，如果创建成功返回 COMMIT_MESSAGE，如果出现异常返回ROLLBACK_MESSAGE。 checkLocalTransaction 方法中回查事务状态，根据消息体中的订单 ID 查询订单是否已经创建。 如果创建成功提交事务。 如果未获取到认为失败，此时回滚事务。 public class OrderTransactionListenerImpl implements TransactionListener { @Autowired private OrderService orderService; // 执行本地事务 @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) { try { // 生成消息体 String body = new String(msg.getBody(), Charset.forName(&quot;UTF-8&quot;)); OrderDTO orderDTO = JSON.parseObject(body, OrderDTO.class); // 模拟生成订单 orderService.createOrder(orderDTO.getOrderId()); } catch (Exception e) { // 出现异常，返回回滚状态 return LocalTransactionState.ROLLBACK_MESSAGE; } // 创建成功，返回提交状态 return LocalTransactionState.COMMIT_MESSAGE; } // 检查本地事务 @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) { String body = new String(msg.getBody(), Charset.forName(&quot;UTF-8&quot;)); OrderDTO orderDTO = JSON.parseObject(body, OrderDTO.class); try { // 根据订单ID查询订单是否存在 Order order = orderService.getOrderByOrderId(orderDTO.getOrderId()); if (null != order) { // 提交事务 return LocalTransactionState.COMMIT_MESSAGE; } } catch (Exception e) { // 回滚事务 return LocalTransactionState.ROLLBACK_MESSAGE; } // 回滚事务 return LocalTransactionState.ROLLBACK_MESSAGE; } } 接下来我们来看下「如何发送事务消息」的，事务消息对应的生产者为 TransactionMQProducer，创建TransactionMQProducer 之后，设置上一步自定义的事务监听器 OrderTransactionListenerImpl，然后将订单 ID放入消息体中， 调用 sendMessageInTransaction 发送事务消息： public class TransactionProducer { public static void main(String[] args) throws MQClientException, InterruptedException { // 创建下单事务监听器 TransactionListener transactionListener = new OrderTransactionListenerImpl(); // 创建生产者 TransactionMQProducer producer = new TransactionMQProducer(&quot;order_group&quot;); // 事务状态回查线程池 ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2000), new ThreadFactory() { @Override public Thread newThread(Runnable r) { Thread thread = new Thread(r); thread.setName(&quot;client-transaction-msg-check-thread&quot;); return thread; } }); // 设置线程池 producer.setExecutorService(executorService); // 设置事务监听器 producer.setTransactionListener(transactionListener); // 启动生产者 producer.start(); try { // 创建订单消息 OrderDTO orderDTO = new OrderDTO(); // 模拟生成订单唯一标识 orderDTO.setOrderId(UUID.randomUUID().toString()); // 转为字节数组 byte[] msgBody = JSON.toJSONString(orderDTO).getBytes(RemotingHelper.DEFAULT_CHARSET); // 构建消息 Message msg = new Message(&quot;ORDER_TOPIC&quot;, msgBody); // 调用 sendMessageInTransaction 发送事务消息 SendResult sendResult = producer.sendMessageInTransaction(msg, null); System.out.printf(sendResult.toString()); // 休息10s Thread.sleep(10); } catch (MQClientException | UnsupportedEncodingException e) { e.printStackTrace(); } for (int i = 0; i &lt; 100000; i++) { Thread.sleep(1000); } producer.shutdown(); } } 整个的执行流程： 在订单服务下单后，向 Borker 发送生成订单的事务消息，投递到 ORDER_TOPIC 主题中。 Broker 收到事务消息之后，不会直接投递到 ORDER_TOPIC 主题中，而是先放在另外一个主题中，也叫 [half 主题](http://xn--half -t73k1046c/)，half 主题对消费者不可见。 half 主题加入消息成功之后，会回调事务监听器的的 executeLocalTransaction 方法，执行本地事务也就是订单创建，如果创建成功返回 COMMIT 状态，如果出现异常返回 ROLLBACK 状态。 根据上一步的返回状态进行结束事务的处理。 提交：从 [half 主题](http://xn-- half -jy2p2252e/) 中删除消息，然后将消息投送到 ORDER_TOPIC 主题中，积分服务订阅 ORDER_TOPIC 主题进行消费，生成积分记录。 回滚：从 half主题 中删除消息即可。 如果本地事务返回的执行结果状态由于网络原因或者其他原因未能成功的发送给 Broker，Broker 未收到事务的执行结果，在补偿机制定时检查 half主题 中消息的事务执行状态时，会回调事务监听器 checkLocalTransaction 的接口，进行状态回查，判断订单是否创建成功，然后进行结束事务的处理。 03 事务消息实现原理 在 RocketMQ 4.3.0 版中开始支持事务消息，它通过使用「两阶段 2PC 提交协议」来实现事务消息，同时增加「补偿机制」定时对事务的状态进行回查，来处理「未提交/回滚」的事务。 发送事务消息分为两个阶段： 第一阶段：生产者向 Broker 发送 half（prepare） 消息，生产者发送事务消息的时候，消息不会直接存入对应的主题中，而是先将消息存入 RMQ_SYS_TRANS_HALF_TOPIC 主题中，此时消息对「消费者不可见」不能被消费者消费，称为 [half 消息](http://xn--half -yn4n665g/)，half 消息发送成功之后，开始执行本地事务。 第二阶段：提交阶段，根据第一阶段的本地事务执行结果来决定是提交事务还是回滚事务，提交或者回滚的事务会从RMQ_SYS_TRANS_HALF_TOPIC 中删除，对于提交的事务消息，会将消息投送到实际的主题队列中，之后消费者可以从队列中拉取到消息进行消费，对于回滚的事务消息，直接从 RMQ_SYS_TRANS_HALF_TOPIC 主题中删除即可。 注意：由于 RocketMQ 追加写的性能并不会直接从 RMQ_SYS_TRANS_HALF_TOPIC 队列中删除消息，而是使用了另外一个队列，将已提交或者回滚的事务放入到 OP 队列中，在补偿机制对 [half 消息](http://xn--half -yn4n665g/)进行检查的时候会从 OP 中判断是消息是否「已提交」或者「回滚」。 3.1 补偿机制 两阶段提交事务的过程中，任一阶段出现异常都有可能导致事务未能成功的进行「提交」或者「回滚」，所以需要增加「补偿机制」来定时对 RMQ_SYS_TRANS_HALF_TOPIC 主题中的 half 消息 进行处理。 RocketMQ 使用了一种「回查机制」，在处理 [half 消息](http://xn--half -yn4n665g/)时，对该消息的「本地事务」执行状态进行回查，根据回查结果决定是否需要「提交」或者「回滚」，或者是等待下一次回查。 接下来我们就从源码的角度研究一下事务的实现原理。 整个事务消息的处理流程，可以分为以下五大步骤： Half 消息发送过程 Half 消息存储过程 提交事务状态过程 处理事务状态过程 事务回查过程 更新消费进度 ![img](images/RocketMQ 事务消息源码阅读/FsfRbAPhADHdZUb7dpFzVMnc81g7.jpeg) ** ** 3.2 Half 消息发送过程 [TransactionMQProducer](http://transactionmqproducer /) 是 RocketMQ 提供的支持发送事务消息的生产者，它继承自 DefaultMQProducer，也是一个外观类，非常的简单，核心逻辑依然在 DefaultMQProducerImpl，属性如下： public class TransactionMQProducer extends DefaultMQProducer { // 事务回查监听 private TransactionCheckListener transactionCheckListener; // 回查线程池最小线程数 private int checkThreadPoolMinSize = 1; // 回查线程池最大线程数 private int checkThreadPoolMaxSize = 1; // 最大回查请求数，阻塞队列容量 private int checkRequestHoldMax = 2000; // 执行本地事务/事务回查的线程池 private ExecutorService executorService; // 事务监听器:本地事务、事务回查逻辑 private TransactionListener transactionListener; .... } 启动 TransactionMQProducer 必须先注册 TransactionListener，实现「本地事务的执行逻辑」和「事务回查逻辑」，Producer 在发送 [half 消息](http://xn--half -yn4n665g/) 成功后会自动执行 executeLocalTransaction，在 Broker 请求事务回查时自动执行 checkLocalTransaction。 然后，Producer 就可以启动了，在启动默认 Producer 之前，会对 checkExecutor 和 checkRequestQueue 进行初始化，如果没有设置线程池会自动创建。 public class DefaultMQProducerImpl implements MQProducerInner { /** * 初始化事务 env */ public void initTransactionEnv() { // 强制转换成事务生产者 TransactionMQProducer producer = (TransactionMQProducer) this.defaultMQProducer; if (producer.getExecutorService() != null) { this.checkExecutor = producer.getExecutorService(); } else { // 事务回查请求队列 this.checkRequestQueue = new LinkedBlockingQueue&lt;&gt;(producer.getCheckRequestHoldMax()); // 事务回查线程池 this.checkExecutor = new ThreadPoolExecutor( producer.getCheckThreadPoolMinSize(), producer.getCheckThreadPoolMaxSize(), 1000 * 60, TimeUnit.MILLISECONDS, this.checkRequestQueue); } } } 初始化完成以后，就是 Producer 的正常启动逻辑，这里不再赘述。通过上面得出，发送事务消息调用的是 TransactionMQProducer#sendMessageInTransaction 方法： public class TransactionMQProducer extends DefaultMQProducer { @Override public TransactionSendResult sendMessageInTransaction(final Message msg, final Object arg) throws MQClientException { if (null == this.transactionListener) { throw new MQClientException(&quot;TransactionListener is null&quot;, null); } // 设置 topic msg.setTopic(NamespaceUtil.wrapNamespace(this.getNamespace(), msg.getTopic())); // 发送事务消息 return this.defaultMQProducerImpl.sendMessageInTransaction(msg, null, arg); } } public class DefaultMQProducerImpl implements MQProducerInner { // 发送事务消息 public TransactionSendResult sendMessageInTransaction(final Message msg, final LocalTransactionExecuter localTransactionExecuter, final Object arg) throws MQClientException { // 获取事务监听器 TransactionListener transactionListener = getCheckListener(); // 判断检查本地事务 Listener 是否存在 if (null == localTransactionExecuter &amp;&amp; null == transactionListener) { throw new MQClientException(&quot;tranExecutor is null&quot;, null); } SendResult sendResult = null; // 设置 prepared 属性 MessageAccessor.putProperty(msg, MessageConst.PROPERTY_TRANSACTION_PREPARED, &quot;true&quot;); // 设置生产者组 MessageAccessor.putProperty(msg, MessageConst.PROPERTY_PRODUCER_GROUP, this.defaultMQProducer.getProducerGroup()); try { // 发送消息 sendResult = this.send(msg); } catch (Exception e) { throw new MQClientException(&quot;send message Exception&quot;, e); } // 本地事务状态 LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW; Throwable localException = null; switch (sendResult.getSendStatus()) { // 判断消息发送状态 case SEND_OK: { // 如果发送成功 try { if (null != localTransactionExecuter) { // 如果本地事务执行器不为空 // 执行本地事务 localTransactionState = localTransactionExecuter.executeLocalTransactionBranch(msg, arg); } else if (transactionListener != null) { // 如果事务监听器不为空 log.debug(&quot;Used new transaction API&quot;); // 执行本地事务 localTransactionState = transactionListener.executeLocalTransaction(msg, arg); } if (null == localTransactionState) { // 如果本地事务状态为空，设置为 UNKNOW localTransactionState = LocalTransactionState.UNKNOW; } } catch (Throwable e) { log.info(&quot;executeLocalTransactionBranch exception&quot;, e); log.info(msg.toString()); localException = e; } } break; case FLUSH_DISK_TIMEOUT: case FLUSH_SLAVE_TIMEOUT: case SLAVE_NOT_AVAILABLE: localTransactionState = LocalTransactionState.ROLLBACK_MESSAGE; // 本地事务状态设置为回滚 break; default: break; } try { // 结束事务 // 如果半消息发送失败或本地事务执行失败告诉服务端是删除半消息， // 半消息发送成功且本地事务执行成功则告诉 broker 提交半消息 this.endTransaction(msg, sendResult, localTransactionState, localException); } catch (Exception e) { log.warn(&quot;local transaction execute &quot; + localTransactionState + &quot;, but end broker transaction failed&quot;, e); } return transactionSendResult; } } sendMessageInTransaction 在 DefaultMQProducerImpl 中实现，主要有以下几个步骤： 获取事务监听器 TransactionListener，如果获取为空或者本地事务执行器 LocalTransactionExecuter 为空将抛出异常，因为需要通过 TransactionListener 或者 LocalTransactionExecuter 来执行本地事务，所以不能为空。 在消息中设置 prepared 属性，此时与普通消息（非事务消息）相比多了 PROPERTY_TRANSACTION_PREPARED 属性 调用 send 方法发送 prepared 消息也就是 half 消息，发送消息的流程与普通消息一致。 根据消息的发送结果判断： 如果发送成功执行本地事务，并返回本地事务执行结果状态，如果返回的执行状态结果为空，将本地事务状态设置为UNKNOW。 发送成功之外的其他情况，包括 FLUSH_DISK_TIMEOUT 刷盘超时、FLUSH_SLAVE_TIMEOUT 和SLAVE_NOT_AVAILABLE 从节点不可用三种情况，此时意味着 half 消息 发送失败，本地事务状态置为ROLLBACK_MESSAGE 回滚消息。 调用 endTransaction 方法结束事务。 这里需要注意：事务消息不支持延时，会在发送前自动忽略延迟级别。 Broker 端判断是否是事务消息的依据是通过 PROPERTY_TRANSACTION_PREPARED 属性判断的，Producer 在发送消息前会进行设置。 消息属性设置完毕，调用 send 方法同步发送给 Broker，并获取发送状态。 3.3 Half 消息存储过程 [half 消息 ](http://xn--half -0s4ti33j/)发送到 Broker，Broker 要负责存储，且此时消息对 Consumer 是不可见的，看看它是如何处理的。 在 Broker 对消息发送请求的处理在 SendMessageProcessor 中，当 Broker 收到消息后，判断消息是否含有PROPERTY_TRANSACTION_PREPARED 属性，如果含有 prepared 属性，会转交给TransactionalMessageService 进行处理，然后调用 asyncPrepareMessage 对消息进行处理，普通消息直接转交给 [MessageStore](http://messagestore /) 处理， 如下图： 这里的重点是调用 TransactionalMessageService#asyncPrepareMessage，我们接着来剖析。 源码位置：https://github.com/apache/rocketmq/blob/release-5.1.2/store/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageServiceImpl.java 3.3.1 异步处理 Prepare 消息 public class TransactionalMessageServiceImpl implements TransactionalMessageService { @Override public CompletableFuture&lt;PutMessageResult&gt; asyncPrepareMessage(MessageExtBrokerInner messageInner) { // 添加 half 消息 return transactionalMessageBridge.asyncPutHalfMessage(messageInner); } } 可以看到这里又调用了 TransactionalMessageBridge#asyncPutHalfMessage 方法来「添加 half 消息」。 3.3.2 添加 Half 消息 [TransactionalMessageService](http://transactionalmessageservice /) 使用了「桥接模式」，大部分操作会交给桥接类 [TransactionalMessageBridge](http://transactionalmessagebridge /) 执行。在处理 Half消息 时，为了不让 Consumer 可见，会像处理延迟消息一样，改写 Topic 和 queueId，将消息统一扔到 RMQ_SYS_TRANS_HALF_TOPIC 这个 Topic 下，默认的 queueId 为 0。同时为了后续消息 Commit 时重新写入正常消息，必须将真实的 Topic 和 queueId 等属性预先保留到 Properties 中。 public class TransactionalMessageBridge { /** * 异步写入 Half 消息 * @param messageInner * @return */ public CompletableFuture&lt;PutMessageResult&gt; asyncPutHalfMessage(MessageExtBrokerInner messageInner) { // 异步添加消息 return store.asyncPutMessage(parseHalfMessageInner(messageInner)); } /** * 解析 Half 消息 * @param msgInner * @return */ private MessageExtBrokerInner parseHalfMessageInner(MessageExtBrokerInner msgInner) { // 计算唯一id String uniqId = msgInner.getUserProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (uniqId != null &amp;&amp; !uniqId.isEmpty()) { MessageAccessor.putProperty(msgInner, TransactionalMessageUtil.TRANSACTION_ID, uniqId); } // 真实的 Topic 和 queueId 存储到 Properties MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_TOPIC, msgInner.getTopic()); MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msgInner.getQueueId())); // 设置系统 flag msgInner.setSysFlag( MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), MessageSysFlag.TRANSACTION_NOT_TYPE)); // 设置事务主题 RMQ_SYS_TRANS_HALF_TOPIC msgInner.setTopic(TransactionalMessageUtil.buildHalfTopic()); // 设置事务队列ID msgInner.setQueueId(0); msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties())); return msgInner; } } public class TransactionalMessageUtil { public static String buildHalfTopic() { // half 消息主题 return TopicValidator.RMQ_SYS_TRANS_HALF_TOPIC; } } public class TopicValidator { public static final String RMQ_SYS_TRANS_HALF_TOPIC = &quot;RMQ_SYS_TRANS_HALF_TOPIC&quot;; } 在 asyncPutHalfMessage 方法中，调用了 parseHalfMessageInner 方法设置 [half 消息](http://xn--half -yn4n665g/) 的相关属性。 正因为是 half 消息，此时还「不能直接加入」到「实际的消息队列」中，否则一旦加入就会被消费者消费，所以需要先对 half消息 进行「暂存」，等收到消息提交请求时才可以添加到实际的消息队列中，在 RocketMQ 中设置了一个 RMQ_SYS_TRANS_HALF_TOPIC 主题来暂存 half消息。 来看下 parseHalfMessageInner 方法对消息进行的处理： 设置消息实际的主题和队列 ID，待收到事务提交请求后恢复实际的主题和队列 ID，向实际的队列中添加消息。 更改消息的主题为 half 消息主题 RMQ_SYS_TRANS_HALF_TOPIC，先将消息投送到 half 消息队列中。 half Topic 对应的消息队列 ID 为 0，所以更改消息的队列 ID 为 0。 消息的 [Topic](http://topic /) 被改写后，正常写入 CommitLog，但此时不会对 Consumer 可见。之后调用 asyncPutMessage 进行异步添加消息，接下来的流程就和普通消息的添加基本一致了，具体可点击：【Broker端源码分析系列第十六篇】图解 RocketMQ 源码之 Broker MessageStore 存储架构。 3.4 提交事务状态过程 Broker 将消息写入 CommitLog 后，会返回结果 SendResult，如果发送成功，Producer 开始执行本地事务： 在进行了 half消息 「发送」和「执行本地事务」的操作后，消息暂存在 Broker 的 half主题 中，接下来生产者需要根据本地事务的执行状态结果 LocalTransactionState，向 Broker 发送结束事务的请求，结束事务的方法 endTransaction 也是在 DefaultMQProducerImpl 中实现。 3.4.1 生产者发送结束事务消息 先根据 [MessageQueue](http://messagequeue /) 找到 Broker 的主机地址，然后构建提交事务请求头 [EndTransactionRequestHeader](http://endtransactionrequestheader /) 并设置相关属性，请求头属性如下： 事务状态 [commitOrRollback](http://commitorrollback /) 用数字表示，8 代表 Commit、12 代表 Rollback、0 代表未知状态。请求头构建好以后，通过 Netty 发送数据包给 Broker，对应的 RequestCode 为 END_TRANSACTION。 public class DefaultMQProducerImpl implements MQProducerInner { /** * 结束事务消息 * @param msg * @param sendResult * @param localTransactionState * @param localException * @throws RemotingException * @throws MQBrokerException * @throws InterruptedException * @throws UnknownHostException */ public void endTransaction( final Message msg, final SendResult sendResult, final LocalTransactionState localTransactionState, final Throwable localException) throws RemotingException, MQBrokerException, InterruptedException, UnknownHostException { // 消息 final MessageId id; // 解析 MessageId，内含消息 Offset if (sendResult.getOffsetMsgId() != null) { id = MessageDecoder.decodeMessageId(sendResult.getOffsetMsgId()); } else { id = MessageDecoder.decodeMessageId(sendResult.getMsgId()); } // 获取事务ID String transactionId = sendResult.getTransactionId(); final String destBrokerName = this.mQClientFactory.getBrokerNameFromMessageQueue(defaultMQProducer.queueWithNamespace(sendResult.getMessageQueue())); // 获取 MessageQueue 所在 Broker 的 Master 主机地址 final String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(destBrokerName); // 创建结束事务请求头 EndTransactionRequestHeader requestHeader = new EndTransactionRequestHeader(); // 设置事务ID requestHeader.setTransactionId(transactionId); // 设置 commitLog 偏移量 requestHeader.setCommitLogOffset(id.getOffset()); // 设置 broker name requestHeader.setBname(destBrokerName); // 设置本地事务状态 switch (localTransactionState) { case COMMIT_MESSAGE: // 提交事务消息 requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE); break; case ROLLBACK_MESSAGE: // 提交事务消息 requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE); break; case UNKNOW: // 未知 requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE); break; default: break; } doExecuteEndTransactionHook(msg, sendResult.getMsgId(), brokerAddr, localTransactionState, false); requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup()); requestHeader.setTranStateTableOffset(sendResult.getQueueOffset()); requestHeader.setMsgId(sendResult.getMsgId()); String remark = localException != null ? (&quot;executeLocalTransactionBranch exception: &quot; + localException.toString()) : null; // 发送结束事务的请求 this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, requestHeader, remark, this.defaultMQProducer.getSendMsgTimeout()); } } 构建结束事务的请求头 EndTransactionRequestHeader。 判断本地事务执行状态： COMMIT_MESSAGE：表示提交事务，结束事务的请求头中设置 TRANSACTION_COMMIT_TYPE 标识进行事务提交。 ROLLBACK_MESSAGE：表示回滚事务，请求头中设置 TRANSACTION_ROLLBACK_TYPE 标识进行事务回滚。 UNKNOW：事务执行结果未知状态，请求头中设置 TRANSACTION_NOT_TYPE 标识未知状态的事务。 最后调用 endTransactionOneway 向 Broker 发送结束事务的请求。 3.5 处理事务状态过程 源码位置：https://github.com/apache/rocketmq/blob/release-5.1.2/store/src/main/java/org/apache/rocketmq/broker/processor/EndTransactionProcessor.java Broker 端通过 [EndTransactionProcessor](http://endtransactionprocessor /) 类来处理 [Producer](http://producer /) 提交的事务请求。 /** * Broker 端处理结束事务请求 * @param ctx * @param request * @return * @throws RemotingCommandException */ @Override public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException { // 创建结束事务响应 final RemotingCommand response = RemotingCommand.createResponseCommand(null); // 解析结束事务请求头 final EndTransactionRequestHeader requestHeader = (EndTransactionRequestHeader) request.decodeCommandCustomHeader(EndTransactionRequestHeader.class); LOGGER.debug(&quot;Transaction request:{}&quot;, requestHeader); // 如果是从节点，从节点没有结束事务的权限，返回 SLAVE_NOT_AVAILABLE if (BrokerRole.SLAVE == brokerController.getMessageStoreConfig().getBrokerRole()) { response.setCode(ResponseCode.SLAVE_NOT_AVAILABLE); LOGGER.warn(&quot;Message store is slave mode, so end transaction is forbidden. &quot;); return response; } // 请求头处理 if (requestHeader.getFromTransactionCheck()) { // 根据提交或回滚的标记进行不同的处理 switch (requestHeader.getCommitOrRollback()) { // 如果标记为等待确认类型的话，记录警告日志 case MessageSysFlag.TRANSACTION_NOT_TYPE: { LOGGER.warn(&quot;Check producer[{}] transaction state, but it's pending status.&quot; + &quot;RequestHeader: {} Remark: {}&quot;, RemotingHelper.parseChannelRemoteAddr(ctx.channel()), requestHeader.toString(), request.getRemark()); return null; } // 如果标记为提交类型的话，记录警告日志 case MessageSysFlag.TRANSACTION_COMMIT_TYPE: { LOGGER.warn(&quot;Check producer[{}] transaction state, the producer commit the message.&quot; + &quot;RequestHeader: {} Remark: {}&quot;, RemotingHelper.parseChannelRemoteAddr(ctx.channel()), requestHeader.toString(), request.getRemark()); break; } // 如果标记为回滚类型的话，记录警告日志 case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: { LOGGER.warn(&quot;Check producer[{}] transaction state, the producer rollback the message.&quot; + &quot;RequestHeader: {} Remark: {}&quot;, RemotingHelper.parseChannelRemoteAddr(ctx.channel()), requestHeader.toString(), request.getRemark()); break; } default: return null; } } else { // 根据提交或回滚的标记进行不同的处理 switch (requestHeader.getCommitOrRollback()) { // 如果标记为等待确认类型的话，记录警告日志 case MessageSysFlag.TRANSACTION_NOT_TYPE: { LOGGER.warn(&quot;The producer[{}] end transaction in sending message, and it's pending status.&quot; + &quot;RequestHeader: {} Remark: {}&quot;, RemotingHelper.parseChannelRemoteAddr(ctx.channel()), requestHeader.toString(), request.getRemark()); return null; } // 对于提交类型的标记不进行任何处理 case MessageSysFlag.TRANSACTION_COMMIT_TYPE: { break; } // 如果标记为回滚类型的话，记录警告日志 case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: { LOGGER.warn(&quot;The producer[{}] end transaction in sending message, rollback the message.&quot; + &quot;RequestHeader: {} Remark: {}&quot;, RemotingHelper.parseChannelRemoteAddr(ctx.channel()), requestHeader.toString(), request.getRemark()); break; } default: return null; } } // 处理结果集 OperationResult result = new OperationResult(); // 判断事务提交类型，如果是提交事务 if (MessageSysFlag.TRANSACTION_COMMIT_TYPE == requestHeader.getCommitOrRollback()) { // 提交事务消息 result = this.brokerController.getTransactionalMessageService().commitMessage(requestHeader); if (result.getResponseCode() == ResponseCode.SUCCESS) { if (rejectCommitOrRollback(requestHeader, result.getPrepareMessage())) { response.setCode(ResponseCode.ILLEGAL_OPERATION); LOGGER.warn(&quot;Message commit fail [producer end]. currentTimeMillis - bornTime &gt; checkImmunityTime, msgId={},commitLogOffset={}, wait check&quot;, requestHeader.getMsgId(), requestHeader.getCommitLogOffset()); return response; } // 校验 Prepare 消息 RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); if (res.getCode() == ResponseCode.SUCCESS) { // 结束事务，创建新的Message，恢复真实的 Topic、queueId 等属性，重新写入 CommitLog MessageExtBrokerInner msgInner = endMessageTransaction(result.getPrepareMessage()); msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), requestHeader.getCommitOrRollback())); msgInner.setQueueOffset(requestHeader.getTranStateTableOffset()); msgInner.setPreparedTransactionOffset(requestHeader.getCommitLogOffset()); msgInner.setStoreTimestamp(result.getPrepareMessage().getStoreTimestamp()); MessageAccessor.clearProperty(msgInner, MessageConst.PROPERTY_TRANSACTION_PREPARED); // 调用 sendFinalMessage 方法将消息重新写入 CommitLog RemotingCommand sendResult = sendFinalMessage(msgInner); if (sendResult.getCode() == ResponseCode.SUCCESS) { /** * 事务消息提交，删除 Half 消息 * Half消息不会真的被删除，通过写入 Op 消息来标记它被处理。 */ this.brokerController.getTransactionalMessageService(). deletePrepareMessage(result.getPrepareMessage()); } return sendResult; } return res; } } else if (MessageSysFlag.TRANSACTION_ROLLBACK_TYPE == requestHeader.getCommitOrRollback()) { // 如果是回滚 // 回滚事务消息，事实上没做任何处理 result = this.brokerController.getTransactionalMessageService().rollbackMessage(requestHeader); if (result.getResponseCode() == ResponseCode.SUCCESS) { if (rejectCommitOrRollback(requestHeader, result.getPrepareMessage())) { response.setCode(ResponseCode.ILLEGAL_OPERATION); LOGGER.warn(&quot;Message rollback fail [producer end]. currentTimeMillis - bornTime &gt; checkImmunityTime, msgId={},commitLogOffset={}, wait check&quot;, requestHeader.getMsgId(), requestHeader.getCommitLogOffset()); return response; } // 删除 half 消息 RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); if (res.getCode() == ResponseCode.SUCCESS) { // 写入 Op 消息，代表 Half 消息被处理 this.brokerController.getTransactionalMessageService(). deletePrepareMessage(result.getPrepareMessage()); } return res; } } // 设置响应 Code 和 Remark response.setCode(result.getResponseCode()); response.setRemark(result.getResponseRemark()); return response; } 处理逻辑如下： 首先做校验确保是 Master 节点处理该请求，因为 Slave 是没有写权限的（没有结束事务的权限），如果是从节点返回 SLAVE_NOT_AVAILABLE。 解析请求头，从请求头中获取事务的提交类型： TRANSACTION_COMMIT_TYPE：表示提交事务，会调用 commitMessage 方法提交消息，如果提交成功根据请求头里的 [CommitLogOffset](http://commitlogoffset /) 读取出完整的消息，从 [Properties](http://properties /) 中恢复消息真实的 Topic、[queueId](http://queueid /) 等属性，再调用 [sendFinalMessage](http://sendfinalmessage /) 方法将消息重新写入 CommitLog，稍后构建好 [ConsumeQueue](http://consumequeue /) 消息对 [Consumer](http://consumer /) 就可见了，最后调用 deletePrepareMessage 方法删除 half 消息。 TRANSACTION_ROLLBACK_TYPE：表示回滚事务，会调用 rollbackMessage 方法回滚事务，处理就更加简单了，因为消息本来就对 Consumer 是不可见的，然后删掉 half 消息。 3.5.1 删除 Half 消息 实际上，[half 消息](http://xn--half -yn4n665g/) 并不会删除，因为 CommitLog 是顺序追加写的，不可能删除单个消息。「删除 half 消息」仅仅是给该消息打上一个标记，代表它的最终状态已知，不需要再回查了。 RocketMQ 通过引入 Op 消息来给 [half 消息](http://xn--half -yn4n665g/) 打标记，[half 消息](http://xn--half -yn4n665g/) 状态确认后，会写入「已经提交」/「回滚」这样一条消息到 Op队列，对应的Topic 为 MQ_SYS_TRANS_OP_HALF_TOPIC，反之 Op 队列 中不存在的，就是状态未确认，需要回查的 [half 消息](http://xn--half -yn4n665g/)。 /** * 删除 half 消息 * @param messageExt 扩展消息 * @return */ @Override public boolean deletePrepareMessage(MessageExt messageExt) { // 从 messageExt 中获取消息队列的 ID Integer queueId = messageExt.getQueueId(); // 从 deleteContext 中获取消息队列操作上下文对象 MessageQueueOpContext mqContext = deleteContext.get(queueId); // 如果消息队列操作上下文对象为空，则创建一个新的对象，并尝试将其放入 deleteContext 中 if (mqContext == null) { mqContext = new MessageQueueOpContext(System.currentTimeMillis(), 20000); MessageQueueOpContext old = deleteContext.putIfAbsent(queueId, mqContext); if (old != null) { mqContext = old; } } // 构建要存储的数据，包括消息队列偏移量和事务消息的偏移量分隔符 String data = messageExt.getQueueOffset() + TransactionalMessageUtil.OFFSET_SEPARATOR; try { // 将数据加入到消息队列操作上下文的队列中，设置超时时间为 100 毫秒 boolean res = mqContext.getContextQueue().offer(data, 100, TimeUnit.MILLISECONDS); if (res) { // 增加消息队列操作上下文的总大小，并检查是否超过最大限制，如果超过则唤醒事务操作批处理服务 int totalSize = mqContext.getTotalSize().addAndGet(data.length()); if (totalSize &gt; transactionalMessageBridge.getBrokerController().getBrokerConfig().getTransactionOpMsgMaxSize()) { this.transactionalOpBatchService.wakeup(); } return true; } else { // 如果加入失败，则唤醒事务操作批处理服务 this.transactionalOpBatchService.wakeup(); } } catch (InterruptedException ignore) { } // 获取代表事务操作的消息对象 Message msg = getOpMessage(queueId, data); // 添加到 OP 消息队列 if (this.transactionalMessageBridge.writeOp(queueId, msg)) { log.warn(&quot;Force add remove op data. queueId={}&quot;, queueId); return true; } else { log.error(&quot;Transaction op message write failed. messageId is {}, queueId is {}&quot;, messageExt.getMsgId(), messageExt.getQueueId()); return false; } } 源码位置：https://github.com/apache/rocketmq/blob/release-5.1.2/store/src/main/java/org/apache/rocketmq/broker/transaction\\queue\\TransactionalMessageBridge.java public class TransactionalMessageBridge { private final ConcurrentHashMap&lt;Integer, MessageQueue&gt; opQueueMap = new ConcurrentHashMap&lt;&gt;(); /** * 写入 op 消息 * @param queueId * @param message * @return */ public boolean writeOp(Integer queueId,Message message) { // 通过 queueId 从 opQueueMap 中获取对应的消息队列对象 MessageQueue opQueue = opQueueMap.get(queueId); // 如果未获取到消息队列对象，则尝试创建一个新的消息队列对象并放入 opQueueMap 中 if (opQueue == null) { opQueue = getOpQueueByHalf(queueId,this.brokerController.getBrokerConfig().getBrokerName()); MessageQueue oldQueue = opQueueMap.putIfAbsent(queueId,opQueue); if (oldQueue != null) { opQueue = oldQueue; } } // 构建事务操作消息，将消息写入 OP 队列，获取消息存储结果 PutMessageResult result = putMessageReturnResult(makeOpMessageInner(message,opQueue)); // 如果消息存储结果不为空且存储状态为 PUT_OK，则返回 true，表示写入成功 if (result != null &amp;&amp; result.getPutMessageStatus() == PutMessageStatus.PUT_OK) { return true; } // 如果写入失败，则返回 false return false; } /** * 构建 op 消息 * @param message * @param messageQueue * @return */ private MessageExtBrokerInner makeOpMessageInner(Message message,MessageQueue messageQueue) { // 创建一个内部消息对象 MessageExtBrokerInner msgInner = new MessageExtBrokerInner(); // 设置消息的主题 msgInner.setTopic(message.getTopic()); // 设置消息的内容 msgInner.setBody(message.getBody()); // 设置消息的队列ID msgInner.setQueueId(messageQueue.getQueueId()); // 设置消息的标签 msgInner.setTags(message.getTags()); // 将消息标签转换为标签码 msgInner.setTagsCode(MessageExtBrokerInner.tagsString2tagsCode(msgInner.getTags())); // 设置消息的系统标记 msgInner.setSysFlag(0); // 设置消息的属性 MessageAccessor.setProperties(msgInner,message.getProperties()); // 将消息的属性转换为字符串 msgInner.setPropertiesString(MessageDecoder.messageProperties2String(message.getProperties())); // 设置消息的生产时间戳 msgInner.setBornTimestamp(System.currentTimeMillis()); // 设置消息的生产主机 msgInner.setBornHost(this.storeHost); // 设置消息的存储主机 msgInner.setStoreHost(this.storeHost); // 设置是否等待消息存储结果 msgInner.setWaitStoreMsgOK(false); // 设置消息的唯一ID MessageClientIDSetter.setUniqID(msgInner); // 返回设置好的消息对象 return msgInner; } } 构建 OP 消息，主要是创建 Message 对象，然后设置主题为 RMQ_SYS_TRANS_OP_HALF_TOPIC，设置 half 消息 在队列的偏移量。 调用 writeOp 方法将消息写入 OP 队列，makeOpMessageInner 方法用于构建消息体，然后调用putMessageReturnResult 放将消息写入 CommitLog。 3.6 事务状态检查 当 [half 消息](http://xn--half -yn4n665g/) 写入成功，可能由于各种原因没有收到 Producer 的事务状态「已经提交」/「回滚」请求。此时，Broker 会主动发起事务回查请求给 Producer，以决定最终将消息 Commit 还是 Rollback。 [half 消息](http://xn--half -yn4n665g/) 最终状态有没有被确认，是通过 Op 队列 里的消息判断的。当 Broker 服务启动时，会开启TransactionalMessageCheckService 线程，它实现了 ServiceThread 默认可以看到在 onWaitEnd 方法中调用了 check 方法进行状态检查。 每隔 60 秒进行一次 half 消息 状态回查。为了避免消息被无限次的回查，RocketMQ 通过 [transactionCheckMax](http://transactioncheckmax /) 属性设置消息回查的最大次数，默认是 15 次。 public class TransactionalMessageCheckService extends ServiceThread { @Override protected void onWaitEnd() { // 回查超时 long timeout = brokerController.getBrokerConfig().getTransactionTimeOut(); // 回查最大次数 int checkMax = brokerController.getBrokerConfig().getTransactionCheckMax(); long begin = System.currentTimeMillis(); log.info(&quot;Begin to check prepare message, begin time:{}&quot;, begin); // 开始回查 this.brokerController.getTransactionalMessageService().check(timeout, checkMax, this.brokerController.getTransactionalMessageCheckListener()); log.info(&quot;End to check prepare message, consumed time:{}&quot;, System.currentTimeMillis() - begin); } } 通过追踪得出 [check](http://check /) 方法在 [TransactionalMessageServiceImpl](http://transactionalmessageserviceimpl/) 中实现： ![img](images/RocketMQ 事务消息源码阅读/FogIeIMa6NMCIYhgMeyyAkqLx62M.png) 回查 [Half消息](http://xn--half-ti4hr48d/) 时，首先要获取 [Half 主题](http://xn--half-3h5fu250b/) 下的所有消息队列。 public class TransactionalMessageServiceImpl implements TransactionalMessageService { /** * 事务回查 * @param transactionTimeout The minimum time of the transactional message to be checked firstly, one message only * exceed this time interval that can be checked. * @param transactionCheckMax The maximum number of times the message was checked, if exceed this value, this * message will be discarded. * @param listener When the message is considered to be checked or discarded, the relative method of this class will * be invoked. */ @Override public void check(long transactionTimeout, int transactionCheckMax, AbstractTransactionalMessageCheckListener listener) { try { // half 消息对应的 Topic String topic = TopicValidator.RMQ_SYS_TRANS_HALF_TOPIC; // 根据主题获取消息队列 Set&lt;MessageQueue&gt; msgQueues = transactionalMessageBridge.fetchMessageQueues(topic); if (msgQueues == null || msgQueues.size() == 0) { log.warn(&quot;The queue of topic is empty :&quot; + topic); return; } log.debug(&quot;Check topic={}, queues={}&quot;, topic, msgQueues); // 遍历所有的消息队列 for (MessageQueue messageQueue : msgQueues) { // 获取当前时间做为开始时间 long startTime = System.currentTimeMillis(); // 那么怎么判断消息需要回查呢？前面说过了，通过 Op 队列判断，因此还需要定位到 HalfQueue 对应的 OpQueue，以及它们的 ConsumeQueue 偏移量。 // 获取对应的 OP 消息队列 MessageQueue opQueue = getOpQueue(messageQueue); // 获取 half 消息队列的消费进度 long halfOffset = transactionalMessageBridge.fetchConsumeOffset(messageQueue); // 获取 op 消息队列的消费进度 long opOffset = transactionalMessageBridge.fetchConsumeOffset(opQueue); log.info(&quot;Before check, the queue={} msgOffset={} opOffset={}&quot;, messageQueue, halfOffset, opOffset); // 如果消费进度小于 0 表示不合法 if (halfOffset &lt; 0 || opOffset &lt; 0) { log.error(&quot;MessageQueue: {} illegal offset read: {}, op offset: {},skip this queue&quot;, messageQueue, halfOffset, opOffset); continue; } // 存储已处理的消息 List&lt;Long&gt; doneOpOffset = new ArrayList&lt;&gt;(); HashMap&lt;Long, Long&gt; removeMap = new HashMap&lt;&gt;(); HashMap&lt;Long, HashSet&lt;Long&gt;&gt; opMsgMap = new HashMap&lt;Long, HashSet&lt;Long&gt;&gt;(); // 根据当前的消费进度从已处理队列中拉取消息 PullResult pullResult = fillOpRemoveMap(removeMap, opQueue, opOffset, halfOffset, opMsgMap, doneOpOffset); if (null == pullResult) { // 如果拉取消息为空，打印错误继续处理下一个消息队列 log.error(&quot;The queue={} check msgOffset={} with opOffset={} failed, pullResult is null&quot;, messageQueue, halfOffset, opOffset); continue; } // single thread // 获取消息为空的数量默认为1 int getMessageNullCount = 1; // 新的进度 long newOffset = halfOffset; // 获取 half 队列的消费进度，赋值给i long i = halfOffset; // 获取下一个待处理的 op 消息队列的消费进度 long nextOpOffset = pullResult.getNextBeginOffset(); int putInQueueCount = 0; int escapeFailCnt = 0; while (true) { // 如果当前时间减去开始时间大于最大处理时间限制，终止循环 if (System.currentTimeMillis() - startTime &gt; MAX_PROCESS_TIME_LIMIT) { log.info(&quot;Queue={} process time reach max={}&quot;, messageQueue, MAX_PROCESS_TIME_LIMIT); break; } // 如果 OP 队列中包含当前偏移量，表示消息已经被处理，加入到已处理集合中 if (removeMap.containsKey(i)) { log.debug(&quot;Half offset {} has been committed/rolled back&quot;, i); Long removedOpOffset = removeMap.remove(i); opMsgMap.get(removedOpOffset).remove(i); if (opMsgMap.get(removedOpOffset).size() == 0) { // 从集合中进行删除 opMsgMap.remove(removedOpOffset); // 加入到 doneOpOffset 集合中 doneOpOffset.add(removedOpOffset); } } else { // 如果已处理队列中不包含当前消息 // 根据偏移量从 half 队列获取 half 消息 GetResult getResult = getHalfMsg(messageQueue, i); // 获取消息对象 MessageExt msgExt = getResult.getMsg(); // 如果获取消息为空 if (msgExt == null) { // 判断获取空消息的次数是否大于 MAX_RETRY_COUNT_WHEN_HALF_NULL if (getMessageNullCount++ &gt; MAX_RETRY_COUNT_WHEN_HALF_NULL) { break; } // 判断从 half 队列获取消息的结果是 NO_NEW_MSG，表示没有消息，此时终止循环等待下一次进行检查 if (getResult.getPullResult().getPullStatus() == PullStatus.NO_NEW_MSG) { log.debug(&quot;No new msg, the miss offset={} in={}, continue check={}, pull result={}&quot;, i, messageQueue, getMessageNullCount, getResult.getPullResult()); break; } else { log.info(&quot;Illegal offset, the miss offset={} in={}, continue check={}, pull result={}&quot;, i, messageQueue, getMessageNullCount, getResult.getPullResult()); // 执行到这里说明消息的偏移量不合法，继续获取下一条消息进行处理 i = getResult.getPullResult().getNextBeginOffset(); newOffset = i; continue; } } if (this.transactionalMessageBridge.getBrokerController().getBrokerConfig().isEnableSlaveActingMaster() &amp;&amp; this.transactionalMessageBridge.getBrokerController().getMinBrokerIdInGroup() == this.transactionalMessageBridge.getBrokerController().getBrokerIdentity().getBrokerId() &amp;&amp; BrokerRole.SLAVE.equals(this.transactionalMessageBridge.getBrokerController().getMessageStoreConfig().getBrokerRole()) ) { final MessageExtBrokerInner msgInner = this.transactionalMessageBridge.renewHalfMessageInner(msgExt); final boolean isSuccess = this.transactionalMessageBridge.escapeMessage(msgInner); if (isSuccess) { escapeFailCnt = 0; newOffset = i + 1; i++; } else { log.warn(&quot;Escaping transactional message failed {} times! msgId(offsetId)={}, UNIQ_KEY(transactionId)={}&quot;, escapeFailCnt + 1, msgExt.getMsgId(), msgExt.getUserProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX)); if (escapeFailCnt &lt; MAX_RETRY_TIMES_FOR_ESCAPE) { escapeFailCnt++; Thread.sleep(100L * (2 ^ escapeFailCnt)); } else { escapeFailCnt = 0; newOffset = i + 1; i++; } } continue; } // 是否需要丢弃消息或者需要跳过消息 if (needDiscard(msgExt, transactionCheckMax) || needSkip(msgExt)) { // 回查次数超过 15，丢弃消息，扔到 TRANS_CHECK_MAX_TIME_TOPIC listener.resolveDiscardMsg(msgExt); // 继续处理下一条消息 newOffset = i + 1; i++; continue; } // 如果消息的添加时间是否大于等于本次检查的开始时间，说明是在检查开始之后加入的消息，暂不进行处理 if (msgExt.getStoreTimestamp() &gt;= startTime) { log.debug(&quot;Fresh stored. the miss offset={}, check it later, store={}&quot;, i, new Date(msgExt.getStoreTimestamp())); break; } // 计算 half 消息在队列中的保留时间：当前时间减去消息加入的时间 long valueOfCurrentMinusBorn = System.currentTimeMillis() - msgExt.getBornTimestamp(); // 事务超时时间 long checkImmunityTime = transactionTimeout; // 获取 PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS 属性，表示事务回查最晚的时间 String checkImmunityTimeStr = msgExt.getUserProperty(MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS); // 如果 PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS 属性不为空 if (null != checkImmunityTimeStr) { // 获取事务回查最晚检查时间，如果 checkImmunityTimeStr 为 -1 则返回事务超时时间， // 否则返回 checkImmunityTimeStr 转为 long 后乘以 1000 得到的值 checkImmunityTime = getImmunityTime(checkImmunityTimeStr, transactionTimeout); // 如果消息的保留时间小于事务回查最晚检查时间 if (valueOfCurrentMinusBorn &lt; checkImmunityTime) { // 检查 half 消息在队列中的偏移量，如果返回 true 跳过本条消息 if (checkPrepareQueueOffset(removeMap, doneOpOffset, msgExt, checkImmunityTimeStr)) { // 处理下一个消息 newOffset = i + 1; i++; continue; } } } else { // 如果 valueOfCurrentMinusBorn 小于 checkImmunityTime if (0 &lt;= valueOfCurrentMinusBorn &amp;&amp; valueOfCurrentMinusBorn &lt; checkImmunityTime) { log.debug(&quot;New arrived, the miss offset={}, check it later checkImmunity={}, born={}&quot;, i, checkImmunityTime, new Date(msgExt.getBornTimestamp())); break; } } // 获取 OP 消息 List&lt;MessageExt&gt; opMsg = pullResult == null ? null : pullResult.getMsgFoundList(); // 判断是否需要检查，满足检查的条件为以下三种情况之一： // 1.拉取消息为空 &amp;&amp; 消息的保留时间已经大于事务设置的最晚回查时间 // 2.拉取消息不为空 &amp;&amp; 拉取到的最后一条消息的存入时间减去当前时间超过了事务的超时时间 // 3.half 消息存留时间为负数 boolean isNeedCheck = opMsg == null &amp;&amp; valueOfCurrentMinusBorn &gt; checkImmunityTime || opMsg != null &amp;&amp; opMsg.get(opMsg.size() - 1).getBornTimestamp() - startTime &gt; transactionTimeout || valueOfCurrentMinusBorn &lt;= -1; // 如果需要进行回查 if (isNeedCheck) { // 将 half 消息重新加入到队列中 if (!putBackHalfMsgQueue(msgExt, i)) { continue; } putInQueueCount++; log.info(&quot;Check transaction. real_topic={},uniqKey={},offset={},commitLogOffset={}&quot;, msgExt.getUserProperty(MessageConst.PROPERTY_REAL_TOPIC), msgExt.getUserProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX), msgExt.getQueueOffset(), msgExt.getCommitLogOffset()); // 发送回查请求 listener.resolveHalfMsg(msgExt); } else { nextOpOffset = pullResult != null ? pullResult.getNextBeginOffset() : nextOpOffset; // 继续从 OP 队列中拉取消息 pullResult = fillOpRemoveMap(removeMap, opQueue, nextOpOffset, halfOffset, opMsgMap, doneOpOffset); if (pullResult == null || pullResult.getPullStatus() == PullStatus.NO_NEW_MSG || pullResult.getPullStatus() == PullStatus.OFFSET_ILLEGAL || pullResult.getPullStatus() == PullStatus.NO_MATCHED_MSG) { try { Thread.sleep(SLEEP_WHILE_NO_OP); } catch (Throwable ignored) { } } else { log.info(&quot;The miss message offset:{}, pullOffsetOfOp:{}, miniOffset:{} get more opMsg.&quot;, i, nextOpOffset, halfOffset); } continue; } } // 加 1 继续处理下一条消息 newOffset = i + 1; i++; } if (newOffset != halfOffset) { // 更新消费进度 transactionalMessageBridge.updateConsumeOffset(messageQueue, newOffset); } long newOpOffset = calculateOpOffset(doneOpOffset, opOffset); if (newOpOffset != opOffset) { // 更新处理进度 transactionalMessageBridge.updateConsumeOffset(opQueue, newOpOffset); } // 记录日志使用 GetResult getResult = getHalfMsg(messageQueue, newOffset); pullResult = pullOpMsg(opQueue, newOpOffset, 1); long maxMsgOffset = getResult.getPullResult() == null ? newOffset : getResult.getPullResult().getMaxOffset(); long maxOpOffset = pullResult == null ? newOpOffset : pullResult.getMaxOffset(); long msgTime = getResult.getMsg() == null ? System.currentTimeMillis() : getResult.getMsg().getStoreTimestamp(); log.info(&quot;After check, {} opOffset={} opOffsetDiff={} msgOffset={} msgOffsetDiff={} msgTime={} msgTimeDelayInMs={} putInQueueCount={}&quot;, messageQueue, newOpOffset, maxOpOffset - newOpOffset, newOffset, maxMsgOffset - newOffset, new Date(msgTime), System.currentTimeMillis() - msgTime, putInQueueCount); } } catch (Throwable e) { log.error(&quot;Check error&quot;, e); } } } 方法很长，这里会获取 RMQ_SYS_TRANS_HALF_TOPIC 下的所有消息队列，遍历所有的 half 消息队列，对队列中的 half 消息进行处理，步骤比较多，我们分别来看下。 3.6.1 构建 OP 队列的 MessageQueue /** * 构建 OP 队列的消息队列对象 MessageQueue * @param messageQueue * @return */ private MessageQueue getOpQueue(MessageQueue messageQueue) { // 获取 OP 消息队列 MessageQueue opQueue = opQueueMap.get(messageQueue); if (opQueue == null) { // 如果获取为空，则创建 MessageQueue，主题设置为 OP TOPIC，设置 Broker 名称和队列 ID opQueue = new MessageQueue(TransactionalMessageUtil.buildOpTopic(), messageQueue.getBrokerName(), messageQueue.getQueueId()); // 加入到 opQueueMap 中 opQueueMap.put(messageQueue, opQueue); } return opQueue; } 3.6.2 获取 Half 队列与 OP 消费队列的消费进度 消费进度的获取是通过调用 [transactionalMessageBridge#fetchConsumeOffset](http:// transactionalmessagebridge/#fetchConsumeOffset) 方法进行查询的，可以看到方法的参数是 MessageQueue 类型的，所以第一步需要构造 OP 队列的 MessageQueue 对象，在这一步查询消费进度使用。 /** * 获取 Half 队列与 OP 消费队列的消费进度 * @param mq * @return */ public long fetchConsumeOffset(MessageQueue mq) { // 根据 topic、队列id、消费者组获取消费进度 long offset = brokerController.getConsumerOffsetManager().queryOffset(TransactionalMessageUtil.buildConsumerGroup(), mq.getTopic(), mq.getQueueId()); if (offset == -1) { // 如果没有设置为队列中最小的偏移量 offset = store.getMinOffsetInQueue(mq.getTopic(), mq.getQueueId()); } return offset; } 3.6.3 从 OP 队列中拉取消息 根据消费进度信息从 OP 队列中拉取消息，将拉取的消费放入 removeMap 中，用于判断 half 消息 是否已经处理。 /** * Read op message, parse op message, and fill removeMap * 从 OP 队列中拉取消息 * @param removeMap Half message to be remove, key:halfOffset, value: opOffset. * @param opQueue Op message queue. * @param pullOffsetOfOp The begin offset of op message queue. * @param miniOffset The current minimum offset of half message queue. * @param opMsgMap Half message offset in op message * @param doneOpOffset Stored op messages that have been processed. * @return Op message result. */ private PullResult fillOpRemoveMap(HashMap&lt;Long, Long&gt; removeMap, MessageQueue opQueue, long pullOffsetOfOp, long miniOffset, Map&lt;Long, HashSet&lt;Long&gt;&gt; opMsgMap, List&lt;Long&gt; doneOpOffset) { // 从OP队列中拉取消息，每次拉取 32 条 PullResult pullResult = pullOpMsg(opQueue, pullOffsetOfOp, OP_MSG_PULL_NUMS); if (null == pullResult) { // 如果拉取为空返回 null return null; } // 如果拉取状态为消费进度不合法或者没有匹配的消息 if (pullResult.getPullStatus() == PullStatus.OFFSET_ILLEGAL || pullResult.getPullStatus() == PullStatus.NO_MATCHED_MSG) { log.warn(&quot;The miss op offset={} in queue={} is illegal, pullResult={}&quot;, pullOffsetOfOp, opQueue, pullResult); // 从拉取结果中获取消费进度并更新消费进度 transactionalMessageBridge.updateConsumeOffset(opQueue, pullResult.getNextBeginOffset()); return pullResult; } else if (pullResult.getPullStatus() == PullStatus.NO_NEW_MSG) { log.warn(&quot;The miss op offset={} in queue={} is NO_NEW_MSG, pullResult={}&quot;, pullOffsetOfOp, opQueue, pullResult); return pullResult; } // 获取拉取到的消息 List&lt;MessageExt&gt; opMsg = pullResult.getMsgFoundList(); if (opMsg == null) { log.warn(&quot;The miss op offset={} in queue={} is empty, pullResult={}&quot;, pullOffsetOfOp, opQueue, pullResult); return pullResult; } // 遍历拉取的消息 for (MessageExt opMessageExt : opMsg) { if (opMessageExt.getBody() == null) { log.error(&quot;op message body is null. queueId={}, offset={}&quot;, opMessageExt.getQueueId(), opMessageExt.getQueueOffset()); doneOpOffset.add(opMessageExt.getQueueOffset()); continue; } HashSet&lt;Long&gt; set = new HashSet&lt;Long&gt;(); // 构建队列进度消息体 String queueOffsetBody = new String(opMessageExt.getBody(), TransactionalMessageUtil.CHARSET); log.debug(&quot;Topic: {} tags: {}, OpOffset: {}, HalfOffset: {}&quot;, opMessageExt.getTopic(), opMessageExt.getTags(), opMessageExt.getQueueOffset(), queueOffsetBody); if (TransactionalMessageUtil.REMOVE_TAG.equals(opMessageExt.getTags())) { String[] offsetArray = queueOffsetBody.split(TransactionalMessageUtil.OFFSET_SEPARATOR); for (String offset : offsetArray) { // 获取队列中的偏移量 Long offsetValue = getLong(offset); // 如果偏移量小于最小的偏移量 if (offsetValue &lt; miniOffset) { continue; } // 加入到已处理消息的集合 removeMap 中 removeMap.put(offsetValue, opMessageExt.getQueueOffset()); set.add(offsetValue); } } else { log.error(&quot;Found a illegal tag in opMessageExt= {} &quot;, opMessageExt); } if (set.size() &gt; 0) { // 加入到已处理消息的集合 opMsgMap 中 opMsgMap.put(opMessageExt.getQueueOffset(), set); } else { // 加入到 doneOpOffset 中 doneOpOffset.add(opMessageExt.getQueueOffset()); } } log.debug(&quot;Remove map: {}&quot;, removeMap); log.debug(&quot;Done op list: {}&quot;, doneOpOffset); log.debug(&quot;opMsg map: {}&quot;, opMsgMap); return pullResult; } 3.6.4 循环处理每一个 half 消息 执行 [while](http://while /) 循环，从 [half 队列](http://xn--half -no0lh071c/)的消费进度处开始，处理每一个 [half 消息](http://xn--half -yn4n665g/)，处理逻辑如下： 如果当前时间减去检查开始时间大于最大处理时间，此时终止循环。 如果removeMap中包含当前 half 消息，表示消息已经被处理，则放入到已处理消息集合中 doneOpOffset。 如果 removeMap 不包含当前 half 消息， 调用 getHalfMsg 方法根据偏移量从 half 队列获取 half 消息，如果消息获取不为空继续下一步，否则进行如下处理： 判断获取空消息的个数是否大于MAX_RETRY_COUNT_WHEN_HALF_NULL，如果大于将终止本次循环，处理下一个 half 消息队列。 判断拉取消息的状态是否为NO_NEW_MSG，如果是表示队列中没有消息，先终止循环。 如果拉取消息的状态是不是NO_NEW_MSG，表示消费进度不合法，获取half消息队列中下一条消息进行处理。 调用 needDiscard 判断是否需要丢弃 half 消息，或者调用 needSkip 判断是否需要跳过当前 half 消息： needDiscard 是根据 half 消息 的检查次数是否超过最大限制来决定是否丢弃 half 消息。 private boolean needDiscard(MessageExt msgExt, int transactionCheckMax) { // 从属性中获取检查次数 String checkTimes = msgExt.getProperty(MessageConst.PROPERTY_TRANSACTION_CHECK_TIMES); int checkTime = 1; if (null != checkTimes) { // 如果不为空 checkTime = getInt(checkTimes); if (checkTime &gt;= transactionCheckMax) { // 如果检查次数大于事务最大的检查次数，表示需要丢弃 return true; } else { // 检查次数加一 checkTime++; } } // 更新检查次数 msgExt.putUserProperty(MessageConst.PROPERTY_TRANSACTION_CHECK_TIMES, String.valueOf(checkTime)); return false; } 1. [needSkip](http://needskip/) 是根据 [half 消息](http://xn--half-ti4hr48d/) 在队列中的存留时间是否超过了最大的保留时间限制来决定是否跳过。 private boolean needSkip(MessageExt msgExt) { // 计算 half 消息在队列中的保留时间 long valueOfCurrentMinusBorn = System.currentTimeMillis() - msgExt.getBornTimestamp(); // 如果 half 消息在队列中的保留时间大于 Broker 中设置的最大保留时间，表示需要跳过 if (valueOfCurrentMinusBorn \\&gt; transactionalMessageBridge.getBrokerController().getMessageStoreConfig().getFileReservedTime() \\* 3600L * 1000) { log.info(&quot;Half message exceed file reserved time ,so skip it.messageId {},bornTime {}&quot;, msgExt.getMsgId(), msgExt.getBornTimestamp()); return true; } return false; } 判断消息的的存入时间是否大于本次开始检查的时间，如果大于说明是新加入的消息，由于事务消息发送后不会立刻提交，所以此时暂不需要进行检查，中断循环即可。 计算 half 消息 在队列中的存留时间 valueOfCurrentMinusBorn：当前时间 - 消息存入的时间。 设置立刻回查事务状态的时间 checkImmunityTime：事务的超时时间。 从消息属性中获取 PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS 属性的值放在 checkImmunityTimeStr 中，表示事务的最晚回查时间： 如果 checkImmunityTimeStr 获取不为空，调用 getImmunityTime 方法计算事务立刻回查时间，并赋值给checkImmunityTime，从源码中可以看出如果 checkImmunityTimeStr 为 -1 则返回事务的超时时间，否则返回checkImmunityTimeStr 的值并乘以 1000 转为秒。 private long getImmunityTime(String checkImmunityTimeStr, long transactionTimeout) { long checkImmunityTime; // 转为 long checkImmunityTime = getLong(checkImmunityTimeStr); if (-1 == checkImmunityTime) { // 如果为-1，使用事务的超时时间 checkImmunityTime = transactionTimeout; } else { checkImmunityTime *= 1000; // 使用 checkImmunityTime，乘以 1000 转为秒 } return checkImmunityTime; } 计算完 checkImmunityTime 值后，判断 valueOfCurrentMinusBorn 是否小于 checkImmunityTime，如果是表明还未到事务的超时时间，此时调用 checkPrepareQueueOffset 检查 half 消息在队列中的偏移量，根据检查结果判断是否需要跳过当前消息： 如果 PROPERTY_TRANSACTION_PREPARED_QUEUE_OFFSET 属性获取为空，调用putImmunityMsgBackToHalfQueue 将消息重新加入 half 队列，如果返回 true 表示加入成功，此时向前推荐消费进度处理下一条消息，如果加入失败会继续循环处理本条消息（此时进度未向前推进）。 如果 PROPERTY_TRANSACTION_PREPARED_QUEUE_OFFSET 属性获取不为空，转为 long 型，判断 OP 队列中是否已经包含当前消息的偏移量，如果包含加入到 doneOpOffset 中并返回true，此时向前推进消费进度，处理下一条消息，否则同样调用 putImmunityMsgBackToHalfQueue 将消息重新加入 half 队列，并根据加入成功与否判断是否继续处理下一条消息。 如果事务设置了 PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS 属性，并且 half 消息 的存留时间小于立刻检查事务的时间，说明还未到时间不需要进行状态检查，此时获取消息在 half 队列 的偏移量，如果获取为空，将消息重新加入到 half 队列 中，如果获取不为空判断是否已经在 OP 处理队列 中，如果返回 true处理下一个消息即可，否则同样将消息重新加入 half 队列 中。 RocketMQ 在事务未到最晚回查时间时将消息重新加入了 half 消息队列，因为加入之后 half 队列 的消费进度会往前推进并在回查结束时更新进度，所以下次检查时并不会检查到旧的half 消息。 private boolean checkPrepareQueueOffset(HashMap&lt;Long, Long&gt; removeMap, List&lt;Long&gt; doneOpOffset, MessageExt msgExt, String checkImmunityTimeStr) { // 从属性中获取消息在 half 队列的偏移量 String prepareQueueOffsetStr = msgExt.getUserProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED_QUEUE_OFFSET); if (null == prepareQueueOffsetStr) { // 将消息重新加入 half 队列 return putImmunityMsgBackToHalfQueue(msgExt); } else { // 转为 long long prepareQueueOffset = getLong(prepareQueueOffsetStr); // 如果为 -1，返回 false，等待下次循环进行处理 if (-1 == prepareQueueOffset) { return false; } else { // 如果 OP 队列中已经包含当前消息的偏移量 if (removeMap.containsKey(prepareQueueOffset)) { long tmpOpOffset = removeMap.remove(prepareQueueOffset); // 加入到已完成的消息集合中 doneOpOffset.add(tmpOpOffset); log.info(&quot;removeMap contain prepareQueueOffset. real_topic={},uniqKey={},immunityTime={},offset={}&quot;, msgExt.getUserProperty(MessageConst.PROPERTY_REAL_TOPIC), msgExt.getUserProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX), checkImmunityTimeStr, msgExt.getQueueOffset()); return true; } else { // 将消息重新加入 half 队列 return putImmunityMsgBackToHalfQueue(msgExt); } } } } 如果 checkImmunityTimeStr 获取为空，判断 valueOfCurrentMinusBorn（消息存留时间）是否大于等于 0并且小于 checkImmunityTime（事务超时时间），如果满足条件表示新加入的消息并且还未过事务的超时时间，此时终止循环暂不进行回查，否则进入下一步。 判断是否需要进行状态回查 isNeedCheck，满足检查的条件为以下三种情况之一： 从 OP 队列 中拉取消息为空并且当前 half 消息 的存留时间已经大于事务设置的最晚回查时间。 opMsg == null &amp;&amp; valueOfCurrentMinusBorn &gt; checkImmunityTime 从 OP队列 中拉取的消息不为空，并且拉取的最后一条消息的存入时间减去本次开始检查时间大于事务的超时时间。 opMsg != null &amp;&amp; opMsg.get(opMsg.size() - 1).getBornTimestamp() - startTime &gt; transactionTimeout half 消息 在队列中的保留时间小于等于1，说明加入half 消息的时间大于本次开始检查的时间。 valueOfCurrentMinusBorn &lt;= -1 根据 [isNeedCheck](http://isneedcheck /) 判断是否需要回查： 需要回查：调用 putBackHalfMsgQueue 将 half 消息 重新加入到队列中，如果加入失败继续循环再次处理，如果加入成功调用 resolveHalfMsg 发送回查请求。 不需要回查：调用 fillOpRemoveMap 继续从 OP 队列 中拉取消息判断。 最后更新 i 的值，继续处理下一个half 消息。 3.7 更新消费进度 此处主要是更新「Half 队列」和「OP 队列」的消费进度。 3.7.1 重新添加 Half 消息到队列 将消息重新加入到了half 队列 是在 [putBackHalfMsgQueue](http://putbackhalfmsgqueue /) 方法执行。 /** * 重新添加 half 消息到队列中 * @param msgExt * @param offset * @return */ private boolean putBackHalfMsgQueue(MessageExt msgExt, long offset) { // 重新将消息入到 half 消息队列中 PutMessageResult putMessageResult = putBackToHalfQueueReturnResult(msgExt); // 如果加入成功 if (putMessageResult != null &amp;&amp; putMessageResult.getPutMessageStatus() == PutMessageStatus.PUT_OK) { // 设置消息的逻辑偏移量 msgExt.setQueueOffset( putMessageResult.getAppendMessageResult().getLogicsOffset()); // 设置消息在 CommitLog 的偏移量 msgExt.setCommitLogOffset( putMessageResult.getAppendMessageResult().getWroteOffset()); // 设消息ID msgExt.setMsgId(putMessageResult.getAppendMessageResult().getMsgId()); log.debug( &quot;Send check message, the offset={} restored in queueOffset={} &quot; + &quot;commitLogOffset={} &quot; + &quot;newMsgId={} realMsgId={} topic={}&quot;, offset, msgExt.getQueueOffset(), msgExt.getCommitLogOffset(), msgExt.getMsgId(), msgExt.getUserProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX), msgExt.getTopic()); return true; } else { // 加入失败 log.error( &quot;PutBackToHalfQueueReturnResult write failed, topic: {}, queueId: {}, &quot; + &quot;msgId: {}&quot;, msgExt.getTopic(), msgExt.getQueueId(), msgExt.getMsgId()); return false; } } 3.7.2 发送事务状态回查请求 ** **向客户端发送事务状态回查的请求是在 AbstractTransactionalMessageCheckListener#resolveHalfMsg 方法执行，可以看到是通过线程池异步实现的，构建请求信息并向消息的生产者发送事务状态回查的请求。 public abstract class AbstractTransactionalMessageCheckListener { private static final Logger LOGGER = LoggerFactory.getLogger(LoggerName.TRANSACTION_LOGGER_NAME); private BrokerController brokerController; //queue nums of topic TRANS_CHECK_MAX_TIME_TOPIC protected final static int TCMT_QUEUE_NUMS = 1; private static volatile ExecutorService executorService; public AbstractTransactionalMessageCheckListener() { } public AbstractTransactionalMessageCheckListener(BrokerController brokerController) { this.brokerController = brokerController; } public void sendCheckMessage(MessageExt msgExt) throws Exception { // 构建回查请求头 CheckTransactionStateRequestHeader checkTransactionStateRequestHeader = new CheckTransactionStateRequestHeader(); // 设置Commitlog偏移量 checkTransactionStateRequestHeader.setCommitLogOffset(msgExt.getCommitLogOffset()); // 设置偏移量消息id checkTransactionStateRequestHeader.setOffsetMsgId(msgExt.getMsgId()); // 设置消息id checkTransactionStateRequestHeader.setMsgId(msgExt.getUserProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX)); // 设置事务id checkTransactionStateRequestHeader.setTransactionId(checkTransactionStateRequestHeader.getMsgId()); // 设置事务状态表偏移量 checkTransactionStateRequestHeader.setTranStateTableOffset(msgExt.getQueueOffset()); // 设置 brokername checkTransactionStateRequestHeader.setBname(brokerController.getBrokerConfig().getBrokerName()); // 设置消息实际的TOPIC msgExt.setTopic(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_TOPIC)); // 设置消息实际的队列ID msgExt.setQueueId(Integer.parseInt(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_QUEUE_ID))); // 设置存储大小 msgExt.setStoreSize(0); String groupId = msgExt.getProperty(MessageConst.PROPERTY_PRODUCER_GROUP); // 获取channel Channel channel = brokerController.getProducerManager().getAvailableChannel(groupId); if (channel != null) { // 发送回查请求 brokerController.getBroker2Client().checkProducerTransactionState(groupId, channel, checkTransactionStateRequestHeader, msgExt); } else { LOGGER.warn(&quot;Check transaction failed, channel is null. groupId={}&quot;, groupId); } } public void resolveHalfMsg(final MessageExt msgExt) { if (executorService != null) { executorService.execute(new Runnable() { @Override public void run() { try { // 发送状态回查请求 sendCheckMessage(msgExt); } catch (Exception e) { LOGGER.error(&quot;Send check message error!&quot;, e); } } }); } else { LOGGER.error(&quot;TransactionalMessageCheckListener not init&quot;); } } public BrokerController getBrokerController() { return brokerController; } public void shutDown() { if (executorService != null) { executorService.shutdown(); } } /** \\* 初始化线程池 */ public synchronized void initExecutorService() { // 如果线程池为空，则创建新的线程池 if (executorService == null) { // 创建一个线程池，初始线程数为 2，最大线程数为 5，空闲线程超过 100 秒会被回收 // 使用数组阻塞队列作为任务队列，容量为 2000 // 使用自定义的 ThreadFactory 创建线程，调用者运行的饱和策略 executorService = new ThreadPoolExecutor(2,5,100,TimeUnit.SECONDS,new ArrayBlockingQueue&lt;&gt;(2000), new ThreadFactoryImpl(&quot;Transaction-msg-check-thread&quot;,brokerController.getBrokerIdentity()),new CallerRunsPolicy()); } } /** \\* Inject brokerController for this listener * \\* @param brokerController */ public void setBrokerController(BrokerController brokerController) { this.brokerController = brokerController; initExecutorService(); } /** \\* In order to avoid check back unlimited, we will discard the message that have been checked more than a certain \\* number of times. * \\* @param msgExt Message to be discarded. */ public abstract void resolveDiscardMsg(MessageExt msgExt); } 3.7.3 处理事务状态回查请求 事务状态回查请求的处理在 ClientRemotingProcessor 中进行处理。 ![img](https://github.com/PansonPanson/supply-chain/blob/main/%E4%BE%9B%E5%BA%94%E9%93%BE%E5%AD%90%E7%B3%BB%E7%BB%9F/%E6%99%BA%E8%83%BD%E4%BB%93%E5%82%A8%E7%B3%BB%E7%BB%9F/%E6%8A%80%E6%9C%AF%E7%AF%87/images/RocketMQ%20%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/FsYK8t1SoP2YWNiFLLQvs2s4pPEy.png?raw=true public class ClientRemotingProcessor implements NettyRequestProcessor { /** * 处理事务状态回查请求 * @param ctx * @param request * @return * @throws RemotingCommandException */ public RemotingCommand checkTransactionState(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException { // 解析事务状态回查请求头 final CheckTransactionStateRequestHeader requestHeader = (CheckTransactionStateRequestHeader) request.decodeCommandCustomHeader(CheckTransactionStateRequestHeader.class); final ByteBuffer byteBuffer = ByteBuffer.wrap(request.getBody()); // 获取消息 final MessageExt messageExt = MessageDecoder.decode(byteBuffer); // 如果消息不为空 if (messageExt != null) { if (StringUtils.isNotEmpty(this.mqClientFactory.getClientConfig().getNamespace())) { messageExt.setTopic(NamespaceUtil .withoutNamespace(messageExt.getTopic(), this.mqClientFactory.getClientConfig().getNamespace())); } // 获取事务ID String transactionId = messageExt.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (null != transactionId &amp;&amp; !&quot;&quot;.equals(transactionId)) { messageExt.setTransactionId(transactionId); } // 获取生产者组 final String group = messageExt.getProperty(MessageConst.PROPERTY_PRODUCER_GROUP); if (group != null) { // 获取 MQProducerInner MQProducerInner producer = this.mqClientFactory.selectProducer(group); if (producer != null) { final String addr = RemotingHelper.parseChannelRemoteAddr(ctx.channel()); // 调用 checkTransactionState 进行状态检查 producer.checkTransactionState(addr, messageExt, requestHeader); } else { logger.debug(&quot;checkTransactionState, pick producer by group[{}] failed&quot;, group); } } else { logger.warn(&quot;checkTransactionState, pick producer group failed&quot;); } } else { logger.warn(&quot;checkTransactionState, decode message failed&quot;); } return null; } } 最后在 [DefaultMQProducerImpl](http://defaultmqproducerimpl /) 中进行状态检查，可以看到它创建了 [Runnable](http://runnable /) 对象，然后提交到线程池中进行异步执行事务的状态检查。 public class DefaultMQProducerImpl implements MQProducerInner { /** * 事务状态回查 * @param addr * @param msg * @param header */ @Override public void checkTransactionState(final String addr, final MessageExt msg, final CheckTransactionStateRequestHeader header) { Runnable request = new Runnable() { private final String brokerAddr = addr; private final MessageExt message = msg; private final CheckTransactionStateRequestHeader checkRequestHeader = header; private final String group = DefaultMQProducerImpl.this.defaultMQProducer.getProducerGroup(); @Override public void run() { // 获取 TransactionCheckListener 监听器 TransactionCheckListener transactionCheckListener = DefaultMQProducerImpl.this.checkListener(); // 获取事务监听器 TransactionListener transactionListener = getCheckListener(); // 如果其中之一不为空 if (transactionCheckListener != null || transactionListener != null) { // 初始化为 UNKNOW 状态 LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW; Throwable exception = null; try { if (transactionCheckListener != null) { // 调用 checkLocalTransactionState 回查状态 localTransactionState = transactionCheckListener.checkLocalTransactionState(message); } else { log.debug(&quot;TransactionCheckListener is null, used new check API, producerGroup={}&quot;, group); // 调用 checkLocalTransaction 回查状态 localTransactionState = transactionListener.checkLocalTransaction(message); } } catch (Throwable e) { log.error(&quot;Broker call checkTransactionState, but checkLocalTransactionState exception&quot;, e); exception = e; } // 处理事务状态 this.processTransactionState( localTransactionState, group, exception); } else { log.warn(&quot;CheckTransactionState, pick transactionCheckListener by group[{}] failed&quot;, group); } } /** * 处理事务状态 * @param localTransactionState * @param producerGroup * @param exception */ private void processTransactionState( final LocalTransactionState localTransactionState, final String producerGroup, final Throwable exception) { // 构建结束事务的请求头 final EndTransactionRequestHeader thisHeader = new EndTransactionRequestHeader(); // 设置 CommitLog 的偏移量 thisHeader.setCommitLogOffset(checkRequestHeader.getCommitLogOffset()); // 设置生产者组 thisHeader.setProducerGroup(producerGroup); // 设置事务状态表偏移量 thisHeader.setTranStateTableOffset(checkRequestHeader.getTranStateTableOffset()); // 设置状态检查为 true thisHeader.setFromTransactionCheck(true); // 设置 brokerName thisHeader.setBname(checkRequestHeader.getBname()); String uniqueKey = message.getProperties().get(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX); if (uniqueKey == null) { uniqueKey = message.getMsgId(); } // 设置消息id thisHeader.setMsgId(uniqueKey); // 设置事务id thisHeader.setTransactionId(checkRequestHeader.getTransactionId()); switch (localTransactionState) { case COMMIT_MESSAGE: // 设置为提交 thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE); break; case ROLLBACK_MESSAGE: // 设置为回滚 thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE); log.warn(&quot;when broker check, client rollback this transaction, {}&quot;, thisHeader); break; case UNKNOW: // 设置为未知 thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE); log.warn(&quot;when broker check, client does not know this transaction state, {}&quot;, thisHeader); break; default: break; } String remark = null; if (exception != null) { remark = &quot;checkLocalTransactionState Exception: &quot; + UtilAll.exceptionSimpleDesc(exception); } // 执行结束事务钩子函数 doExecuteEndTransactionHook(msg, uniqueKey, brokerAddr, localTransactionState, true); try { // 向 Broker 发送消息的回查结果 DefaultMQProducerImpl.this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, thisHeader, remark, 3000); } catch (Exception e) { log.error(&quot;endTransactionOneway exception&quot;, e); } } }; // 提交到线程池中执行任务 this.checkExecutor.submit(request); } } 04 总结 对于「事务消息」来说主要是通过消息的「异步处理」，可以保证「本地事务」和「消息发送同时成功或者失败」，从而保证数据的「最终一致性」，这里我们先看看一条事务消息从诞生到结束的整个时间线流程图，如下： ","link":"https://panson.top/post/rocketmq-shi-wu-xiao-xi-yuan-ma-yue-du/"},{"title":"RocketMQ 事务是如何实现的？","content":"RocketMQ的事务消息通过两阶段提交（2PC） 实现的，核心是 Half 消息。下面我们来具体聊聊。 一、核心流程 先来看看官网上的一张图： 再来张中文版的： 发送半消息（Half Message） 生产者发送一条对消费者不可见的消息到Broker（状态为PREPARED）。 Broker存储消息（但不会投递给消费者），并响应生产者。 执行本地事务 生产者收到半消息确认后，执行本地事务（如数据库操作）。 提交或回滚事务 成功提交：生产者发送commit指令，Broker将消息标记为COMMITTED（对消费者可见）。 失败回滚：生产者发送rollback指令，Broker删除半消息。 未响应：若生产者宕机/超时未响应，进入事务回查机制。 事务状态回查 Broker定时扫描未处理的半消息（PREPARED状态），向生产者发起回查请求。 生产者检查本地事务状态，返回commit/rollback结果。 Broker根据回查结果提交或删除消息。 二、生产者端实现 // 1. 创建事务生产者 TransactionMQProducer producer = new TransactionMQProducer(&quot;group&quot;); producer.setNamesrvAddr(&quot;localhost:9876&quot;); // 2. 设置事务监听器（核心） producer.setTransactionListener(new TransactionListener() { // 执行本地事务 @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) { try { // 业务操作（如更新数据库） boolean success = doBusinessLogic(); return success ? LocalTransactionState.COMMIT_MESSAGE : LocalTransactionState.ROLLBACK_MESSAGE; } catch (Exception e) { return LocalTransactionState.UNKNOW; // 触发回查 } } // Broker回查时调用 @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) { // 根据消息内容检查本地事务状态 return checkBusinessStatus(msg) ? LocalTransactionState.COMMIT_MESSAGE : LocalTransactionState.ROLLBACK_MESSAGE; } }); // 3. 发送半消息 Message msg = new Message(&quot;Topic&quot;, &quot;Tag&quot;, &quot;Hello TX&quot;.getBytes()); SendResult result = producer.sendMessageInTransaction(msg, null); RocketMQLocalTransactionListener 接口规范了事务监听类必须实现的两个接口：executeLocalTransaction用于执行本地事务，checkLocalTransaction 用于 broker 回调，检查本地事务执行。 package org.apache.rocketmq.spring.core; import org.springframework.messaging.Message; public interface RocketMQLocalTransactionListener { RocketMQLocalTransactionState executeLocalTransaction(final Message msg, final Object arg); RocketMQLocalTransactionState checkLocalTransaction(final Message msg); } 三、Broker端处理 半消息存储：半消息存入单独的Topic（RMQ_SYS_TRANS_HALF_TOPIC），避免被消费。 定时任务扫描： Broker启动定时任务（默认60秒），扫描超过阈值的半消息。 向生产者发起回查（最多15次，超过则视为失败）。 状态转换： COMMIT → 将消息恢复到原Topic，供消费者消费。 ROLLBACK/超时 → 删除半消息。 四、异常情况 异常1：如果步骤 4 发生异常（COMMIT或ROLLBACK发送失败）怎么办？ 在RocketMQ的事务消息机制中，若Broker长时间未收到生产者发送的COMMIT或ROLLBACK指令（例如因生产者宕机、网络故障或本地事务执行超时），系统会通过事务状态回查机制确保消息的最终一致性。 1. 事务状态回查机制 触发条件： Broker在固定周期（默认60秒）内扫描未确认状态（PREPARED）的半消息（half消息）。若消息超过指定等待时间仍未收到确认指令，则触发回查。 回查流程： Broker向生产者发起回调请求，调用生产者实现的TransactionListener.checkLocalTransaction()方法； 生产者需在该方法中查询本地事务状态（如检查数据库操作结果）； 根据业务状态返回以下结果之一： COMMIT_MESSAGE：提交消息（消息对消费者可见）； ROLLBACK_MESSAGE：回滚消息（删除半消息）； UNKNOW：状态未明，等待下次回查。 2. Broker端的处理逻辑 消息存储隔离： 半消息存储在特殊Topic（RMQ_SYS_TRANS_HALF_TOPIC）中，消费者无法直接消费，确保未提交消息不会泄露。 回查策略： 回查次数限制：默认最多15次（可配置），超过后自动视为失败并回滚消息； 回查间隔：首次回查后若仍返回UNKNOW，后续回查间隔逐步增加（如60秒→2分钟→10分钟）。 结果处理： 收到COMMIT：将消息从RMQ_SYS_TRANS_HALF_TOPIC转移到原始Topic，写入磁盘（CommitLog）并投递给消费者； 收到ROLLBACK：删除半消息； 持续UNKNOW：达到最大回查次数后强制回滚。 3. 生产者端的实现要求 生产者需在checkLocalTransaction()方法中实现幂等且可靠的状态查询逻辑，例如： @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) { // 根据消息唯一ID查询数据库事务状态 String orderId = msg.getProperty(&quot;ORDER_ID&quot;); boolean isSuccess = orderService.isTransactionCompleted(orderId); return isSuccess ? LocalTransactionState.COMMIT_MESSAGE : LocalTransactionState.ROLLBACK_MESSAGE; } 注意事项： 幂等性：多次回查可能针对同一消息，需避免重复提交或回滚； 状态判断：若事务结果依赖外部调用（如RPC），需设计降级策略（如超时后视为失败）。 4. 极端场景的应对 生产者永久宕机： Broker在多次回查失败后自动回滚消息，避免消息积压。 回查期间业务状态变更： 生产者需记录事务日志（如数据库事务表），确保回查时能获取准确状态。 总结 环节 动作 Broker 定时扫描未确认消息 → 触发回查 → 根据结果提交/回滚/重试 生产者 实现状态检查接口 → 查询本地事务日志 → 返回明确状态 消息存储 半消息隔离存储（RMQ_SYS_TRANS_HALF_TOPIC） → 提交后转至目标Topic ","link":"https://panson.top/post/rocketmq-shi-wu-shi-ru-he-shi-xian-de/"},{"title":"分布式事务之 Saga","content":"Saga是针对分布式长活事务的解决方案，针对事务长、多、复杂的情况，特别是服务由多个公司开发具有不可控性，可以使用Saga模式进行分布式事务的处理。 Saga在处理事务一致性方面采取了向前恢复和向后恢复策略，前者通过不断重试的方式保证事务完成，而后者通过子事务的补偿事务，逐一回滚的方式让事务标记失败。 在分布式协调方面，Saga采用了两种模式：编排和控制。前者让参与者（服务）之间通过消息进行沟通，根据事件出发事务的执行流程，是一种去中心化的模式。后者通过中心控制类，处理事务的执行和回滚步骤，统一调用服务和接受服务的反馈。 一、核心场景：电商订单全流程拆解 想象一个国际电商订单流程： 订单服务 → 创建订单 支付服务 → 扣款 风控服务 → 反欺诈检查（耗时1-5秒） 物流服务 → 分配仓库 库存服务 → 扣减库存 若风控审核失败，系统需按倒序回滚： 撤销仓库分配（物流服务） 退款（支付服务） 取消订单（订单服务） 二、Saga实现机制：两种核心模式对比 1. 协同式 (Choreography) 无中心协调器，服务间通过事件触发 特征： 服务直接发布/订阅事件 无单点故障风险 调试复杂度较高（需跟踪事件流） 2. 编排式 (Orchestration) 由协调器统一控制流程 特征： 集中管理状态流转 易监控和调试 协调器成为性能瓶颈风险 💡 技术选型建议： 流程节点 ≤ 5 → 协同式（轻量敏捷） 流程节点 &gt; 5 → 编排式（可控性强） ","link":"https://panson.top/post/fen-bu-shi-shi-wu-zhi-saga/"},{"title":"Panson-Weekly-013","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 100. 相同的树 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { public boolean isSameTree(TreeNode p, TreeNode q) { if(p == null &amp;&amp; q == null) { return true; } else if (p == null || q == null) { return false; } else if(p.val != q.val) { return false; } else { return isSameTree(p.left, q.left) &amp;&amp; isSameTree(p.right, q.right); } } } 104. 二叉树的最大深度 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { public int maxDepth(TreeNode root) { if(root == null) { return 0; } else { int leftMax = maxDepth(root.left); int rightMax = maxDepth(root.right); return Math.max(leftMax, rightMax) + 1; } } } 226. 翻转二叉树 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { public TreeNode invertTree(TreeNode root) { if(root == null) { return null; } TreeNode tmp = root.right; root.right = root.left; root.left = tmp; invertTree(root.left); invertTree(root.right); return root; } } 101. 对称二叉树 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { public boolean isSymmetric(TreeNode root) { if(root == null) { return true; } return isSymmetric(root.left, root.right); } public boolean isSymmetric(TreeNode left, TreeNode right) { if(left == null &amp;&amp; right == null) { return true; } if(right == null || left == null) { return false; } if(left.val != right.val) { return false; } return isSymmetric(left.left, right.right) &amp;&amp; isSymmetric(left.right, right.left); } } 215. 数组中的第K个最大元素 class Solution { public int findKthLargest(int[] nums, int k) { PriorityQueue&lt;Integer&gt; pq = new PriorityQueue&lt;&gt;(); for (int e : nums) { pq.offer(e); if (pq.size() &gt; k) { pq.poll(); } } return pq.peek(); } } class Solution { Random random = new Random(); public int findKthLargest(int[] nums, int k) { return quickSelect(nums, 0, nums.length - 1, nums.length - k); } public int quickSelect(int[] a, int l, int r, int index) { int q = randomPartition(a, l, r); if (q == index) { return a[q]; } else { return q &lt; index ? quickSelect(a, q + 1, r, index) : quickSelect(a, l, q - 1, index); } } public int randomPartition(int[] a, int l, int r) { int i = random.nextInt(r - l + 1) + l; swap(a, i, r); return partition(a, l, r); } public int partition(int[] a, int l, int r) { int x = a[r], i = l - 1; for (int j = l; j &lt; r; ++j) { if (a[j] &lt;= x) { swap(a, ++i, j); } } swap(a, i + 1, r); return i + 1; } public void swap(int[] a, int i, int j) { int temp = a[i]; a[i] = a[j]; a[j] = temp; } } +912. 排序数组 class Solution { public int[] sortArray(int[] nums) { if (nums == null || nums.length == 1) { return nums; } quickSort(nums, 0, nums.length - 1); return nums; } private void quickSort(int[] nums, int l, int r) { if (l &gt;= r) { return; } int q = randomPartition(nums, l, r); quickSort(nums, l, q - 1); quickSort(nums, q + 1, r); } private int partition(int[] nums, int l, int r) { int pivot = nums[r]; int i = l; for (int j = l; j &lt; r; j++) { if (nums[j] &lt; pivot) { if (i == j) { // 此时无需交换，两者相等 i++; } else { swap(nums, i++, j); } } } swap(nums, i, r); return i; } private void swap(int[] nums, int i, int j) { int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; } private int randomPartition(int[] nums, int l, int r) { Random random = new Random(); int pivotIndex = random.nextInt(r - l + 1) + l; // 随机选择划分点的索引 swap(nums, pivotIndex, r); // 将划分点交换到数组末尾 return partition(nums, l, r); // 调用普通的 partition 方法 } } ","link":"https://panson.top/post/panson-weekly-013/"},{"title":"分布式事务之 TCC","content":"本文部分内容来源于网络，觉得挺好的，不重复造轮子了。 业务场景介绍 咱们先来看看业务场景，假设你现在有一个电商系统，里面有一个支付订单的场景。 那对一个订单支付之后，我们需要做下面的步骤： 更改订单的状态为“已支付” 扣减商品库存 给会员增加积分 创建销售出库单通知仓库发货 这是一系列比较真实的步骤，无论大家有没有做过电商系统，应该都能理解。 进一步思考 好，业务场景有了，现在我们要更进一步，实现一个 TCC 分布式事务的效果。 什么意思呢？也就是说，[1] 订单服务-修改订单状态，[2] 库存服务-扣减库存，[3] 积分服务-增加积分，[4] 仓储服务-创建销售出库单。 上述这几个步骤，要么一起成功，要么一起失败，必须是一个整体性的事务。 举个例子，现在订单的状态都修改为“已支付”了，结果库存服务扣减库存失败。那个商品的库存原来是 100 件，现在卖掉了 2 件，本来应该是 98 件了。 结果呢？由于库存服务操作数据库异常，导致库存数量还是 100。这不是在坑人么，当然不能允许这种情况发生了！ 但是如果你不用 TCC 分布式事务方案的话，就用个 Spring Cloud 开发这么一个微服务系统，很有可能会干出这种事儿来。 我们来看看下面的这个图，直观的表达了上述的过程： 所以说，我们有必要使用 TCC 分布式事务机制来保证各个服务形成一个整体性的事务。 上面那几个步骤，要么全部成功，如果任何一个服务的操作失败了，就全部一起回滚，撤销已经完成的操作。 比如说库存服务要是扣减库存失败了，那么订单服务就得撤销那个修改订单状态的操作，然后得停止执行增加积分和通知出库两个操作。 说了那么多，老规矩，给大家上一张图，大伙儿顺着图来直观的感受一下： 落地实现 TCC 分布式事务 那么现在到底要如何来实现一个 TCC 分布式事务，使得各个服务，要么一起成功？要么一起失败呢？ 大家稍安勿躁，我们这就来一步一步的分析一下。咱们就以一个 Spring Cloud 开发系统作为背景来解释。 TCC 实现阶段一：Try 首先，订单服务那儿，它的代码大致来说应该是这样子的： public class OrderService { // 库存服务 @Autowired private InventoryService inventoryService; // 积分服务 @Autowired private CreditService creditService; // 仓储服务 @Autowired private WmsService wmsService; // 对这个订单完成支付 public void pay(){ //对本地的的订单数据库修改订单状态为&quot;已支付&quot; orderDAO.updateStatus(OrderStatus.PAYED); //调用库存服务扣减库存 inventoryService.reduceStock(); //调用积分服务增加积分 creditService.addCredit(); //调用仓储服务通知发货 wmsService.saleDelivery(); } } 如果你之前看过 Spring Cloud 架构原理那篇文章，同时对 Spring Cloud 有一定的了解的话，应该是可以理解上面那段代码的。 其实就是订单服务完成本地数据库操作之后，通过 Spring Cloud 的 Feign 来调用其他的各个服务罢了。 但是光是凭借这段代码，是不足以实现 TCC 分布式事务的啊？！兄弟们，别着急，我们对这个订单服务修改点儿代码好不好。 首先，上面那个订单服务先把自己的状态修改为：OrderStatus.UPDATING。 这是啥意思呢？也就是说，在 pay() 那个方法里，你别直接把订单状态修改为已支付啊！你先把订单状态修改为 UPDATING，也就是修改中的意思。 这个状态是个没有任何含义的这么一个状态，代表有人正在修改这个状态罢了。 然后呢，库存服务直接提供的那个 reduceStock() 接口里，也别直接扣减库存啊，你可以是冻结掉库存。 举个例子，本来你的库存数量是 100，你别直接 100 - 2 = 98，扣减这个库存！ 你可以把可销售的库存：100 - 2 = 98，设置为 98 没问题，然后在一个单独的冻结库存的字段里，设置一个 2。也就是说，有 2 个库存是给冻结了。 积分服务的 addCredit() 接口也是同理，别直接给用户增加会员积分。你可以先在积分表里的一个预增加积分字段加入积分。 比如：用户积分原本是 1190，现在要增加 10 个积分，别直接 1190 + 10 = 1200 个积分啊！ 你可以保持积分为 1190 不变，在一个预增加字段里，比如说 prepare_add_credit 字段，设置一个 10，表示有 10 个积分准备增加。 仓储服务的 saleDelivery() 接口也是同理啊，你可以先创建一个销售出库单，但是这个销售出库单的状态是“UNKNOWN”。 也就是说，刚刚创建这个销售出库单，此时还不确定它的状态是什么呢！ 上面这套改造接口的过程，其实就是所谓的 TCC 分布式事务中的第一个 T 字母代表的阶段，也就是 Try 阶段。 总结上述过程，如果你要实现一个 TCC 分布式事务，首先你的业务的主流程以及各个接口提供的业务含义，不是说直接完成那个业务操作，而是完成一个 Try 的操作。 这个操作，一般都是锁定某个资源，设置一个预备类的状态，冻结部分数据，等等，大概都是这类操作。 咱们来一起看看下面这张图，结合上面的文字，再来捋一捋整个过程： TCC 实现阶段二：Confirm 然后就分成两种情况了，第一种情况是比较理想的，那就是各个服务执行自己的那个 Try 操作，都执行成功了，Bingo！ 这个时候，就需要依靠 TCC 分布式事务框架来推动后续的执行了。这里简单提一句，如果你要玩儿 TCC 分布式事务，必须引入一款 TCC 分布式事务框架，比如国内开源的 ByteTCC、Himly、TCC-transaction。 否则的话，感知各个阶段的执行情况以及推进执行下一个阶段的这些事情，不太可能自己手写实现，太复杂了。 如果你在各个服务里引入了一个 TCC 分布式事务的框架，订单服务里内嵌的那个 TCC 分布式事务框架可以感知到，各个服务的 Try 操作都成功了。 此时，TCC 分布式事务框架会控制进入 TCC 下一个阶段，第一个 C 阶段，也就是 Confirm 阶段。 为了实现这个阶段，你需要在各个服务里再加入一些代码。比如说，订单服务里，你可以加入一个 Confirm 的逻辑，就是正式把订单的状态设置为“已支付”了，大概是类似下面这样子： public class OrderServiceConfirm { public void pay(){ orderDao.updateStatus(OrderStatus.PAYED); } } 库存服务也是类似的，你可以有一个 InventoryServiceConfirm 类，里面提供一个 reduceStock() 接口的 Confirm 逻辑，这里就是将之前冻结库存字段的 2 个库存扣掉变为 0。 这样的话，可销售库存之前就已经变为 98 了，现在冻结的 2 个库存也没了，那就正式完成了库存的扣减。 积分服务也是类似的，可以在积分服务里提供一个 CreditServiceConfirm 类，里面有一个 addCredit() 接口的 Confirm 逻辑，就是将预增加字段的 10 个积分扣掉，然后加入实际的会员积分字段中，从 1190 变为 1200。 仓储服务也是类似，可以在仓储服务中提供一个 WmsServiceConfirm 类，提供一个 saleDelivery() 接口的 Confirm 逻辑，将销售出库单的状态正式修改为“已创建”，可以供仓储管理人员查看和使用，而不是停留在之前的中间状态“UNKNOWN”了。 好了，上面各种服务的 Confirm 的逻辑都实现好了，一旦订单服务里面的 TCC 分布式事务框架感知到各个服务的 Try 阶段都成功了以后，就会执行各个服务的 Confirm 逻辑。 订单服务内的 TCC 事务框架会负责跟其他各个服务内的 TCC 事务框架进行通信，依次调用各个服务的 Confirm 逻辑。然后，正式完成各个服务的所有业务逻辑的执行。 同样，给大家来一张图，顺着图一起来看看整个过程： TCC 实现阶段三：Cancel 好，这是比较正常的一种情况，那如果是异常的一种情况呢？ 举个例子：在 Try 阶段，比如积分服务吧，它执行出错了，此时会怎么样？ 那订单服务内的 TCC 事务框架是可以感知到的，然后它会决定对整个 TCC 分布式事务进行回滚。 也就是说，会执行各个服务的第二个 C 阶段，Cancel 阶段。同样，为了实现这个 Cancel 阶段，各个服务还得加一些代码。 首先订单服务，它得提供一个 OrderServiceCancel 的类，在里面有一个 pay() 接口的 Cancel 逻辑，就是可以将订单的状态设置为“CANCELED”，也就是这个订单的状态是已取消。 库存服务也是同理，可以提供 reduceStock() 的 Cancel 逻辑，就是将冻结库存扣减掉 2，加回到可销售库存里去，98 + 2 = 100。 积分服务也需要提供 addCredit() 接口的 Cancel 逻辑，将预增加积分字段的 10 个积分扣减掉。 仓储服务也需要提供一个 saleDelivery() 接口的 Cancel 逻辑，将销售出库单的状态修改为“CANCELED”设置为已取消。 然后这个时候，订单服务的 TCC 分布式事务框架只要感知到了任何一个服务的 Try 逻辑失败了，就会跟各个服务内的 TCC 分布式事务框架进行通信，然后调用各个服务的 Cancel 逻辑。 大家看看下面的图，直观的感受一下： 总结与思考 好了，兄弟们，聊到这儿，基本上大家应该都知道 TCC 分布式事务具体是怎么回事了！ 总结一下，你要玩儿 TCC 分布式事务的话：首先需要选择某种 TCC 分布式事务框架，各个服务里就会有这个 TCC 分布式事务框架在运行。 然后你原本的一个接口，要改造为 3 个逻辑，Try-Confirm-Cancel： 先是服务调用链路依次执行 Try 逻辑。 如果都正常的话，TCC 分布式事务框架推进执行 Confirm 逻辑，完成整个事务。 如果某个服务的 Try 逻辑有问题，TCC 分布式事务框架感知到之后就会推进执行各个服务的 Cancel 逻辑，撤销之前执行的各种操作。 这就是所谓的 TCC 分布式事务。TCC 分布式事务的核心思想，说白了，就是当遇到下面这些情况时： 某个服务的数据库宕机了。 某个服务自己挂了。 那个服务的 Redis、Elasticsearch、MQ 等基础设施故障了。 某些资源不足了，比如说库存不够这些。 先来 Try 一下，不要把业务逻辑完成，先试试看，看各个服务能不能基本正常运转，能不能先冻结我需要的资源。 如果 Try 都 OK，也就是说，底层的数据库、Redis、Elasticsearch、MQ 都是可以写入数据的，并且你保留好了需要使用的一些资源（比如冻结了一部分库存）。 接着，再执行各个服务的 Confirm 逻辑，基本上 Confirm 就可以很大概率保证一个分布式事务的完成了。 那如果 Try 阶段某个服务就失败了，比如说底层的数据库挂了，或者 Redis 挂了，等等。 此时就自动执行各个服务的 Cancel 逻辑，把之前的 Try 逻辑都回滚，所有服务都不要执行任何设计的业务逻辑。保证大家要么一起成功，要么一起失败。 等一等，你有没有想到一个问题？如果有一些意外的情况发生了，比如说订单服务突然挂了，然后再次重启，TCC 分布式事务框架是如何保证之前没执行完的分布式事务继续执行的呢？ 所以，TCC 事务框架都是要记录一些分布式事务的活动日志的，可以在磁盘上的日志文件里记录，也可以在数据库里记录。保存下来分布式事务运行的各个阶段和状态。 问题还没完，万一某个服务的 Cancel 或者 Confirm 逻辑执行一直失败怎么办呢？ 那也很简单，TCC 事务框架会通过活动日志记录各个服务的状态。举个例子，比如发现某个服务的 Cancel 或者 Confirm 一直没成功，会不停的重试调用它的 Cancel 或者 Confirm 逻辑，务必要它成功！ 当然了，如果你的代码没有写什么 Bug，有充足的测试，而且 Try 阶段都基本尝试了一下，那么其实一般 Confirm、Cancel 都是可以成功的！ 最后，再给大家来一张图，来看看给我们的业务，加上分布式事务之后的整个执行流程： 不少大公司里，其实都是自己研发 TCC 分布式事务框架的，专门在公司内部使用，比如我们就是这样。 不过如果自己公司没有研发 TCC 分布式事务框架的话，那一般就会选用开源的框架。 这里笔者给大家推荐几个比较不错的框架，都是咱们国内自己开源出去的：ByteTCC，TCC-transaction，Himly。 大家有兴趣的可以去它们的 GitHub 地址，学习一下如何使用，以及如何跟 Spring Cloud、Dubbo 等服务框架整合使用。 只要把那些框架整合到你的系统里，很容易就可以实现上面那种奇妙的 TCC 分布式事务的效果了。 ","link":"https://panson.top/post/fen-bu-shi-shi-wu-zhi-tcc/"},{"title":"分布式事务之 XA 协议","content":"一、XA协议核心概念 1. 定义 XA（Extended Architecture）：由X/Open组织（现为Open Group）提出的分布式事务处理规范。 核心目标：确保跨多个独立资源（如数据库、消息队列）的事务操作满足ACID中的原子性（Atomicity）。 2. 关键角色 角色 英文全称 职责 AP Application Program 发起全局事务的应用程序 TC Transaction Coordinator 事务协调器，管理全局事务生命周期 RM Resource Manager 资源管理器（如MySQL、Oracle等数据库） 3. 核心协议：2PC（Two-Phase Commit，两阶段提交） 二、两阶段提交详解 阶段1：Prepare Phase（准备阶段） TC向所有RM发送 XA PREPARE 指令。 各RM执行本地事务（不提交），锁定资源并写入Undo/Redo日志。 RM返回投票结果： YES：确保本地事务可提交。 NO：本地事务失败（如违反约束）。 阶段2：Commit Phase（提交阶段） Case 1: 全部YES → 提交 TC发送 XA COMMIT，RM提交事务并释放锁。 Case 2: 任一NO → 回滚 TC发送 XA ROLLBACK，RM撤销操作并释放锁。 +-----------------+ Phase 1 +-----------------+ | Transaction | ----------------&gt; | Resource | | Coordinator (TC)| &lt;---------------- | Manager (RM) | +-----------------+ Vote (YES/NO) +-----------------+ | | Phase 2 (根据投票结果) v +-----------+-----------+ | | +----+-----+ +-----+----+ | COMMIT | | ROLLBACK | +----+-----+ +-----+----+ | | v v 资源持久化 撤销本地操作 三、XA关键接口（API） 接口 英文全称 功能 xa_open() XA Open 连接RM xa_close() XA Close 断开RM连接 xa_start() XA Start 启动事务分支 xa_end() XA End 结束事务分支 xa_prepare() XA Prepare 进入准备阶段 xa_commit() XA Commit 提交事务 xa_rollback() XA Rollback 回滚事务 xa_recover() XA Recover 恢复悬挂事务 四、XA的挑战与缺陷 1. 性能瓶颈 2. 故障风险 单点故障（SPOF）：TC宕机导致所有RM阻塞。 悬挂事务（In-doubt Transaction）： RM在Prepare后未收到TC指令时，事务状态不确定。 网络分区：可能导致部分提交、部分回滚。 3. 恢复机制 TC崩溃后：新TC通过 xa_recover() 扫描所有RM的Prepared状态事务，重做决策。 RM崩溃后：根据日志重放事务（提交/回滚）。 五、XA vs. CAP定理 Consistency ↑ XA强一致 → 牺牲Availability ↓ Partition Tolerance (必须保障) 结论：XA在分区（Partition）发生时，会阻塞系统（CP模型），无法满足高可用。 六、适用场景 ✅ 传统金融系统（强一致性优先） ✅ 单应用整合多个关系型数据库（如MySQL+Oracle） ❌ 微服务架构（服务自治要求高） ❌ 高并发低延迟场景（如电商秒杀） 附录：XA事务状态机 +---------+ +----------+ +-----------+ | BEGIN | ----&gt; | ACTIVE | ----&gt; | PREPARED | +---------+ +----------+ +-----------+ | | | (失败/超时) | (TC决策) v v +-----------+ +-----------+ | ROLLBACK | &lt;-----| COMMITTED | +-----------+ +-----------+ 通过以上分析，XA协议通过标准化接口和2PC机制解决了分布式原子性问题，但其性能与可用性限制使其在云原生时代逐渐被TCC、Saga等柔性事务替代。 ","link":"https://panson.top/post/fen-bu-shi-shi-wu-zhi-xa-xie-yi/"},{"title":"Panson-Weekly-012","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 20. 有效的括号 class Solution { public boolean isValid(String s) { // 如果长度不能被 2 整除，则必定无效 int n = s.length(); if(n % 2 != 0) { return false; } Map&lt;Character, Character&gt; map = new HashMap&lt;&gt;(); map.put(')', '('); map.put(']', '['); map.put('}', '{'); Deque&lt;Character&gt; stack = new ArrayDeque&lt;&gt;(); for(int i = 0; i &lt; n; i++) { char ch = s.charAt(i); // 当前元素是右括号，如果栈顶元素不是左括号，那么 return false if(map.containsKey(ch)) { if(stack.isEmpty() || stack.peek() != map.get(ch)) { return false; } stack.pop(); } else { stack.push(ch); } } return stack.isEmpty(); } } 83. 删除排序链表中的重复元素 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { public ListNode deleteDuplicates(ListNode head) { ListNode cur = head; while(cur != null &amp;&amp; cur.next != null) { if(cur.val == cur.next.val) { cur.next = cur.next.next; } else { cur = cur.next; } } return head; } } 面试题 01.03. URL化 class Solution { public String replaceSpaces(String S, int length) { char[] chars = S.toCharArray(); int index = chars.length - 1; for (int i = length - 1; i &gt;= 0; i--) { if (chars[i] == ' ') { chars[index--] = '0'; chars[index--] = '2'; chars[index--] = '%'; } else { chars[index--] = chars[i]; } } return new String(chars, index + 1, chars.length - index - 1); } } 71. 简化路径 class Solution { public String simplifyPath(String path) { // 使用 &quot;/&quot; 分割路径字符串，得到各个组件 String[] components = path.split(&quot;/&quot;); // 使用栈来辅助简化路径 Deque&lt;String&gt; stack = new ArrayDeque&lt;&gt;(); // 遍历路径的各个组件 for (String component : components) { // 如果是 &quot;..&quot;，表示向上一级目录，从栈中弹出元素 if (component.equals(&quot;..&quot;)) { if (!stack.isEmpty()) { stack.pop(); } } else if (!component.isEmpty() &amp;&amp; !component.equals(&quot;.&quot;)) { // 如果不为空且不是 &quot;.&quot;，表示有效目录名，推入栈中 stack.push(component); } } // 构建简化后的路径 StringBuilder simplifiedPath = new StringBuilder(&quot;/&quot;); for (String component : stack) { simplifiedPath.append(component).append(&quot;/&quot;); } // 如果路径长度大于1，移除末尾的 &quot;/&quot; if (simplifiedPath.length() &gt; 1) { simplifiedPath.setLength(simplifiedPath.length() - 1); } // 返回简化后的路径字符串 return simplifiedPath.toString(); } } ","link":"https://panson.top/post/panson-weekly-012/"},{"title":"Panson-Weekly-011","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 202. 快乐数 class Solution { public boolean isHappy(int n) { if(n == 1) { return true; } Set&lt;Integer&gt; set = new HashSet&lt;&gt;(); int sum = 0; while(!set.contains(n)) { set.add(n); while(n &gt; 0) { int remain = n % 10; n = n / 10; sum += Math.pow(remain, 2); } if(sum == 1) { return true; } n = sum; sum = 0; } return false; } } 219. 存在重复元素 II class Solution { public boolean containsNearbyDuplicate(int[] nums, int k) { Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for(int i = 0; i &lt; nums.length; i++) { if(map.containsKey(nums[i]) &amp;&amp; i - map.get(nums[i]) &lt;= k) { return true; } map.put(nums[i], i); } return false; } } 128. 最长连续序列 class Solution { public int longestConsecutive(int[] nums) { Set&lt;Integer&gt; allNums = new HashSet&lt;&gt;(); for(int num : nums) { allNums.add(num); } int ret = 0; for(int num : allNums) { if(allNums.contains(num - 1)) { continue; } int start = num; int length = 1; while(allNums.contains(start + 1)) { start += 1; length += 1; } ret = Math.max(length, ret); } return ret; } } class Solution { public List&lt;String&gt; summaryRanges(int[] nums) { List&lt;String&gt; ret = new ArrayList&lt;&gt;(); if(nums.length == 0) { return ret; } if(nums.length == 1) { ret.add(Integer.toString(nums[0])); return ret; } int i = 0; while(i &lt; nums.length) { int start = i; i++; while(i &lt; nums.length &amp;&amp; nums[i] == nums[i - 1] + 1) { i++; } int end = i - 1; if(start &lt; end) { ret.add(nums[start] + &quot;-&gt;&quot; + nums[end]); } else { ret.add(Integer.toString(nums[start])); } } return ret; } } 56. 合并区间 class Solution { public int[][] merge(int[][] intervals) { ArrayList&lt;int[]&gt; ret = new ArrayList&lt;&gt;(); Arrays.sort(intervals, Comparator.comparingInt(a -&gt; a[0])); int i = 0; while(i &lt; intervals.length) { int start = i; i++; while(i &lt; intervals.length &amp;&amp; intervals[i - 1][1] &gt;= intervals[i][0]) { intervals[i][0] = Math.min(intervals[i][0], intervals[i - 1][0]); intervals[i][1] = Math.max(intervals[i][1], intervals[i - 1][1]); i++; } int end = i - 1; int[] arr = new int[2]; arr[0] = intervals[start][0]; arr[1] = intervals[end][1]; ret.add(arr); } return ret.toArray(new int[ret.size()][]); } } +57. 插入区间 class Solution { public int[][] insert(int[][] intervals, int[] newInterval) { int left = newInterval[0]; int right = newInterval[1]; boolean placed = false; List&lt;int[]&gt; ansList = new ArrayList&lt;int[]&gt;(); for (int[] interval : intervals) { if (interval[0] &gt; right) { // 在插入区间的右侧且无交集 if (!placed) { ansList.add(new int[]{left, right}); placed = true; } ansList.add(interval); } else if (interval[1] &lt; left) { // 在插入区间的左侧且无交集 ansList.add(interval); } else { // 与插入区间有交集，计算它们的并集 left = Math.min(left, interval[0]); right = Math.max(right, interval[1]); } } if (!placed) { ansList.add(new int[]{left, right}); } int[][] ans = new int[ansList.size()][2]; for (int i = 0; i &lt; ansList.size(); ++i) { ans[i] = ansList.get(i); } return ans; } } ","link":"https://panson.top/post/panson-weekly-011/"},{"title":"Panson-Weekly-010","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 54. 螺旋矩阵 class Solution { public List&lt;Integer&gt; spiralOrder(int[][] matrix) { List&lt;Integer&gt; ret = new ArrayList&lt;&gt;(); if(matrix.length == 0) { return ret; } int left = 0; int right = matrix[0].length - 1; int top = 0; int bottom = matrix.length - 1; int index = 0; while(true) { for(int i = left; i &lt;= right; i++) { ret.add(matrix[top][i]); index++; } if(++top &gt; bottom) { break; } for(int i = top; i &lt;= bottom; i++) { ret.add(matrix[i][right]); index++; } if(left &gt; --right) { break; } for(int i = right; i &gt;= left; i--) { ret.add(matrix[bottom][i]); index++; } if(--bottom &lt; top) { break; } for(int i = bottom; i &gt;= top; i--) { ret.add(matrix[i][left]); index++; } if(++left &gt; right) { break; } } return ret; } } 48. 旋转图像 class Solution { public void rotate(int[][] matrix) { int n = matrix.length; for(int i = 0; i &lt; n / 2; i++) { for(int j = 0; j &lt; n; j++) { int tmp = matrix[i][j]; matrix[i][j] = matrix[n - i - 1][j]; matrix[n - i - 1][j] = tmp; } } for(int k = 0; k &lt; n; k++) { for(int l = k + 1; l &lt; n; l++) { int tmp1 = matrix[k][l]; matrix[k][l] = matrix[l][k]; matrix[l][k] = tmp1; } } } } 73. 矩阵置零 class Solution { public void setZeroes(int[][] matrix) { int m = matrix.length; int n = matrix[0].length; // 首行标记，默认为 1，表示不置零 int r0 = 1; // 首列标记，默认为 1，表示不置零 int c0 = 1; for(int i = 0; i &lt; n; i++) { if(matrix[0][i] == 0) { r0 = 0; break; } } for(int i = 0; i &lt; m; i++) { if(matrix[i][0] == 0) { c0 = 0; break; } } // 将首行首列作为备忘录 for(int i = 1; i &lt; m; i++) { for(int j = 1; j &lt; n; j++) { if(matrix[i][j] == 0) { matrix[i][0] = 0; matrix[0][j] = 0; } } } // 遍历第一行，如果有 0，该列置零 for(int j = 1; j &lt; n; j++) { if(matrix[0][j] == 0) { // 首行有元素被标记为 1，该列整列被置为 0 for(int i = 0; i &lt; m; i++) { matrix[i][j] = 0; } } } // 从第一行开始 for(int i = 1; i &lt; m; i++) { // 首列有元素被标记为 1， 该行整行被置为 0 if(matrix[i][0] == 0) { for(int j = 1; j &lt; n; j++) { matrix[i][j] = 0; } } } if(r0 == 0) { for(int i = 0; i &lt; n; i++) { matrix[0][i] = 0; } } if(c0 == 0) { for(int i = 0; i &lt; m; i++) { matrix[i][0] = 0; } } } } 383. 赎金信 class Solution { public boolean canConstruct(String ransomNote, String magazine) { int[] countMem = new int[26]; for(char c : magazine.toCharArray()) { countMem[c -'a'] += 1; } for(char c1 : ransomNote.toCharArray()) { if(countMem[c1 - 'a'] &lt;= 0) { return false; } countMem[c1 - 'a'] -= 1; } return true; } } 205. 同构字符串 class Solution { public boolean isIsomorphic(String s, String t) { Map&lt;Character, Character&gt; s2t = new HashMap&lt;&gt;(); Map&lt;Character, Character&gt; t2s = new HashMap&lt;&gt;(); for(int i = 0; i &lt; s.length(); i++) { char sch = s.charAt(i); char tch = t.charAt(i); if(s2t.containsKey(sch) &amp;&amp; s2t.get(sch) != tch || t2s.containsKey(tch) &amp;&amp; t2s.get(tch) != sch) { return false; } s2t.put(sch, tch); t2s.put(tch, sch); } return true; } } 290. 单词规律 class Solution { public boolean wordPattern(String pattern, String s) { String[] split = s.split(&quot; &quot;); if(pattern.length() != split.length) { return false; } Map&lt;Character, String&gt; a2b = new HashMap&lt;&gt;(); Map&lt;String, Character&gt; b2a = new HashMap&lt;&gt;(); for(int i = 0; i &lt; pattern.length(); i++) { char ch = pattern.charAt(i); String str = split[i]; if(a2b.containsKey(ch) &amp;&amp; !a2b.get(ch).equals(str) || b2a.containsKey(str) &amp;&amp; !b2a.get(str).equals(ch)) { return false; } a2b.put(ch, str); b2a.put(str, ch); } return true; } } 242. 有效的字母异位词 class Solution { public boolean isAnagram(String s, String t) { int l1 = s.length(); int l2 = t.length(); if(l1 != l2) { return false; } Map&lt;Character, Integer&gt; sCount = new HashMap&lt;&gt;(); Map&lt;Character, Integer&gt; tCount = new HashMap&lt;&gt;(); for(int i = 0; i &lt; l1; i++) { char sch = s.charAt(i); char tch = t.charAt(i); if(sCount.containsKey(sch)) { sCount.put(s.charAt(i), sCount.get(sch) + 1); } else { sCount.put(s.charAt(i), 1); } if(tCount.containsKey(t.charAt(i))) { tCount.put(t.charAt(i), tCount.get(tch) + 1); } else { tCount.put(t.charAt(i), 1); } } for(Map.Entry&lt;Character, Integer&gt; entry : sCount.entrySet()) { if(!entry.getValue().equals(tCount.get(entry.getKey()))) { return false; } } return true; } } 43. 字符串相乘 class Solution { public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) { Map&lt;String, List&lt;String&gt;&gt; map = new HashMap&lt;&gt;(); for(String str : strs) { char[] chs = str.toCharArray(); Arrays.sort(chs); String strSort = new String(chs); if(map.containsKey(strSort)) { map.get(strSort).add(str); } else { List&lt;String&gt; arr = new ArrayList&lt;&gt;(); arr.add(str); map.put(strSort, arr); } } return new ArrayList&lt;&gt;(map.values()); } } 1. 两数之和 class Solution { public int[] twoSum(int[] nums, int target) { Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for(int i = 0; i &lt; nums.length; i++) { if(map.containsKey(target - nums[i])) { return new int[]{i, map.get(target - nums[i])}; } map.put(nums[i], i); } return new int[]{-1, -2}; } } ","link":"https://panson.top/post/panson-weekly-010/"},{"title":"Panson-Weekly-009","content":"日拱一卒 1 一周见闻 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 167. 两数之和 II - 输入有序数组 class Solution { public int[] twoSum(int[] numbers, int target) { int left = 0; int right = numbers.length - 1; while(left &lt; right) { if(numbers[left] + numbers[right] == target) { return new int[]{left + 1, right +1}; } if(numbers[left] + numbers[right] &gt; target) { right--; } else { left++; } } return new int[]{-1, -1}; } } 11. 盛最多水的容器 class Solution { public int maxArea(int[] height) { int left = 0; int right = height.length - 1; int max = 0; while(left &lt; right) { if(height[left] &lt; height[right]) { max = Math.max(max, (right - left) * height[left++]); } else { max = Math.max(max, (right - left) * height[right--]); } } return max; } } 15. 三数之和 class Solution { public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) { Arrays.sort(nums); int n = nums.length; List&lt;List&lt;Integer&gt;&gt; ret = new ArrayList&lt;&gt;(); Set&lt;String&gt; set = new HashSet&lt;&gt;(); for(int i = 0; i &lt; n - 2; i++) { int j = i + 1; int k = n - 1; while(j &lt; k) { if(nums[i] + nums[j] + nums[k] == 0) { List&lt;Integer&gt; newArray = Arrays.asList(nums[i], nums[j], nums[k]); String str = &quot;&quot; + nums[i] + nums[j] + nums[k]; if(!set.contains(str)) { ret.add(newArray); set.add(str); } j++; k--; } else if(nums[i] + nums[j] + nums[k] &lt; 0) { j++; } else { k--; } } } return ret; } } 904. 水果成篮 class Solution { public int totalFruit(int[] fruits) { int n = fruits.length; if(n &lt;= 2) { return n; } int left = 0; int max = 0; Map&lt;Integer, Integer&gt; count = new HashMap&lt;&gt;(); for(int i = 0; i &lt; n; i++) { count.put(fruits[i], count.getOrDefault(fruits[i], 0) + 1); while(count.size() &gt; 2) { count.put(fruits[left], count.get(fruits[left]) - 1); if(count.get(fruits[left]) == 0) { count.remove(fruits[left]); } left++; } max = Math.max(max, i - left + 1); } return max; } } 209. 长度最小的子数组 class Solution { public int minSubArrayLen(int target, int[] nums) { int n = nums.length; int ret = Integer.MAX_VALUE;; int left = 0; int right = 0; int sum = 0; while(right &lt; n) { sum += nums[right]; while(sum &gt;= target) { ret = Math.min(ret, right - left + 1); sum -= nums[left]; left++; } right++; } return ret == Integer.MAX_VALUE ? 0 : ret; } } 3. 无重复字符的最长子串 class Solution { public int lengthOfLongestSubstring(String s) { int max = 0; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); int left = 0; for(int i = 0; i &lt; s.length(); i++) { if(map.containsKey(s.charAt(i))) { // 如果遇到重复的字符，则移动左边界 left = Math.max(map.get(s.charAt(i)) + 1, left); } map.put(s.charAt(i), i); max = Math.max(max, i - left + 1); } return max; } } 739. 每日温度 class Solution { public int[] dailyTemperatures(int[] temperatures) { Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); int[] ret = new int[temperatures.length]; for(int i = 0; i &lt; temperatures.length; i++) { while(!stack.isEmpty() &amp;&amp; temperatures[i] &gt; temperatures[stack.peek()]) { Integer topIndex = stack.pop(); ret[topIndex] = i - topIndex; } // 此时，单调栈中的元素全都比当前遍历元素大了 stack.push(i); } return ret; } } 36. 有效的数独 class Solution { public boolean isValidSudoku(char[][] board) { Map&lt;Integer, Set&lt;Integer&gt;&gt; row = new HashMap&lt;&gt;(); Map&lt;Integer, Set&lt;Integer&gt;&gt; col = new HashMap&lt;&gt;(); Map&lt;Integer, Set&lt;Integer&gt;&gt; area = new HashMap&lt;&gt;(); for (int i = 0; i &lt; 9; i++) { row.put(i, new HashSet&lt;&gt;()); col.put(i, new HashSet&lt;&gt;()); area.put(i, new HashSet&lt;&gt;()); } for(int i = 0; i &lt; 9; i++) { for(int j = 0; j &lt; 9; j++) { char ch = board[i][j]; if(ch == '.') { continue; } int val = Integer.valueOf(ch); if(row.get(i).contains(val)) { return false; } else { row.get(i).add(val); } if(col.get(j).contains(val)) { return false; } else { col.get(j).add(val); } int areaIndex = i / 3 * 3 + j / 3; if(area.get(areaIndex).contains(val)) { return false; } else { area.get(areaIndex).add(val); } } } return true; } } ","link":"https://panson.top/post/panson-weekly-009/"},{"title":"万字长文-线程池源码深入分析","content":"完整的线程池源码注释见章尾。 一、JDK 中的线程池类图 线程池核心类图 classDiagram %% ================= 接口与抽象类 ================= class Executor { &lt;&lt;interface&gt;&gt; +execute(Runnable command) void } class ExecutorService { &lt;&lt;interface&gt;&gt; +shutdown() void +shutdownNow() List~Runnable~ +submit(Callable~T~ task) Future~T~ +invokeAll(Collection~Callable~T~~ tasks) List~Future~T~~ ...其他方法... } class AbstractExecutorService { &lt;&lt;abstract&gt;&gt; +submit(Runnable task) Future~?~ +invokeAny(Collection~Callable~T~~ tasks) T ...其他方法... } %% ================= 核心实现类 ================= class ThreadPoolExecutor { -corePoolSize: int -maximumPoolSize: int -keepAliveTime: long -workQueue: BlockingQueue~Runnable~ -threadFactory: ThreadFactory -handler: RejectedExecutionHandler +execute(Runnable command) void +shutdown() void +shutdownNow() List~Runnable~ +prestartAllCoreThreads() int ...其他方法... } class ScheduledThreadPoolExecutor { +schedule(Runnable command, long delay, TimeUnit unit) ScheduledFuture~?~ +scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) ScheduledFuture~?~ ...其他定时任务方法... } %% ================= 依赖组件 ================= class BlockingQueue~Runnable~ { &lt;&lt;interface&gt;&gt; +offer(Runnable e) boolean +poll(long timeout, TimeUnit unit) Runnable +take() Runnable ...其他方法... } class ThreadFactory { &lt;&lt;interface&gt;&gt; +newThread(Runnable r) Thread } class RejectedExecutionHandler { &lt;&lt;interface&gt;&gt; +rejectedExecution(Runnable r, ThreadPoolExecutor executor) void } %% ================= 继承与实现关系 ================= Executor &lt;|-- ExecutorService ExecutorService &lt;|.. AbstractExecutorService AbstractExecutorService &lt;|-- ThreadPoolExecutor ThreadPoolExecutor &lt;|-- ScheduledThreadPoolExecutor %% ================= 组合关系 ================= ThreadPoolExecutor *-- BlockingQueue~Runnable~ : 任务队列 ThreadPoolExecutor *-- ThreadFactory : 线程工厂 ThreadPoolExecutor *-- RejectedExecutionHandler : 拒绝策略 类图说明 1. 接口与抽象类 Executor 最基础的执行器接口，定义任务提交方法 execute()。 ExecutorService 扩展 Executor，添加线程池生命周期管理（如 shutdown()）和任务批量操作方法（如 submit()）。 AbstractExecutorService 提供 ExecutorService 接口的默认实现（如 submit() 的通用逻辑）。 2. 核心实现类 ThreadPoolExecutor 标准线程池实现，核心参数： corePoolSize: 核心线程数 maximumPoolSize: 最大线程数 keepAliveTime: 非核心线程空闲存活时间 workQueue: 任务队列（如 LinkedBlockingQueue） threadFactory: 线程创建工厂 handler: 拒绝策略（如 AbortPolicy） ScheduledThreadPoolExecutor 支持定时任务的线程池（继承自 ThreadPoolExecutor）。 3. 依赖组件 BlockingQueue&lt;Runnable&gt; 任务队列接口，决定线程池的任务调度策略（如无界队列、有界队列、同步移交队列）。 ThreadFactory 线程创建工厂，允许自定义线程名称、优先级、守护状态等。 RejectedExecutionHandler 拒绝策略处理器，定义队列和线程池满时的行为（如抛出异常、直接运行、静默丢弃等）。 类关系说明 关系类型 示例 说明 **继承（&lt; --）** `Executor &lt; **实现（&lt; ..）** `ExecutorService &lt; 组合（*--） ThreadPoolExecutor *-- BlockingQueue 线程池持有任务队列实例 渲染方法 在线预览 将代码粘贴到 Mermaid Live Editor 中查看效果。 本地工具 使用支持 Mermaid 的 Markdown 工具（如 VSCode + Mermaid 插件、Typora）。 应用场景 面试复习：快速理解线程池的架构设计 代码评审：分析自定义线程池的参数配置 系统设计：规划线程池与其他组件的交互关系 通过此图可以清晰看到线程池如何通过 组合模式 将任务队列、线程工厂、拒绝策略等组件解耦，实现高度可定制化的并发处理框架。 二、线程池构造函数详解 ThreadPoolExecutor 是 Java 中功能最强大的线程池实现类，其构造函数包含多个核心参数，直接影响线程池的行为和性能。以下是其构造函数及各参数的详细解析： public ThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler ) 1. 核心参数解析 参数名 类型 作用 默认值/示例 corePoolSize int 核心线程数：即使线程空闲也保留的线程数（除非设置allowCoreThreadTimeOut） 需显式设置（如CPU密集型任务建议设置为CPU核数） maximumPoolSize int 最大线程数：线程池允许创建的最大线程数 需显式设置（一般为核心数的2倍） keepAliveTime long 非核心线程的空闲存活时间：超出核心数的线程在空闲时的存活时间 60（秒） unit TimeUnit 时间单位：keepAliveTime的时间单位（纳秒、毫秒、秒等） TimeUnit.SECONDS workQueue BlockingQueue 任务队列：用于保存等待执行的任务的阻塞队列 LinkedBlockingQueue threadFactory ThreadFactory 线程工厂：用于创建新线程（可自定义线程名称、优先级等） Executors.defaultThreadFactory() handler RejectedExecutionHandler 拒绝策略：当线程池和队列都满时，处理新提交任务的策略 AbortPolicy（抛出异常） 2. 线程池工作流程 当新任务提交时，线程池的处理逻辑如下： graph TD A[提交任务] --&gt; B{核心线程是否已满?} B --&gt;|未满| C[创建新线程执行] B --&gt;|已满| D{队列是否已满?} D --&gt;|未满| E[任务入队等待] D --&gt;|已满| F{最大线程数是否已满?} F --&gt;|未满| G[创建非核心线程执行] F --&gt;|已满| H[触发拒绝策略] 具体步骤： 核心线程优先：任务提交后优先创建核心线程执行。 任务入队：核心线程满后，任务进入阻塞队列。 扩容线程：当队列已满且线程数未达最大值时，创建非核心线程。 拒绝策略：队列和线程池均满时，按策略处理新任务。 3. 关键参数详解 生产环境需要结合实际业务，压测并优化线程数。 （1）线程数配置 CPU密集型任务（如计算、压缩）： corePoolSize = CPU核数（Runtime.getRuntime().availableProcessors()） maximumPoolSize = corePoolSize（避免过多线程竞争） IO密集型任务（如网络请求、数据库操作）： corePoolSize = CPU核数 * 2 maximumPoolSize = corePoolSize + 预期并发数 （2）任务队列（workQueue） 队列类型 特点 适用场景 LinkedBlockingQueue 无界队列（默认容量Integer.MAX_VALUE），导致maximumPoolSize无效 任务量平稳且需要保证所有任务被处理 ArrayBlockingQueue 有界队列，需指定固定容量 需要控制队列大小防止内存溢出 SynchronousQueue 不存储任务，直接移交线程执行（需配合较大maximumPoolSize） 高并发且任务处理快速的场景 PriorityBlockingQueue 带优先级的无界队列 需要任务按优先级执行 示例： // 创建容量为100的有界队列 BlockingQueue&lt;Runnable&gt; queue = new ArrayBlockingQueue&lt;&gt;(100); （3）拒绝策略（handler） 策略类 行为 适用场景 AbortPolicy 直接抛出RejectedExecutionException 需要明确感知任务被拒绝（生产环境常用） CallerRunsPolicy 由提交任务的线程直接执行任务 需要保证任务不丢失（如日志记录） DiscardPolicy 静默丢弃新任务 可容忍任务丢失（如监控数据上报） DiscardOldestPolicy 丢弃队列中最旧的任务，然后重试提交 需要优先处理新任务（如实时消息处理） 自定义拒绝策略示例： new RejectedExecutionHandler() { @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) { // 记录日志并降级处理 logger.warn(&quot;Task rejected: {}&quot;, r); r.run(); // 降级由当前线程执行 } } （4）线程工厂（threadFactory） 用于自定义线程属性，增强可观测性： ThreadFactory factory = new ThreadFactory() { private final AtomicInteger counter = new AtomicInteger(1); @Override public Thread newThread(Runnable r) { Thread t = new Thread(r); t.setName(&quot;Worker-&quot; + counter.getAndIncrement()); t.setPriority(Thread.NORM_PRIORITY); t.setDaemon(false); // 非守护线程 return t; } }; 4. 完整配置示例 ThreadPoolExecutor executor = new ThreadPoolExecutor( 4, // corePoolSize 8, // maximumPoolSize 30, // keepAliveTime TimeUnit.SECONDS, // unit new ArrayBlockingQueue&lt;&gt;(100), // workQueue new CustomThreadFactory(), // threadFactory new ThreadPoolExecutor.CallerRunsPolicy() // handler ); 5. 注意事项 避免使用无界队列：可能导致内存溢出（如LinkedBlockingQueue默认容量极大）。 合理设置最大线程数：避免过高导致线程竞争，或过低导致任务堆积。 监控线程池状态：通过getActiveCount()、getQueue().size()等API监控运行状态。 优雅关闭：调用shutdown()平滑关闭，或shutdownNow()强制终止。 6. 常见问题 Q1：核心线程数设为0会怎样？ 所有线程都会被视为非核心线程，空闲时会被回收。适合任务量波动大的场景。 Q2：如何预热核心线程？ 调用prestartAllCoreThreads()提前创建所有核心线程。 Q3：动态调整参数 通过setCorePoolSize()和setMaximumPoolSize()动态调整线程数。 通过合理配置这些参数，可以构建出适应不同业务场景的高效线程池，平衡系统资源利用率和任务处理能力。 三、状态与线程数的原子控制 /** * 用它来计算当前线程池的运行状态：原子变量，高3位保存线程池状态，低29位保存工作线程数 */ private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); 在线程池中，线程状态和线程数维护在一个单原子变量中，这样做可以避免多变量同步问题。 /** * 29位 */ private static final int COUNT_BITS = Integer.SIZE - 3; /** * 最大线程数：2^29 - 1 */ private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bits /** * 线程池状态 * 1. RUNNING：接受新任务并处理阻塞队列中的任务。11100000 00000000 00000000 00000000 * 2. SHUTDOWN：不接受新任务，但处理阻塞队列中的任务。00000000 00000000 00000000 00000000 * 3. STOP：不接受新任务，不处理阻塞队列中的任务，中断正在处理的任务。00100000 00000000 00000000 00000000 * 4. TIDYING：所有任务已终止，workerCount（有效线程数）为0，线程过渡到该状态时，会执行terminated()方法。00100000 00000000 00000000 00000000 * 5. TERMINATED：terminated()方法完成后，线程池的状态就会变成TERMINATED。01100000 00000000 00000000 00000000 */ private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; private static final int STOP = 1 &lt;&lt; COUNT_BITS; private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // Packing and unpacking ctl /** * 计算线程池状态 * 解释如下： * 1. ctl是一个AtomicInteger类型的变量，它同时存储了线程池的状态和当前工作线程数 * 2. ctl的高3位存储线程池状态，低29位存储工作线程数 * 3. CAPACITY是一个常量，值为(1 &lt;&lt; COUNT_BITS) - 1，其中COUNT_BITS是29 * 4. ~CAPACITY是对CAPACITY取反，得到的是一个高3位为1，低29位为0的掩码 * 5. c &amp; ~CAPACITY通过与操作，将ctl的低29位（工作线程数）置为0，只保留高3位的线程池状态 */ private static int runStateOf(int c) { return c &amp; ~CAPACITY; } /** * 计算工作线程数 * 解释如下： * 1. ctl是一个AtomicInteger类型的变量，它同时存储了线程池的状态和当前工作线程数 * 2. ctl的高3位存储线程池状态，低29位存储工作线程数 * 3. CAPACITY是一个常量，值为(1 &lt;&lt; COUNT_BITS) - 1，其中COUNT_BITS是29 * 4. c &amp; CAPACITY通过与操作，将ctl的高3位（线程池状态）置为0，只保留低29位的工作线程数 */ private static int workerCountOf(int c) { return c &amp; CAPACITY; } /** * 计算ctl的值 * 解释如下： * 1. rs是线程池状态，wc是工作线程数 * 2. rs &lt;&lt; COUNT_BITS将线程池状态左移29位，得到一个高3位为线程池状态，低29位为0的数字 * 3. wc &amp; CAPACITY将工作线程数与CAPACITY进行与操作，得到一个低29位为工作线程数，高3位为0的数字 * 4. rs &lt;&lt; COUNT_BITS | wc &amp; CAPACITY将两个数字进行或操作，得到一个高3位为线程池状态，低29位为工作线程数的数字 */ private static int ctlOf(int rs, int wc) { return rs | wc; } /* * Bit field accessors that don't require unpacking ctl. * These depend on the bit layout and on workerCount being never negative. */ /** * 线程池状态小于s * 解释如下： * 1. c是ctl的值，它同时存储了线程池的状态和当前工作线程数 * 2. s是线程池状态 * 3. c &lt; s通过比较操作，判断ctl的高3位是否小于s，如果小于，则返回true，否则返回false */ private static boolean runStateLessThan(int c, int s) { return c &lt; s; } /** * 线程池状态大于等于s * 解释如下： * 1. c是ctl的值，它同时存储了线程池的状态和当前工作线程数 * 2. s是线程池状态 * 3. c &gt;= s通过比较操作，判断ctl的高3位是否大于等于s，如果大于等于，则返回true，否则返回false */ private static boolean runStateAtLeast(int c, int s) { return c &gt;= s; } /** * 线程池状态是RUNNING * 解释如下： * 1. c是ctl的值，它同时存储了线程池的状态和当前工作线程数 * 2. c == RUNNING通过比较操作，判断ctl的高3位是否等于RUNNING，如果等于，则返回true，否则返回false */ private static boolean isRunning(int c) { return c &lt; SHUTDOWN; } 四、Worker线程核心逻辑 private final class Worker extends AbstractQueuedSynchronizer implements Runnable { final Thread thread; // 实际执行任务的线程对象 Runnable firstTask; // 初始任务（可能为null） volatile long completedTasks; // 完成的任务计数器 Worker(Runnable firstTask) { setState(-1); // 初始状态-1禁止中断（直到runWorker执行） this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); // 关键：将Worker自身作为Runnable传给线程 } public void run() { runWorker(this); // 实际执行入口 } // 实现简单的不可重入锁 protected boolean isHeldExclusively() { return getState() != 0; } protected boolean tryAcquire(int unused) { if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } protected boolean tryRelease(int unused) { setExclusiveOwnerThread(null); setState(0); return true; } public void lock() { acquire(1); } public boolean tryLock() { return tryAcquire(1); } public void unlock() { release(1); } } 关键设计： Worker本身作为Runnable：通过 thread.start() 触发 runWorker() 执行 AQS锁的作用： 防止任务执行期间被外部中断 实现 shutdownNow() 时批量中断空闲线程 状态-1初始化：避免线程启动前被意外中断 五、任务提交完整流程 public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); // 阶段1：尝试创建核心线程 if (workerCountOf(c) &lt; corePoolSize) { // 条件1：当前线程数 &lt; 核心数 if (addWorker(command, true)) // 参数true表示核心线程 return; // 创建成功直接返回 c = ctl.get(); // 创建失败（并发导致状态变化）重新获取ctl } // 阶段2：尝试将任务加入队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { // 再次检查运行状态并入队 int recheck = ctl.get(); if (!isRunning(recheck) &amp;&amp; remove(command)) // 二次检查：线程池已关闭？ reject(command); // 触发拒绝策略（任务被移除） else if (workerCountOf(recheck) == 0) // 无存活线程但队列有任务 addWorker(null, false); // 创建救急线程处理队列 } // 阶段3：队列已满，尝试创建非核心线程 else if (!addWorker(command, false)) // 参数false表示非核心线程 reject(command); // 创建失败触发拒绝策略 } 关键设计： 核心线程创建：即使队列未满，只要线程数不足立即创建 队列双检锁：workQueue.offer() 后必须二次检查线程池状态 救急线程机制：当队列有任务但线程数为零时（例如被回收），创建新线程处理 六、任务执行核心（runWorker() 完整流程） 在Worker 类中，执行 run 方法，底层调用了 runWorker方法。在 runWorker 方法中，提供了一些扩展点，比如说 beforeExecute(wt, task) 和 afterExecute(task, thrown)。在自定义线程池中，可以扩展实现这两个方法并自定义逻辑，比如加上耗时时间日志之类的。 final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // 状态置为0，允许中断 boolean completedAbruptly = true; try { // 循环获取任务：首次执行firstTask，后续从队列获取 while (task != null || (task = getTask()) != null) { w.lock(); // 加锁防止中断 // 处理线程中断信号（STOP状态） if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; // 清除中断标志 runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); // 重新设置中断标志 try { beforeExecute(wt, task); // 扩展点：执行前回调 Throwable thrown = null; try { task.run(); // 执行用户任务 } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); // 扩展点：执行后回调 } } finally { task = null; // 清空当前任务 w.completedTasks++; w.unlock(); // 释放锁 } } completedAbruptly = false; // 正常退出循环 } finally { processWorkerExit(w, completedAbruptly); // 处理线程退出 } } 关键机制： 锁的释放顺序：unlock() 必须在 completedTasks++ 之后，保证计数的可见性 异常处理：捕获所有Throwable但仅记录Error和RuntimeException 扩展点：beforeExecute() 和 afterExecute() 可用于监控任务执行 七、任务获取机制（getTask() 源码解析） private Runnable getTask() { boolean timedOut = false; // 上次poll是否超时 for (;;) { int c = ctl.get(); int rs = runStateOf(c); // 状态检查：当线程池关闭且队列为空时不再获取任务 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) { decrementWorkerCount(); // 减少线程数 return null; } int wc = workerCountOf(c); // 是否允许超时回收：当前线程数超过核心数 或 允许核心线程超时 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 两个终止条件： // 1. (线程数超过最大值 或 超时发生) 且 (线程数&gt;1 或 队列为空) // 2. 线程数超过容量限制 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } try { // 根据timed决定使用poll或take Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; // 标记超时 } catch (InterruptedException retry) { timedOut = false; // 中断重试 } } } 核心逻辑： 超时控制：非核心线程使用 poll(keepAliveTime)，核心线程默认使用 take()（除非开启allowCoreThreadTimeOut） 优雅终止：当线程池关闭且队列为空时，逐步减少工作线程数 并发安全：通过CAS操作 compareAndDecrementWorkerCount 保证线程数准确 八、线程退出处理（processWorkerExit() 逻辑） 在 任务执行核心runWorker() 方法的最后，会调用 processWorkerExit() 执行线程退出逻辑。 private void processWorkerExit(Worker w, boolean completedAbruptly) { // 异常退出时需要手动减少线程数 if (completedAbruptly) decrementWorkerCount(); // 统计完成任务数 completedTaskCount += w.completedTasks; workers.remove(w); // 从集合中移除Worker // 尝试终止线程池（如果状态是SHUTDOWN且工作队列为空） tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) { // 线程池仍在运行 if (!completedAbruptly) { // 正常退出 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; !workQueue.isEmpty()) min = 1; // 至少保留一个线程处理队列任务 if (workerCountOf(c) &gt;= min) return; // 无需补充新线程 } addWorker(null, false); // 创建新Worker处理剩余任务 } } 核心逻辑： 补偿机制：当非异常退出且当前线程数不足时，补充新线程 保留核心线程：根据 allowCoreThreadTimeOut 决定是否保留核心线程 尝试终止线程池：tryTerminate() 会向其他线程发送终止信号 九、线程池终止流程（shutdown() vs shutdownNow()） 1. shutdown() public void shutdown() { checkShutdownAccess(); advanceRunState(SHUTDOWN); // 状态转为SHUTDOWN interruptIdleWorkers(); // 仅中断空闲线程 onShutdown(); // 空方法（扩展点） } private void interruptIdleWorkers() { for (Worker w : workers) { Thread t = w.thread; if (!t.isInterrupted() &amp;&amp; w.tryLock()) { // 尝试获取Worker锁 try { t.interrupt(); } finally { w.unlock(); } } } } 2. shutdownNow() public List&lt;Runnable&gt; shutdownNow() { List&lt;Runnable&gt; tasks; checkShutdownAccess(); advanceRunState(STOP); // 直接进入STOP状态 interruptWorkers(); // 强制中断所有线程 tasks = drainQueue(); // 清空任务队列 return tasks; } private void interruptWorkers() { for (Worker w : workers) { w.interruptIfStarted(); // 不需要获取锁，直接中断 } } 关键区别： shutdown() 允许执行完队列剩余任务，shutdownNow() 立即停止所有任务 中断策略：shutdown() 只中断空闲线程，shutdownNow() 中断所有线程 十、线程池扩展点/动态修改/监控 凡是可以 set 的成员变量，都可以被动态更新 线程池的核心线程数量 corePoolSize 可以被动态更新。 线程池的最大线程数量 maximumPoolSize 可以被动态更新。 线程池的拒绝策略处理器 RejectedExecutionHandler 可以被动态更新。 线程池核心线程是否允许超时回收的标志 allowCoreThreadTimeOut 可以被动态更新。 线程池线程的最大空闲时间 keepAliveTime 可以被动态更新(之所以没有 threadFactory，是因为一般来说不会动态更新线程工厂)。 凡是可以 get 的成员变量，它们的信息都可以在线程池运行过程中被收集： 线程池的核心线程数 corePoolSize、最大线程数 maximumPoolSize 可以被收集。 线程池线程的空闲时间 keepAliveTime、核心线程是否允许超时回收 allowCoreThreadTimeOut 可以被收集。 线程池的拒绝策略 RejectedExecutionHandler 和任务队列 workQueue 可以被收集。 线程池当前创建的线程数量 poolSize、曾经创建线程的最大数量 largestPoolSize、当前活跃线程数量 activeCount 可以被收集。 线程池的执行的任务总数 taskCount、已经执行完毕的任务总数 completedTaskCount 可以被收集。 1. 动态参数调整（setCorePoolSize 示例） public void setCorePoolSize(int corePoolSize) { if (corePoolSize &lt; 0) throw new IllegalArgumentException(); int delta = corePoolSize - this.corePoolSize; this.corePoolSize = corePoolSize; // 如果当前线程数超过新核心数，尝试中断空闲线程 if (workerCountOf(ctl.get()) &gt; corePoolSize) interruptIdleWorkers(); // 如果新核心数更大，可能需要创建新线程 else if (delta &gt; 0) { int k = Math.min(delta, workQueue.size()); // 需要创建的线程数 while (k-- &gt; 0) { if (addWorker(null, true)) // 创建核心线程处理队列任务 continue; break; } } } 设计亮点： 动态扩容：当核心数增加时，自动创建新线程处理积压任务 智能缩容：通过 interruptIdleWorkers() 逐步回收多余线程 2. 拒绝策略实现原理（以CallerRunsPolicy为例） public static class CallerRunsPolicy implements RejectedExecutionHandler { public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { // 线程池未关闭 r.run(); // 由调用者线程直接执行任务 } } } 特点： 同步执行可能降低整体吞吐量，但保证任务不会丢失 适用于需要保证任务绝对执行的场景 3. 监控接口实现原理 可以通过继承 ThreadPoolExecutor 并重写钩子方法实现监控： protected void beforeExecute(Thread t, Runnable r) { super.beforeExecute(t, r); // 记录任务开始时间 ((MyTask) r).setStartTime(System.nanoTime()); } protected void afterExecute(Runnable r, Throwable t) { super.afterExecute(r, t); // 统计任务耗时 long cost = System.nanoTime() - ((MyTask) r).getStartTime(); metrics.recordTaskTime(cost); } protected void terminated() { super.terminated(); // 线程池完全终止时触发 logger.info(&quot;ThreadPool terminated&quot;); } 设计哲学总结： 状态驱动：所有行为由 ctl 的状态变化触发 锁粒度优化：Worker级别的锁而非全局锁，提高并发度 资源弹性：动态调整线程数，平衡系统负载 扩展友好：通过多个protected方法提供扩展点 失败隔离：单个任务异常不会导致整个线程池崩溃 建议通过调试模式观察以下场景的代码路径： 核心线程数、队列容量、最大线程数都满时的拒绝流程 keepAliveTime到期时线程回收过程 shutdown() 与队列中剩余任务的交互 核心线程超时参数开启后的行为变 十一、ThreadPoolExecutor 类源码注释 public class ThreadPoolExecutor extends AbstractExecutorService { /** * 用它来计算当前线程池的运行状态：原子变量，高3位保存线程池状态，低29位保存工作线程数 */ private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); /** * 29位 */ private static final int COUNT_BITS = Integer.SIZE - 3; /** * 最大线程数：2^29 - 1 */ private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bits /** * 线程池状态 * 1. RUNNING：接受新任务并处理阻塞队列中的任务。11100000 00000000 00000000 00000000 * 2. SHUTDOWN：不接受新任务，但处理阻塞队列中的任务。00000000 00000000 00000000 00000000 * 3. STOP：不接受新任务，不处理阻塞队列中的任务，中断正在处理的任务。00100000 00000000 00000000 00000000 * 4. TIDYING：所有任务已终止，workerCount（有效线程数）为0，线程过渡到该状态时，会执行terminated()方法。00100000 00000000 00000000 00000000 * 5. TERMINATED：terminated()方法完成后，线程池的状态就会变成TERMINATED。01100000 00000000 00000000 00000000 */ private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; private static final int STOP = 1 &lt;&lt; COUNT_BITS; private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // Packing and unpacking ctl /** * 计算线程池状态 * 解释如下： * 1. ctl是一个AtomicInteger类型的变量，它同时存储了线程池的状态和当前工作线程数 * 2. ctl的高3位存储线程池状态，低29位存储工作线程数 * 3. CAPACITY是一个常量，值为(1 &lt;&lt; COUNT_BITS) - 1，其中COUNT_BITS是29 * 4. ~CAPACITY是对CAPACITY取反，得到的是一个高3位为1，低29位为0的掩码 * 5. c &amp; ~CAPACITY通过与操作，将ctl的低29位（工作线程数）置为0，只保留高3位的线程池状态 */ private static int runStateOf(int c) { return c &amp; ~CAPACITY; } /** * 计算工作线程数 * 解释如下： * 1. ctl是一个AtomicInteger类型的变量，它同时存储了线程池的状态和当前工作线程数 * 2. ctl的高3位存储线程池状态，低29位存储工作线程数 * 3. CAPACITY是一个常量，值为(1 &lt;&lt; COUNT_BITS) - 1，其中COUNT_BITS是29 * 4. c &amp; CAPACITY通过与操作，将ctl的高3位（线程池状态）置为0，只保留低29位的工作线程数 */ private static int workerCountOf(int c) { return c &amp; CAPACITY; } /** * 计算ctl的值 * 解释如下： * 1. rs是线程池状态，wc是工作线程数 * 2. rs &lt;&lt; COUNT_BITS将线程池状态左移29位，得到一个高3位为线程池状态，低29位为0的数字 * 3. wc &amp; CAPACITY将工作线程数与CAPACITY进行与操作，得到一个低29位为工作线程数，高3位为0的数字 * 4. rs &lt;&lt; COUNT_BITS | wc &amp; CAPACITY将两个数字进行或操作，得到一个高3位为线程池状态，低29位为工作线程数的数字 */ private static int ctlOf(int rs, int wc) { return rs | wc; } /* * Bit field accessors that don't require unpacking ctl. * These depend on the bit layout and on workerCount being never negative. */ /** * 线程池状态小于s * 解释如下： * 1. c是ctl的值，它同时存储了线程池的状态和当前工作线程数 * 2. s是线程池状态 * 3. c &lt; s通过比较操作，判断ctl的高3位是否小于s，如果小于，则返回true，否则返回false */ private static boolean runStateLessThan(int c, int s) { return c &lt; s; } /** * 线程池状态大于等于s * 解释如下： * 1. c是ctl的值，它同时存储了线程池的状态和当前工作线程数 * 2. s是线程池状态 * 3. c &gt;= s通过比较操作，判断ctl的高3位是否大于等于s，如果大于等于，则返回true，否则返回false */ private static boolean runStateAtLeast(int c, int s) { return c &gt;= s; } /** * 线程池状态是RUNNING * 解释如下： * 1. c是ctl的值，它同时存储了线程池的状态和当前工作线程数 * 2. c == RUNNING通过比较操作，判断ctl的高3位是否等于RUNNING，如果等于，则返回true，否则返回false */ private static boolean isRunning(int c) { return c &lt; SHUTDOWN; } /** * Attempts to CAS-increment the workerCount field of ctl. */ private boolean compareAndIncrementWorkerCount(int expect) { return ctl.compareAndSet(expect, expect + 1); } /** * Attempts to CAS-decrement the workerCount field of ctl. */ private boolean compareAndDecrementWorkerCount(int expect) { return ctl.compareAndSet(expect, expect - 1); } /** * 自旋减少工作线程数 */ private void decrementWorkerCount() { do {} while (! compareAndDecrementWorkerCount(ctl.get())); } /** * 任务队列 */ private final BlockingQueue&lt;Runnable&gt; workQueue; private final ReentrantLock mainLock = new ReentrantLock(); /** * 线程池核心任务：相当于真正意义上的线程池。 * 当线程池创建时，会创建一个Worker对象，Worker对象会创建一个线程，线程会执行Worker对象的run方法。 * * 因为Worker中定义了Thread成员变量，可以说一个Worker就对应着一个线程，线程池每创建 * 一个Worker对象就意味着创建了一个新的线程，并且会把新创建的Worker对象添加到workerPool中 * Set containing all worker threads in pool. Accessed only when * holding mainLock. */ private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); /** * * Wait condition to support awaitTermination */ private final Condition termination = mainLock.newCondition(); /** * 线程池执行完毕的任务的数量 */ private int largestPoolSize; /** * 线程池执行完毕的任务的数量 */ private long completedTaskCount; /** * 创建线程的工厂 */ private volatile ThreadFactory threadFactory; /** * 拒绝策略处理器 */ private volatile RejectedExecutionHandler handler; /** * 线程的存活时间，这个一般是针对非核心线程的，如果allowCoreThreadTimeOut设置为true了 * 那么核心线程在经过keepAliveTime空闲时间之后，也会被回收 */ private volatile long keepAliveTime; /** * 这个成员变量就是用来判断是否允许核心线程超时后被回收的标志 * 也就是说，当线程池中没有了任务，那么超过线程存活时间之后，线程池的核心线程也允许被回收 */ private volatile boolean allowCoreThreadTimeOut; /** * 线程池的核心线程数量 */ private volatile int corePoolSize; /** * 线程池最大线程数量 * */ private volatile int maximumPoolSize; /** * The default rejected execution handler */ private static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); /** * Permission required for callers of shutdown and shutdownNow. * We additionally require (see checkShutdownAccess) that callers * have permission to actually interrupt threads in the worker set * (as governed by Thread.interrupt, which relies on * ThreadGroup.checkAccess, which in turn relies on * SecurityManager.checkAccess). Shutdowns are attempted only if * these checks pass. * * All actual invocations of Thread.interrupt (see * interruptIdleWorkers and interruptWorkers) ignore * SecurityExceptions, meaning that the attempted interrupts * silently fail. In the case of shutdown, they should not fail * unless the SecurityManager has inconsistent policies, sometimes * allowing access to a thread and sometimes not. In such cases, * failure to actually interrupt threads may disable or delay full * termination. Other uses of interruptIdleWorkers are advisory, * and failure to actually interrupt will merely delay response to * configuration changes so is not handled exceptionally. */ private static final RuntimePermission shutdownPerm = new RuntimePermission(&quot;modifyThread&quot;); /* The context to be used when executing the finalizer, or null. */ private final AccessControlContext acc; /** * Class Worker mainly maintains interrupt control state for * threads running tasks, along with other minor bookkeeping. * This class opportunistically extends AbstractQueuedSynchronizer * to simplify acquiring and releasing a lock surrounding each * task execution. This protects against interrupts that are * intended to wake up a worker thread waiting for a task from * instead interrupting a task being run. We implement a simple * non-reentrant mutual exclusion lock rather than use * ReentrantLock because we do not want worker tasks to be able to * reacquire the lock when they invoke pool control methods like * setCorePoolSize. Additionally, to suppress interrupts until * the thread actually starts running tasks, we initialize lock * state to a negative value, and clear it upon start (in * runWorker). */ private final class Worker extends AbstractQueuedSynchronizer implements Runnable { /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } /** Delegates main run loop to outer runWorker */ public void run() { runWorker(this); } // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. protected boolean isHeldExclusively() { return getState() != 0; } protected boolean tryAcquire(int unused) { if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } protected boolean tryRelease(int unused) { setExclusiveOwnerThread(null); setState(0); return true; } public void lock() { acquire(1); } public boolean tryLock() { return tryAcquire(1); } public void unlock() { release(1); } public boolean isLocked() { return isHeldExclusively(); } void interruptIfStarted() { Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) { try { t.interrupt(); } catch (SecurityException ignore) { } } } } /* * Methods for setting control state */ /** * Transitions runState to given target, or leaves it alone if * already at least the given target. * * @param targetState the desired state, either SHUTDOWN or STOP * (but not TIDYING or TERMINATED -- use tryTerminate for that) */ private void advanceRunState(int targetState) { for (;;) { int c = ctl.get(); if (runStateAtLeast(c, targetState) || ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c)))) break; } } /** * Transitions to TERMINATED state if either (SHUTDOWN and pool * and queue empty) or (STOP and pool empty). If otherwise * eligible to terminate but workerCount is nonzero, interrupts an * idle worker to ensure that shutdown signals propagate. This * method must be called following any action that might make * termination possible -- reducing worker count or removing tasks * from the queue during shutdown. The method is non-private to * allow access from ScheduledThreadPoolExecutor. */ final void tryTerminate() { for (;;) { int c = ctl.get(); if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; if (workerCountOf(c) != 0) { // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; } final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { try { terminated(); } finally { ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); } return; } } finally { mainLock.unlock(); } // else retry on failed CAS } } /* * Methods for controlling interrupts to worker threads. */ /** * If there is a security manager, makes sure caller has * permission to shut down threads in general (see shutdownPerm). * If this passes, additionally makes sure the caller is allowed * to interrupt each worker thread. This might not be true even if * first check passed, if the SecurityManager treats some threads * specially. */ private void checkShutdownAccess() { SecurityManager security = System.getSecurityManager(); if (security != null) { security.checkPermission(shutdownPerm); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) security.checkAccess(w.thread); } finally { mainLock.unlock(); } } } /** * Interrupts all threads, even if active. Ignores SecurityExceptions * (in which case some threads may remain uninterrupted). */ private void interruptWorkers() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) w.interruptIfStarted(); } finally { mainLock.unlock(); } } /** * Interrupts threads that might be waiting for tasks (as * indicated by not being locked) so they can check for * termination or configuration changes. Ignores * SecurityExceptions (in which case some threads may remain * uninterrupted). * * @param onlyOne If true, interrupt at most one worker. This is * called only from tryTerminate when termination is otherwise * enabled but there are still other workers. In this case, at * most one waiting worker is interrupted to propagate shutdown * signals in case all threads are currently waiting. * Interrupting any arbitrary thread ensures that newly arriving * workers since shutdown began will also eventually exit. * To guarantee eventual termination, it suffices to always * interrupt only one idle worker, but shutdown() interrupts all * idle workers so that redundant workers exit promptly, not * waiting for a straggler task to finish. */ private void interruptIdleWorkers(boolean onlyOne) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) { Thread t = w.thread; if (!t.isInterrupted() &amp;&amp; w.tryLock()) { try { t.interrupt(); } catch (SecurityException ignore) { } finally { w.unlock(); } } if (onlyOne) break; } } finally { mainLock.unlock(); } } /** * Common form of interruptIdleWorkers, to avoid having to * remember what the boolean argument means. */ private void interruptIdleWorkers() { interruptIdleWorkers(false); } private static final boolean ONLY_ONE = true; /* * Misc utilities, most of which are also exported to * ScheduledThreadPoolExecutor */ /** * Invokes the rejected execution handler for the given command. * Package-protected for use by ScheduledThreadPoolExecutor. */ final void reject(Runnable command) { handler.rejectedExecution(command, this); } /** * Performs any further cleanup following run state transition on * invocation of shutdown. A no-op here, but used by * ScheduledThreadPoolExecutor to cancel delayed tasks. */ void onShutdown() { } /** * State check needed by ScheduledThreadPoolExecutor to * enable running tasks during shutdown. * * @param shutdownOK true if should return true if SHUTDOWN */ final boolean isRunningOrShutdown(boolean shutdownOK) { int rs = runStateOf(ctl.get()); return rs == RUNNING || (rs == SHUTDOWN &amp;&amp; shutdownOK); } /** * Drains the task queue into a new list, normally using * drainTo. But if the queue is a DelayQueue or any other kind of * queue for which poll or drainTo may fail to remove some * elements, it deletes them one by one. */ private List&lt;Runnable&gt; drainQueue() { BlockingQueue&lt;Runnable&gt; q = workQueue; ArrayList&lt;Runnable&gt; taskList = new ArrayList&lt;Runnable&gt;(); q.drainTo(taskList); if (!q.isEmpty()) { for (Runnable r : q.toArray(new Runnable[0])) { if (q.remove(r)) taskList.add(r); } } return taskList; } /* * Methods for creating, running and cleaning up after workers */ /** * Checks if a new worker can be added with respect to current * pool state and the given bound (either core or maximum). If so, * the worker count is adjusted accordingly, and, if possible, a * new worker is created and started, running firstTask as its * first task. This method returns false if the pool is stopped or * eligible to shut down. It also returns false if the thread * factory fails to create a thread when asked. If the thread * creation fails, either due to the thread factory returning * null, or due to an exception (typically OutOfMemoryError in * Thread.start()), we roll back cleanly. * * @param firstTask the task the new thread should run first (or * null if none). Workers are created with an initial first task * (in method execute()) to bypass queuing when there are fewer * than corePoolSize threads (in which case we always start one), * or when the queue is full (in which case we must bypass queue). * Initially idle threads are usually created via * prestartCoreThread or to replace other dying workers. * * @param core if true use corePoolSize as bound, else * maximumPoolSize. (A boolean indicator is used here rather than a * value to ensure reads of fresh values after checking other pool * state). * @return true if successful */ private boolean addWorker(Runnable firstTask, boolean core) { retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) { int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { t.start(); workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } return workerStarted; } /** * Rolls back the worker thread creation. * - removes worker from workers, if present * - decrements worker count * - rechecks for termination, in case the existence of this * worker was holding up termination */ private void addWorkerFailed(Worker w) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { if (w != null) workers.remove(w); decrementWorkerCount(); tryTerminate(); } finally { mainLock.unlock(); } } /** * Performs cleanup and bookkeeping for a dying worker. Called * only from worker threads. Unless completedAbruptly is set, * assumes that workerCount has already been adjusted to account * for exit. This method removes thread from worker set, and * possibly terminates the pool or replaces the worker if either * it exited due to user task exception or if fewer than * corePoolSize workers are running or queue is non-empty but * there are no workers. * * @param w the worker * @param completedAbruptly if the worker died due to user exception */ private void processWorkerExit(Worker w, boolean completedAbruptly) { if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { completedTaskCount += w.completedTasks; workers.remove(w); } finally { mainLock.unlock(); } tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) { if (!completedAbruptly) { int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed } addWorker(null, false); } } /** * Performs blocking or timed wait for a task, depending on * current configuration settings, or returns null if this worker * must exit because of any of: * 1. There are more than maximumPoolSize workers (due to * a call to setMaximumPoolSize). * 2. The pool is stopped. * 3. The pool is shutdown and the queue is empty. * 4. This worker timed out waiting for a task, and timed-out * workers are subject to termination (that is, * {@code allowCoreThreadTimeOut || workerCount &gt; corePoolSize}) * both before and after the timed wait, and if the queue is * non-empty, this worker is not the last thread in the pool. * * @return task, or null if the worker must exit, in which case * workerCount is decremented */ private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) { decrementWorkerCount(); return null; } int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } try { Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } } /** * Main worker run loop. Repeatedly gets tasks from queue and * executes them, while coping with a number of issues: * * 1. We may start out with an initial task, in which case we * don't need to get the first one. Otherwise, as long as pool is * running, we get tasks from getTask. If it returns null then the * worker exits due to changed pool state or configuration * parameters. Other exits result from exception throws in * external code, in which case completedAbruptly holds, which * usually leads processWorkerExit to replace this thread. * * 2. Before running any task, the lock is acquired to prevent * other pool interrupts while the task is executing, and then we * ensure that unless pool is stopping, this thread does not have * its interrupt set. * * 3. Each task run is preceded by a call to beforeExecute, which * might throw an exception, in which case we cause thread to die * (breaking loop with completedAbruptly true) without processing * the task. * * 4. Assuming beforeExecute completes normally, we run the task, * gathering any of its thrown exceptions to send to afterExecute. * We separately handle RuntimeException, Error (both of which the * specs guarantee that we trap) and arbitrary Throwables. * Because we cannot rethrow Throwables within Runnable.run, we * wrap them within Errors on the way out (to the thread's * UncaughtExceptionHandler). Any thrown exception also * conservatively causes thread to die. * * 5. After task.run completes, we call afterExecute, which may * also throw an exception, which will also cause thread to * die. According to JLS Sec 14.20, this exception is the one that * will be in effect even if task.run throws. * * The net effect of the exception mechanics is that afterExecute * and the thread's UncaughtExceptionHandler have as accurate * information as we can provide about any problems encountered by * user code. * * @param w the worker */ final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try { while (task != null || (task = getTask()) != null) { w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try { beforeExecute(wt, task); Throwable thrown = null; try { task.run(); } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); } } finally { task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } } // Public constructors and methods /** * Creates a new {@code ThreadPoolExecutor} with the given initial * parameters and default thread factory and rejected execution handler. * It may be more convenient to use one of the {@link Executors} factory * methods instead of this general purpose constructor. * * @param corePoolSize the number of threads to keep in the pool, even * if they are idle, unless {@code allowCoreThreadTimeOut} is set * @param maximumPoolSize the maximum number of threads to allow in the * pool * @param keepAliveTime when the number of threads is greater than * the core, this is the maximum time that excess idle threads * will wait for new tasks before terminating. * @param unit the time unit for the {@code keepAliveTime} argument * @param workQueue the queue to use for holding tasks before they are * executed. This queue will hold only the {@code Runnable} * tasks submitted by the {@code execute} method. * @throws IllegalArgumentException if one of the following holds:&lt;br&gt; * {@code corePoolSize &lt; 0}&lt;br&gt; * {@code keepAliveTime &lt; 0}&lt;br&gt; * {@code maximumPoolSize &lt;= 0}&lt;br&gt; * {@code maximumPoolSize &lt; corePoolSize} * @throws NullPointerException if {@code workQueue} is null */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); } /** * Creates a new {@code ThreadPoolExecutor} with the given initial * parameters and default rejected execution handler. * * @param corePoolSize the number of threads to keep in the pool, even * if they are idle, unless {@code allowCoreThreadTimeOut} is set * @param maximumPoolSize the maximum number of threads to allow in the * pool * @param keepAliveTime when the number of threads is greater than * the core, this is the maximum time that excess idle threads * will wait for new tasks before terminating. * @param unit the time unit for the {@code keepAliveTime} argument * @param workQueue the queue to use for holding tasks before they are * executed. This queue will hold only the {@code Runnable} * tasks submitted by the {@code execute} method. * @param threadFactory the factory to use when the executor * creates a new thread * @throws IllegalArgumentException if one of the following holds:&lt;br&gt; * {@code corePoolSize &lt; 0}&lt;br&gt; * {@code keepAliveTime &lt; 0}&lt;br&gt; * {@code maximumPoolSize &lt;= 0}&lt;br&gt; * {@code maximumPoolSize &lt; corePoolSize} * @throws NullPointerException if {@code workQueue} * or {@code threadFactory} is null */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); } /** * Creates a new {@code ThreadPoolExecutor} with the given initial * parameters and default thread factory. * * @param corePoolSize the number of threads to keep in the pool, even * if they are idle, unless {@code allowCoreThreadTimeOut} is set * @param maximumPoolSize the maximum number of threads to allow in the * pool * @param keepAliveTime when the number of threads is greater than * the core, this is the maximum time that excess idle threads * will wait for new tasks before terminating. * @param unit the time unit for the {@code keepAliveTime} argument * @param workQueue the queue to use for holding tasks before they are * executed. This queue will hold only the {@code Runnable} * tasks submitted by the {@code execute} method. * @param handler the handler to use when execution is blocked * because the thread bounds and queue capacities are reached * @throws IllegalArgumentException if one of the following holds:&lt;br&gt; * {@code corePoolSize &lt; 0}&lt;br&gt; * {@code keepAliveTime &lt; 0}&lt;br&gt; * {@code maximumPoolSize &lt;= 0}&lt;br&gt; * {@code maximumPoolSize &lt; corePoolSize} * @throws NullPointerException if {@code workQueue} * or {@code handler} is null */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler); } /** * Creates a new {@code ThreadPoolExecutor} with the given initial * parameters. * * @param corePoolSize the number of threads to keep in the pool, even * if they are idle, unless {@code allowCoreThreadTimeOut} is set * @param maximumPoolSize the maximum number of threads to allow in the * pool * @param keepAliveTime when the number of threads is greater than * the core, this is the maximum time that excess idle threads * will wait for new tasks before terminating. * @param unit the time unit for the {@code keepAliveTime} argument * @param workQueue the queue to use for holding tasks before they are * executed. This queue will hold only the {@code Runnable} * tasks submitted by the {@code execute} method. * @param threadFactory the factory to use when the executor * creates a new thread * @param handler the handler to use when execution is blocked * because the thread bounds and queue capacities are reached * @throws IllegalArgumentException if one of the following holds:&lt;br&gt; * {@code corePoolSize &lt; 0}&lt;br&gt; * {@code keepAliveTime &lt; 0}&lt;br&gt; * {@code maximumPoolSize &lt;= 0}&lt;br&gt; * {@code maximumPoolSize &lt; corePoolSize} * @throws NullPointerException if {@code workQueue} * or {@code threadFactory} or {@code handler} is null */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; } /** * Executes the given task sometime in the future. The task * may execute in a new thread or in an existing pooled thread. * * If the task cannot be submitted for execution, either because this * executor has been shutdown or because its capacity has been reached, * the task is handled by the current {@code RejectedExecutionHandler}. * * @param command the task to execute * @throws RejectedExecutionException at discretion of * {@code RejectedExecutionHandler}, if the task * cannot be accepted for execution * @throws NullPointerException if {@code command} is null */ public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } else if (!addWorker(command, false)) reject(command); } /** * Initiates an orderly shutdown in which previously submitted * tasks are executed, but no new tasks will be accepted. * Invocation has no additional effect if already shut down. * * &lt;p&gt;This method does not wait for previously submitted tasks to * complete execution. Use {@link #awaitTermination awaitTermination} * to do that. * * @throws SecurityException {@inheritDoc} */ public void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); advanceRunState(SHUTDOWN); interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor } finally { mainLock.unlock(); } tryTerminate(); } /** * Attempts to stop all actively executing tasks, halts the * processing of waiting tasks, and returns a list of the tasks * that were awaiting execution. These tasks are drained (removed) * from the task queue upon return from this method. * * &lt;p&gt;This method does not wait for actively executing tasks to * terminate. Use {@link #awaitTermination awaitTermination} to * do that. * * &lt;p&gt;There are no guarantees beyond best-effort attempts to stop * processing actively executing tasks. This implementation * cancels tasks via {@link Thread#interrupt}, so any task that * fails to respond to interrupts may never terminate. * * @throws SecurityException {@inheritDoc} */ public List&lt;Runnable&gt; shutdownNow() { List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); advanceRunState(STOP); interruptWorkers(); tasks = drainQueue(); } finally { mainLock.unlock(); } tryTerminate(); return tasks; } public boolean isShutdown() { return ! isRunning(ctl.get()); } /** * Returns true if this executor is in the process of terminating * after {@link #shutdown} or {@link #shutdownNow} but has not * completely terminated. This method may be useful for * debugging. A return of {@code true} reported a sufficient * period after shutdown may indicate that submitted tasks have * ignored or suppressed interruption, causing this executor not * to properly terminate. * * @return {@code true} if terminating but not yet terminated */ public boolean isTerminating() { int c = ctl.get(); return ! isRunning(c) &amp;&amp; runStateLessThan(c, TERMINATED); } public boolean isTerminated() { return runStateAtLeast(ctl.get(), TERMINATED); } public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (;;) { if (runStateAtLeast(ctl.get(), TERMINATED)) return true; if (nanos &lt;= 0) return false; nanos = termination.awaitNanos(nanos); } } finally { mainLock.unlock(); } } /** * Invokes {@code shutdown} when this executor is no longer * referenced and it has no threads. */ protected void finalize() { SecurityManager sm = System.getSecurityManager(); if (sm == null || acc == null) { shutdown(); } else { PrivilegedAction&lt;Void&gt; pa = () -&gt; { shutdown(); return null; }; AccessController.doPrivileged(pa, acc); } } /** * Sets the thread factory used to create new threads. * * @param threadFactory the new thread factory * @throws NullPointerException if threadFactory is null * @see #getThreadFactory */ public void setThreadFactory(ThreadFactory threadFactory) { if (threadFactory == null) throw new NullPointerException(); this.threadFactory = threadFactory; } /** * Returns the thread factory used to create new threads. * * @return the current thread factory * @see #setThreadFactory(ThreadFactory) */ public ThreadFactory getThreadFactory() { return threadFactory; } /** * Sets a new handler for unexecutable tasks. * * @param handler the new handler * @throws NullPointerException if handler is null * @see #getRejectedExecutionHandler */ public void setRejectedExecutionHandler(RejectedExecutionHandler handler) { if (handler == null) throw new NullPointerException(); this.handler = handler; } /** * Returns the current handler for unexecutable tasks. * * @return the current handler * @see #setRejectedExecutionHandler(RejectedExecutionHandler) */ public RejectedExecutionHandler getRejectedExecutionHandler() { return handler; } /** * Sets the core number of threads. This overrides any value set * in the constructor. If the new value is smaller than the * current value, excess existing threads will be terminated when * they next become idle. If larger, new threads will, if needed, * be started to execute any queued tasks. * * @param corePoolSize the new core size * @throws IllegalArgumentException if {@code corePoolSize &lt; 0} * @see #getCorePoolSize */ public void setCorePoolSize(int corePoolSize) { if (corePoolSize &lt; 0) throw new IllegalArgumentException(); int delta = corePoolSize - this.corePoolSize; this.corePoolSize = corePoolSize; if (workerCountOf(ctl.get()) &gt; corePoolSize) interruptIdleWorkers(); else if (delta &gt; 0) { // We don't really know how many new threads are &quot;needed&quot;. // As a heuristic, prestart enough new workers (up to new // core size) to handle the current number of tasks in // queue, but stop if queue becomes empty while doing so. int k = Math.min(delta, workQueue.size()); while (k-- &gt; 0 &amp;&amp; addWorker(null, true)) { if (workQueue.isEmpty()) break; } } } public int getCorePoolSize() { return corePoolSize; } public boolean prestartCoreThread() { return workerCountOf(ctl.get()) &lt; corePoolSize &amp;&amp; addWorker(null, true); } void ensurePrestart() { int wc = workerCountOf(ctl.get()); if (wc &lt; corePoolSize) addWorker(null, true); else if (wc == 0) addWorker(null, false); } public int prestartAllCoreThreads() { int n = 0; while (addWorker(null, true)) ++n; return n; } public boolean allowsCoreThreadTimeOut() { return allowCoreThreadTimeOut; } public void allowCoreThreadTimeOut(boolean value) { if (value &amp;&amp; keepAliveTime &lt;= 0) throw new IllegalArgumentException(&quot;Core threads must have nonzero keep alive times&quot;); if (value != allowCoreThreadTimeOut) { allowCoreThreadTimeOut = value; if (value) interruptIdleWorkers(); } } public void setMaximumPoolSize(int maximumPoolSize) { if (maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize) throw new IllegalArgumentException(); this.maximumPoolSize = maximumPoolSize; if (workerCountOf(ctl.get()) &gt; maximumPoolSize) interruptIdleWorkers(); } public int getMaximumPoolSize() { return maximumPoolSize; } public void setKeepAliveTime(long time, TimeUnit unit) { if (time &lt; 0) throw new IllegalArgumentException(); if (time == 0 &amp;&amp; allowsCoreThreadTimeOut()) throw new IllegalArgumentException(&quot;Core threads must have nonzero keep alive times&quot;); long keepAliveTime = unit.toNanos(time); long delta = keepAliveTime - this.keepAliveTime; this.keepAliveTime = keepAliveTime; if (delta &lt; 0) interruptIdleWorkers(); } public long getKeepAliveTime(TimeUnit unit) { return unit.convert(keepAliveTime, TimeUnit.NANOSECONDS); } public BlockingQueue&lt;Runnable&gt; getQueue() { return workQueue; } public boolean remove(Runnable task) { boolean removed = workQueue.remove(task); tryTerminate(); // In case SHUTDOWN and now empty return removed; } public void purge() { final BlockingQueue&lt;Runnable&gt; q = workQueue; try { Iterator&lt;Runnable&gt; it = q.iterator(); while (it.hasNext()) { Runnable r = it.next(); if (r instanceof Future&lt;?&gt; &amp;&amp; ((Future&lt;?&gt;)r).isCancelled()) it.remove(); } } catch (ConcurrentModificationException fallThrough) { // Take slow path if we encounter interference during traversal. // Make copy for traversal and call remove for cancelled entries. // The slow path is more likely to be O(N*N). for (Object r : q.toArray()) if (r instanceof Future&lt;?&gt; &amp;&amp; ((Future&lt;?&gt;)r).isCancelled()) q.remove(r); } tryTerminate(); // In case SHUTDOWN and now empty } public int getPoolSize() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Remove rare and surprising possibility of // isTerminated() &amp;&amp; getPoolSize() &gt; 0 return runStateAtLeast(ctl.get(), TIDYING) ? 0 : workers.size(); } finally { mainLock.unlock(); } } public int getActiveCount() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { int n = 0; for (Worker w : workers) if (w.isLocked()) ++n; return n; } finally { mainLock.unlock(); } } public int getLargestPoolSize() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { return largestPoolSize; } finally { mainLock.unlock(); } } public long getTaskCount() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { long n = completedTaskCount; for (Worker w : workers) { n += w.completedTasks; if (w.isLocked()) ++n; } return n + workQueue.size(); } finally { mainLock.unlock(); } } public long getCompletedTaskCount() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { long n = completedTaskCount; for (Worker w : workers) n += w.completedTasks; return n; } finally { mainLock.unlock(); } } public String toString() { long ncompleted; int nworkers, nactive; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { ncompleted = completedTaskCount; nactive = 0; nworkers = workers.size(); for (Worker w : workers) { ncompleted += w.completedTasks; if (w.isLocked()) ++nactive; } } finally { mainLock.unlock(); } int c = ctl.get(); String rs = (runStateLessThan(c, SHUTDOWN) ? &quot;Running&quot; : (runStateAtLeast(c, TERMINATED) ? &quot;Terminated&quot; : &quot;Shutting down&quot;)); return super.toString() + &quot;[&quot; + rs + &quot;, pool size = &quot; + nworkers + &quot;, active threads = &quot; + nactive + &quot;, queued tasks = &quot; + workQueue.size() + &quot;, completed tasks = &quot; + ncompleted + &quot;]&quot;; } protected void beforeExecute(Thread t, Runnable r) { } protected void afterExecute(Runnable r, Throwable t) { } protected void terminated() { } public static class CallerRunsPolicy implements RejectedExecutionHandler { public CallerRunsPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { r.run(); } } } public static class AbortPolicy implements RejectedExecutionHandler { public AbortPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { throw new RejectedExecutionException(&quot;Task &quot; + r.toString() + &quot; rejected from &quot; + e.toString()); } } public static class DiscardPolicy implements RejectedExecutionHandler { public DiscardPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { } } public static class DiscardOldestPolicy implements RejectedExecutionHandler { public DiscardOldestPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { e.getQueue().poll(); e.execute(r); } } } } ","link":"https://panson.top/post/wan-zi-chang-wen-xian-cheng-chi-yuan-ma-shen-ru-fen-xi/"},{"title":"Panson-Weekly-008","content":"日拱一卒 1 一周见闻 动态模糊 1.1 技术文章 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 13. 罗马数字转整数 class Solution { public int romanToInt(String s) { Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); map.put('I', 1); map.put('V', 5); map.put('X', 10); map.put('L', 50); map.put('C', 100); map.put('D', 500); map.put('M', 1000); int n = s.length(); int pre = map.get(s.charAt(0)); int ret = 0; for(int i = 1; i &lt; n; i++) { int cur = map.get(s.charAt(i)); // 当小值在大值的左边，则减小值，如 IV=5-1=4； if(pre &lt; cur) { ret -= pre; } else { ret += pre; } pre = cur; } ret += pre; return ret; } } 12. 整数转罗马数字 class Solution { public String intToRoman(int num) { int[] values = {1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1}; String[] strs = {&quot;M&quot;, &quot;CM&quot;, &quot;D&quot;, &quot;CD&quot;, &quot;C&quot;, &quot;XC&quot;, &quot;L&quot;, &quot;XL&quot;, &quot;X&quot;, &quot;IX&quot;, &quot;V&quot;, &quot;IV&quot;, &quot;I&quot;}; int n = values.length; StringBuffer ret = new StringBuffer(); for(int i = 0; i &lt; n; i++) { int value = values[i]; String str = strs[i]; while(num &gt;= value) { num -= value; ret.append(str); } if(num == 0) { break; } } return ret.toString(); } } 58. 最后一个单词的长度 class Solution { public int lengthOfLastWord(String s) { int i = s.length() - 1; while(i &gt;= 0 &amp;&amp; s.charAt(i) == ' ' &amp;&amp; i &gt;= 0) { i--; } int ret = 0; while(i &gt;= 0 &amp;&amp;s.charAt(i) != ' ') { ret++; i--; } return ret; } } 14. 最长公共前缀 class Solution { public String longestCommonPrefix(String[] strs) { int n = strs.length; if(n == 0) { return &quot;&quot;; } if(n == 1) { return strs[0]; } int ret = 0; for(int i = 0; i &lt; strs[0].length(); i++) { char cur = strs[0].charAt(i); for(int j = 1; j &lt; n; j++) { if(ret &lt; i || strs[j].length() - 1 &lt; i || cur != strs[j].charAt(i)) { break; } if(j == n - 1) { ret++; } } } return strs[0].substring(0, ret); } } 151. 反转字符串中的单词 class Solution { public String reverseWords(String s) { // int head = 0; int tail = s.length() - 1; StringBuilder stringBuffer = new StringBuilder(); // while(head &lt; tail) { if(s.charAt(head) != ' ') { break; } else { head++; } } while(head &lt; tail) { if(s.charAt(tail) != ' ') { break; } else { tail--; } } int i = head; int j = tail; int blankCount = 0; while(i &lt;= j) { if(s.charAt(i) == ' ') { blankCount++; } else { if(blankCount &gt;= 1) { stringBuffer.append(&quot; &quot;); } stringBuffer.append(s.charAt(i)); blankCount = 0; } i++; } String removedBlankString = stringBuffer.toString(); String[] splits = removedBlankString.split(&quot; &quot;); StringBuffer ret = new StringBuffer(); for(int k = splits.length - 1; k &gt;= 0; k--) { ret.append(splits[k]); if(k != 0) { ret.append(&quot; &quot;); } } return ret.toString(); } } 6. N 字形变换 class Solution { public String convert(String s, int numRows) { if(numRows == 1) { return s; } List&lt;StringBuilder&gt; ret = new ArrayList&lt;&gt;(); for(int i = 0; i &lt; numRows; i++) { ret.add(new StringBuilder()); } int flag = -1; int i = 0; int count = 0; while(count &lt; s.length()) { if(i == 0 || i == numRows - 1) { flag = -flag; } ret.get(i).append(s.charAt(count)); i += flag; count++; } StringBuilder stringBuilder = new StringBuilder(); for(int j = 0; j &lt; numRows; j++) { stringBuilder.append(ret.get(j)); } return stringBuilder.toString(); } } 28找出字符串中第一个匹配项的下标 class Solution { public int strStr(String haystack, String needle) { int n = haystack.length(); int m = needle.length(); for(int i = 0; i &lt;= n - m; i++) { int a = i; int b = 0; while(b &lt; m &amp;&amp; haystack.charAt(a) == needle.charAt(b)) { a++; b++; } if(b == m) { return i; } } return -1; } } ","link":"https://panson.top/post/panson-weekly-008/"},{"title":"Panson-Weekly-007","content":"日拱一卒 1 一周见闻 1.1 技术文章 [《极客时间-Redis技术核心技术与实战》16 ~ 21] 1.2 泛互联网文章 2 技术总结 3 Algorithm(算法题) 135. 分发糖果 class Solution { public int candy(int[] ratings) { int n = ratings.length; int[] left = new int[n]; int[] right = new int[n]; left[0] = 1; for(int i = 1; i &lt; n; i++) { if(ratings[i] &gt; ratings[i - 1]) { left[i] = left[i - 1] + 1; } else { left[i] = 1; } } right[n - 1] = 1; for(int i = n - 2; i &gt;= 0; i--) { if(ratings[i] &gt; ratings[i + 1]) { right[i] = right[i + 1] + 1; } else { right[i] = 1; } } int ret = 0; for(int i = 0; i &lt; n; i++) { ret += Math.max(left[i], right[i]); } return ret; } } 42. 接雨水 暴力破解法： class Solution { public int trap(int[] height) { int n = height.length; int leftMax = 0, rightMax = 0; int ret = 0; for(int i = 0; i &lt; n; i++) { leftMax = calculateLeftMax(i, height); rightMax = calculateRightMax(i, height); ret += Math.min(leftMax, rightMax) - height[i]; } return ret; } public int calculateLeftMax(int i, int[] height) { int leftMax = 0; for(int j = i; j &gt;= 0; j--) { leftMax = Math.max(leftMax, height[j]); } return leftMax; } public int calculateRightMax(int i, int[] height) { int rightMax = 0; for(int j = i; j &lt; height.length; j++) { rightMax = Math.max(rightMax, height[j]); } return rightMax; } } ","link":"https://panson.top/post/panson-weekly-007/"},{"title":"Panson-Weekly-006","content":"日拱一卒 1 一周见闻 1.1 技术文章 一次性讲清楚「连接池获取连接慢」的所有原因｜得物技术 一次访问Redis延时高问题排查与总结 1.2 泛互联网文章 供应链核心业务、流程及系统v1.0 2 技术总结 3 Algorithm(算法题) 238. 除自身以外数组的乘积 class Solution { public int[] productExceptSelf(int[] nums) { // 使用两个数组，分别保存当前元素的左乘积和右乘积 int n = nums.length; int[] left = new int[n]; int[] right = new int[n]; left[0] = 1; for(int i = 1; i &lt; n; i++) { left[i] = left[i - 1] * nums[i - 1]; } right[n - 1] = 1; for(int j = n - 2; j &gt;= 0; j--) { right[j] = right[j + 1] * nums[j + 1]; } for(int i = 0; i &lt; n; i++) { nums[i] = left[i] * right[i]; } return nums; } } 134. 加油站 class Solution { public int canCompleteCircuit(int[] gas, int[] cost) { // 如果从 x 到 y 无法到达，那么从 x 与 y 间任何一个加油站出发都无法到达 y。 // 题目保证如果有解则必为唯一解 int n = gas.length; int sum = 0; for(int i = 0; i &lt; n; i++) { sum += (gas[i] - cost[i]); } if(sum &lt; 0) { return -1; } // 必定有解 sum = 0; int i = 0; int from = 0; while(i &lt; n){ sum += (gas[i] - cost[i]); if(sum &lt; 0) { from = i + 1; i = i + 1; sum = 0; } else { i++; } } return from; } } ","link":"https://panson.top/post/panson-weekly-006/"},{"title":"Panson-Weekly-005","content":"日拱一卒 1 一周见闻 1.1 技术文章 得物商品状态体系介绍 1.2 泛互联网文章 2 技术总结 2.1 Redis 源码阅读 —— sds 结构体源码阅读 /* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */ struct __attribute__ ((__packed__)) sdshdr5 { unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr32 { uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; 在 Redis 中，设计了 5 个 sds 结构体，用于存储不同长度的字符串。设计 5 个不同的结构体，主要是出于节约存储的目的，比如说用 sdshdr8 就能存下的字符串，如果用 sdshdr64 存储，那就是 8 倍的存储空间消耗，对于一家稍微上体量的互联网公司，可能是过百亿级别的数据量，单就字符串存储上就要多耗费 70GB 的内存。由此可见，Redis 在数据结构上是做了诸多设计优化的。 字段注释： struct __attribute__ ((__packed__)) sdshdr8 { // buf 数组已使用字节数 uint8_t len; // buf 数组总共分配的字节数 uint8_t alloc; // 低三位用于表示字符串类型 unsigned char flags; // 用于存储字符串的真实数据 char buf[]; }; 在结构体上使用 __attribute__ ((__packed__)) 指定 ，可以强制不进行内存对齐。这样的话，sds 就可以通过指针移动来便捷地读取值。在 sds 的结构体中，flags 一共 8 位，其中低 3 位用于表示 sds 类型， sds 类型如下： #define SDS_TYPE_5 0 #define SDS_TYPE_8 1 #define SDS_TYPE_16 2 #define SDS_TYPE_32 3 #define SDS_TYPE_64 4 #define SDS_TYPE_MASK 7 #define SDS_TYPE_BITS 3 #define SDS_HDR_VAR(T,s) struct sdshdr##T *sh = (void*)((s)-(sizeof(struct sdshdr##T))); #define SDS_HDR(T,s) ((struct sdshdr##T *)((s)-(sizeof(struct sdshdr##T)))) #define SDS_TYPE_5_LEN(f) ((f)&gt;&gt;SDS_TYPE_BITS) static inline size_t sdslen(const sds s) { unsigned char flags = s[-1]; switch(flags&amp;SDS_TYPE_MASK) { case SDS_TYPE_5: return SDS_TYPE_5_LEN(flags); case SDS_TYPE_8: return SDS_HDR(8,s)-&gt;len; case SDS_TYPE_16: return SDS_HDR(16,s)-&gt;len; case SDS_TYPE_32: return SDS_HDR(32,s)-&gt;len; case SDS_TYPE_64: return SDS_HDR(64,s)-&gt;len; } return 0; } 3 Algorithm(算法题) 380. O(1) 时间插入、删除和获取随机元素 class RandomizedSet { private Map&lt;Integer, Integer&gt; val2IndexMap; private List&lt;Integer&gt; vals; private Random random; public RandomizedSet() { val2IndexMap = new HashMap&lt;&gt;(); vals = new ArrayList&lt;&gt;(); random = new Random(); } public boolean insert(int val) { if(val2IndexMap.containsKey(val)) { return false; } vals.add(val); val2IndexMap.put(val, vals.size() - 1); return true; } public boolean remove(int val) { if(!val2IndexMap.containsKey(val)) { return false; } Integer needDeleteValIndex = val2IndexMap.get(val); int lastVal = vals.get(vals.size() - 1); vals.set(needDeleteValIndex, lastVal); vals.remove(vals.size() - 1); val2IndexMap.put(lastVal, needDeleteValIndex); val2IndexMap.remove(val); return true; } public int getRandom() { int randomIndex = random.nextInt(vals.size()); return vals.get(randomIndex); } } /** * Your RandomizedSet object will be instantiated and called as such: * RandomizedSet obj = new RandomizedSet(); * boolean param_1 = obj.insert(val); * boolean param_2 = obj.remove(val); * int param_3 = obj.getRandom(); */ ","link":"https://panson.top/post/panson-weekly-005/"},{"title":"Panson-Weekly-004","content":"永远别说永远，凡事皆有可能。 —— 《放牛班的春天》 1 Algorithm(算法题) 274. H 指数 class Solution { public int hIndex(int[] citations) { // 使用计数排序. countMap 下标索引表示引用次数，值表示对应引用次数的文章数 // 引用次数超过 citations.length，也视作 citations.length int length = citations.length; int[] countMap = new int[length + 1]; // 30615 -&gt; 010102 for(int citation : citations) { countMap[Math.min(citation, length)]++; } int sum = 0; for(int i = length; i &gt;= 0; i--) { // 引用次数大于等于 i 的文章数总和 // 010102 -&gt; 2 -&gt; 2 -&gt; 3 &gt;= 3 return sum += countMap[i]; if(sum &gt;= i) { return i; } } return -1; } } 2 Technique/Tips(分享一个小技术) 2.1 Redis 源码阅读 —— sds 结构体源码阅读 3 Share(分享我的所见所闻) 本来第 3 部分应该是“分享一个观点”，但我觉得许多时候，人在经常性地分享观点时，会趋于建议或者劝诫，类似“知识陷阱”一样。 这让我对“分享观点”这件事情有些迟疑，基于上述的原因，我将第 4 点改为了“分享我的所见所闻”，内容比较杂乱，包含一周内读过的书、看过的博客、学习的摄影知识等等。 3.1 技术文章 中通快递“双十一”技术战：RocketMQ性能压测揭秘 得物供应链复杂业务实时数仓建设之路 供应链时效域接口性能进阶之路 ｜ 得物技术 一个著名的日志系统是怎么设计出来的？ 开源 | 携程 Redis On Rocks 实践，节省 2/3 Redis成本 3.2 泛互联网文章 得物供应链：创新引领潮流消费新模式 和 Fenng 的一次聊天 ","link":"https://panson.top/post/panson-weekly-004/"},{"title":"Panson-Weekly-003","content":"&quot;We don't read and write poetry because it's cute. We read and write poetry because we are members of the human race. And the human race is filled with passion. And medicine, law, business, engineering, these are noble pursuits and necessary to sustain life. But poetry, beauty, romance, love, these are what we stay alive for.&quot; - Dead Poets Society 1 Algorithm(算法题) 55. 跳跃游戏 class Solution { public boolean canJump(int[] nums) { // 定义 maxDistance，表示遍历当前元素时能跳到的最大距离 int maxDistance = 0; for(int i = 0; i &lt; nums.length; i++) { // base case if(i &gt; maxDistance) { return false; } maxDistance = Math.max(maxDistance, i + nums[i]); } return true; } } 45. 跳跃游戏 II class Solution { public int jump(int[] nums) { // 使用贪心算法 // 最优跳跃次数 int times = 0; // 当前跳跃次数下的所能到达的右边界 int border = 0; // 记录已遍历元素所能跳跃的最远位置的下标 int maxIndex = 0; for(int i = 0; i &lt; nums.length - 1; i++) { maxIndex = Math.max(maxIndex, i + nums[i]); if(i == border) { times++; // 更新下一轮次跳跃的右边界 border = maxIndex; } } return times; } } 2 Technique/Tips(分享一个小技术) 2.1 Redis 源码阅读 —— sds 结构体1：为什么 Redis 没有使用 C 语言自带的字符串？ Redis 设计时，考虑到 C 语言字符串的诸多限制，重新设计与实现了字符串。 老生常谈的问题，Redis 为什么要设计专用的字符串，也就是 sds 结构体？ 我问了 chatGPT，它给出了以下的回答： 英文： Redis does not use the C language's built-in strings primarily because Redis is designed to be a high-performance, in-memory data store that offers advanced data manipulation and storage capabilities. The built-in C strings in the C programming language have limitations that make them unsuitable for Redis' requirements. Here are a few reasons why Redis does not use C's built-in strings: Dynamic resizing: Redis needs to efficiently handle strings of varying lengths, including very large strings. C's built-in strings have a fixed size and cannot dynamically resize themselves, which would limit Redis' ability to handle dynamic data. Memory management: Redis manages memory dynamically and optimizes memory usage. C's built-in strings do not provide automatic memory management or support for efficient memory allocation strategies, which Redis requires to optimize memory usage and prevent memory leaks. Performance considerations: Redis is designed to offer high-performance data storage and manipulation. C's built-in strings have limitations in terms of performance optimizations, such as efficient substring extraction, concatenation, and comparison operations, which could impact Redis' overall performance. Additional data structure requirements: Redis supports various data types, including lists, sets, hashes, and more. C's built-in strings do not provide the necessary abstractions and functionality required to handle these complex data structures efficiently. Compatibility with other languages: Redis is widely used as a data store in various programming languages. By implementing its own string data structure, Redis ensures consistency and compatibility across different language bindings and client libraries. By designing its own string data structure, Redis can tailor it specifically to meet the performance, memory management, and functionality requirements of a high-performance data store. This allows Redis to offer efficient storage and manipulation of data, making it popular for caching, messaging, and other data-intensive applications. 中文： Redis不使用C语言本身的字符串主要是因为Redis被设计为高性能的内存数据存储，提供高级的数据操作和存储功能。C语言的内置字符串具有一些限制，使其不适用于Redis的需求。以下是Redis不使用C语言内置字符串的几个原因： 动态调整大小：Redis需要高效地处理长度可变的字符串，包括非常大的字符串。C语言的内置字符串具有固定的大小，无法动态调整大小，这将限制Redis处理动态数据的能力。 内存管理：Redis动态管理内存并优化内存使用。C语言的内置字符串不提供自动的内存管理或支持高效的内存分配策略，而这是Redis需要的，以优化内存使用并防止内存泄漏。 性能考虑：Redis旨在提供高性能的数据存储和操作。C语言的内置字符串在性能优化方面存在限制，例如高效的子字符串提取、连接和比较操作，这可能会影响Redis的整体性能。 额外的数据结构要求：Redis支持各种数据类型，包括列表、集合、哈希等。C语言的内置字符串不提供处理这些复杂数据结构所需的抽象和功能。 与其他语言的兼容性：Redis被广泛用作各种编程语言中的数据存储。通过实现自己的字符串数据结构，Redis确保不同语言绑定和客户端库之间的一致性和兼容性。 通过设计自己的字符串数据结构，Redis可以根据高性能数据存储的要求进行定制。这使得Redis能够高效地存储和操作数据，因此在缓存、消息传递和其他数据密集型应用中非常受欢迎。 我个人觉得最主要的是以下 3 个方面： 二进制安全（binary safe）： 所谓“二进制安全”，简单来说指的是可以存储任意类型的数据。C 语言字符串中，\\0 表示字符串结尾，如果字符串内容想保存 \\0这类特殊字符，C 语言自带的字符串显然是无法满足要求的。 高性能：比如说字符串长度的读取、字符串追加、比较、扩缩容等操作，比原生的 C 语言字符串更加高效。 避免缓冲区溢出：C 语言中，在字符串拼接时，如果忘记提前申请分配内存空间，会导致缓冲区溢出。在 Redis 中，字符串拼接会自动检查空间是否足够，不够则扩容，避免缓冲区溢出。 3 Share(分享我的所见所闻) 本来第 3 部分应该是“分享一个观点”，但我觉得许多时候，人在经常性地分享观点时，会趋于建议或者劝诫，类似“知识陷阱”一样。 这让我对“分享观点”这件事情有些迟疑，基于上述的原因，我将第 4 点改为了“分享我的所见所闻”，内容比较杂乱，包含一周内读过的书、看过的博客、学习的摄影知识等等。 3.1 技术文章 极客时间-《Redis 核心技术与实战》-16 | 异步机制：如何避免单线程模型的阻塞？ 3.2 泛互联网文章 张一鸣：为什么BAT挖不走我们的人才？ ","link":"https://panson.top/post/panson-weekly-003/"},{"title":"Redis 源码阅读系列-sds","content":"Redis 源码阅读第二弹：sds 1 Redis 为什么不使用 C 语言原生字符串？ Redis 设计时，考虑到 C 语言字符串的诸多限制，重新设计与实现了字符串。 老生常谈的问题，Redis 为什么要设计专用的字符串，也就是 sds 结构体？ 我问了 chatGPT，它给出了以下的回答： 英文： Redis does not use the C language's built-in strings primarily because Redis is designed to be a high-performance, in-memory data store that offers advanced data manipulation and storage capabilities. The built-in C strings in the C programming language have limitations that make them unsuitable for Redis' requirements. Here are a few reasons why Redis does not use C's built-in strings: Dynamic resizing: Redis needs to efficiently handle strings of varying lengths, including very large strings. C's built-in strings have a fixed size and cannot dynamically resize themselves, which would limit Redis' ability to handle dynamic data. Memory management: Redis manages memory dynamically and optimizes memory usage. C's built-in strings do not provide automatic memory management or support for efficient memory allocation strategies, which Redis requires to optimize memory usage and prevent memory leaks. Performance considerations: Redis is designed to offer high-performance data storage and manipulation. C's built-in strings have limitations in terms of performance optimizations, such as efficient substring extraction, concatenation, and comparison operations, which could impact Redis' overall performance. Additional data structure requirements: Redis supports various data types, including lists, sets, hashes, and more. C's built-in strings do not provide the necessary abstractions and functionality required to handle these complex data structures efficiently. Compatibility with other languages: Redis is widely used as a data store in various programming languages. By implementing its own string data structure, Redis ensures consistency and compatibility across different language bindings and client libraries. By designing its own string data structure, Redis can tailor it specifically to meet the performance, memory management, and functionality requirements of a high-performance data store. This allows Redis to offer efficient storage and manipulation of data, making it popular for caching, messaging, and other data-intensive applications. 中文： Redis不使用C语言本身的字符串主要是因为Redis被设计为高性能的内存数据存储，提供高级的数据操作和存储功能。C语言的内置字符串具有一些限制，使其不适用于Redis的需求。以下是Redis不使用C语言内置字符串的几个原因： 动态调整大小：Redis需要高效地处理长度可变的字符串，包括非常大的字符串。C语言的内置字符串具有固定的大小，无法动态调整大小，这将限制Redis处理动态数据的能力。 内存管理：Redis动态管理内存并优化内存使用。C语言的内置字符串不提供自动的内存管理或支持高效的内存分配策略，而这是Redis需要的，以优化内存使用并防止内存泄漏。 性能考虑：Redis旨在提供高性能的数据存储和操作。C语言的内置字符串在性能优化方面存在限制，例如高效的子字符串提取、连接和比较操作，这可能会影响Redis的整体性能。 额外的数据结构要求：Redis支持各种数据类型，包括列表、集合、哈希等。C语言的内置字符串不提供处理这些复杂数据结构所需的抽象和功能。 与其他语言的兼容性：Redis被广泛用作各种编程语言中的数据存储。通过实现自己的字符串数据结构，Redis确保不同语言绑定和客户端库之间的一致性和兼容性。 通过设计自己的字符串数据结构，Redis可以根据高性能数据存储的要求进行定制。这使得Redis能够高效地存储和操作数据，因此在缓存、消息传递和其他数据密集型应用中非常受欢迎。 我个人觉得最主要的是以下 3 个方面： 二进制安全（binary safe）： 所谓“二进制安全”，简单来说指的是可以存储任意类型的数据。C 语言字符串中，\\0 表示字符串结尾，如果字符串内容想保存 \\0这类特殊字符，C 语言自带的字符串显然是无法满足要求的。 高性能：比如说字符串长度的读取、字符串追加、比较、扩缩容等操作，比原生的 C 语言字符串更加高效。 避免缓冲区溢出：C 语言中，在字符串拼接时，如果忘记提前申请分配内存空间，会导致缓冲区溢出。在 Redis 中，字符串拼接会自动检查空间是否足够，不够则扩容，避免缓冲区溢出。 2 sds 结构体 /* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */ struct __attribute__ ((__packed__)) sdshdr5 { unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr32 { uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; 在 Redis 中，设计了 5 个 sds 结构体，用于存储不同长度的字符串。设计 5 个不同的结构体，主要是出于节约存储的目的，比如说用 sdshdr8 就能存下的字符串，如果用 sdshdr64 存储，那就是 8 倍的存储空间消耗，对于一家稍微上体量的互联网公司，可能是过百亿级别的数据量，单就字符串存储上就要多耗费 70GB 的内存。由此可见，Redis 在数据结构上是做了诸多设计优化的。 字段注释： struct __attribute__ ((__packed__)) sdshdr8 { // buf 数组已使用字节数 uint8_t len; // buf 数组总共分配的字节数 uint8_t alloc; // 低三位用于表示字符串类型 unsigned char flags; // 用于存储字符串的真实数据 char buf[]; }; 在结构体上 ","link":"https://panson.top/post/redis-yuan-ma-yue-du-xi-lie-sds/"},{"title":"Panson-Weekly-002","content":"千里之行，始于足下 1 Algorithm(算法题) 121. 买卖股票的最佳时机 再次聊聊这道题，看到网上有人整理了股票题目的通用解法。 class Solution { public int maxProfit(int[] prices) { int n = prices.length; // base case: dp[-1][0] = 0, dp[-1][1] = -infinity // 第 1 天不持有股票，第 1 天持有股票 int dp_i_0 = 0, dp_i_1 = Integer.MIN_VALUE; for (int i = 0; i &lt; n; i++) { // dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i]) dp_i_0 = Math.max(dp_i_0, dp_i_1 + prices[i]); // dp[i][1] = max(dp[i-1][1], -prices[i]) dp_i_1 = Math.max(dp_i_1, -prices[i]); } return dp_i_0; } } 122. 买卖股票的最佳时机 II 代码： class Solution { public int maxProfit(int[] prices) { // 动态规划状态转移方程 // dp[i][0] = max(dp[i - 1][0], dp[i - 1][1] + prices[i]); // dp[i][1] = max(dp[i - 1][1], dp[i - 1][0] - prices[i]); int[][] dp = new int[prices.length][2]; dp[0][0] = 0; dp[0][1] = -prices[0]; for(int i = 1; i &lt; prices.length; i++) { dp[i][0] = Math.max(dp[i - 1][0], dp[i - 1][1] + prices[i]); dp[i][1] = Math.max(dp[i - 1][1], dp[i - 1][0] - prices[i]); } return dp[prices.length - 1][0]; } } 2 Technique/Tips(分享一个小技术) 2.1 Redis 源码阅读 —— 千里之行，始于足下，如何搭建 Redis 7.x 源码阅读环境 2.1.1 源码下载 直接从 GitHub 源码仓库下载： git clone https://github.com/redis/redis.git 我们以最新的 tag 上去: git checkout tags/7.0.4 -b 7.0.4 2.1.2 编译 首先确保安装了 GCC，我本地已安装。 编译： make CFLAGS=&quot;-g -O0&quot; 备注：-O0 参数旨在强制编译器不要进行编译优化，避免 debug 的时候源码与实际运行代码不匹配 2.1.3 启动 拥抱 jetbrains 全家桶，使用 CLion 2023.2.2 编译好的 Redis 源码。 启动配置如下： ![]( 3 Share(分享我的所见所闻) 本来第 4 部分应该是“分享一个观点”，但我觉得许多时候，人在经常性地分享观点时，会趋于建议或者劝诫，类似“知识陷阱”一样。 这让我对“分享观点”这件事情有些迟疑，基于上述的原因，我将第 4 点改为了“分享我的所见所闻”，内容比较杂乱，包含一周内读过的书、看过的博客、学习的摄影知识等等。 3.1 技术博客 虚拟线程原理及性能分析｜得物技术 Redis成本优化-版本升级-1.SDS优化历史 客服发送一条消息背后的技术和思考｜得物技术 得物 Redis 设计与实践 浅析Redis大Key 记一次Redis Cluster Pipeline导致的死锁问题 线上问题排查实例分析｜关于网络超时 ","link":"https://panson.top/post/panson-weekly-002/"},{"title":"Panson-Weekly-001","content":"千里之行，始于足下 1 Algorithm(一道算法题) Leetcode 121. 买卖股票的最佳时机 代码： class Solution { public int maxProfit(int[] prices) { // 核心思路在于计算每日卖出时的利润最大值 int cost = Integer.MAX_VALUE; int profit = 0; for(int i = 0; i &lt; prices.length; i++) { // 在遍历到当前元素时， cost 已经是遍历过的元素中的最小值了 if(prices[i] - cost &gt; profit) { profit = prices[i] - cost; } cost = Math.min(cost, prices[i]); } return profit; } } 核心思路： 我觉得核心思路是模拟真实买卖股票的流程，以时间为横轴，最大利润为纵轴，假设我在今天卖掉股票，那我的最大收益是多少？ 那有卖就有买，想要在今天卖掉股票并获得最大收益，那我是不是得在历史的价格最低点买入，这样我在今日卖出的收益才是最大的。 想通了上述的流程，就可以写出代码了，以 cost 代表历史价格最低点，遍历计算每天的利润最大值时，同时维护最低点买入价格 如果想要再精简一下代码： class Solution { public int maxProfit(int[] prices) { // 核心思路在于计算每日卖出时的利润最大值 int cost = Integer.MAX_VALUE; int profit = 0; for(int i = 0; i &lt; prices.length; i++) { // 在遍历到当前元素时， cost 已经是遍历过的元素中的最小值了 profit = Math.max(prices[i] - cost, profit); cost = Math.min(cost, prices[i]); } return profit; } } 2 Review(一篇英文文章) 2.1 来源 Ted：https://www.ted.com/talks/joao_pedro_de_magalhaes_why_do_animals_have_such_different_lifespans 题目：Why do animals have such different lifespans? 2.2 原文 原文（使用 claude.ai 分段）： For the microscopic lab worm, C. elegans life equates to just a few short weeks on Earth. Compare that with the tortoise, which can age to more than 100 years. Mice and rats reach the end of their lives after just four years, while for the bowhead whale, Earth's longest-lived mammal, death can come after 200. Like most living things, the vast majority of animals gradually degenerate after reaching sexual maturity in the process known as aging. But what does it really mean to age? The drivers behind this process are varied and complicated, but aging is ultimately caused by cell death and dysfunction. When we're young, we constantly regenerate cells in order to replace dead and dying ones. But as we age, this process slows down. In addition, older cells don't perform their functions as well as young ones. That makes our bodies go into a decline, which eventually results in disease and death. But if that's consistently true, why the huge variance in aging patterns and lifespan within the animal kingdom? The answer lies in several factors, including environment and body size. These can place powerful evolutionary pressures on animals to adapt, which in turn makes the aging process different across species. Consider the cold depths of the Atlantic and Arctic Seas, where Greenland sharks can live to over 400 years, and the Arctic clam known as the quahog can live up to 500. Perhaps the most impressive of these ocean-dwelling ancients is the Antarctic glass sponge, which can survive over 10,000 years in frigid waters. In cold environments like these, heartbeats and metabolic rates slow down. Researchers theorize that this also causes a slowing of the aging process. In this way, the environment shapes longevity. When it comes to size, it's often, but not always, the case that larger species have a longer lifespan than smaller ones. For instance, an elephant or whale will live much longer than a mouse, rat, or vole, which in turn have years on flies and worms. Some small animals, like worms and flies, are also limited by the mechanics of their cell division. They're mostly made up of cells that can't divide and be replaced when damaged, so their bodies expire more quickly. And size is a powerful evolutionary driver in animals. Smaller creatures are more prone to predators. A mouse, for instance, can hardly expect to survive more than a year in the wild. So, it has evolved to grow and reproduce more rapidly, like an evolutionary defense mechanism against its shorter lifespan. Larger animals, by contrast, are better at fending off predators, and so they have the luxury of time to grow to large sizes and reproduce multiple times during their lives. Exceptions to the size rule include bats, birds, moles, and turtles, but in each case, these animals have other adaptations that allow them to escape predators. But there are still cases where animals with similar defining features, like size and habitat, age at completely different rates. In these cases, genetic differences, like how each organism's cells respond to threats, often account for the discrepancies in longevity. So it's the combination of all these factors playing out to differing degrees in different animals that explains the variability we see in the animal kingdom. So what about us? Humans currently have an average life expectancy of 71 years, meaning that we're not even close to being the longest living inhabitants on Earth. But we are very good at increasing our life expectancy. In the early 1900s, humans only lived an average of 50 years. Since then, we've learned to adapt by managing many of the factors that cause deaths, like environmental exposure and nutrition. This, and other increases in life expectancy make us possibly the only species on Earth to take control over our natural fate. 2.3 总结 自然界生物寿命具有差异性，从几周到上百年不等，影响生物寿命的主要因素主要包括环境、体型和遗传差异这 3 种。 环境：寒冷环境下,心跳和新陈代谢会放慢，研究人员认为这也会使衰老过程变慢。比如寒冷的大西洋和北极海域，那里的格陵兰鲨鱼可以活过400年，北极蛤蜊甚至可以活到500岁。最令人印象深刻的可能是南极玻璃海绵，它可以在冰冷的海水中存活1万多年。 体型：大型物种的寿命通常比小型物种长，但也有例外。大象和鲸鱼的寿命要比老鼠、鼹鼠或田鼠长的多，后者又比苍蝇和蠕虫长寿。原因可能是小型动物更容易手动掠食者的攻击，为了繁衍，逐渐变得生长迅速并性成熟。 遗传差异：有一些动物，尽管它们有相似的特征如体型和栖息地，但衰老速度完全不同。在这种情况下，遗传差异往往解释了长寿的差异，例如每个生物体细胞响应威胁的方式。 关于人类：人类的平均预期寿命现在是71岁，这意味着我们远未成为地球上最长寿的生物。但我们在延长预期寿命方面非常成功。在20世纪初，人类的平均寿命只有50岁。但是后来我们通过控制环境和增加膳食营养等方式来增加预期寿命。 3 Technique/Tips(分享一个小技术) 某内部服务接口，单线程测试时，接口响应时长在 2 秒以内，但使用 jmeter 压测 20 个线程时，响应时长飙升到 27 秒左右。 观察日志发现业务代码中有一条批量插入 的慢 sql。 SQL 语句如下： &lt;insert id=&quot;batchInsertOrUpdate&quot; parameterType=&quot;java.util.List&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt; insert into ...... values &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; separator=&quot;,&quot;&gt; ( ...... ) &lt;/foreach&gt; on duplicate key update last_updated_date = now() &lt;/insert&gt; 使用了 on duplicate key update，加了排他锁，在并发情况下导致后更新的语句一直在等待先前sql语句的锁释放，从而导致接口性能骤降。 考虑到该表的更新为非核心业务，加了一个异步线程去执行该sql。 参考：https://time.geekbang.org/column/article/80801?utm_campaign=geektime_search&amp;utm_content=geektime_search&amp;utm_medium=geektime_search&amp;utm_source=geektime_search&amp;utm_term=geektime_search 4 Share(分享我的所见所闻) 本来第 4 部分应该是“分享一个观点”，但我觉得许多时候，人在经常性地分享观点时，会趋于建议或者劝诫，类似“知识陷阱”一样。 这让我对“分享观点”这件事情有些迟疑，基于上述的原因，我将第 4 点改为了“分享我的所见所闻”，内容比较杂乱，包含一周内读过的书、看过的博客、学习的摄影知识等等。 4.1 技术博客 得物数据库中间件平台“彩虹桥”演进之路 彩虹桥架构演进之路-性能篇｜得物技术 如何正确使用 Bean Validation 进行数据校验｜得物技术 ","link":"https://panson.top/post/panson-weekly-001/"},{"title":"Redis 源码阅读系列-MacOS 搭建Redis 源码阅读环境","content":"Redis 源码阅读第一弹：MacOS + CLion 2023.2.2 搭建 Redis 源码阅读环境 1 源码下载 直接从 GitHub 源码仓库下载： git clone https://github.com/redis/redis.git 我们以最新的 tag 上去: git checkout tags/7.0.4 -b 7.0.4 编译 首先确保安装了 GCC，我本地已安装。 编译： make CFLAGS=&quot;-g -O0&quot; 备注：-O0 参数旨在强制编译器不要进行编译优化，避免 debug 的时候源码与实际运行代码不匹配 启动 拥抱 jetbrains 全家桶，使用 CLion 2023.2.2 编译好的 Redis 源码。 启动配置如下： ![]( ","link":"https://panson.top/post/redis-yuan-ma-yue-du-xi-lie-macos-da-jian-redis-yuan-ma-yue-du-huan-jing/"},{"title":"无聊刷题系列-007","content":"Leetcode 121. 买卖股票的最佳时机 题： 给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价格。 你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。设计一个算法来计算你所能获取的最大利润。 返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。 示例 1： 输入：[7,1,5,3,6,4] 输出：5 解释：在第 2 天（股票价格 = 1）的时候买入，在第 5 天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5 。 注意利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格；同时，你不能在买入前卖出股票。 示例 2： 输入：prices = [7,6,4,3,1] 输出：0 解释：在这种情况下, 没有交易完成, 所以最大利润为 0。 提示： 1 &lt;= prices.length &lt;= 105 0 &lt;= prices[i] &lt;= 104 题解： 代码： class Solution { public int maxProfit(int[] prices) { // 核心思路在于计算每日卖出时的利润最大值 int cost = Integer.MAX_VALUE; int profit = 0; for(int i = 0; i &lt; prices.length; i++) { // 在遍历到当前元素时， cost 已经是遍历过的元素中的最小值了 if(prices[i] - cost &gt; profit) { profit = prices[i] - cost; } cost = Math.min(cost, prices[i]); } return profit; } } 核心思路： 我觉得核心思路是模拟真实买卖股票的流程，以时间为横轴，最大利润为纵轴，假设我在今天卖掉股票，那我的最大收益是多少？ 那有卖就有买，想要在今天卖掉股票并获得最大收益，那我是不是得在历史的价格最低点买入，这样我在今日卖出的收益才是最大的。 想通了上述的流程，就可以写出代码了，以 cost 代表历史价格最低点，遍历计算每天的利润最大值时，同时维护最低点买入价格 如果想要再精简一下代码： class Solution { public int maxProfit(int[] prices) { // 核心思路在于计算每日卖出时的利润最大值 int cost = Integer.MAX_VALUE; int profit = 0; for(int i = 0; i &lt; prices.length; i++) { // 在遍历到当前元素时， cost 已经是遍历过的元素中的最小值了 profit = Math.max(prices[i] - cost, profit); cost = Math.min(cost, prices[i]); } return profit; } } ","link":"https://panson.top/post/wu-liao-shua-ti-xi-lie-007/"},{"title":"无聊刷题系列-006","content":"leetcode 189. 轮转数组：https://leetcode.cn/problems/rotate-array/?envType=study-plan-v2&amp;envId=top-interview-150 题： 给定一个整数数组 nums，将数组中的元素向右轮转 k 个位置，其中 k 是非负数。 示例 1: 输入: nums = [1,2,3,4,5,6,7], k = 3 输出: [5,6,7,1,2,3,4] 解释: 向右轮转 1 步: [7,1,2,3,4,5,6] 向右轮转 2 步: [6,7,1,2,3,4,5] 向右轮转 3 步: [5,6,7,1,2,3,4] 示例 2: 输入：nums = [-1,-100,3,99], k = 2 输出：[3,99,-1,-100] 解释: 向右轮转 1 步: [99,-1,-100,3] 向右轮转 2 步: [3,99,-1,-100] 提示： 1 &lt;= nums.length &lt;= 105 -231 &lt;= nums[i] &lt;= 231 - 1 0 &lt;= k &lt;= 105 进阶： 尽可能想出更多的解决方案，至少有 三种 不同的方法可以解决这个问题。 你可以使用空间复杂度为 O(1) 的 原地 算法解决这个问题吗？ 答： 粗暴解决： class Solution { public void rotate(int[] nums, int k) { k = k % nums.length; // 暂存后 k 个数 int[] tmp = new int[k]; for(int i = 0; i &lt; k; i++) { tmp[i] = nums[nums.length - 1 - i]; } for(int i = nums.length - 1; i &gt;= k; i--) { nums[i] = nums[i - k]; } int j = 0; for(int i = k - 1; i &gt;= 0; i--) { nums[i] = tmp[j++]; } } } ","link":"https://panson.top/post/wu-liao-shua-ti-xi-lie-006/"},{"title":"无聊刷题系列-005","content":" 多数元素：https://leetcode.cn/problems/majority-element 题目： 给定一个大小为 n 的数组 nums ，返回其中的多数元素。多数元素是指在数组中出现次数 大于 ⌊ n/2 ⌋ 的元素。 你可以假设数组是非空的，并且给定的数组总是存在多数元素。 示例 1： 输入：nums = [3,2,3] 输出：3 示例 2： 输入：nums = [2,2,1,1,1,2,2] 输出：2 提示： n == nums.length 1 &lt;= n &lt;= 5 * 104 -109 &lt;= nums[i] &lt;= 109 进阶：尝试设计时间复杂度为 O(n)、空间复杂度为 O(1) 的算法解决此问题。 答： class Solution { public int majorityElement(int[] nums) { // 假设第一个数就是多数元素 int res = nums[0]; int count = 0; for (int num : nums) { if (count == 0) { res = num; } if (res == num) { count++; } else { count--; } } return res; } } ","link":"https://panson.top/post/wu-liao-shua-ti-xi-lie-005/"},{"title":"无聊刷题系列-004","content":" 删除有序数组中的重复项 II：https://leetcode.cn/problems/remove-duplicates-from-sorted-array-ii/description/ 题目 给你一个有序数组 nums ，请你 原地 删除重复出现的元素，使得出现次数超过两次的元素只出现两次 ，返回删除后数组的新长度。 不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。 说明： 为什么返回数值是整数，但输出的答案是数组呢？ 请注意，输入数组是以「引用」方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。 你可以想象内部操作如下: // nums 是以“引用”方式传递的。也就是说，不对实参做任何拷贝 int len = removeDuplicates(nums); // 在函数里修改输入数组对于调用者是可见的。 // 根据你的函数返回的长度, 它会打印出数组中 该长度范围内 的所有元素。 for (int i = 0; i &lt; len; i++) { print(nums[i]); } 示例 1： 输入：nums = [1,1,1,2,2,3] 输出：5, nums = [1,1,2,2,3] 解释：函数应返回新长度 length = 5, 并且原数组的前五个元素被修改为 1, 1, 2, 2, 3。 不需要考虑数组中超出新长度后面的元素。 示例 2： 输入：nums = [0,0,1,1,1,1,2,3,3] 输出：7, nums = [0,0,1,1,2,3,3] 解释：函数应返回新长度 length = 7, 并且原数组的前五个元素被修改为 0, 0, 1, 1, 2, 3, 3。不需要考虑数组中超出新长度后面的元素。 提示： 1 &lt;= nums.length &lt;= 3 * 104 -104 &lt;= nums[i] &lt;= 104 nums 已按升序排列 答 public static int removeDuplicates(int[] nums) { return process(nums, 2); } /** * 通用方法 * * @param nums * @param k * @return */ static int process(int[] nums, int k) { // int index = 0; // for (int iteratorNum : nums) { // // index &lt; k ：前两位数，直接保留 // // nums[index - k] != iteratorNum : 遍历元素与当前写入位置前面第 k 个元素不同，因为如果相同的话说明遍历元素是重复的 // if (index &lt; k || nums[index - k] != iteratorNum) { // nums[index++] = iteratorNum; // } // } // return index; if(nums.length &lt;= 2) { return nums.length; } int p1 = 2, p2 = 2; while(p2 &lt; nums.length) { if(nums[p2] != nums[p1 -2]) { nums[p1++] = nums[p2]; } p2++; } return p1; } ","link":"https://panson.top/post/wu-liao-shua-ti-xi-tong-004/"},{"title":"无聊刷题系列-003","content":" 删除有序数组中的重复项： https://leetcode.cn/problems/remove-duplicates-from-sorted-array/?envType=study-plan-v2&amp;envId=top-interview-150 题目 给你一个 非严格递增排列 的数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。元素的 相对顺序 应该保持 一致 。然后返回 nums 中唯一元素的个数。 考虑 nums 的唯一元素的数量为 k ，你需要做以下事情确保你的题解可以被通过： 更改数组 nums ，使 nums 的前 k 个元素包含唯一元素，并按照它们最初在 nums 中出现的顺序排列。nums 的其余元素与 nums 的大小不重要。 返回 k 。 判题标准: 系统会用下面的代码来测试你的题解: int[] nums = [...]; // 输入数组 int[] expectedNums = [...]; // 长度正确的期望答案 int k = removeDuplicates(nums); // 调用 assert k == expectedNums.length; for (int i = 0; i &lt; k; i++) { assert nums[i] == expectedNums[i]; } 如果所有断言都通过，那么您的题解将被 通过。 示例 1： 输入：nums = [1,1,2] 输出：2, nums = [1,2,_] 解释：函数应该返回新的长度 2 ，并且原数组 nums 的前两个元素被修改为 1, 2 。不需要考虑数组中超出新长度后面的元素。 示例 2： 输入：nums = [0,0,1,1,1,2,2,3,3,4] 输出：5, nums = [0,1,2,3,4] 解释：函数应该返回新的长度 5 ， 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4 。不需要考虑数组中超出新长度后面的元素。 提示： 1 &lt;= nums.length &lt;= 3 * 104 -104 &lt;= nums[i] &lt;= 104 nums 已按 非严格递增 排列 答 class Solution { public int removeDuplicates(int[] nums) { if(nums.length &lt;= 1) { return nums.length; } // p1 指向已处理完成的最后一个数 int p1 = 0; // p2 指向待处理的第一个数 int p2 = 1; // 1 1 2 while(p2 &lt; nums.length) { if(nums[p1] == nums[p2]) { p2++; } else { p1++; nums[p1] = nums[p2]; p2++; } } return p1 + 1; } } ","link":"https://panson.top/post/wu-liao-shua-ti-xi-lie-003/"},{"title":"无聊刷题系列-002","content":" 移除元素：https://leetcode.cn/problems/remove-element/description/?envType=study-plan-v2&amp;envId=top-interview-150 题目： 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。 不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。 元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。 说明: 为什么返回数值是整数，但输出的答案是数组呢? 请注意，输入数组是以「引用」方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。 你可以想象内部操作如下: // nums 是以“引用”方式传递的。也就是说，不对实参作任何拷贝 int len = removeElement(nums, val); // 在函数里修改输入数组对于调用者是可见的。 // 根据你的函数返回的长度, 它会打印出数组中 该长度范围内 的所有元素。 for (int i = 0; i &lt; len; i++) { print(nums[i]); } 示例 1： 输入：nums = [3,2,2,3], val = 3 输出：2, nums = [2,2] 解释：函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。例如，函数返回的新长度为 2 ，而 nums = [2,2,3,3] 或 nums = [2,2,0,0]，也会被视作正确答案。 示例 2： 输入：nums = [0,1,2,2,3,0,4,2], val = 2 输出：5, nums = [0,1,4,0,3] 解释：函数应该返回新的长度 5, 并且 nums 中的前五个元素为 0, 1, 3, 0, 4。注意这五个元素可为任意顺序。你不需要考虑数组中超出新长度后面的元素。 提示： 0 &lt;= nums.length &lt;= 100 0 &lt;= nums[i] &lt;= 50 0 &lt;= val &lt;= 100 答 public class L027 { static class Solution { public static int removeElement(int[] nums, int val) { int p1 = 0; int p2 = nums.length - 1; while(p1 &lt;= p2) { if(nums[p1] == val) { swap(nums, p1, p2); p2--; } else { p1++; } } return p1; } public static void swap(int[] nums, int p1, int p2) { int tmp = nums[p1]; nums[p1] = nums[p2]; nums[p2] = tmp; } } public static void main(String[] args) { int[] nums = new int[]{3,2,2,3}; Solution.removeElement(nums, 3); } } ","link":"https://panson.top/post/wu-liao-shua-ti-xi-lie-002/"},{"title":"无聊刷题系列-001","content":"合并两个有序数组：https://leetcode.cn/problems/merge-sorted-array/?envType=study-plan-v2&amp;envId=top-interview-150 题目： 给你两个按 非递减顺序 排列的整数数组 nums1 和 nums2，另有两个整数 m 和 n ，分别表示 nums1 和 nums2 中的元素数目。 请你 合并 nums2 到 nums1 中，使合并后的数组同样按 非递减顺序 排列。 注意：最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元素为 0 ，应忽略。nums2 的长度为 n 。 示例 1： 输入：nums1 = [1,2,3,0,0,0], m = 3, nums2 = [2,5,6], n = 3 输出：[1,2,2,3,5,6] 解释：需要合并 [1,2,3] 和 [2,5,6] 。 合并结果是 [1,2,2,3,5,6] ，其中斜体加粗标注的为 nums1 中的元素。 示例 2： 输入：nums1 = [1], m = 1, nums2 = [], n = 0 输出：[1] 解释：需要合并 [1] 和 [] 。 合并结果是 [1] 。 示例 3： 输入：nums1 = [0], m = 0, nums2 = [1], n = 1 输出：[1] 解释：需要合并的数组是 [] 和 [1] 。 合并结果是 [1] 。 注意，因为 m = 0 ，所以 nums1 中没有元素。nums1 中仅存的 0 仅仅是为了确保合并结果可以顺利存放到 nums1 中。 提示： nums1.length == m + n nums2.length == n 0 &lt;= m, n &lt;= 200 1 &lt;= m + n &lt;= 200 -109 &lt;= nums1[i], nums2[j] &lt;= 109 进阶：你可以设计实现一个时间复杂度为 O(m + n) 的算法解决此问题吗？ 答： class Solution { public void merge(int[] nums1, int m, int[] nums2, int n) { int p1 = m - 1; int p2 = n - 1; int tail = m + n - 1; int cur; // 从后往前，双指针 while (p1 &gt;= 0 || p2 &gt;= 0) { if(p1 == -1) { cur = nums2[p2]; p2--; } else if(p2 == -1) { cur = nums1[p1]; p1--; } else if(nums1[p1] &lt;= nums2[p2]) { cur = nums2[p2]; p2--; } else { cur = nums1[p1]; p1--; } nums1[tail--] = cur; } } } &lt;!-- more --&gt; ","link":"https://panson.top/post/wu-liao-shua-ti-xi-lie/"},{"title":"RocketMQ 源码阅读—— DefaultMQProducerImpl 中 Topic 校验","content":"在 DefaultMQProducerImpl 的启动过程中，会校验 Topic，RocketMQ 用了了一个简易的位图来维护合法值范围，蛮小巧别致的。 public static boolean isTopicOrGroupIllegal(String str) { int strLen = str.length(); int len = VALID_CHAR_BIT_MAP.length; boolean[] bitMap = VALID_CHAR_BIT_MAP; for (int i = 0; i &lt; strLen; i++) { char ch = str.charAt(i); if (ch &gt;= len || !bitMap[ch]) { return true; } } return false; } public static final boolean[] VALID_CHAR_BIT_MAP = new boolean[128]; VALID_CHAR_BIT_MAP['%'] = true; // - VALID_CHAR_BIT_MAP['-'] = true; // _ VALID_CHAR_BIT_MAP['_'] = true; // | VALID_CHAR_BIT_MAP['|'] = true; for (int i = 0; i &lt; VALID_CHAR_BIT_MAP.length; i++) { if (i &gt;= '0' &amp;&amp; i &lt;= '9') { // 0-9 VALID_CHAR_BIT_MAP[i] = true; } else if (i &gt;= 'A' &amp;&amp; i &lt;= 'Z') { // A-Z VALID_CHAR_BIT_MAP[i] = true; } else if (i &gt;= 'a' &amp;&amp; i &lt;= 'z') { // a-z VALID_CHAR_BIT_MAP[i] = true; } } ","link":"https://panson.top/post/rocketmq-yuan-ma-yue-du-defaultmqproducerimpl-zhong-topic-xiao-yan/"},{"title":"\"月\"读计划之2023-03","content":"Stay Hungry, Stay Foolish BLOG 阿里 IM 技术分享 (二)：Flutter IM跨端架构设计和实现 阿里 IM 技术分享 (三)：闲鱼亿级 IM 消息系统的架构演进之路 阿里 IM 技术分享 (四)：闲鱼亿级 IM 消息系统的可靠投递优化实践 阿里 IM 技术分享 (五)：闲鱼亿级 IM 消息系统的及时性优化实践 阿里 IM 技术分享 (六)：闲鱼亿级 IM 消息系统的离线推送到达率优化 阿里 IM 技术分享 (七)：闲鱼 IM 的在线、离线聊天数据同步机制优化实践 阿里 IM 技术分享 (八)：深度解密钉钉即时消息服务 DTIM 的技术设计 阿里 IM 技术分享 (九)：深度揭密 RocketMQ 在钉钉 IM 系统中的应用实践 阿里 IM 技术分享 (十)：深度揭密钉钉后端架构的单元化演进之路 专栏 读完了极客时间《Dubbo源码剖析与实战》 ","link":"https://panson.top/post/yue-du-ji-hua-zhi-2023-03/"},{"title":"“月度”LeetCode刷题之2023-02","content":"今年的计划是用 Go 刷 150道 LeetCode21. 合并两个有序链表 func mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode { dummyHead := &amp;ListNode{} p := dummyHead for list1 != nil &amp;&amp; list2 != nil { if list1.Val &gt;= list2.Val { p.Next = list2 list2 = list2.Next } else { p.Next = list1 list1 = list1.Next } p = p.Next } if list1 != nil { p.Next = list1 } if list2 != nil { p.Next = list2 } return dummyHead.Next } LeetCode 86. 分隔链表 func partition(head *ListNode, x int) *ListNode { small := &amp;ListNode{} smallHead := small large := &amp;ListNode{} largeHead := large for head != nil { if head.Val &lt; x { small.Next = head small = small.Next } else { large.Next = head large = large.Next } head = head.Next; } large.Next = nil small.Next = largeHead.Next return smallHead.Next } LeetCode 83. 删除排序链表中的重复元素 func deleteDuplicates(head *ListNode) *ListNode { if head == nil { return nil } cur := head for cur.Next != nil { if cur.Val == cur.Next.Val { cur.Next = cur.Next.Next } else { cur = cur.Next } } return head } LeetCode 27. 移除元素 func removeElement(nums []int, val int) int { left := 0 for _,v := range nums { if(v != val) { nums[left] = v left++ } } return left } ","link":"https://panson.top/post/yue-du-leetcode-shua-ti-zhi/"},{"title":"\"月\"读计划之2023-02","content":"Stay Hungry, Stay Foolish BLOG 2022 春节抖音视频红包系统设计与实现 浅谈任务分发中的机制与并发 现代 IM 系统中的消息系统架构——架构篇 现代 IM 系统中的消息系统架构——模型篇 现代 IM 系统中的消息系统架构——实现篇 专栏 读完了极客时间《即时消息技术剖析与实战》 读完了极客时间《Spring 编程常见错误 50 例》 ","link":"https://panson.top/post/yue-du-ji-hua/"},{"title":"“月”读计划之2023-01","content":"Stay Hungry, Stay Foolish BLOG vivo营销自动化技术解密｜开篇 设计模式如何提升 vivo 营销自动化业务扩展性 | 引擎篇01 状态机引擎在vivo营销自动化中的深度实践 | 引擎篇02 工作流引擎在vivo营销自动化中的应用实践 | 引擎篇03 实时营销引擎在vivo营销自动化中的实践 | 引擎篇04 ","link":"https://panson.top/post/yue-du-ji-hua-zhi-2023-01/"},{"title":"weekly study 012","content":"from 2022-10-31 to 2022-11-06 LeetCode Reading 《MySQL 45讲》010：MySQL为什么有时候会选错索引？ 《MySQL 45讲》011：怎么给字符串加索引？ 《MySQL 45讲》12丨为什么我的MySQL会“抖”一下？ 《MySQL 45讲》13丨为什么表数据删掉一半，表文件大小不变？ 《MySQL 45讲》14 | count(*)这么慢，我该怎么办？ English Writing English Listening ","link":"https://panson.top/post/weekly-study-012/"},{"title":"weekly study 010","content":"from 2022-10-17 to 2022-10-23 LeetCode Reading rouyi-vue-pro 开发指南阅读简介部分 English Writing English Listening 原文标题：What the Disease Feels Like, and Presidents Can't End Pandemics: COVID, Quickly, Episode 39 原文链接：https://www.scientificamerican.com/podcast/episode/what-the-disease-feels-like-and-presidents-cant-end-pandemics-covid-quickly-episode-39/ ● By Josh Fischman, Tanya Lewis, Tulika Bose on September 27, 2022 以下为正文 On this episode of the COVID, Quickly podcast, Josh Fischman gets COVID, and President Joe Biden says the pandemic is over. Full Transcript Tanya Lewis: Hi, and welcome to COVID, Quickly, a Scientific American podcast series! Josh Fischman: This is your fast-track update on the COVID pandemic. We bring you up to speed on the science behind the most urgent questions about the virus and the disease. We demystify the research, and help you understand what it really means. Lewis: I’m Tanya Lewis. Fischman: I’m Josh Fischman. Lewis: And we’re Scientific American’s senior health editors. Lewis: And we’re Scientific American’s senior health editors. Today we’re going to take a personal look at a moderate case of COVID—if Josh’s voice holds up… Fischman: And we’ll talk about how we decide when pandemics are really over—not just when presidents say they are. -- Fischman: Can you hear me OK? Do I sound too rough? Lewis: Actually you sound fairly normal. Fischman: Oh, good. That’s a change for the better. Yesterday I sounded like I was at the bottom of a well, but without the cool echo-y effect. And with more gurgling. Lewis: Because… Fischman: Because I have COVID. I started showing symptoms almost two weeks ago, and I still have them. Lewis: That sucks. I’m so sorry. Fischman: Thanks. I don’t want to make this episode all about me, though. Lewis: I don’t either. But we talk a lot about scientific studies, and we don’t often talk about what it’s like to actually have COVID. Fischman: I didn’t believe I caught it at first. I’ve spent two and half years avoiding it. I’m vaccinated and boosted. So to see that positive line on a rapid antigen test strip made me go “Wait. What? No, that can’t be right.” So I took another test. And there was the line again. Lewis: Do you know how you got infected? Fischman: I’m pretty sure it was on a business trip to New York City. That meant trains, subways, sitting in a big meeting with about 200 other people, most of whom didn’t wear masks. I wore a mask. But I did go to an outside bar with some friends from work, and there was a nice breeze and, well, you can’t drink beer through a mask. So I took mine off. Lewis: When did you know there was a problem? Fischman: Three days later. I was in my backyard, nice warm day, and I started to get chills. And I knew I’d been in riskier situations than normal. So I took a test and did the whole double-take thing. Lewis: Was it scary? Fischman: I wasn’t scared for me. My lungs are in pretty good shape, I have good medical care, all that good stuff. But I worried about infecting my spouse. We grabbed masks right away and I moved into a different part of the house. Not everyone has the luxury of that kind of space, though. I was thinking we were lucky. Fischman: By the next evening I couldn’t get out of bed and I wasn’t feeling so lucky. Lewis: What were the worst symptoms? Fischman: Um, I don’t want to get into icky details. Lewis: Give us the non-icky version. Fischman: Coughing, pretty much non-stop. And my throat got so painful from it that I couldn’t even swallow tea with honey, which is usually soothing. There were two days where I lay in bed and ate a little apple sauce and gargled with salt water. And I swallowed a lot of NyQuil. Lewis: Did you try Paxlovid? Fischman: I did. Got it right away. And I think it really helped. The cough got better after about two days and I felt more energetic. And six days after the symptoms started I was in my yard again, and walked my dog–wearing a mask, because I was still positive on the rapid tests. But then I had a relapse. Lewis: Really? One of those Paxlovid rebounds that we’ve heard about? Fischman: No, because I never cleared the virus. I have a whole souvenir row of positive test strips lined up on my dresser. And I still had some symptoms, like chills and fatigue. Those tests are pretty accurate. I looked them up on Cochrane Reviews, the web site of a really good non-profit that evaluates medical evidence with very strict standards, and only about 11 percent of people taking antigen tests would get a false positive. Lewis: So how are things today? Fischman: I feel better, really better, and this is day 11. And this has been just moderate disease. I’ve had the flu, but no flu ever hit me this hard. So I’m back to feeling lucky. We’re still losing 400 to 500 Americans every day to COVID. But I think I can get back to work, at least from home, and I don’t think I’ve infected anyone around me, and if I stop testing positive I can get out of the house. Lewis: Well, that’s good to hear you’re feeling better. Just don’t eat any NyQuil chicken. -- Fischman: President Biden caused a stir last week when he casually declared on 60 Minutes that the pandemic is over. Is it really? Lewis: Not as far as I can tell. But it turns out the point at which a pandemic is really over is hard to define. I wrote about this back in March, when I interviewed John M. Barry, author of a comprehensive history of the 1918 influenza pandemic. Barry told me then that the decision about when a pandemic ends is as much a human one as a scientific one. Lewis: Interesting. But there are some scientific criteria, right? Fischman: Well, sort of. As Georgetown international health law professor Alexandra Phelan pointed out on Twitter, there’s no formal law or process for declaring a pandemic over. For influenza pandemics, they’re usually considered to be in a post-pandemic phase when flu cases return to seasonal levels. But it’s not clear what those will be for COVID, or if we’ve even gotten there yet. Fischman: Right. 400 people a day are still dying of COVID in the U.S., and many more around the world. That doesn’t seem like the end of a pandemic to me. Lewis: Nor me. COVID is still spreading widely around the world, and is likely to be around for the rest of our lives as an endemic virus. But thanks to vaccines and better treatments like Paxlovid, it’s not killing nearly as many people. Lewis: That said, we could still see a new variant this fall or winter that’s better at evading the vaccines or is more severe. That could cause cases and hospitalizations to tick up again. Fischman: Now’s a good time to get your updated Omicron booster shot if you haven’t already. Lewis: Exactly. Fischman: But back to Biden—some people strongly criticized him for saying the pandemic isA over. Others say he was just acknowledging that most people are already living their lives with the virus. Lewis: It may be true that many people have moved on. Others are still being cautious, or struggling with lingering symptoms that have upended their lives. But whether or not you consider the pandemic “over,” the more important question is how we’re going to deal with COVID going forward, especially for the most vulnerable among us. Lewis: There is reason for hope. Fewer people are dying from COVID globally now than at any time since March 2020. As the WHO director-general said in a recent press briefing: “We are not there yet. But the end is in sight.” -- Lewis: Now you’re up to speed. Thanks for joining us. Our show is edited by Jeff Delviscio and Tulika Bose. Fischman: Come back in two weeks for the next episode of COVID, Quickly! And check out sciam.com for updated and in-depth COVID news. ","link":"https://panson.top/post/weekly-study-010/"},{"title":"weekly study 009","content":"from 2022-10-10 to 2022-10-16 LeetCode Reading 《MySQL 45讲》09：普通索引和唯一索引，应该怎么选择？ English Writing English Listening ","link":"https://panson.top/post/weekly-study-009/"},{"title":"weekly study 008","content":"from 2022-10-03 to 2022 -10-09 LeetCode Reading 掘金小册《Netty 入门与实战：仿写微信 IM 即时通讯系统》第 14 节到完结 《MySQL 45讲》08：事务到底是隔离的还是不隔离的 English Writing English Listening 10月8日： ","link":"https://panson.top/post/weekly-study-008/"},{"title":"weekly study 007","content":"from 2022-09-26 to 2022-10-02 LeetCode 435 无重叠区间 public int eraseOverlapIntervals(int[][] intervals) { if(intervals.length == 0) { return 0; } int removeCount = 0; Arrays.sort(intervals, Comparator.comparingInt(o -&gt; o[1])); int right = intervals[0][1]; for(int i = 1; i &lt; intervals.length; i++) { if(right &gt; intervals[i][0]) { removeCount++; } else { right = intervals[i][1]; } } return removeCount; } } 452 用最少数量的箭引爆气球 class Solution { public int findMinArrowShots(int[][] points) { if(points == null || points.length == 0) { return 0; } Arrays.sort(points, Comparator.comparingInt(arr -&gt; arr[1])); int right = points[0][1]; int removeCount = 0; for (int i = 1; i &lt; points.length; i++) { if(right &gt;= points[i][0]) { removeCount++; } else { right = points[i][1]; } } return points.length - removeCount; } } Reading 掘金小册《Netty 入门与实战：仿写微信 IM 即时通讯系统》第 4 节到第 13 节 English Writing English Listening ","link":"https://panson.top/post/weekly-study-007/"},{"title":"weekly stydy 005","content":"from 2022-09-12 to 2022-09-18 LeetCode 435 无重叠区间：https://leetcode.cn/problems/non-overlapping-intervals/ Reading raft paper： http://nil.lcs.mit.edu/6.824/2020/papers/raft-extended.pdf 掘金小册：《Java开发者的RPC实战课》第四节 English Writing English Listening ","link":"https://panson.top/post/weekly-stydy-005/"},{"title":"weekly study 003","content":"from 2022-08-29 to 2022-09-04 leetcode 1470.重新排列数组 class Solution { public int[] shuffle(int[] nums, int n) { int[] ans = new int[2 * n]; for (int i = 0; i &lt; n; i++) { ans[2 * i] = nums[i]; ans[2 * i + 1] = nums[i + n]; } return ans; } } leetcode 998.最大二叉树 II class Solution { public TreeNode insertIntoMaxTree(TreeNode root, int val) { // val 如果是最大值，那么直接把原先的树设为新节点的左子树 // 否则，遍历最右子节点，寻找临界节点 if(root == null) { return new TreeNode(val); } TreeNode father = null; TreeNode child = root; while(child != null &amp;&amp; child.val &gt; val) { father = child; child = child.right; } // val 为最大值 if(father == null) { return new TreeNode(val, child, null); } else { father.right = new TreeNode(val, child, null); return root; } } } LeetCode 946.验证栈序列 class Solution { public boolean validateStackSequences(int[] pushed, int[] popped) { Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); int n = pushed.length; for (int i = 0, j = 0; i &lt; n; i++) { stack.push(pushed[i]); while (!stack.isEmpty() &amp;&amp; stack.peek() == popped[j]) { stack.pop(); j++; } } return stack.isEmpty(); } } leetcode 1475.商品折扣后的最终价格 class Solution { public int[] finalPrices(int[] prices) { int[] res = new int[prices.length]; for(int i = 0; i &lt; prices.length; i++) { res[i] = prices[i]; } for(int i = 0; i &lt; prices.length; i++) { for(int j = i + 1; j &lt; prices.length; j++) { if(prices[j] &lt;= prices[i]) { res[i] = prices[i] - prices[j]; break; } } } return res; } } class Solution1 { public int[] finalPrices(int[] prices) { int[] res = new int[prices.length]; for(int i = 0; i &lt; prices.length; i++) { int discount = 0; for(int j = i + 1; j &lt; prices.length; j++) { if(prices[j] &lt;= prices[i]) { discount = prices[j]; break; } } res[i] = prices[i] - discount; } return res; } } leetcode 687.最长同值路径 class Solution { int max = 0; public int longestUnivaluePath(TreeNode root) { helper(root); return max; } private int helper(TreeNode root) { if(root == null) { return 0; } int lefMax = helper(root.left); int rightMax = helper(root.right); int left1 = 0; int right1 = 0; if(root.left != null &amp;&amp; root.left.val == root.val) { left1 = lefMax + 1; } if(root.right != null &amp;&amp; root.right.val == root.val) { right1 = rightMax + 1; } max = Math.max(max, left1 + right1); return Math.max(left1, right1); } } leetcode 646.最长数对链 class Solution { public int findLongestChain(int[][] pairs) { int n = pairs.length; Arrays.sort(pairs, (a, b) -&gt; a[0] - b[0]); int[] dp = new int[n]; Arrays.fill(dp, 1); for (int i = 0; i &lt; n; i++) { for (int j = 0; j &lt; i; j++) { if (pairs[i][0] &gt; pairs[j][1]) { dp[i] = Math.max(dp[i], dp[j] + 1); } } } return dp[n - 1]; } } leetcode 1582. 二进制矩阵中的特殊位置 class Solution { public int numSpecial(int[][] mat) { int res = 0; int rowsSum[] = new int[mat.length]; int columSum[] = new int[mat[0].length]; for (int i = 0; i &lt; mat.length; i++) { for (int j = 0; j &lt; mat[0].length; j++) { rowsSum[i] += mat[i][j]; columSum[j] += mat[i][j]; } } for (int i = 0; i &lt; mat.length; i++) { for (int j = 0; j &lt; mat[0].length; j++) { if (mat[i][j] == 1 &amp;&amp; rowsSum[i] == 1 &amp;&amp; columSum[j] == 1) { res++; } } } return res; } } ","link":"https://panson.top/post/weekly-study-003/"},{"title":"weekly sdudy 002","content":"from 2022-08-22 to 2022-08-28 1 Algorithm leetcode 655.输出二叉树 class Solution { private final String BLANK = &quot;&quot;; private int height = 0; int m = 0; int n = 0; int r = 0; int c = 0; private final List&lt;List&lt;String&gt;&gt; res = new ArrayList&lt;&gt;(); public List&lt;List&lt;String&gt;&gt; printTree(TreeNode root) { height = traverse(root) - 1; m = height + 1; n = (int)Math.pow(2, height + 1) - 1; r = 0; c = (n - 1) / 2; fill(); build(root, r, c); return res; } private void fill() { for(int i = 0; i &lt; m; i++) { List&lt;String&gt; currentLevel = new ArrayList&lt;&gt;(n); for(int j = 0; j &lt; n; j++) { currentLevel.add(BLANK); } res.add(currentLevel); } } private void build(TreeNode root, int r, int c) { if(root == null) { return; } res.get(r).set(c, String.valueOf(root.val)); build(root.left, r + 1, (int) (c - Math.pow(2, height - r -1))); build(root.right, r + 1, (int) (c + Math.pow(2, height - r -1))); } private int traverse(TreeNode root) { if(root == null) { return 0; 。。。 } int leftHeight = traverse(root.left); int rightHeight = traverse(root.right); return Math.max(leftHeight, rightHeight) + 1; } 1445.检查单词是否为句中其他单词的前缀 static class Solution { public static int isPrefixOfWord(String sentence, String searchWord) { int sentenceIndex = 0; int wordIndex = 0; int res = 1; while(sentenceIndex &lt; sentence.length()) { if(Character.isWhitespace(sentence.charAt(sentenceIndex))) { sentenceIndex++; res++; } while(sentence.charAt(sentenceIndex) == searchWord.charAt(wordIndex)) { if(wordIndex == searchWord.length() - 1) { return res; } sentenceIndex++; wordIndex++; } wordIndex = 0; while(sentenceIndex &lt; sentence.length() &amp;&amp; !Character.isWhitespace(sentence.charAt(sentenceIndex))) { sentenceIndex++; } } return -1; } public static void main(String[] args) { int prefixOfWord = isPrefixOfWord(&quot;dumb dream duck duck i&quot;, &quot;dream&quot;); System.out.println(prefixOfWord); } } 1460.通过翻转子数组使两个数组相等 class Solution { public boolean canBeEqual(int[] target, int[] arr) { Arrays.sort(target); Arrays.sort(arr); for(int i = 0; i &lt; target.length; i++) { if(target[i] != arr[i]) { return false; } } return true; } } 658.找到 K 个最接近的元素 class Solution { public List&lt;Integer&gt; findClosestElements(int[] arr, int k, int x) { int left = 0; int right = arr.length - 1; while(right - left != k -1) { if(x - arr[left] &gt; arr[right] - x) { left++; } else { right--; } } List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); for(int i = left; i &lt;= right; i++) { res.add(arr[i]); } return res; } } 1464.数组中两元素的最大乘积 class Solution { public int maxProduct(int[] nums) { int left = 0, right = nums.length - 1, max = Integer.MIN_VALUE; while(left &lt; right) { max = Math.max(max, (nums[right] - 1) * (nums[left] - 1)); if(nums[left] &lt; nums[right]) { left++; } else { right--; } } return max; } } class Solution1 { public int maxProduct(int[] nums) { int max0 = Integer.MIN_VALUE, max1 = Integer.MIN_VALUE; for(int num : nums) { if(num &gt;= max0) { max1 = max0; max0 = num; } else if(num &gt;= max1){ max1 = num; } } return (max0 - 1) * (max1 - 1); } } 662.二叉树最大宽度( public int widthOfBinaryTree(TreeNode root) { if(root == null) { return 0; } List&lt;Pair&lt;TreeNode, Integer&gt;&gt; currentLevel = new ArrayList&lt;&gt;(); currentLevel.add(new Pair&lt;&gt;(root, 1)); int res = 1; while(!currentLevel.isEmpty()) { List&lt;Pair&lt;TreeNode, Integer&gt;&gt; nextLevel = new ArrayList&lt;&gt;(); for (Pair&lt;TreeNode, Integer&gt; treeNodeIntegerPair : currentLevel) { if (treeNodeIntegerPair.getKey().left != null) { nextLevel.add(new Pair&lt;&gt;(treeNodeIntegerPair.getKey().left, treeNodeIntegerPair.getValue() * 2)); } if (treeNodeIntegerPair.getKey().right != null) { nextLevel.add(new Pair&lt;&gt;(treeNodeIntegerPair.getKey().right, treeNodeIntegerPair.getValue() * 2 + 1)); } } res = Math.max(currentLevel.get(currentLevel.size() - 1).getValue() - currentLevel.get(0).getValue() + 1, res); currentLevel = nextLevel; } return res; } 172.阶乘后的零 class Solution { public int trailingZeroes(int n) { int count = 0; while(n &gt;= 5) { count += n / 5; n = n / 5; } return count; } } 2 Reading 新浪微博从 Kafka 到 Pulsar 的演变 3 English Writing is an entry ticket to : …… 是获得……（成功、健康、爱情）等的通行证 【相似句型】be a passport to sth 【例句精选】 a. But Tadateru Konoe, the IFRC's Japanese persident, reports that neutrality is still an entry ticket to many disaster zones.(The Economist) 但是红十字会与红新月会国际联合会的日裔主席近卫忠辉反驳说，保持中立仍旧是进入许多灾难地区的通行证。 b. While firms' profits have soared, wages for typical worker have barely budged. The middle class——admittedly a vague term in America——feels squeezed. A college degree is no longer a passport to ever-higher pay.(The Economist) 企业利润暴涨，但普通工人的工资几乎没有变动。中产阶级——一个在美国已变得模糊的概念——感到被挤压。大学学位已经不再是获得高薪的保证。 ","link":"https://panson.top/post/weekly-sdudy-002/"},{"title":"weekly study 001","content":"from 2022-08-15 to 2022-08-21 leetcode 623: 在二叉树中增加一行 class Solution { public TreeNode addOneRow(TreeNode root, int val, int depth) { if(depth == 1) { TreeNode newRoot = new TreeNode(val); newRoot.left = root; return newRoot; } else { recursion(root, val, depth - 1); return root; } } public void recursion(TreeNode root, int val, int depth) { if(root == null) { return; } if(depth == 1) { TreeNode newLeft = new TreeNode(val); newLeft.left = root.left; root.left = newLeft; TreeNode newRight = new TreeNode(val); newRight.right = root.right; root.right = newRight; } else { recursion(root.left, val, depth - 1); recursion(root.right, val, depth - 1); } } } leetcode 641：设计循环双端队列 public class MyCircularDeque { private List&lt;Integer&gt; values; private int last = 0; private int capacity = 0; public MyCircularDeque(int k) { values = new LinkedList&lt;&gt;(); capacity = k; } public boolean insertFront(int value) { if(last &gt;= capacity) { return false; } values.add(0, value); last++; return true; } public boolean insertLast(int value) { if(last &gt;= capacity) { return false; } values.add(last, value); last++; return true; } public boolean deleteFront() { if(last &lt;= 0) { return false; } values.remove(0); last--; return true; } public boolean deleteLast() { if(last &lt;= 0) { return false; } values.remove(last - 1); last--; return true; } public int getFront() { if(last &lt;= 0) { return -1; } return values.get(0); } public int getRear() { if(last &lt;= 0) { return -1; } return values.get(last - 1); } public boolean isEmpty() { return last == 0; } public boolean isFull() { return last &gt;= capacity; } } leetcode 1656：设计有序流 class OrderedStream { private String[] values; private int ptr = 1; public OrderedStream(int n) { values = new String[n + 1]; } public List&lt;String&gt; insert(int idKey, String value) { values[idKey] = value; List&lt;String&gt; res = new ArrayList&lt;&gt;(); for (int i = ptr; i &lt; values.length; i++) { if (values[i] == null) { ptr = i; return res; } else { res.add(values[i]); } } return res; } } leetcode 1032: 层数最深叶子节点的和 class Solution { public int deepestLeavesSum(TreeNode root) { if (root == null) { return 0; } int levelSum = 0; Deque&lt;TreeNode&gt; level = new ArrayDeque&lt;&gt;(); level.offer(root); while (!level.isEmpty()) { int levelSize = level.size(); levelSum = 0; for(int i = 0; i &lt; levelSize; i++) { TreeNode node = level.poll(); levelSum += node.val; if (node.left != null) { level.offer(node.left); } if(node.right != null) { level.offer(node.right); } } } return levelSum; } } leetcode 1224. 最大相等频率 class Solution { int[] cnt = new int[100010], sum = new int[100010]; public int maxEqualFreq(int[] nums) { Arrays.fill(cnt, 0); Arrays.fill(sum, 0); int n = nums.length, max = 0, ans = 0; for (int i = 0; i &lt; n; i++) { int t = nums[i], cur = ++cnt[t], len = i + 1; sum[cur]++; sum[cur - 1]--; max = Math.max(max, cur); if (max == 1) ans = len; if (max * sum[max] + 1 == len) ans = len; if ((max - 1) * (sum[max - 1] + 1) + 1 == len) ans = len; } return ans; } } leetcode 1450: 在既定时间做作业的学生人数 class Solution { public int busyStudent(int[] startTime, int[] endTime, int queryTime) { int res = 0; for(int i = 0; i &lt; startTime.length; i++) { if(queryTime &gt;= startTime[i] &amp;&amp; queryTime &lt; endTime[i]) { res++; } } return res; } } leetcode 654: 最大二叉树 class Solution { public TreeNode constructMaximumBinaryTree(int[] nums) { return helper(nums, 0, nums.length - 1); } private TreeNode helper(int[] nums, int left, int right) { if(left &lt; right) { return null; } int max = Integer.MIN_VALUE; int maxIndex = left; for(int i = left; i &lt;= right; i++) { if(nums[i] &gt; max) { max = nums[i]; maxIndex = i; } } TreeNode root = new TreeNode(max); root.left = helper(nums, left, maxIndex - 1); root.right = helper(nums, maxIndex + 1, right); return root; } } ","link":"https://panson.top/post/weekly-study-001/"},{"title":"RocketMQ Broker 源码阅读","content":"// 龟速写作中，思路比较乱，还在整理行文 1 Broker 的核心配置与启动过程 Broker 是 RocketMQ 的存储中心，可以说是最核心的模块，有许多值得研究的地方。话不多说，我们直接看源码吧。 启动类 org.apache.rocketmq.broker.BrokerStartup 也是和NameServer 类似的，核心的组件是 BrokerController， BrokerController 和 NameServerController的配置有很多相似的配置，考虑到前文NameServer 的源码阅读一文中已经做了对配置类的详解，这里不再赘述。 final BrokerController controller = new BrokerController( brokerConfig, nettyServerConfig, nettyClientConfig, messageStoreConfig); Broker 一方面需要作为 client 注册到 NameServer 上去，另一方面又需要作为 server 接收 producer 的消息，所以拥有两份配置 nettyServerConfig 和 nettyClientConfig。messageStoreConfig 则是消息存储的配置。 另外 BrokerController 还包含了许多管控组件以及线程池： this.consumerOffsetManager = messageStoreConfig.isEnableLmq() ? new LmqConsumerOffsetManager(this) : new ConsumerOffsetManager(this); this.topicConfigManager = messageStoreConfig.isEnableLmq() ? new LmqTopicConfigManager(this) : new TopicConfigManager(this); this.pullMessageProcessor = new PullMessageProcessor(this); this.pullRequestHoldService = messageStoreConfig.isEnableLmq() ? new LmqPullRequestHoldService(this) : new PullRequestHoldService(this); this.messageArrivingListener = new NotifyMessageArrivingListener(this.pullRequestHoldService); this.consumerIdsChangeListener = new DefaultConsumerIdsChangeListener(this); this.consumerManager = new ConsumerManager(this.consumerIdsChangeListener); this.consumerFilterManager = new ConsumerFilterManager(this); this.producerManager = new ProducerManager(); …… …… this.sendThreadPoolQueue = new LinkedBlockingQueue&lt;Runnable&gt;(this.brokerConfig.getSendThreadPoolQueueCapacity()); this.putThreadPoolQueue = new LinkedBlockingQueue&lt;Runnable&gt;(this.brokerConfig.getPutThreadPoolQueueCapacity()); this.pullThreadPoolQueue = new LinkedBlockingQueue&lt;Runnable&gt;(this.brokerConfig.getPullThreadPoolQueueCapacity()); this.replyThreadPoolQueue = new LinkedBlockingQueue&lt;Runnable&gt;(this.brokerConfig.getReplyThreadPoolQueueCapacity()); this.queryThreadPoolQueue = new LinkedBlockingQueue&lt;Runnable&gt;(this.brokerConfig.getQueryThreadPoolQueueCapacity()); this.clientManagerThreadPoolQueue = new LinkedBlockingQueue&lt;Runnable&gt;(this.brokerConfig.getClientManagerThreadPoolQueueCapacity()); this.consumerManagerThreadPoolQueue = new LinkedBlockingQueue&lt;Runnable&gt;(this.brokerConfig.getConsumerManagerThreadPoolQueueCapacity()); this.heartbeatThreadPoolQueue = new LinkedBlockingQueue&lt;Runnable&gt;(this.brokerConfig.getHeartbeatThreadPoolQueueCapacity()); this.endTransactionThreadPoolQueue = new LinkedBlockingQueue&lt;Runnable&gt;(this.brokerConfig.getEndTransactionPoolQueueCapacity()); 再看看 broker 的初始化过程： public boolean initialize() throws CloneNotSupportedException { // 加载Topic 的配置、consumer 的消费 offset、 // consumer 的订阅组、过滤器 等数据到内存 boolean result = this.topicConfigManager.load(); result = result &amp;&amp; this.consumerOffsetManager.load(); result = result &amp;&amp; this.subscriptionGroupManager.load(); result = result &amp;&amp; this.consumerFilterManager.load(); if (result) { try { // 消息存储管理组件 this.messageStore = new DefaultMessageStore(this.messageStoreConfig, this.brokerStatsManager, this.messageArrivingListener, this.brokerConfig); // 如果启用了dleger技术管理 commitlog， // 要初始化一堆 dleger 相关的组件 if (messageStoreConfig.isEnableDLegerCommitLog()) { DLedgerRoleChangeHandler roleChangeHandler = new DLedgerRoleChangeHandler(this, (DefaultMessageStore) messageStore); ((DLedgerCommitLog)((DefaultMessageStore) messageStore).getCommitLog()).getdLedgerServer().getdLedgerLeaderElector().addRoleChangeHandler(roleChangeHandler); } // broker 的统计组件 this.brokerStats = new BrokerStats((DefaultMessageStore) this.messageStore); //load plugin MessageStorePluginContext context = new MessageStorePluginContext(messageStoreConfig, brokerStatsManager, messageArrivingListener, brokerConfig); this.messageStore = MessageStoreFactory.build(context, this.messageStore); this.messageStore.getDispatcherList().addFirst(new CommitLogDispatcherCalcBitMap(this.brokerConfig, this.consumerFilterManager)); } catch (IOException e) { result = false; log.error(&quot;Failed to initialize&quot;, e); } } result = result &amp;&amp; this.messageStore.load(); if (result) { // 也是使用 netty 来做为通信服务器，处理producer和 consumer 的消息 this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.clientHousekeepingService); NettyServerConfig fastConfig = (NettyServerConfig) this.nettyServerConfig.clone(); fastConfig.setListenPort(nettyServerConfig.getListenPort() - 2); this.fastRemotingServer = new NettyRemotingServer(fastConfig, this.clientHousekeepingService); // 下面是一堆线程池 // 处理 producer 发送的消息线程池 this.sendMessageExecutor = new BrokerFixedThreadPoolExecutor( this.brokerConfig.getSendMessageThreadPoolNums(), this.brokerConfig.getSendMessageThreadPoolNums(), 1000 * 60, TimeUnit.MILLISECONDS, this.sendThreadPoolQueue, new ThreadFactoryImpl(&quot;SendMessageThread_&quot;)); this.putMessageFutureExecutor = new BrokerFixedThreadPoolExecutor( this.brokerConfig.getPutMessageFutureThreadPoolNums(), this.brokerConfig.getPutMessageFutureThreadPoolNums(), 1000 * 60, TimeUnit.MILLISECONDS, this.putThreadPoolQueue, new ThreadFactoryImpl(&quot;PutMessageThread_&quot;)); // 处理 consumer 拉去消息线程池 this.pullMessageExecutor = new BrokerFixedThreadPoolExecutor( this.brokerConfig.getPullMessageThreadPoolNums(), this.brokerConfig.getPullMessageThreadPoolNums(), 1000 * 60, TimeUnit.MILLISECONDS, this.pullThreadPoolQueue, new ThreadFactoryImpl(&quot;PullMessageThread_&quot;)); // 回复消息 this.replyMessageExecutor = new BrokerFixedThreadPoolExecutor( this.brokerConfig.getProcessReplyMessageThreadPoolNums(), this.brokerConfig.getProcessReplyMessageThreadPoolNums(), 1000 * 60, TimeUnit.MILLISECONDS, this.replyThreadPoolQueue, new ThreadFactoryImpl(&quot;ProcessReplyMessageThread_&quot;)); // 查询消息 this.queryMessageExecutor = new BrokerFixedThreadPoolExecutor( this.brokerConfig.getQueryMessageThreadPoolNums(), this.brokerConfig.getQueryMessageThreadPoolNums(), 1000 * 60, TimeUnit.MILLISECONDS, this.queryThreadPoolQueue, new ThreadFactoryImpl(&quot;QueryMessageThread_&quot;)); this.adminBrokerExecutor = Executors.newFixedThreadPool(this.brokerConfig.getAdminBrokerThreadPoolNums(), new ThreadFactoryImpl( &quot;AdminBrokerThread_&quot;)); this.clientManageExecutor = new ThreadPoolExecutor( this.brokerConfig.getClientManageThreadPoolNums(), this.brokerConfig.getClientManageThreadPoolNums(), 1000 * 60, TimeUnit.MILLISECONDS, this.clientManagerThreadPoolQueue, new ThreadFactoryImpl(&quot;ClientManageThread_&quot;)); // 心跳处理 this.heartbeatExecutor = new BrokerFixedThreadPoolExecutor( this.brokerConfig.getHeartbeatThreadPoolNums(), this.brokerConfig.getHeartbeatThreadPoolNums(), 1000 * 60, TimeUnit.MILLISECONDS, this.heartbeatThreadPoolQueue, new ThreadFactoryImpl(&quot;HeartbeatThread_&quot;, true)); this.endTransactionExecutor = new BrokerFixedThreadPoolExecutor( this.brokerConfig.getEndTransactionThreadPoolNums(), this.brokerConfig.getEndTransactionThreadPoolNums(), 1000 * 60, TimeUnit.MILLISECONDS, this.endTransactionThreadPoolQueue, new ThreadFactoryImpl(&quot;EndTransactionThread_&quot;)); this.consumerManageExecutor = Executors.newFixedThreadPool(this.brokerConfig.getConsumerManageThreadPoolNums(), new ThreadFactoryImpl( &quot;ConsumerManageThread_&quot;)); this.registerProcessor(); final long initialDelay = UtilAll.computeNextMorningTimeMillis() - System.currentTimeMillis(); final long period = 1000 * 60 * 60 * 24; this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { try { BrokerController.this.getBrokerStats().record(); } catch (Throwable e) { log.error(&quot;schedule record error.&quot;, e); } } }, initialDelay, period, TimeUnit.MILLISECONDS); this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { try { BrokerController.this.consumerOffsetManager.persist(); } catch (Throwable e) { log.error(&quot;schedule persist consumerOffset error.&quot;, e); } } }, 1000 * 10, this.brokerConfig.getFlushConsumerOffsetInterval(), TimeUnit.MILLISECONDS); this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { try { BrokerController.this.consumerFilterManager.persist(); } catch (Throwable e) { log.error(&quot;schedule persist consumer filter error.&quot;, e); } } }, 1000 * 10, 1000 * 10, TimeUnit.MILLISECONDS); this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { try { BrokerController.this.protectBroker(); } catch (Throwable e) { log.error(&quot;protectBroker error.&quot;, e); } } }, 3, 3, TimeUnit.MINUTES); this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { try { BrokerController.this.printWaterMark(); } catch (Throwable e) { log.error(&quot;printWaterMark error.&quot;, e); } } }, 10, 1, TimeUnit.SECONDS); this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { try { log.info(&quot;dispatch behind commit log {} bytes&quot;, BrokerController.this.getMessageStore().dispatchBehindBytes()); } catch (Throwable e) { log.error(&quot;schedule dispatchBehindBytes error.&quot;, e); } } }, 1000 * 10, 1000 * 60, TimeUnit.MILLISECONDS); if (this.brokerConfig.getNamesrvAddr() != null) { this.brokerOuterAPI.updateNameServerAddressList(this.brokerConfig.getNamesrvAddr()); log.info(&quot;Set user specified name server address: {}&quot;, this.brokerConfig.getNamesrvAddr()); } else if (this.brokerConfig.isFetchNamesrvAddrByAddressServer()) { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { try { BrokerController.this.brokerOuterAPI.fetchNameServerAddr(); } catch (Throwable e) { log.error(&quot;ScheduledTask fetchNameServerAddr exception&quot;, e); } } }, 1000 * 10, 1000 * 60 * 2, TimeUnit.MILLISECONDS); } if (!messageStoreConfig.isEnableDLegerCommitLog()) { if (BrokerRole.SLAVE == this.messageStoreConfig.getBrokerRole()) { if (this.messageStoreConfig.getHaMasterAddress() != null &amp;&amp; this.messageStoreConfig.getHaMasterAddress().length() &gt;= 6) { this.messageStore.updateHaMasterAddress(this.messageStoreConfig.getHaMasterAddress()); this.updateMasterHAServerAddrPeriodically = false; } else { this.updateMasterHAServerAddrPeriodically = true; } } else { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { try { BrokerController.this.printMasterAndSlaveDiff(); } catch (Throwable e) { log.error(&quot;schedule printMasterAndSlaveDiff error.&quot;, e); } } }, 1000 * 10, 1000 * 60, TimeUnit.MILLISECONDS); } } if (TlsSystemConfig.tlsMode != TlsMode.DISABLED) { // Register a listener to reload SslContext try { fileWatchService = new FileWatchService( new String[] { TlsSystemConfig.tlsServerCertPath, TlsSystemConfig.tlsServerKeyPath, TlsSystemConfig.tlsServerTrustCertPath }, new FileWatchService.Listener() { boolean certChanged, keyChanged = false; @Override public void onChanged(String path) { if (path.equals(TlsSystemConfig.tlsServerTrustCertPath)) { log.info(&quot;The trust certificate changed, reload the ssl context&quot;); reloadServerSslContext(); } if (path.equals(TlsSystemConfig.tlsServerCertPath)) { certChanged = true; } if (path.equals(TlsSystemConfig.tlsServerKeyPath)) { keyChanged = true; } if (certChanged &amp;&amp; keyChanged) { log.info(&quot;The certificate and private key changed, reload the ssl context&quot;); certChanged = keyChanged = false; reloadServerSslContext(); } } private void reloadServerSslContext() { ((NettyRemotingServer) remotingServer).loadSslContext(); ((NettyRemotingServer) fastRemotingServer).loadSslContext(); } }); } catch (Exception e) { log.warn(&quot;FileWatchService created error, can't load the certificate dynamically&quot;); } } initialTransaction(); initialAcl(); initialRpcHooks(); } return result; } 流程有点长，如果对 RocketMQ 有全局的认识，光凭名字就能猜出来大致的组件的作用。后续有用到的地方会再回过头介绍。 接下来继续看启动的过程： public void start() throws Exception { if (this.messageStore != null) { this.messageStore.start(); } if (this.remotingServer != null) { this.remotingServer.start(); } if (this.fastRemotingServer != null) { this.fastRemotingServer.start(); } if (this.fileWatchService != null) { this.fileWatchService.start(); } if (this.brokerOuterAPI != null) { this.brokerOuterAPI.start(); } if (this.pullRequestHoldService != null) { this.pullRequestHoldService.start(); } if (this.clientHousekeepingService != null) { this.clientHousekeepingService.start(); } if (this.filterServerManager != null) { this.filterServerManager.start(); } if (!messageStoreConfig.isEnableDLegerCommitLog()) { startProcessorByHa(messageStoreConfig.getBrokerRole()); handleSlaveSynchronize(messageStoreConfig.getBrokerRole()); this.registerBrokerAll(true, false, true); } this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { try { BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister()); } catch (Throwable e) { log.error(&quot;registerBrokerAll Exception&quot;, e); } } }, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)), TimeUnit.MILLISECONDS); if (this.brokerStatsManager != null) { this.brokerStatsManager.start(); } if (this.brokerFastFailure != null) { this.brokerFastFailure.start(); } } 2 Broker 的注册机制 Broker 的注册流程在 registerBrokerAll 的方法里面： public synchronized void registerBrokerAll(final boolean checkOrderConfig, boolean oneway, boolean forceRegister) { // topic 配置相关信息，暂时不用管它 TopicConfigSerializeWrapper topicConfigWrapper = this.getTopicConfigManager().buildTopicConfigSerializeWrapper(); if (!PermName.isWriteable(this.getBrokerConfig().getBrokerPermission()) || !PermName.isReadable(this.getBrokerConfig().getBrokerPermission())) { ConcurrentHashMap&lt;String, TopicConfig&gt; topicConfigTable = new ConcurrentHashMap&lt;String, TopicConfig&gt;(); for (TopicConfig topicConfig : topicConfigWrapper.getTopicConfigTable().values()) { TopicConfig tmp = new TopicConfig(topicConfig.getTopicName(), topicConfig.getReadQueueNums(), topicConfig.getWriteQueueNums(), this.brokerConfig.getBrokerPermission()); topicConfigTable.put(topicConfig.getTopicName(), tmp); } topicConfigWrapper.setTopicConfigTable(topicConfigTable); } if (forceRegister || needRegister(this.brokerConfig.getBrokerClusterName(), this.getBrokerAddr(), this.brokerConfig.getBrokerName(), this.brokerConfig.getBrokerId(), this.brokerConfig.getRegisterBrokerTimeoutMills())) { doRegisterBrokerAll(checkOrderConfig, oneway, topicConfigWrapper); } } 继续debug : private void doRegisterBrokerAll(boolean checkOrderConfig, boolean oneway, TopicConfigSerializeWrapper topicConfigWrapper) { // 核心就是调用 brokerOuterAPI 去向所有的NameServer注册本机的路由信息 List&lt;RegisterBrokerResult&gt; registerBrokerResultList = this.brokerOuterAPI.registerBrokerAll( this.brokerConfig.getBrokerClusterName(), this.getBrokerAddr(), this.brokerConfig.getBrokerName(), this.brokerConfig.getBrokerId(), this.getHAServerAddr(), topicConfigWrapper, this.filterServerManager.buildNewFilterServerList(), oneway, this.brokerConfig.getRegisterBrokerTimeoutMills(), this.brokerConfig.isCompressedRegister()); if (registerBrokerResultList.size() &gt; 0) { RegisterBrokerResult registerBrokerResult = registerBrokerResultList.get(0); if (registerBrokerResult != null) { if (this.updateMasterHAServerAddrPeriodically &amp;&amp; registerBrokerResult.getHaServerAddr() != null) { this.messageStore.updateHaMasterAddress(registerBrokerResult.getHaServerAddr()); } this.slaveSynchronize.setMasterAddr(registerBrokerResult.getMasterAddr()); if (checkOrderConfig) { this.getTopicConfigManager().updateOrderTopicConfig(registerBrokerResult.getKvTable()); } } } } 继续debug ： public List&lt;RegisterBrokerResult&gt; registerBrokerAll( final String clusterName, final String brokerAddr, final String brokerName, final long brokerId, final String haServerAddr, final TopicConfigSerializeWrapper topicConfigWrapper, final List&lt;String&gt; filterServerList, final boolean oneway, final int timeoutMills, final boolean compressed) { // 注册结果 final List&lt;RegisterBrokerResult&gt; registerBrokerResultList = new CopyOnWriteArrayList&lt;&gt;(); // nameserver 地址列表 List&lt;String&gt; nameServerAddressList = this.remotingClient.getNameServerAddressList(); if (nameServerAddressList != null &amp;&amp; nameServerAddressList.size() &gt; 0) { // 构建网络请求头 final RegisterBrokerRequestHeader requestHeader = new RegisterBrokerRequestHeader(); requestHeader.setBrokerAddr(brokerAddr); requestHeader.setBrokerId(brokerId); requestHeader.setBrokerName(brokerName); requestHeader.setClusterName(clusterName); requestHeader.setHaServerAddr(haServerAddr); requestHeader.setCompressed(compressed); // 构建请求体 RegisterBrokerBody requestBody = new RegisterBrokerBody(); requestBody.setTopicConfigSerializeWrapper(topicConfigWrapper); requestBody.setFilterServerList(filterServerList); final byte[] body = requestBody.encode(compressed); final int bodyCrc32 = UtilAll.crc32(body); requestHeader.setBodyCrc32(bodyCrc32); // CountDownLatch：注册到全部的 NameServer 之后才能继续执行 final CountDownLatch countDownLatch = new CountDownLatch(nameServerAddressList.size()); // 遍历 NameServer 地址列表 for (final String namesrvAddr : nameServerAddressList) { brokerOuterExecutor.execute(new Runnable() { @Override public void run() { try { // 注册 RegisterBrokerResult result = registerBroker(namesrvAddr, oneway, timeoutMills, requestHeader, body); if (result != null) { registerBrokerResultList.add(result); } log.info(&quot;register broker[{}]to name server {} OK&quot;, brokerId, namesrvAddr); } catch (Exception e) { log.warn(&quot;registerBroker Exception, {}&quot;, namesrvAddr, e); } finally { // 确保 countDownLatch 能够减少 countDownLatch.countDown(); } } }); } try { // 等所有的 countDownLatch 处理完之后 countDownLatch.await(timeoutMills, TimeUnit.MILLISECONDS); } catch (InterruptedException e) { } } return registerBrokerResultList; } debug 进入 RegisterBrokerResult result = registerBroker(namesrvAddr, oneway, timeoutMills, requestHeader, body) 这个方法。 private RegisterBrokerResult registerBroker( final String namesrvAddr, final boolean oneway, final int timeoutMills, final RegisterBrokerRequestHeader requestHeader, final byte[] body ) throws RemotingCommandException, MQBrokerException, RemotingConnectException, RemotingSendRequestException, RemotingTimeoutException, InterruptedException { // 组合请求头和请求体 RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.REGISTER_BROKER, requestHeader); request.setBody(body); // oneway 的消息发送方式 if (oneway) { try { this.remotingClient.invokeOneway(namesrvAddr, request, timeoutMills); } catch (RemotingTooMuchRequestException e) { // Ignore } return null; } // 使用nettyClient 发送请求 RemotingCommand response = this.remotingClient.invokeSync(namesrvAddr, request, timeoutMills); assert response != null; switch (response.getCode()) { case ResponseCode.SUCCESS: { RegisterBrokerResponseHeader responseHeader = (RegisterBrokerResponseHeader) response.decodeCommandCustomHeader(RegisterBrokerResponseHeader.class); RegisterBrokerResult result = new RegisterBrokerResult(); result.setMasterAddr(responseHeader.getMasterAddr()); result.setHaServerAddr(responseHeader.getHaServerAddr()); if (response.getBody() != null) { result.setKvTable(KVTable.decode(response.getBody(), KVTable.class)); } return result; } default: break; } throw new MQBrokerException(response.getCode(), response.getRemark(), requestHeader == null ? null : requestHeader.getBrokerAddr()); } 再往下debug: RemotingCommand response = this.remotingClient.invokeSync(namesrvAddr, request, timeoutMills); @Override public RemotingCommand invokeSync(String addr, final RemotingCommand request, long timeoutMillis) throws InterruptedException, RemotingConnectException, RemotingSendRequestException, RemotingTimeoutException { long beginStartTime = System.currentTimeMillis(); // Broker 和 NameServer 之间建立 channel 连接 final Channel channel = this.getAndCreateChannel(addr); // 网络连接OK if (channel != null &amp;&amp; channel.isActive()) { try { doBeforeRpcHooks(addr, request); long costTime = System.currentTimeMillis() - beginStartTime; if (timeoutMillis &lt; costTime) { throw new RemotingTimeoutException(&quot;invokeSync call the addr[&quot; + addr + &quot;] timeout&quot;); } // 发送请求 RemotingCommand response = this.invokeSyncImpl(channel, request, timeoutMillis - costTime); doAfterRpcHooks(RemotingHelper.parseChannelRemoteAddr(channel), request, response); return response; } catch (RemotingSendRequestException e) { log.warn(&quot;invokeSync: send request exception, so close the channel[{}]&quot;, addr); this.closeChannel(addr, channel); throw e; } catch (RemotingTimeoutException e) { if (nettyClientConfig.isClientCloseSocketIfTimeout()) { this.closeChannel(addr, channel); log.warn(&quot;invokeSync: close socket because of timeout, {}ms, {}&quot;, timeoutMillis, addr); } log.warn(&quot;invokeSync: wait response timeout exception, the channel[{}]&quot;, addr); throw e; } } else { this.closeChannel(addr, channel); throw new RemotingConnectException(addr); } } 看一下建立连接的部分：final Channel channel = this.getAndCreateChannel(addr); // 如果缓存池里没有的话，就新建一个连接 private Channel getAndCreateChannel(final String addr) throws RemotingConnectException, InterruptedException { if (null == addr) { return getAndCreateNameserverChannel(); } ChannelWrapper cw = this.channelTables.get(addr); if (cw != null &amp;&amp; cw.isOK()) { return cw.getChannel(); } return this.createChannel(addr); } 那 NameServer 是如何接收 Broker 的注册请求的呢？可以查看 NamesrvController.initialize()方法。 public boolean initialize() { this.kvConfigManager.load(); this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.brokerHousekeepingService); this.remotingExecutor = Executors.newFixedThreadPool(nettyServerConfig.getServerWorkerThreads(), new ThreadFactoryImpl(&quot;RemotingExecutorThread_&quot;)); // here this.registerProcessor(); // …… 省略一大堆代码 private void registerProcessor() { if (namesrvConfig.isClusterTest()) { this.remotingServer.registerDefaultProcessor(new ClusterTestRequestProcessor(this, namesrvConfig.getProductEnvName()), this.remotingExecutor); } else { // NettyServer 接收的网络请求都会交由 DefaultRequestProcessor 处理 this.remotingServer.registerDefaultProcessor(new DefaultRequestProcessor(this), this.remotingExecutor); } } 这个 DefaultRequestProcessor 直接看 switch 中的 case 就行： @Override public RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException { if (ctx != null) { log.debug(&quot;receive request, {} {} {}&quot;, request.getCode(), RemotingHelper.parseChannelRemoteAddr(ctx.channel()), request); } switch (request.getCode()) { case RequestCode.PUT_KV_CONFIG: return this.putKVConfig(ctx, request); case RequestCode.GET_KV_CONFIG: return this.getKVConfig(ctx, request); case RequestCode.DELETE_KV_CONFIG: return this.deleteKVConfig(ctx, request); case RequestCode.QUERY_DATA_VERSION: return queryBrokerTopicConfig(ctx, request); case RequestCode.REGISTER_BROKER: Version brokerVersion = MQVersion.value2Version(request.getVersion()); if (brokerVersion.ordinal() &gt;= MQVersion.Version.V3_0_11.ordinal()) { return this.registerBrokerWithFilterServer(ctx, request); } else { // 重点看这里 return this.registerBroker(ctx, request); } case RequestCode.UNREGISTER_BROKER: return this.unregisterBroker(ctx, request); case RequestCode.GET_ROUTEINFO_BY_TOPIC: return this.getRouteInfoByTopic(ctx, request); case RequestCode.GET_BROKER_CLUSTER_INFO: return this.getBrokerClusterInfo(ctx, request); case RequestCode.WIPE_WRITE_PERM_OF_BROKER: return this.wipeWritePermOfBroker(ctx, request); case RequestCode.ADD_WRITE_PERM_OF_BROKER: return this.addWritePermOfBroker(ctx, request); case RequestCode.GET_ALL_TOPIC_LIST_FROM_NAMESERVER: return getAllTopicListFromNameserver(ctx, request); case RequestCode.DELETE_TOPIC_IN_NAMESRV: return deleteTopicInNamesrv(ctx, request); case RequestCode.GET_KVLIST_BY_NAMESPACE: return this.getKVListByNamespace(ctx, request); case RequestCode.GET_TOPICS_BY_CLUSTER: return this.getTopicsByCluster(ctx, request); case RequestCode.GET_SYSTEM_TOPIC_LIST_FROM_NS: return this.getSystemTopicListFromNs(ctx, request); case RequestCode.GET_UNIT_TOPIC_LIST: return this.getUnitTopicList(ctx, request); case RequestCode.GET_HAS_UNIT_SUB_TOPIC_LIST: return this.getHasUnitSubTopicList(ctx, request); case RequestCode.GET_HAS_UNIT_SUB_UNUNIT_TOPIC_LIST: return this.getHasUnitSubUnUnitTopicList(ctx, request); case RequestCode.UPDATE_NAMESRV_CONFIG: return this.updateConfig(ctx, request); case RequestCode.GET_NAMESRV_CONFIG: return this.getConfig(ctx, request); default: break; } return null; } 重点看 registerBroker(ctx, request) 方法： public RemotingCommand registerBroker(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException { final RemotingCommand response = RemotingCommand.createResponseCommand(RegisterBrokerResponseHeader.class); final RegisterBrokerResponseHeader responseHeader = (RegisterBrokerResponseHeader) response.readCustomHeader(); final RegisterBrokerRequestHeader requestHeader = (RegisterBrokerRequestHeader) request.decodeCommandCustomHeader(RegisterBrokerRequestHeader.class); if (!checksum(ctx, request, requestHeader)) { response.setCode(ResponseCode.SYSTEM_ERROR); response.setRemark(&quot;crc32 not match&quot;); return response; } TopicConfigSerializeWrapper topicConfigWrapper; if (request.getBody() != null) { topicConfigWrapper = TopicConfigSerializeWrapper.decode(request.getBody(), TopicConfigSerializeWrapper.class); } else { topicConfigWrapper = new TopicConfigSerializeWrapper(); topicConfigWrapper.getDataVersion().setCounter(new AtomicLong(0)); topicConfigWrapper.getDataVersion().setTimestamp(0); } // 重点看这行 RegisterBrokerResult result = this.namesrvController.getRouteInfoManager().registerBroker( requestHeader.getClusterName(), requestHeader.getBrokerAddr(), requestHeader.getBrokerName(), requestHeader.getBrokerId(), requestHeader.getHaServerAddr(), topicConfigWrapper, null, ctx.channel() ); responseHeader.setHaServerAddr(result.getHaServerAddr()); responseHeader.setMasterAddr(result.getMasterAddr()); byte[] jsonValue = this.namesrvController.getKvConfigManager().getKVListByNamespace(NamesrvUtil.NAMESPACE_ORDER_TOPIC_CONFIG); response.setBody(jsonValue); response.setCode(ResponseCode.SUCCESS); response.setRemark(null); return response; } 会使用 RouteInfoManager 管理路由信息。 3 Broker 的故障检测机制 Broker 在启动的时候通过一个定时任务，30 s 更新一次注册信息： this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { try { BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister()); } catch (Throwable e) { log.error(&quot;registerBrokerAll Exception&quot;, e); } } }, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)), TimeUnit.MILLISECONDS); /** * This configurable item defines interval of topics registration of broker to name server. Allowing values are * between 10, 000 and 60, 000 milliseconds. */ private int registerNameServerPeriod = 1000 * 30; 上节文章提到的 RouteInfoManager 会管理 Broker 的注册信息： public RegisterBrokerResult registerBroker( final String clusterName, final String brokerAddr, final String brokerName, final long brokerId, final String haServerAddr, final TopicConfigSerializeWrapper topicConfigWrapper, final List&lt;String&gt; filterServerList, final Channel channel) { RegisterBrokerResult result = new RegisterBrokerResult(); try { try { // 写锁独占 this.lock.writeLock().lockInterruptibly(); // clusterName -&gt; set （broker集合），并更新 Set&lt;String&gt; brokerNames = this.clusterAddrTable.get(clusterName); if (null == brokerNames) { brokerNames = new HashSet&lt;String&gt;(); this.clusterAddrTable.put(clusterName, brokerNames); } brokerNames.add(brokerName); boolean registerFirst = false; // brokerName -&gt; BrokerData BrokerData brokerData = this.brokerAddrTable.get(brokerName); // 第一次注册时候会执行这段逻辑，将 brokerData 注册进去 if (null == brokerData) { registerFirst = true; brokerData = new BrokerData(clusterName, brokerName, new HashMap&lt;Long, String&gt;()); this.brokerAddrTable.put(brokerName, brokerData); } Map&lt;Long, String&gt; brokerAddrsMap = brokerData.getBrokerAddrs(); //Switch slave to master: first remove &lt;1, IP:PORT&gt; in namesrv, then add &lt;0, IP:PORT&gt; //The same IP:PORT must only have one record in brokerAddrTable Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerAddrsMap.entrySet().iterator(); while (it.hasNext()) { Entry&lt;Long, String&gt; item = it.next(); if (null != brokerAddr &amp;&amp; brokerAddr.equals(item.getValue()) &amp;&amp; brokerId != item.getKey()) { it.remove(); } } String oldAddr = brokerData.getBrokerAddrs().put(brokerId, brokerAddr); registerFirst = registerFirst || (null == oldAddr); if (null != topicConfigWrapper &amp;&amp; MixAll.MASTER_ID == brokerId) { if (this.isBrokerTopicConfigChanged(brokerAddr, topicConfigWrapper.getDataVersion()) || registerFirst) { ConcurrentMap&lt;String, TopicConfig&gt; tcTable = topicConfigWrapper.getTopicConfigTable(); if (tcTable != null) { for (Map.Entry&lt;String, TopicConfig&gt; entry : tcTable.entrySet()) { this.createAndUpdateQueueData(brokerName, entry.getValue()); } } } } // 将时间戳更新 BrokerLiveInfo prevBrokerLiveInfo = this.brokerLiveTable.put(brokerAddr, new BrokerLiveInfo( System.currentTimeMillis(), topicConfigWrapper.getDataVersion(), channel, haServerAddr)); if (null == prevBrokerLiveInfo) { log.info(&quot;new broker registered, {} HAServer: {}&quot;, brokerAddr, haServerAddr); } if (filterServerList != null) { if (filterServerList.isEmpty()) { this.filterServerTable.remove(brokerAddr); } else { this.filterServerTable.put(brokerAddr, filterServerList); } } if (MixAll.MASTER_ID != brokerId) { String masterAddr = brokerData.getBrokerAddrs().get(MixAll.MASTER_ID); if (masterAddr != null) { BrokerLiveInfo brokerLiveInfo = this.brokerLiveTable.get(masterAddr); if (brokerLiveInfo != null) { result.setHaServerAddr(brokerLiveInfo.getHaServerAddr()); result.setMasterAddr(masterAddr); } } } } finally { this.lock.writeLock().unlock(); } } catch (Exception e) { log.error(&quot;registerBroker Exception&quot;, e); } return result; } 对于那些心跳注册不正常的broker，NameServer 也准备了一个定时任务,10秒扫描一次： this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { NamesrvController.this.routeInfoManager.scanNotActiveBroker(); } }, 5, 10, TimeUnit.SECONDS); public void scanNotActiveBroker() { Iterator&lt;Entry&lt;String, BrokerLiveInfo&gt;&gt; it = this.brokerLiveTable.entrySet().iterator(); // 遍历 Broker 的心跳数据，如果超时，就剔除出去 while (it.hasNext()) { Entry&lt;String, BrokerLiveInfo&gt; next = it.next(); long last = next.getValue().getLastUpdateTimestamp(); if ((last + BROKER_CHANNEL_EXPIRED_TIME) &lt; System.currentTimeMillis()) { RemotingUtil.closeChannel(next.getValue().getChannel()); it.remove(); log.warn(&quot;The broker channel expired, {} {}ms&quot;, next.getKey(), BROKER_CHANNEL_EXPIRED_TIME); this.onChannelDestroy(next.getKey(), next.getValue().getChannel()); } } } ","link":"https://panson.top/post/rocketmq-broker-yuan-ma-yue-du/"},{"title":"刷题记录","content":"看了下leetcode，工作之后其实只刷了两百道左右，有一点怠惰。最近要疯狂刷题，练一下手感，记录一下各个题型的刷题记录。 多线程 lettcode 1114 按序打印 首先想到的就是使用信号量来解决： class Foo { private Semaphore firsteSmaphore; private Semaphore secondSmaphore; private Semaphore thirdSmaphore; public Foo() { firsteSmaphore = new Semaphore(1); secondSmaphore = new Semaphore(0); thirdSmaphore = new Semaphore(0); } public void first(Runnable printFirst) throws InterruptedException { firsteSmaphore.acquire(); // printFirst.run() outputs &quot;first&quot;. Do not change or remove this line. printFirst.run(); secondSmaphore.release(); } public void second(Runnable printSecond) throws InterruptedException { secondSmaphore.acquire(); // printSecond.run() outputs &quot;second&quot;. Do not change or remove this line. printSecond.run(); thirdSmaphore.release(); } public void third(Runnable printThird) throws InterruptedException { thirdSmaphore.acquire(); // printThird.run() outputs &quot;third&quot;. Do not change or remove this line. printThird.run(); } } 代码也可以优化一下： class Foo { private Semaphore semaphore12; private Semaphore semaphore23; public Foo() { semaphore12 = new Semaphore(0); semaphore23 = new Semaphore(0); } public void first(Runnable printFirst) throws InterruptedException { // printFirst.run() outputs &quot;first&quot;. Do not change or remove this line. printFirst.run(); semaphore12.release(); } public void second(Runnable printSecond) throws InterruptedException { semaphore12.acquire(); // printSecond.run() outputs &quot;second&quot;. Do not change or remove this line. printSecond.run(); semaphore23.release(); } public void third(Runnable printThird) throws InterruptedException { semaphore23.acquire(); // printThird.run() outputs &quot;third&quot;. Do not change or remove this line. printThird.run(); } } 还可以基于原子类来实现，其实本质上都是利用 AQS： class Foo { private AtomicInteger firstAtomicInteger; private AtomicInteger secondAtomicInteger; public Foo() { firstAtomicInteger = new AtomicInteger(0); secondAtomicInteger = new AtomicInteger(0); } public void first(Runnable printFirst) throws InterruptedException { // printFirst.run() outputs &quot;first&quot;. Do not change or remove this line. printFirst.run(); firstAtomicInteger.incrementAndGet(); } public void second(Runnable printSecond) throws InterruptedException { while(firstAtomicInteger.get() != 1) { // waiting } // printSecond.run() outputs &quot;second&quot;. Do not change or remove this line. printSecond.run(); secondAtomicInteger.incrementAndGet(); } public void third(Runnable printThird) throws InterruptedException { while(secondAtomicInteger.get() != 1) { // waiting } // printThird.run() outputs &quot;third&quot;. Do not change or remove this line. printThird.run(); } } 2. 1115 交替打印 FooBar // 使用 Semaphore class FooBar { private int n; private Semaphore fooSemaphore; private Semaphore barSemaphore; public FooBar(int n) { this.n = n; fooSemaphore = new Semaphore(1); barSemaphore = new Semaphore(0); } public void foo(Runnable printFoo) throws InterruptedException { for (int i = 0; i &lt; n; i++) { fooSemaphore.acquire(); // printFoo.run() outputs &quot;foo&quot;. Do not change or remove this line. printFoo.run(); barSemaphore.release(); } } public void bar(Runnable printBar) throws InterruptedException { for (int i = 0; i &lt; n; i++) { barSemaphore.acquire(); // printBar.run() outputs &quot;bar&quot;. Do not change or remove this line. printBar.run(); fooSemaphore.release(); } } } // 使用阻塞队列 class FooBar { private int n; private BlockingQueue&lt;Integer&gt; fooBlockingQueue; private BlockingQueue&lt;Integer&gt; barBlockingQueue; public FooBar(int n) { this.n = n; fooBlockingQueue = new LinkedBlockingQueue&lt;&gt;(1); barBlockingQueue = new LinkedBlockingQueue&lt;&gt;(1); } public void foo(Runnable printFoo) throws InterruptedException { for (int i = 0; i &lt; n; i++) { fooBlockingQueue.put(i); // printFoo.run() outputs &quot;foo&quot;. Do not change or remove this line. printFoo.run(); barBlockingQueue.put(i); } } public void bar(Runnable printBar) throws InterruptedException { for (int i = 0; i &lt; n; i++) { barBlockingQueue.take(); // printBar.run() outputs &quot;bar&quot;. Do not change or remove this line. printBar.run(); fooBlockingQueue.take(); } } } 滑动窗口 ","link":"https://panson.top/post/shua-ti-ji-lu/"},{"title":"疫情下如何回到1998","content":"从朋友圈和外界的社交媒体上旁观了上海疫情发展的各个阶段，看着各种魔幻的剧情在魔都上演，觉得太过不可思议，演变到后来，发现朋友每天早上六点起床抢购东西，有时候抢到一根黄瓜就赞美上帝，总有种回到几十年前的错觉。在家里的时候总是看到父母把冰箱和冰柜塞得满满当当，对于崇尚极简生活的自己来说，显然是与我的生活理念相悖的。旁观上海疫情后，有点明白父母的“屯屯鼠”心理了，想着自己也要囤一些东西，参考了网上的一些清单，自己也按照个人需求，列一下物品清单：尽量以可以长时间保存的为主，想到再补充 1 主食 米：主食 挂面：若干筒 泡面：家庭包 米线：家庭包 冷冻的包子： 若干种 冷冻饺子：若干种 2 肉类 罐头：若干盒，可以常温保存 冷冻肉： 还得再找找备选的，小龙虾尾还不错 鱼丸之类：不太喜欢，但还是备一点吧 3 牛奶和饮料 牛奶：买三个月以上 饮料：买家庭装的 麦片：家庭包 奶粉：可以冲泡喝 4 药品 退烧贴：物理降温 板蓝根之类的预防类药品 午时茶之类：调养胃的 维生素片：封城期间蔬菜肯定很少，得补充点维生素 微量元素：看看有没有和维生素的多合一的保健品 5 调料 葱姜蒜酱：最近看到的比较nice 的东西，因为生的葱姜蒜保质期不够长 小龙虾调料：口味比较喜欢辣的 油：植物油、蚝油、香油 辣酱：封城期间可能胃口变差，需要一些酱料 拌饭的小菜：橄榄菜、酸豆角、海带、酸辣大白菜，早上喝粥比较好 五香粉之类的调料 6 零食 看个人口味吧，怕主食吃完，买点备用，平时其实不太吃零食 7 生活用品 餐巾纸：家庭包，多备点 牙膏牙刷：家庭装 洗衣液：家庭装 洗发液：家庭装 沐浴露：家庭装 护肤用品：若干 酒精消毒液：一份不知道够不够 洗手液：视情况购买，估计封城也不会出门了 ","link":"https://panson.top/post/yi-qing-xia-ru-he-hui-dao-1998/"},{"title":"RocketMQ NameServer 源码阅读","content":"0 引言 最近找了许多 RocketMQ 的资料，以为会很齐全，但翻了一下市面上的资料，包括极客时间上的消息队列课程、阿里云的文档以及网上零零散散的博文，总觉得有些意犹未尽，还是觉得再翻翻源码，自己消化整理一下理解会更透彻。这种时候就觉得有些贪心，恨不得阅尽天下书。 开卷有益，那从功利主义的角度来讨论，阅读 NameServer 能够获得什么知识？我觉得主要包括以下几个方面： 了解路由中心架构设计的取舍：RocketMQ 做为 Kafka 的后继者，肯定有对前辈的借鉴。RocketMQ 的 路由中心出于轻量化的考虑，设计了 NameServer，并没有直接使用 ZooKeeper。 了解常用 JVM 参数作用：RocektMQ 对不同的JDK 版本使用了不同的垃圾收集器，在启动脚本中会做判断。 了解 NameSever 的核心配置与启动流程 1 NameServer 设计者的思考 先看看 RocektMQ 的组件架构图吧，直接参考官方 doc：https://rocketmq.apache.org/docs/rmq-arc/，原图截取下来比较糊，我就直接贴地址了。 RocektMQ 没有使用业界常用的 ZooKeeper管理路由信息，而是使用了自研的NameServer，看《RocketMQ 技术内幕》的作者们在阐述NameServer设计理念时讲道：追求最终一致，容忍分钟级的不一致， NameServer 之间不通信，极大降低 NameSever 的实现复杂度。 了解 ZooKeeper 的同学应该都知道 paxos 和 zab协议的复杂性，实现过程很复杂，而且消息广播时，网络的开销也很大，简洁的系统优雅且易维护，从这个角度上来说，NameSever 的设计无疑是正确的。 在正式开始阅读源码之前，我一般会习惯性自己捋一下思路，如果让我自己设计一个新的注册中心，我该如何设计。首先是 NameServer，作为一个路由中心，首先是在单机模式下，需要具备什么功能：路由表、与数据的生产者通信、与数据消费者通信、还有与存储服务器间的通信，其中可能又涉及到心跳机制。然后再分布式系统中，如何保证可用性呢，肯定需要集群部署，好了，分布式系统的经典问题CAP又出现了，需要像 zk 一样吗？采用什么协议呢？如果某个存储机器挂了，怎么进行路由更新？总之就是一大堆问题。还是接着看 NameSever 的实现源码吧。 2 隔靴搔痒不如直面源码 下载 RocketMQ 最新的 release 版本（目前最新的release 是 4.9.3），namesever 对应的模块： 看到代码狂喜，NameServer 的代码量好像很少呀，先跑起来看看。NameServer 的启动类是 org.apache.rocketmq.namesrv.NameServerStartup，配置好环境之后，就可以正常启动了。 Connected to the target VM, address: '127.0.0.1:60554', transport: 'socket' The Name Server boot success. serializeType=JSON 注：nameserver 启动之前需要配置一下初始环境，包括一些日志文件和默认的本机配置，因为网络上随便搜索都能找到 step-by-step 的教程，这些不是本文的侧重点，故不在此赘述。 接着启动 broker 模块下的 BrokerStartup 类，启动成功之后，控制台也会打印成功的日志： Connected to the target VM, address: '127.0.0.1:55019', transport: 'socket' The broker[broker-a, 127.0.0.1:10911] boot success. serializeType=JSON and name server is 127.0.0.1:9876 Broker 和 NameServer 启动之后，可以创建一个debug 用的 topic，我本地命名为“TopicTest”。我这里使用控制台新建了一个Topic。 修改 org.apache.rocketmq.example.quickstart.Producer 类，我们发送一条消息到 broker 里面去。 public class Producer { public static void main(String[] args) throws MQClientException, InterruptedException { /* * Instantiate with a producer group name. */ DefaultMQProducer producer = new DefaultMQProducer(&quot;please_rename_unique_group_name&quot;); /* * Specify name server addresses. * &lt;p/&gt; * * Alternatively, you may specify name server addresses via exporting environmental variable: NAMESRV_ADDR * &lt;pre&gt; * {@code * producer.setNamesrvAddr(&quot;name-server1-ip:9876;name-server2-ip:9876&quot;); * } * &lt;/pre&gt; */ /* * Launch the instance. */ producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); producer.start(); for (int i = 0; i &lt; 1; i++) { try { /* * Create a message instance, specifying topic, tag and message body. */ Message msg = new Message(&quot;TopicTest&quot; /* Topic */, &quot;TagA&quot; /* Tag */, (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); /* * Call send message to deliver message to one of brokers. */ SendResult sendResult = producer.send(msg); /* * There are different ways to send message, if you don't care about the send result,you can use this way * {@code * producer.sendOneway(msg); * } */ /* * if you want to get the send result in a synchronize way, you can use this send method * {@code * SendResult sendResult = producer.send(msg); * System.out.printf(&quot;%s%n&quot;, sendResult); * } */ /* * if you want to get the send result in a asynchronize way, you can use this send method * {@code * * producer.send(msg, new SendCallback() { * @Override * public void onSuccess(SendResult sendResult) { * // do something * } * * @Override * public void onException(Throwable e) { * // do something * } *}); * *} */ System.out.printf(&quot;%s%n&quot;, sendResult); } catch (Exception e) { e.printStackTrace(); Thread.sleep(1000); } } /* * Shut down once the producer instance is not longer in use. */ producer.shutdown(); } } 接着便会看到rocketMq 的工作目录多了许多文件： 熟悉RocketMQ 的同学一定一下就看出了相应文件的作用，可能会在下一篇与 RocketMQ 存储相关的文章里再展开详述，这里不赘述。 同理，修改 consumer: public class Consumer { public static void main(String[] args) throws InterruptedException, MQClientException { /* * Instantiate with specified consumer group name. */ DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;please_rename_unique_group_name_4&quot;); /* * Specify name server addresses. * &lt;p/&gt; * * Alternatively, you may specify name server addresses via exporting environmental variable: NAMESRV_ADDR * &lt;pre&gt; * {@code * consumer.setNamesrvAddr(&quot;name-server1-ip:9876;name-server2-ip:9876&quot;); * } * &lt;/pre&gt; */ consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); /* * Specify where to start in case the specific consumer group is a brand-new one. */ consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); /* * Subscribe one more topic to consume. */ consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;); /* * Register callback to execute on arrival of messages fetched from brokers. */ consumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) { System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } }); /* * Launch the consumer instance. */ consumer.start(); System.out.printf(&quot;Consumer Started.%n&quot;); } } 至此，我们在本地搭建好了一套消息生产、路由、存储、消费的流程。我们可以开始真正的源码 debug 流程。 3 聊聊启动脚本中的JVM 知识 NameServer 的启动会调用 distribution 模块下的 runserver.sh ，以下是脚本中的 JVM 启动参数，我们来看看每一个 JVM 参数的含义。 choose_gc_options() { # Example of JAVA_MAJOR_VERSION value : '1', '9', '10', '11', ... # '1' means releases befor Java 9 JAVA_MAJOR_VERSION=$(&quot;$JAVA&quot; -version 2&gt;&amp;1 | sed -r -n 's/.* version &quot;([0-9]*).*$/\\1/p') if [ -z &quot;$JAVA_MAJOR_VERSION&quot; ] || [ &quot;$JAVA_MAJOR_VERSION&quot; -lt &quot;9&quot; ] ; then JAVA_OPT=&quot;${JAVA_OPT} -server -Xms4g -Xmx4g -Xmn2g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot; JAVA_OPT=&quot;${JAVA_OPT} -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+CMSClassUnloadingEnabled -XX:SurvivorRatio=8 -XX:-UseParNewGC&quot; JAVA_OPT=&quot;${JAVA_OPT} -verbose:gc -Xloggc:${GC_LOG_DIR}/rmq_srv_gc_%p_%t.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps&quot; JAVA_OPT=&quot;${JAVA_OPT} -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m&quot; else JAVA_OPT=&quot;${JAVA_OPT} -server -Xms4g -Xmx4g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot; JAVA_OPT=&quot;${JAVA_OPT} -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0&quot; JAVA_OPT=&quot;${JAVA_OPT} -Xlog:gc*:file=${GC_LOG_DIR}/rmq_srv_gc_%p_%t.log:time,tags:filecount=5,filesize=30M&quot; fi } -server： 在 server 模式下启动，性能会更好一些，具体的信息可以参考：Real differences between &quot;java -server&quot; and &quot;java -client&quot;? -Xms4g -Xmx4g -Xmn2g：分别是初始堆大小、最大堆大小、年轻代大小（包括eden 和两个 survivor)，为了防止申请内存抖动，一般都会把初始堆和最大堆大小设置为等大。 -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m：分别是元空间的 FullGC 阈值、元空间占用内存的最大值，具体可以参考：JVM参数MetaspaceSize的误解 -XX:+UseConcMarkSweepGC ：老年代使用 CMS 垃圾收集器 -XX:+UseCMSCompactAtFullCollection ：CMS 是基于“标记-清除”算法的，也就意味着会出现内存碎片，导致明明老年代有足够的空间，但无法找到足够大的连续空间来分配对象，不得不提前触发一次 FullGC，开启该开关后，可以再 FullGC 前先进行一次内存碎片的合并整理。 -XX:CMSInitiatingOccupancyFraction=70 ：还是由于 CMS 浮动垃圾的存在，导致不能等老年代满了再进行垃圾回收，必须预留一部分空间放置浮动垃圾， 可以根据业务需要调整该数值。 -XX:+CMSParallelRemarkEnabled：CMS 包括初始标记、并发标记、重新标记、并发清理四个阶段，开启该参数，可以加快重新标记阶段的速度。 -XX:SoftRefLRUPolicyMSPerMB=0：代表每MB空闲内存空间可以允许SoftReference对象存活多久（对象不可达之后开始计时）。 -XX:+CMSClassUnloadingEnabled ：对永久代进行回收 -XX:SurvivorRatio=8 ：最常见的配置，设置新生代各区域比例，eden : survivor = 8 -XX:-UseParNewGC：新生代使用 ParNewGC -XX:+UseG1GC：从 shell 脚本中可以看到 JDK 9之后改为使用 G1垃圾收集器了。 -XX:G1HeapRegionSize=16m：每一个 region 设置为16MB -XX:G1ReservePercent=25：空闲空间的预留内存百分比，防止溢出 -XX:InitiatingHeapOccupancyPercent=30 可以参考关于G1收集器参数InitiatingHeapOccupancyPercent的正确认知 呼，看完了一大堆JVM 参数，我们回过头来继续阅读 NameServer 的源码。 4 NameServerController——通信的核心 服务的执行入口是在 org.apache.rocketmq.namesrv.NamesrvStartup 中 /** * NameServer 启动其实就是启动 NamesrvController * @param args * @return */ public static NamesrvController main0(String[] args) { try { // 1. 创建 NamesrvController NamesrvController controller = createNamesrvController(args); start(controller); String tip = &quot;The Name Server boot success. serializeType=&quot; + RemotingCommand.getSerializeTypeConfigInThisServer(); log.info(tip); System.out.printf(&quot;%s%n&quot;, tip); return controller; } catch (Throwable e) { e.printStackTrace(); System.exit(-1); } return null; } ``` NameServer 做为路由中心，需要接收很多网络请求，单从 `Controller` 后缀就可以推知是该类大概就是路由的核心类了。 ```java public static NamesrvController createNamesrvController(String[] args) throws IOException, JoranException { System.setProperty(RemotingCommand.REMOTING_VERSION_KEY, Integer.toString(MQVersion.CURRENT_VERSION)); //PackageConflictDetect.detectFastjson(); Options options = ServerUtil.buildCommandlineOptions(new Options()); commandLine = ServerUtil.parseCmdLine(&quot;mqnamesrv&quot;, args, buildCommandlineOptions(options), new PosixParser()); if (null == commandLine) { System.exit(-1); return null; } final NamesrvConfig namesrvConfig = new NamesrvConfig(); final NettyServerConfig nettyServerConfig = new NettyServerConfig(); nettyServerConfig.setListenPort(9876); // 读取 -c 对应的配置文件，解析到 namesrvConfig 和 nettyServerConfig 中去 if (commandLine.hasOption('c')) { String file = commandLine.getOptionValue('c'); if (file != null) { InputStream in = new BufferedInputStream(new FileInputStream(file)); properties = new Properties(); properties.load(in); MixAll.properties2Object(properties, namesrvConfig); MixAll.properties2Object(properties, nettyServerConfig); namesrvConfig.setConfigStorePath(file); System.out.printf(&quot;load config properties file OK, %s%n&quot;, file); in.close(); } } if (commandLine.hasOption('p')) { InternalLogger console = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_CONSOLE_NAME); MixAll.printObjectProperties(console, namesrvConfig); MixAll.printObjectProperties(console, nettyServerConfig); System.exit(0); } MixAll.properties2Object(ServerUtil.commandLine2Properties(commandLine), namesrvConfig); if (null == namesrvConfig.getRocketmqHome()) { System.out.printf(&quot;Please set the %s variable in your environment to match the location of the RocketMQ installation%n&quot;, MixAll.ROCKETMQ_HOME_ENV); System.exit(-2); } LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); JoranConfigurator configurator = new JoranConfigurator(); configurator.setContext(lc); lc.reset(); configurator.doConfigure(namesrvConfig.getRocketmqHome() + &quot;/conf/logback_namesrv.xml&quot;); log = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_LOGGER_NAME); MixAll.printObjectProperties(log, namesrvConfig); MixAll.printObjectProperties(log, nettyServerConfig); //重点关注: 配置完 nettyServerConfig 之后，就可以监听 9876 端口。之后 broker 和 客户端有请求过来，就可以处理了。 final NamesrvController controller = new NamesrvController(namesrvConfig, nettyServerConfig); // remember all configs to prevent discard controller.getConfiguration().registerConfig(properties); return controller; } 创建 NamesrvController 的方法涉及到许多配置的加载，我觉得读源码不要线性阅读，因为这样很容易陷入无穷无尽的细节，导致自己大脑堆栈溢出，看到后面完全忘记上下文了。我们先来关注最核心的部分： 一个 NamesrvController 由哪几个部分组成，方法出口已经我已经加了注释： final NamesrvController controller = new NamesrvController(namesrvConfig, nettyServerConfig); 一共两个核心配置，一个是 NameServerConfig，一个是 NettyServerConfig。 NameServerConfig 的配置如下： public class NamesrvConfig { private static final InternalLogger log = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_LOGGER_NAME); // ROCKET_HOME 环境变量 private String rocketmqHome = System.getProperty(MixAll.ROCKETMQ_HOME_PROPERTY, System.getenv(MixAll.ROCKETMQ_HOME_ENV)); // kv 配置的路径 private String kvConfigPath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;kvConfig.json&quot;; // NameServer 自己的配置存储路径 private String configStorePath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;namesrv.properties&quot;; // 生产环境的名称 private String productEnvName = &quot;center&quot;; // 是否启动了 clusterTest 测试集群 private boolean clusterTest = false; // 是否支持有序消息 private boolean orderMessageEnable = false; // 省略 get set …… } NettyServerConfig 的配置如下： public class NettyServerConfig implements Cloneable { // NettyServer 默认的监听端口号 8888 private int listenPort = 8888; // NettyServer 工作线程的数量，默认是8 private int serverWorkerThreads = 8; // netty 回调线程池数量 private int serverCallbackExecutorThreads = 0; // netty io 线程数量，默认为3，负责解析网络请求， 解析之后会交由work线程处理 private int serverSelectorThreads = 3; // broker 端参数，broker 端基于 netty 构建网络服务器的时候会使用以下两参数 private int serverOnewaySemaphoreValue = 256; private int serverAsyncSemaphoreValue = 64; // 如果一个网络连接空闲时间超过120s，就会被关闭 private int serverChannelMaxIdleTimeSeconds = 120; // socket send buffer 缓冲区 以及 receive buffer 缓冲区的大小 private int serverSocketSndBufSize = NettySystemConfig.socketSndbufSize; private int serverSocketRcvBufSize = NettySystemConfig.socketRcvbufSize; private int writeBufferHighWaterMark = NettySystemConfig.writeBufferHighWaterMark; private int writeBufferLowWaterMark = NettySystemConfig.writeBufferLowWaterMark; private int serverSocketBacklog = NettySystemConfig.socketBacklog; private boolean serverPooledByteBufAllocatorEnable = true; /** * make make install * * * ../glibc-2.10.1/configure \\ --prefix=/usr \\ --with-headers=/usr/include \\ * --host=x86_64-linux-gnu \\ --build=x86_64-pc-linux-gnu \\ --without-gd */ // 是否启动 epoll io 模型，默认是不开启的。 private boolean useEpollNativeSelector = false; } 配置有点多，看到这里可以大概总结一下： NettyServerConfig 和 NameServerConfig 组成了 NamesrvController，NameServer负责对外提供Broker 的注册功能。 以上就是 NameSeverController 的配置部分。我们接着往下看： start(controller); public static NamesrvController start(final NamesrvController controller) throws Exception { if (null == controller) { throw new IllegalArgumentException(&quot;NamesrvController is null&quot;); } // here : 方法里面创建了 new ServerBootstrap()，也就是 netty 的核心组件 boolean initResult = controller.initialize(); if (!initResult) { controller.shutdown(); System.exit(-3); } Runtime.getRuntime().addShutdownHook(new ShutdownHookThread(log, new Callable&lt;Void&gt;() { @Override public Void call() throws Exception { controller.shutdown(); return null; } })); controller.start(); return controller; } ``` ```java public boolean initialize() { // 前文所说的 kv 配置 this.kvConfigManager.load(); // 初始化 netty 服务器 this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.brokerHousekeepingService); // netty 服务器的工作线程 this.remotingExecutor = Executors.newFixedThreadPool(nettyServerConfig.getServerWorkerThreads(), new ThreadFactoryImpl(&quot;RemotingExecutorThread_&quot;)); // 把工作线程池给netty服务器 this.registerProcessor(); // 核心线程： 定时任务线程，定时扫描哪些broker 没发送心跳 this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { NamesrvController.this.routeInfoManager.scanNotActiveBroker(); } }, 5, 10, TimeUnit.SECONDS); // 启动一个后台线程执行定时任务，定时打印 kv 配置 this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { NamesrvController.this.kvConfigManager.printAllPeriodically(); } }, 1, 10, TimeUnit.MINUTES); if (TlsSystemConfig.tlsMode != TlsMode.DISABLED) { // Register a listener to reload SslContext try { fileWatchService = new FileWatchService( new String[] { TlsSystemConfig.tlsServerCertPath, TlsSystemConfig.tlsServerKeyPath, TlsSystemConfig.tlsServerTrustCertPath }, new FileWatchService.Listener() { boolean certChanged, keyChanged = false; @Override public void onChanged(String path) { if (path.equals(TlsSystemConfig.tlsServerTrustCertPath)) { log.info(&quot;The trust certificate changed, reload the ssl context&quot;); reloadServerSslContext(); } if (path.equals(TlsSystemConfig.tlsServerCertPath)) { certChanged = true; } if (path.equals(TlsSystemConfig.tlsServerKeyPath)) { keyChanged = true; } if (certChanged &amp;&amp; keyChanged) { log.info(&quot;The certificate and private key changed, reload the ssl context&quot;); certChanged = keyChanged = false; reloadServerSslContext(); } } private void reloadServerSslContext() { ((NettyRemotingServer) remotingServer).loadSslContext(); } }); } catch (Exception e) { log.warn(&quot;FileWatchService created error, can't load the certificate dynamically&quot;); } } return true; } ``` 看完初始化的代码之后，我们再回过头来看看： ``` ```java public static NamesrvController start(final NamesrvController controller) throws Exception { if (null == controller) { throw new IllegalArgumentException(&quot;NamesrvController is null&quot;); } // here : 方法里面创建了 new ServerBootstrap()，也就是 netty 的核心组件 boolean initResult = controller.initialize(); if (!initResult) { controller.shutdown(); System.exit(-3); } // 钩子，JVM 关闭的时候会回调该函数 Runtime.getRuntime().addShutdownHook(new ShutdownHookThread(log, new Callable&lt;Void&gt;() { @Override public Void call() throws Exception { controller.shutdown(); return null; } })); controller.start(); return controller; } 其实这是一种很常见的编程技巧，通过注册一个 JVM 钩子函数，在 JVM 关闭之前先关闭线程池，释放那个资源。 public void shutdown() { this.remotingServer.shutdown(); this.remotingExecutor.shutdown(); this.scheduledExecutorService.shutdown(); if (this.fileWatchService != null) { this.fileWatchService.shutdown(); } } 最后再看一下 NettyRemotingServer 的启动： public void start() { this.defaultEventExecutorGroup = new DefaultEventExecutorGroup( nettyServerConfig.getServerWorkerThreads(), new ThreadFactory() { private AtomicInteger threadIndex = new AtomicInteger(0); @Override public Thread newThread(Runnable r) { return new Thread(r, &quot;NettyServerCodecThread_&quot; + this.threadIndex.incrementAndGet()); } }); prepareSharableHandlers(); // netty 配置相关 ServerBootstrap childHandler = this.serverBootstrap.group(this.eventLoopGroupBoss, this.eventLoopGroupSelector) .channel(useEpoll() ? EpollServerSocketChannel.class : NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, nettyServerConfig.getServerSocketBacklog()) .option(ChannelOption.SO_REUSEADDR, true) .option(ChannelOption.SO_KEEPALIVE, false) .childOption(ChannelOption.TCP_NODELAY, true) .localAddress(new InetSocketAddress(this.nettyServerConfig.getListenPort())) // 设置了一大堆的网络连接请求处理器 // HandShakeHandler 负责连接握手， NettyDecoder是负责编解码的， // IdleStateHandler是负责网络连接管理的，serverHandler 是负责最关键的网络请求处理的。 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline() .addLast(defaultEventExecutorGroup, HANDSHAKE_HANDLER_NAME, handshakeHandler) .addLast(defaultEventExecutorGroup, encoder, new NettyDecoder(), new IdleStateHandler(0, 0, nettyServerConfig.getServerChannelMaxIdleTimeSeconds()), connectionManageHandler, serverHandler ); } }); if (nettyServerConfig.getServerSocketSndBufSize() &gt; 0) { log.info(&quot;server set SO_SNDBUF to {}&quot;, nettyServerConfig.getServerSocketSndBufSize()); childHandler.childOption(ChannelOption.SO_SNDBUF, nettyServerConfig.getServerSocketSndBufSize()); } if (nettyServerConfig.getServerSocketRcvBufSize() &gt; 0) { log.info(&quot;server set SO_RCVBUF to {}&quot;, nettyServerConfig.getServerSocketRcvBufSize()); childHandler.childOption(ChannelOption.SO_RCVBUF, nettyServerConfig.getServerSocketRcvBufSize()); } if (nettyServerConfig.getWriteBufferLowWaterMark() &gt; 0 &amp;&amp; nettyServerConfig.getWriteBufferHighWaterMark() &gt; 0) { log.info(&quot;server set netty WRITE_BUFFER_WATER_MARK to {},{}&quot;, nettyServerConfig.getWriteBufferLowWaterMark(), nettyServerConfig.getWriteBufferHighWaterMark()); childHandler.childOption(ChannelOption.WRITE_BUFFER_WATER_MARK, new WriteBufferWaterMark( nettyServerConfig.getWriteBufferLowWaterMark(), nettyServerConfig.getWriteBufferHighWaterMark())); } if (nettyServerConfig.isServerPooledByteBufAllocatorEnable()) { childHandler.childOption(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT); } try { // 设置netty 要监听的端口，默认是9876 ChannelFuture sync = this.serverBootstrap.bind().sync(); InetSocketAddress addr = (InetSocketAddress) sync.channel().localAddress(); this.port = addr.getPort(); } catch (InterruptedException e1) { throw new RuntimeException(&quot;this.serverBootstrap.bind().sync() InterruptedException&quot;, e1); } if (this.channelEventListener != null) { this.nettyEventExecutor.start(); } this.timer.scheduleAtFixedRate(new TimerTask() { @Override public void run() { try { NettyRemotingServer.this.scanResponseTable(); } catch (Throwable e) { log.error(&quot;scanResponseTable exception&quot;, e); } } }, 1000 * 3, 1000); } ","link":"https://panson.top/post/rocketmq-nameserver-yuan-ma-yue-du/"},{"title":"Eureka 源码阅读","content":"1 从 Netfix 聊起 程序员男生居多，应该很多人爱看美剧，应该都或多或少听过Netfix 。Netfix 在美国或者全球来说都算是最优秀的视频点播公司，在对外提供视频播放的海量业务中，自然也催生了内部极为优秀的技术。这次要分享的 Eureka 也是他们的社区贡献的。 对于 Java 生态来说，目前国内主流的微服务框架都是 Dubbo 或者 SpringCloud，前些年Spring CLoud Netfix 应该蛮多，不过随着 Spring CLoud Netfix 系列组件逐渐停止迭代和维护，技术选型上已经不会倾向于使用 Spring Cloud Netfix 了。 新起之秀 Spring CLoud Alibaba 也许会成为未来的趋势，但有很多人会忧虑 Dubbo 当年停更的事件是否会重现。 谈起 Eureka，也许有些同学会混淆Netflix Eureka 与 Spring-Cloud-Netflix-Eureka：简单来说，可以认为 Spring-Cloud-Netflix-Eureka 在 Netfix 上又封装了一层。 2 源码结构 首先从 GitHub 上 clone 下 代码，采用的是 Gradle，核心大概分为以下几个部分： eureka-client：eureka的客户端，注册到eureka上面去的一个服务，就是一个eureka client者，都是一个eureka客户端。 eureka-core：eureka的服务端，其实就是eureka的注册中心 eureka-resources：基于jsp开发的eureka控制台，在这个web页面上你可以看到各种注册服务 eureka-server：把eureka-client、eureka-core、eureka-resources打包成了一个war包，也就是说eureka-server自己本身也是一个eureka-client，同时也是注册中心，同时也提供eureka控制台。 eureka-examples：eureka使用的例子 eureka-test-utils：eureka的单元测试工具类 eureka-client-jersey2 和 eureka-core-jersey2： eureka为了方便自己，对 jersey 框架进行了一个封装，提供更多的功能，方便自己使用。eureka client 和 eureka server之间的通信，都是基于jersey 框架实现的（使用 http restful 接口）。 3 Eureka 原理 3.1 工作流程 eureka server启动以及初始化 eureka client启动以及初始化 eureka client向eureka server进行服务实例的注册，eureka控制台可以看到注册的服务 eureka client 全量抓取注册表，后续30s一次增量拉取。 eureka server 接收请求，使用多级缓存，返回注册表信息 eureka client 与 eureka server 基于心跳机制实现续约 eureka client关闭，服务停止，需要调用自身的shutdown() 方法，将服务实例停止 3.2 服务启动流程 核心是基于读取到的环境配置、本地配置构建一个 PeerAwareInstanceRegistry（应用实例信息的注册表，这里面封装了注册相关的信息），最终构造出一个上下文(EurekaServerContext)，通过这个 EurekaServerContext，可以读取server 配置、 应用实例信息的注册表以及Eureka-Server 集群节点集合等信息。 3.3 注册流程 核心也是通过 http 请求发送自身的注册信息， server 保存发送过来的信息到本地内存中。 3.4 拉取注册表 分为启动时全量拉取和启动之后定时增量拉取。 3.5 多级缓存机制 3.6 缓存过期机制 被动过期 主动过期 定时过期 3.7 eureka server 的自我保护机制 4 整体架构设计 5 一些可能值得说道的设计思想 配置管理器中的单例模式以及面向接口的配置读取方式 减少网络传输：基于hash 值校验增量拉取注册表 网络的不稳定性：自我保护机制 6 写在最后 回过头来，其实在 2021 年的今天，再来聊 Eureka，有点谈论历史的感觉，因为早在两年前， Eureka 2.X 就已经“流产”了，有社区本身的原因，但也从另一个方面说明 Eureka 没有持续的生命力。 现在已经很难想象七八年前 Martin fowler 提出 “微服务”这个概念时引起的震动，互联网的技术更新确实太快了，新名词层出不穷，Eureka 已经成为明日黄花，下一个该轮到谁。 这也让技术者思考：什么才是我们的核心生命力？ ","link":"https://panson.top/post/eureka-yuan-ma-yue-du/"},{"title":"Apache curator ZooKeeper 分布式锁源码阅读","content":"工作中 redis 分布式锁和 zk 分布式锁都用，这篇文章想深入了解一下 zk 分布式锁的使用以及底层源码，目前业界主流的客户端是 curator，本文也准备以 curator 做为客户端。我选用的是最新的4.3.0版本，可能不同版本有些许不同。 Curator 的官网提供了示例：https://curator.apache.org/getting-started.html InterProcessMutex lock = new InterProcessMutex(client, lockPath); if (lock.acquire(maxWait, waitUnit)) { try { // do some work inside of the critical section here } finally { lock.release(); } } 1 先看看官方示例 1.1 加锁 加锁重点关注加锁成功的流程、加锁失败的流程、重复加锁的流程。 先来看看第一次加锁的流程 Curator 是如何封装的： private boolean internalLock(long time, TimeUnit unit) throws Exception { /* Note on concurrency: a given lockData instance can be only acted on by a single thread so locking isn't necessary */ Thread currentThread = Thread.currentThread(); LockData lockData = threadData.get(currentThread); if ( lockData != null ) { // re-entering lockData.lockCount.incrementAndGet(); return true; } String lockPath = internals.attemptLock(time, unit, getLockNodeBytes()); if ( lockPath != null ) { LockData newLockData = new LockData(currentThread, lockPath); threadData.put(currentThread, newLockData); return true; } return false; } 可以清晰地知道先做了可重入锁的支持，利用 ConcurrentHashMap 保存了每次获取锁的信息（线程和lockPath）。 再往下 debug： @Override public String createsTheLock(CuratorFramework client, String path, byte[] lockNodeBytes) throws Exception { String ourPath; if ( lockNodeBytes != null ) { ourPath = client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path, lockNodeBytes); } else { ourPath = client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path); } return ourPath; } 可以看到创建路径的时候，其实是创建了一个临时顺序节点。在创建完路径之后，就是判断是否能获取锁的逻辑了。 ourPath = driver.createsTheLock(client, path, localLockNodeBytes); hasTheLock = internalLockLoop(startMillis, millisToWait, ourPath); debug 进入 internalLockLoop：只截取了部分关键代码 while ( (client.getState() == CuratorFrameworkState.STARTED) &amp;&amp; !haveTheLock ) { List&lt;String&gt; children = getSortedChildren(); String sequenceNodeName = ourPath.substring(basePath.length() + 1); // +1 to include the slash PredicateResults predicateResults = driver.getsTheLock(client, children, sequenceNodeName, maxLeases); if ( predicateResults.getsTheLock() ) { haveTheLock = true; } else { ... } } 又调用了 getsTheLock 方法： public PredicateResults getsTheLock(CuratorFramework client, List&lt;String&gt; children, String sequenceNodeName, int maxLeases) throws Exception { int ourIndex = children.indexOf(sequenceNodeName); validateOurIndex(sequenceNodeName, ourIndex); boolean getsTheLock = ourIndex &lt; maxLeases; String pathToWatch = getsTheLock ? null : children.get(ourIndex - maxLeases); return new PredicateResults(pathToWatch, getsTheLock); } 流程就是先判断当前节点是否是正序第一个节点以及获取当前节点的上一节点，方便监听。 如果是已经加锁了，此时第二个客户端来获取锁，由于创建的是临时顺序节点，因为不是正序第一个节点，那么就会加锁失败，加锁失败之后，还有一些逻辑： synchronized(this) { try { // use getData() instead of exists() to avoid leaving unneeded watchers which is a type of resource leak client.getData().usingWatcher(watcher).forPath(previousSequencePath); if ( millisToWait != null ) { millisToWait -= (System.currentTimeMillis() - startMillis); startMillis = System.currentTimeMillis(); if ( millisToWait &lt;= 0 ) { doDelete = true; // timed out - delete our node break; } wait(millisToWait); } else { wait(); } } catch ( KeeperException.NoNodeException e ) { // it has been deleted (i.e. lock released). Try to acquire again } } 可以看到加锁失败之后，对上一节点加了一个 watcher 监听器，监听它是否还存在，同时 zk 分布式锁是支持时效时间的，否则线程会一直 wait。 1.2 释放锁 释放锁的流程相对比较简单，主要是删除当前节点以及对应的线程加锁信息。 public void release() throws Exception { /* Note on concurrency: a given lockData instance can be only acted on by a single thread so locking isn't necessary */ Thread currentThread = Thread.currentThread(); LockData lockData = threadData.get(currentThread); if ( lockData == null ) { throw new IllegalMonitorStateException(&quot;You do not own the lock: &quot; + basePath); } int newLockCount = lockData.lockCount.decrementAndGet(); if ( newLockCount &gt; 0 ) { return; } if ( newLockCount &lt; 0 ) { throw new IllegalMonitorStateException(&quot;Lock count has gone negative for lock: &quot; + basePath); } try { internals.releaseLock(lockData.lockPath); } finally { threadData.remove(currentThread); } } 额外需要注意的一个流程就是当前线程释放锁之后，其他线程是如何获取锁的？ 其实当前线程释放锁的时候会利用 watcher，这样下一个节点对应的线程就可以再次去请求获取锁，由此我们也可以知道默认情况下是公平锁。 2 Semaphore 首先抛一个问题，Curator 是如何实现 Semaphore 的呢？普通的锁只能支持一个线程获取到锁。还是按照官方示例代码，一步步debug 吧。 代码参考：https://curator.apache.org/curator-recipes/shared-semaphore.html public InterProcessSemaphoreV2(CuratorFramework client, String path, int numberOfLeases) Parameters: client - client path - the path to lock numberOfLeases - the number of leases allowed by this semaphore InterProcessSemaphoreV2 semaphoreV2 = new InterProcessSemaphoreV2(client, lockPath, 3); Lease lease = semaphoreV2.acquire(); Thread.sleep(1000); semaphoreV2.returnLease(lease); debug 发现在 new InterProcessSemaphoreV2(client, lockPath, 3)底层其实是新创建了一个path 以 &quot;/locks&quot;结尾的锁lock = new InterProcessMutex(client, ZKPaths.makePath(path, LOCK_PARENT));， 另外还创建了一个以 “/leases&quot; 结尾的path。 private InterProcessSemaphoreV2(CuratorFramework client, String path, int maxLeases, SharedCountReader count) { this.client = client.newWatcherRemoveCuratorFramework(); path = PathUtils.validatePath(path); lock = new InterProcessMutex(client, ZKPaths.makePath(path, LOCK_PARENT)); this.maxLeases = (count != null) ? count.getCount() : maxLeases; leasesPath = ZKPaths.makePath(path, LEASE_PARENT); if ( count != null ) { count.addListener ( new SharedCountListener() { @Override public void countHasChanged(SharedCountReader sharedCount, int newCount) throws Exception { InterProcessSemaphoreV2.this.maxLeases = newCount; client.postSafeNotify(InterProcessSemaphoreV2.this); } @Override public void stateChanged(CuratorFramework client, ConnectionState newState) { // no need to handle this here - clients should set their own connection state listener } } ); } } 在获取锁的时候，我们还可以进一步可看到核心的逻辑如下： PathAndBytesable&lt;String&gt; createBuilder = client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL); String path = (nodeData != null) ? createBuilder.forPath(ZKPaths.makePath(leasesPath, LEASE_BASE_NAME), nodeData) : createBuilder.forPath(ZKPaths.makePath(leasesPath, LEASE_BASE_NAME)); String nodeName = ZKPaths.getNodeFromPath(path); lease = makeLease(path); 每一次获取锁的时候，都会去 lease path 下创建新的节点。 看到这里，Semaphore 的底层实现就比较明了了，可以参考下图： 3 非可重入锁 非可重入锁的实现其实是利用了 Semaphore，就是在构造 InterProcessSemaphoreV2时， numberOfLeases 设置为1。 public InterProcessSemaphoreV2(CuratorFramework client, String path, int numberOfLeases) Parameters: client - client path - the path to lock numberOfLeases - the number of leases allowed by this semaphore 4 读锁与写锁 4.1 读锁 + 读锁 读写锁的基本使用示例: https://curator.apache.org/curator-recipes/shared-reentrant-read-write-lock.html public InterProcessReadWriteLock(CuratorFramework client, String basePath) Parameters: client - the client basePath - path to use for locking 写一个简单demo, debug 一下： InterProcessReadWriteLock lock = new InterProcessReadWriteLock(client, lockPath); lock.readLock().acquire(); Thread.sleep(1000); lock.readLock().release(); lock.writeLock().acquire(); lock.writeLock().release(); 创建读锁的时候，底层会创建一个包含 READ 路径的节点，基本流程与创建普通锁的流程一致。 private final InterProcessMutex readMutex; ... readMutex = new InternalInterProcessMutex ( client, basePath, READ_LOCK_NAME, lockData, Integer.MAX_VALUE, new SortingLockInternalsDriver() { @Override public PredicateResults getsTheLock(CuratorFramework client, List&lt;String&gt; children, String sequenceNodeName, int maxLeases) throws Exception { return readLockPredicate(children, sequenceNodeName); } } ); private PredicateResults readLockPredicate(List&lt;String&gt; children, String sequenceNodeName) throws Exception { if ( writeMutex.isOwnedByCurrentThread() ) { return new PredicateResults(null, true); } int index = 0; int firstWriteIndex = Integer.MAX_VALUE; int ourIndex = -1; for ( String node : children ) { if ( node.contains(WRITE_LOCK_NAME) ) { firstWriteIndex = Math.min(index, firstWriteIndex); } else if ( node.startsWith(sequenceNodeName) ) { ourIndex = index; break; } ++index; } StandardLockInternalsDriver.validateOurIndex(sequenceNodeName, ourIndex); // firstWriteIndex： Interger max 值 boolean getsTheLock = (ourIndex &lt; firstWriteIndex); String pathToWatch = getsTheLock ? null : children.get(firstWriteIndex); return new PredicateResults(pathToWatch, getsTheLock); } 加读锁的处理逻辑比较简单，只是创建一个节点，判断当前节点的索引位置小于 Integer 最大值即可。 由此我们也可以知道不管是不是同一个线程，获取读锁都是不互斥的。 4.2 读锁 + 写锁 InterProcessReadWriteLock lock = new InterProcessReadWriteLock(client, lockPath); lock.readLock().acquire(); lock.writeLock().acquire(); debug 一下先加读锁再加写锁： writeMutex = new InternalInterProcessMutex ( client, basePath, WRITE_LOCK_NAME, lockData, 1, new SortingLockInternalsDriver() { @Override public PredicateResults getsTheLock(CuratorFramework client, List&lt;String&gt; children, String sequenceNodeName, int maxLeases) throws Exception { return super.getsTheLock(client, children, sequenceNodeName, maxLeases); } } ); @Override public PredicateResults getsTheLock(CuratorFramework client, List&lt;String&gt; children, String sequenceNodeName, int maxLeases) throws Exception { int ourIndex = children.indexOf(sequenceNodeName); validateOurIndex(sequenceNodeName, ourIndex); boolean getsTheLock = ourIndex &lt; maxLeases; String pathToWatch = getsTheLock ? null : children.get(ourIndex - maxLeases); return new PredicateResults(pathToWatch, getsTheLock); } 可以看到如果想要获取到写锁，那么写锁对应节点的index 必须小于 maxLeases，但在debug 时，发现 maxleases = 1，明显是不符合条件的，所以加完读锁再加写锁是不可行的。 4.3 写锁 + 读锁 代码debug 流程基本一致，这里不再赘述，直接说结论：同一线程，写锁+读锁可行，不同线程写锁+读锁不可行。 4.4 写锁 + 写锁 不管是不是同一线程，都不行。 ","link":"https://panson.top/post/liao-liao-zookeeper-fen-bu-shi-suo/"},{"title":"聊聊 Dubbo 与微服务","content":"这是一篇旧文，部分写在2018年，我从百度云的一个文件夹中翻了出来，附图和说明重新整理了一下。文中大多数图都是使用 draw.io 画的。 1 引言 其实早在 2014 年的 3 月 25 日，在 ThoughtWorks 工作的 Martin Fowler 和 James Lewis 就共 同提出了“Microservices”，也就是中文里说的“微服务”。 Google Trends 记录了“Microservices”这一词从 2014 年到 2020 年末在 Google 网页搜索的热度趋势，如下所示： 其实可以看到，微服务的热度已经在经历过一八年的极点之后慢慢降低，但无论如何，微服务依旧有很大的热度。另一方面，近几年阿里动作频繁，先是将 Dubbo 捐赠给 Apache， 并在之后推出了 SpringCloud Alibaba，可见阿里并没有放弃开源的影响力，Dubbo 依旧是一个非常值得研究的 RPC 框架。 2 Dubbo 工作原理 2.1 Dubbo 分层 2.2 Dubbo 运行流程 大体上分为 4 个步骤： provider 注册到注册中心 consumer 从注册中心订阅服务，注册中心会通知 consumer 注册好的服务 consumer 调用 provider consumer 和 provider 都异步通知监控中心 2.3 Dubbo 调用流程 2.4 Dubbo 注册到 ZooKeeper 时存储的信息 上面这张图来自 Dubbo 官方doc：Zookeeper 注册中心参考手册 在图中，我们可以看到 Zookeeper 的节点层级，自上而下是： Root 层：根目录，可通过 &lt;dubbo:registry group=&quot;dubbo&quot; /&gt; 的 &quot;group&quot; 设置 Zookeeper 的根节点，缺省使用 &quot;dubbo&quot; 。 Service 层：服务接口全名。 Type 层：分类。目前除了我们在图中看到的 &quot;providers&quot;( 服务提供者列表 ) &quot;consumers&quot;( 服务消费者列表 ) 外，还有 &quot;routes&quot;( 路由规则列表 ) 和 &quot;configurations&quot;( 配置规则列表 )。 URL 层：URL ，根据不同 Type 目录，下面可以是服务提供者 URL 、服务消费者 URL 、路由规则 URL 、配置规则 URL 。实际上 URL 上带有 &quot;category&quot; 参数，已经能判断每个 URL 的分类，但是 Zookeeper 是基于节点目录订阅的，所以增加了 Type 层。 实际上，服务消费者启动后，不仅仅订阅了 &quot;providers&quot; 分类，也订阅了 &quot;routes&quot;、&quot;configurations&quot; 分类。 流程说明： 服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址 服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址 监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址。 2.5 Dubbo 的动态代理策略 如果有 dubbo 使用经验的读者，可能会立马就想起来，服务消费者引入的 jar 包中只有一个 interface，实现逻辑都封装在消费者端，这中间的过程就有动态代理的参与。 目前实现动态代理的工具类主要包括以下 4 种： Javaassist JDK 原生自带 CGLIB ASM ","link":"https://panson.top/post/chang-wen-liao-liao-dubbo-yu-wei-fu-wu/"},{"title":"详解 GC 日志：YoungGC","content":"本文主要介绍了 JVM 的常用参数，并详细分析了YoungGC 日志. 在线上运行着的 Java 开发的系统，YoungGC 是一个循环出现的过程，我们如何在开发过程中分析 YoungGC 呢？ 要想分析 YoungGC，我们首先得让 YoungGC 留下“足迹”—— GC 日志。 我们可以手动创建一个简单的 demo，核心代码如下： public static void main(String[] args) { byte[] array1 = new byte[1024 * 1024]; array1 = new byte[1024 * 1024]; array1 = new byte[1024 * 1024]; array1 = null; byte[] array2 = new byte[2 * 1024 * 1024]; } 我们可以使用以下 jvm 参数： -XX:NewSize=5242880 -XX:MaxNewSize=5242880 -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:SurvivorRatio=8 -XX:PretenureSizeThreshold=10485760 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XXloggc:gc.log 参数解释： -XX:NewSize=5242880：初始新生代大小 5 MB -XX:MaxNewSize=5242880：最大新生代大小 5 MB -XX:InitialHeapSize=10485760：初始堆大小 10 MB -XX:MaxHeapSize=10485760：最大堆大小 10 MB -XX:SurvivorRatio=8：新生代中 Eden 区与一个 Survivor 区的大小之比为 8。 -XX:PretenureSizeThreshold=10485760：大对象阈值为 10 MB，超过此阈值，会尝试放入老年代 -XX:+UseParNewGC：新生代使用 ParNew 垃圾收集器 -XX:+UseConcMarkSweepGC：老年代使用 CMS 垃圾收集器 -XX:+PrintGCDetail：打印详细的GC 日志 -XX:+PrintGCTimeStamps：打印每次GC 发生的时间 将 GC 日志写入磁盘文件 结合以上代码片段和 JVM 参数，我们可以分析知道，在执行 byte[] array2 = new byte[2 * 1024 * 1024]; 时，此时新生代的 Eden 区本身只剩下 4 - 3 = 1MB 的大小，会进行一次垃圾回收。 运行程序，你就会看到在在新生成的文件中保存了 gc 日志： Memory: 4k page, physical 16777216k(418648k free) /proc/meminfo: CommandLine flags: -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:MaxNewSize=5242880 -XX:NewSize=5242880 -XX:OldPLABSize=16 -XX:PretenureSizeThreshold=10485760 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseParNewGC 0.145: [GC (Allocation Failure) 0.146: [ParNew: 3874K-&gt;502K(4608K), 0.0014940 secs] 3874K-&gt;1528K(9728K), 0.0016631 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] Heap par new generation total 4608K, used 3735K [0x00000007bf600000, 0x00000007bfb00000, 0x00000007bfb00000) eden space 4096K, 78% used [0x00000007bf600000, 0x00000007bf928690, 0x00000007bfa00000) from space 512K, 98% used [0x00000007bfa80000, 0x00000007bfafd818, 0x00000007bfb00000) to space 512K, 0% used [0x00000007bfa00000, 0x00000007bfa00000, 0x00000007bfa80000) concurrent mark-sweep generation total 5120K, used 1026K [0x00000007bfb00000, 0x00000007c0000000, 0x00000007c0000000) Metaspace used 3040K, capacity 4496K, committed 4864K, reserved 1056768K class space used 335K, capacity 388K, committed 512K, reserved 1048576K 但是日志信息明显有些混乱，但我们可以将这段 GC 日志分为 3 个部分。 第 1 个部分是： CommandLine flags: -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:MaxNewSize=5242880 -XX:NewSize=5242880 -XX:OldPLABSize=16 -XX:PretenureSizeThreshold=10485760 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseParNewGC 第 2 个部分是： 0.145: [GC (Allocation Failure) 0.146: [ParNew: 3874K-&gt;502K(4608K), 0.0014940 secs] 3874K-&gt;1528K(9728K), 0.0016631 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 第 3 个部分是： Heap par new generation total 4608K, used 3735K [0x00000007bf600000, 0x00000007bfb00000, 0x00000007bfb00000) eden space 4096K, 78% used [0x00000007bf600000, 0x00000007bf928690, 0x00000007bfa00000) from space 512K, 98% used [0x00000007bfa80000, 0x00000007bfafd818, 0x00000007bfb00000) to space 512K, 0% used [0x00000007bfa00000, 0x00000007bfa00000, 0x00000007bfa80000) concurrent mark-sweep generation total 5120K, used 1026K [0x00000007bfb00000, 0x00000007c0000000, 0x00000007c0000000) Metaspace used 3040K, capacity 4496K, committed 4864K, reserved 1056768K class space used 335K, capacity 388K, committed 512K, reserved 1048576K ","link":"https://panson.top/post/jvm-shi-zhan-youggc/"},{"title":"MySQL 存储原理串连","content":"本文是一篇比较散的总结，通过一系列的概念，将 MySQL 核心原理梳理出来，看文章的时候，我可以在脑海里面过一遍，速览并复习。 1、数据库连接池、SQL 接口、SQL 解析器、查询优化器、执行器、存储引擎 2、Buffer Pool、undo 日志文件、Redo Log Buffer、redo 日志文件、binlog redo log 在存储引擎层，记录的是一种偏向物理性质的重做日志，类似于“对哪个数据页中的什么记录，做了个什么修改” binlog 叫做归档日志，在 server 层，记录的是一种偏向于逻辑性的日志，类似于“对 user 表中的 id=10的一行数据做了更新操作，更新以后的值是什么” 小结：在一次数据更新流程中，InnoDB 存储引擎主要包含了一些 buffer pool、redo log buffer 等内存里的缓存数据，同时还包含了 undo 日志文件、redo 日志文件等，同时 mysql server 还有 binlog 日志文件。 每次执行更新的时候，每条 SQL 语句，都会对应修改 buffer pool 里的缓存数据、写 undo 日志、写 redo log buffer 几个步骤。 但是当你提交事务的时候，一定会把 redo log 刷入磁盘，binlog 刷入磁盘，完成 redo log中的事务 commit 标记，最后后台的 IO 线程会随机把 buffer pool 里的脏数据刷入磁盘里去。 3、Buffer Pool 默认大小（128 MB）、Buffer Pool 描述数据、free 链表、flush 链表、LRU 链表（MySQL 对冷热数据的存储优化） 4、使用多个Buffer Pool 优化数据库的并发性能、chunk 机制 5、MySQL 一行数据在磁盘上是如何存储的、行溢出 格式：变长字段的长度列表、null 值列表、数据头、隐藏字段、column01 的值、column02 的值、column03 的值 说明： 变长字段的长度列表：以十六进制逆序存放，实例 0x09 null 值列表以二进制存放，以1表示非NULL，0表示NULL，逆序存储 数据头：40 个 bit 位 第 1 位和第 2 位：都是预留位，没有含义； 第 3 位：delete_mask，他标识的是这行数据是否被删除了； 第 4 位：min_rec_mask，B+ 树的非叶子节点里的最小值都有这个标记； 5 到 8 共 4 位：n_owned，记录数 9 到 21 位：heap_no，当前这行数据在记录堆里的位置 22 到 24 位：record_type，这行数据的类型，0 代表的事普通类型，1 代表的是 B+ 树的非叶子节点，2 代表的是最小值数据，3 代表的是最大值数据。 25 到 40 位：next_record，这个是指向他下一条数据的指针 列值：编码之后再存储 隐藏字段： DB_ROW_ID 字段：行的唯一标识，数据库内部给定，不是主键。如果我们没有指定主键和唯一索引的时候，他就内部自动加一个 ROW_ID 做为主键。 DB_TRX_ID 字段：这是跟事务相关的事务ID DB_ROLL_PTR 字段：回滚指针，用来进行事务回滚。 行数据物理存储示例： 0x09 0x04 00000101 0000000000000000000010000000000000011001 000000000094(DB_ROW_ID) 000000000032D(DB_TRX_ID) EA000010078E(DB_ROL_PTR) 616161 636320 6262626262 6、MySQL的存储模型：表空间有很多组数据区(extend)，一组数据区是256个数据区，每个数据区占 1 Mb，包含了 64 个数据页，每个数据页 16 Kb；数据页的各个部分 表空间的第一组数据区的第一个数据区的前 3 个数据页，都是存放特殊信息的； 表空间的其他组数据区的第一个数据区的前两个数据页，也是存放特殊信息的； 7、数据库日志的顺序读写和数据文件的随机读写 8、Linux 存储系统层级： IO 调度层默认使用 CFQ 公平调度算法，使用该算法事会导致饥饿，生产环境中，建议改为deadline IO，该算法的核心思想是：任何 IO 操作都不能一直不停地等待，在指定的时间范围内，都必须让他去执行。 最后 IO 完成调度之后，就会决定哪个IO 请求先执行，哪个 IO 请求后执行，此时可以执行的 IO 请求就会交给 Block 设备驱动层。 Block 设备驱动层把 IO 请求发送给真正的存储硬件，也就是 Block 设备层。 Block 设备层完成了 IO 读写操作之后，进行读写操作，最后把响应经过上面的层级反向依次返回， MySQL 就可以得到本次 IO 读写操作的结果。 9、Too many connections 故障 与 Linux 文件句柄数量有关，需要调大一点。 ulimit -HSn 65535 然后就可以用如下命令检查最大文件句柄数是否被修改了 cat /etc/security/limits.conf cat /etc/rc.local 我们平时可以用ulimit命令来设置每个进程被限制使用的资源量，用ulimit -a就可以看到进程被限制使用的各种资源的量。 core file size 代表的进程崩溃时候的转储文件的大小限制 max locked memory就是最大锁定内存大小 open files就是最大可以打开的文件句柄数量 max user processes就是最多可以拥有的子进程数量。 设置之后，我们要确保变更落地到/etc/security/limits.conf文件里，永久性的设置进程的资源限制 10、redo log 底层存储格式 redo log 本质上记录的就是在对某个表空间的某个数据页的某个偏移量的地方修改了几个字节的值，具体修改的值是什么，他里面需要记录的就是表空间号+数据页号+偏移量+修改几个字节的值+具体的值. 根据你修改了数据页里的几个字节的值，redo log就划分为了不同的类型，MLOG_1BYTE类型的日志指的就是修改了1个字节的值，MLOG_2BYTE类型的日志指的就是修改了2个字节的值，以此类推，还有修改了4个字节的值的日志类型，修改了8个字节的值的日志类型。当然，如果你要是一下子修改了一大串的值，类型就是MLOG_WRITE_STRING，就是代表你一下子在那个数据页的某个偏移量的位置插入或者修改了一大串的值。 所以其实一条redo log看起来大致的结构如下所示： 日志类型（就是类似MLOG_1BYTE之类的），表空间ID，数据页号，数据页中的偏移量，具体修改的数据 如果是MLOG_WRITE_STRING类型的日志，因为不知道具体修改了多少字节的数据，所以其实会多一个修改数据长度，就告诉你他这次修改了多少字节的数据，如下所示它的格式： 日志类型（就是类似MLOG_1BYTE之类的），表空间ID，数据页号，数据页中的偏移量，修改数据长度，具体修改的数据 11、redo log block 数据结构、redo log buffer 中的缓冲日志何时写入磁盘 ","link":"https://panson.top/post/mysql-he-xin-gai-nian-chuan-lian/"},{"title":"一文以知 ZooKeeper 核心原理","content":"ZooKeeper 应该是一个比较常见的开源工具，加上与分布式系统渊源很深，我们其实可以“望文生义”，大致猜测一下 ZooKeeper 的作用，因为 ZooKeeper 的英文直译是“动物园管理员”，动物园里的动物就像分布式系统里的各个子系统一样，混乱且难以管理，所以 ZooKeeper 大概就是拿来管理分布式系统的，让其可控可用。 事实上，我们的猜测是正确的，ZooKeeper 的主要作用就是拿来做分布式系统管理的。具体的作用主要包括： 分布式协调（系统间信息异步通信） 分布式锁（zk 分布式锁） 元数据/配置信息管理（注册中心） 高可用（主从选举） ZooKeeper 能实现这么多的功能自然离不开底层数据结构的支持。ZooKeeper 是一个树形结构，每一个节点（znode）拥有唯一的路径 path，客户端基于 path 上传节点数据，ZooKeeper 收到后会实时通知对该路径进行监听的客户端。 znode 有 4 种类型，持久节点、持久序号节点、临时节点、临时序号节点。 节点类型英文 节点类型中文 PERSISTENT 持久节点 PERSISTENT_SEQUENTIAL 持久序号节点 EPHEMERAL 临时节点(不可在拥有子节点) EPHEMERAL_SEQUENTIAL 临时序号节点(不可在拥有子节点) 持久节点：哪怕客户端断开连接，也一直存在。 临时节点：只要客户端断开连接，节点就没了。 顺序节点：就是在创建节点的时候自动添加全局递增的序号 ZooKeeper 分布式锁的实现就是基于临时顺序节点来实现的，加锁的时候，创建一个临时顺序节点。 每一个 znode 结构包含如下属性： path:唯一路径 childNode：子节点 stat:状态属性 type:节点类型 我们可以使用命令查看 znode 的属性： stat /cluster 属性列表如下： 属性 描述 cZxid = 0x75 #创建节点的事务 ID ctime = Tue Oct 20 16:49:19 CST 2020 #创建时间 mZxid = 0x75 #修改节点的事务 ID mtime = Tue Oct 20 16:49:19 CST 2020 #最后修改时间 pZxid = 0x76 #子节点变更的事物ID cversion = 1 #这表示对此znode的子节点进行的更改次数（不包括子节点） dataVersion = 0 # 数据版本，变更次数 aclVersion = 0 #权限版本，变更次数 ephemeralOwner = 0x0 #临时节点所属会话ID dataLength = 0 #数据长度 numChildren = 1 #子节点数(不包括子子节点) ZooKeeper 特点： 顺序写：集群中只有一台机器可以写，所有机器都可以读，所有写请求都会分配一个zk集群全局的唯一递增编号，zxid，保证各种客户端发起的写请求都是有顺序的 数据一致性：任何一台zk机器收到了写请求之后都会同步给其他机器，保证数据的强一致，你连接到任何一台zk机器看到的数据都是一致的 高性能：每台zk机器都在内存维护数据，所以zk集群绝对是高并发高性能的，如果你让zk部署在高配置物理机上，一个3台机器的zk集群抗下每秒几万请求没有问题 高可用：哪怕集群中挂掉不超过一半的机器，都能保证可用，数据不会丢失，3台机器可以挂1台，5台机器可以挂2台 高并发：高性能决定的，只要基于纯内存数据结构来处理，并发能力是很高的，只有一台机器进行写，但是高配置的物理机，比如16核32G，写入几万QPS，读，所有机器都可以读，3台机器的话，起码可以支撑十几万QPS ZooKeeper 3 种角色： 通常来说ZooKeeper集群里有三种角色的机器。 Leader：集群启动自动选举一个Leader出来，只有Leader是可以写的。 Follower：Follower 只能同步数据和提供数据的读取，Leader 挂了，Follower 可以继续选举出来Leader。 Observer：只能读，但是Observer不参与选举 ZooKeeper最核心的一个机制：Watcher监听回调 就是客户端可以对 Znode 进行 Watcher 监听，然后 Znode 改变的时候回调客户端。 在整个zk的架构和工作原理中，有一个非常关键的环节，就是zk集群的数据同步是用什么协议做的？其实用的是特别设计的ZAB协议，ZooKeeper Atomic Broadcast，就是ZooKeeper原子广播协议。 ZAB的核心思想介绍：主从同步机制和崩溃恢复机制 两种角色：Leader 和 Follower，只有 Leader 可以接受写操作，Leader 和 Follower 都可以读。 流程：Leader 收到事务请求，转换为事务 Proposal（提议）同步给所有的 Follower，超过半数的 Follower 都说收到事务 Proposal 了（返回 ack），Leader 再给所有的 Follower 发一个Commit 消息，让所有 Follower 提交事务。 崩溃恢复： zk集群启动的时候，进入恢复模式，选举一个leader出来，然后leader等待集群中过半的follower跟他进行数据同步，只要过半follower完成数据同步，接着就退出恢复模式，可以对外提供服务了 集群启动：恢复模式，leader选举（过半机器选举机制） + 数据同步 消息写入：消息广播模式，leader采用2PC模式的过半写机制，给follower进行同步 崩溃恢复：恢复模式，leader/follower宕机，只要剩余机器超过一半，集群宕机不超过一半的机器，就可以选举新的leader，数据同步 采用了2PC两阶段提交思想的ZAB消息广播流程： 每一个消息广播的时候，都是2PC思想走的，先是发起事务Proposal的广播，就是事务提议，仅仅只是个提议而已，各个follower返回ack，过半follower都ack了，就直接发起commit消息到全部follower上去，让大家提交。 发起一个事务proposal之前，leader会分配一个全局唯一递增的事务id，zxid，通过这个可以严格保证顺序。 leader会为每个follower创建一个队列，里面放入要发送给follower的事务proposal，这是保证了一个同步的顺序性。 每个follower收到一个事务proposal之后，就需要立即写入本地磁盘日志中，写入成功之后就可以保证数据不会丢失了，然后返回一个ack给leader，然后过半follower都返回了ack，leader推送commit消息给全部follower。 leader自己也会进行commit操作，commit之后，就意味这个数据可以被读取到了。 ZooKeeper到底是强一致性还是最终一致性： 明显，ZAB协议机制，zk一定不是强一致性，是最终一致，官方的说法是顺序一致性。因为leader一定会保证所有的proposal同步到follower上都是按照顺序来走的，起码顺序不会乱。 使用 Observer 节点来扩展 ZooKeeper 集群： Observer节点是不参与leader选举的，他也不参与ZAB协议同步时候的过半follower ack的那个环节，他只是单纯的接收数据，同步数据，可能数据存在一定的不一致的问题，但是是只读的。 zk集群无论多少台机器，只能是一个leader进行写，单机写入最多每秒上万QPS，这是没法扩展的，所以zk是适合写少的场景。 但是读呢？follower起码有2个或者4个，读你起码可以有每秒几万QPS，没问题，那如果读请求更多呢？此时你可以引入Observer节点，他就只是同步数据，提供读服务，可以无限的扩展机器。 ","link":"https://panson.top/post/yi-wen-yi-zhi-zookeeper-he-xin-yuan-li/"},{"title":"RocketMQ 核心原理总结","content":"消息队列中，最熟悉的应该就是 RocketMQ 了，Kafka 和 RabbitMQ 都不是用 Java 写的，深入研究的话，时间耗费有点大，准备先熟悉透了 RocketMQ 之后再去研究 Kafka。本文很多内容其实都参照了官方文档，有兴趣的读者也可以通读一遍官方文档。 1 架构设计 2 NameServer 工作原理 3 Broker 的主从架构原理 4 消息写入 Broker 4.1 分片机制 4.2 Broker 存储机制 1 架构设计 先来看一下 RocketMQ 的架构设计图： RocketMQ架构上主要分为四部分，如上图所示: Producer：消息发布的角色，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。 Consumer：消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。 NameServer：NameServer是一个非常简单的Topic路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。主要包括两个功能：Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活；路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费。NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer,Consumer仍然可以动态感知Broker的路由的信息。 BrokerServer：Broker主要负责消息的存储、投递和查询以及服务高可用保证，为了实现这些功能， Broker包含了以下几个重要子模块。 Remoting Module：整个Broker的实体，负责处理来自clients端的请求。 Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息 Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。 HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。 Index Service：根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。 下面来看看部署架构： RocketMQ 网络部署特点： NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。 Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。 注意：当前RocketMQ版本在部署架构上支持一Master多Slave，但只有BrokerId=1的从服务器才会参与消息的读负载。 Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic 服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。 Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离（判断是否读老消息，产生读I/O），以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取。 结合部署架构图，描述集群工作流程： 启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。 Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。 心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。 收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。 Producer发送消息。 启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列，然后与队列所在的Broker建立长连接从而向Broker发消息。 Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。 2 NameServer 工作原理 从架构图中可以看到 NameServer 好似一个交通枢纽，所以下面先从 NameServer 聊起。 第一，每个 Broker（包括 master 和 slave） 启动的时候都得向所有的 NameServer 进行注册，也就是说，每个 NameServer 都会有一份集群中所有 Broker 的信息。 第二，consumer 和 producer 都是自己主动从 NameServer 拉取 Broker 信息的。 第三，Broker 与 NameServer 之间存在心跳机制，Broker 每隔 30 秒给所有的 NameServer 发送心跳，告诉所有的 NameServer 自己还活着。每次 NameServer 收到一个 Broker 的心跳，就可以更新一下它的最近一次心跳时间。NameServer 会每隔 10 秒运行一个任务，去检查一下各个 Broker 的最近一次心跳信息，如果某个 Broker 超过 120s 都没发送，那么就认为这个 Broker 已经挂掉了。 第四，Broker 与 NameServer 进行心跳注册时，还会汇报自己的数据情况，比如哪些 Topic 的哪些数据在自己这里，这些信息都是属于路由信息的一部分。 第五，生产者在发送消息之前，会先确定一个 Topic, 然后在发送消息的时候指定 Topic， 发送到 master broker 上。然后生产者会与 NameServer 建立一个 TCP 长连接，然后定时从 NameServer 拉取最新的路由信息，包括集群中有哪些 Topic，每个 Topic 存储在哪些 Broker 上。 3 Broker 的主从架构原理 第一，首先在第二节 NameServer 工作原理 中已经讲了：每个 Broker（包括 master 和 slave） 启动的时候都得向所有的 NameServer 进行注册，也就是说，每个 NameServer 都会有一份集群中所有 Broker 的信息。 第二，master 与 slave 之间的数据同步方式：slave Broker 不停地发送请求到 master Broker 中去去拉取消息。 第三，消费者在获取消息的时候，有可能从 Master 获取，也有可能从 Slave Broker 获取。 做为消费者的系统在获取消息的时候会先发送请求到 master Broker 上去，请求获取一批消息，此时 master broker 是会返回一批消息给消费系统的。 然后 master Broker 在返回消息给消费者系统的时候，会根据当时 master broker 的负载情况和 slave broker 的同步情况，向消费者系统建议下一次拉取消息的时候是从 master broker 拉取还是从 slave broker 拉取。 RocketMQ 4.5 之后，Dledger 可以实现 RocketMQ 的高可用自动切换 4 消息写入 Broker 4.1 分片机制 Topic 为了能分布式存储，引入了 MessageQueue 的概念（分片机制），如下图所示： 在 Producer 中有一个开关：sendLatencyFaultEnable，一旦打开这个开关，就会开启自动容错机制，比如说某次访问一个 broker 发现网络延迟有 500 ms，然后还会无法访问，那么就会自动回避访问这个 Broker 一段时间，比如接下来 3000 ms 内，就不会再访问这个 Broker 了。 4.2 Broker 存储机制 先来讲一下一串名词，这些名词都与Broker 的数据存储有关系。 CommitLog Topic MesageQueue ConsumeQueue 文件 CommitLog offset 偏移量 同步刷盘 异步刷盘 我们可以将上面的名词都串起来，捋一捋，就能知道 Broker 的存储机制了。 Broker 收到生产者的一条消息，会把消息直接顺序写入到磁盘上的一个日志文件，叫做 CommitLog。CommitLog 是许多磁盘文件，每个文件最多 1 GB，Broker 收到消息之后就直接追加写入这个文件的结尾。如果一个 CommitLog 写满了 1 GB，就会创建一个新的 CommitLog 文件。 在 Broker 中，对 Topic 下的每个 MessageQueue 都会有一系列的 ConsumerQueue 文件，ConsumeQueue 文件里存储的消息在 CommitLog 上的物理位置，也就是 offset 偏移量。一个 ConsumerQueue 的大概目录是这样的： $HOME/store/consumequeue/{topic}/{queueId}/{fileName} 实际上 ConsumeQueue 中存储的每条数据不只是消息在 CommitLog 中的 offset 偏移量，还包含了消息的长度，以及 tag hashcode。 Topic 的每个 MessageQueue 都对应了 Broker 机器上的多个ConsumeQueue 文件，保存了这个 MessageQueue 的所有消息在 CommitLog 文件中的物理位置，也就是 offset 偏移量。 在性能优化上， broker 采用了 磁盘文件顺序写 + OS PageCache 写入 + OS 异步刷盘的策略，基本上可以保证让消息写入 CommitLog 的性能跟写入内存差不多，这样才能保证高吞吐量。 消费消息的时候，本质就是根据 MessageQueue 以及开始消费的位置，去找到对应的 ConsumeQueue，读取对应的 offset 偏移量，然后到 CommitLog 中根据 offset 读取消息数据，返回给消费者机器。 ","link":"https://panson.top/post/rocketmq-he-xin-yuan-li-zong-jie/"},{"title":"Leetcode 分类整理","content":"日常刷题，不能断 主要是参照链接来刷的，后面自己又增加了一些题目。买了 leetcode 的会员，刷企业题库，冲~ 双指针遍历/滑动窗口 3. 无重复字符的最长子串 11. 盛最多水的容器 15. 三数之和 16. 最接近的三数之和 26. 删除排序数组中的重复项 121. 买卖股票的最佳时机 209. 长度最小的子数组 数字操作 7. 整数反转 8.字符串转换整数 (atoi) 9.回文数 快慢指针遍历 141. 环形链表 202. 快乐数 876. 链表的中间结点 链表 002.两数相加 021.合并两个有序链表 19. 删除链表的倒数第N个节点 206. 反转链表 61. 旋转链表 138. 复制带随机指针的链表 数组 001.两数之和 合并两个有序数组 48. 旋转图像 169. 多数元素 栈 20. 有效的括号 32. 最长有效括号 155. 最小栈 232. 用栈实现队列 316. 去除重复字母 树 94. 二叉树的中序遍历 144. 二叉树的前序遍历 145. 二叉树的后序遍历 102. 二叉树的层序遍历 101. 对称二叉树 104. 二叉树的最大深度 1325. 删除给定值的叶子节点 字符串 387. 字符串中的第一个唯一字符 6. Z 字形变换 14. 最长公共前缀 763. 划分字母区间 557. 反转字符串中的单词 III 递归 101. 对称二叉树 104. 二叉树的最大深度 226. 翻转二叉树 235. 二叉搜索树的最近公共祖先 236. 二叉树的最近公共祖先 1325. 删除给定值的叶子节点 分治法/二分法 215. 数组中的第K个最大元素 回溯 46. 全排列 22. 括号生成 40. 组合总和 II 合并区间 56. 合并区间 队列 346. 数据流中的移动平均值 数学 172. 阶乘后的零 ","link":"https://panson.top/post/leetcode-fen-lei-zheng-li/"},{"title":"基于原型模式和享元模式完成不同分层POJO 之间的数据拷贝","content":"Once you understand the design patterns and have had an &quot;Aha!&quot; (and not just a &quot;Huh?&quot;) experience with them, you won't ever think about object-oriented design in the same way. You'll have insights that can make your own designs more flexible, modular, reusable, and understandable—which is why you're interested in object-oriented technology in the first place, right? —— GOF 一旦你理解了设计模式并且有了一种“Aha！”（而不是“Huh？”）的应用经验和体验后，你将用一种非同寻常的方式思考面向对象设计。你将拥有一种深刻的洞察力，以帮助你设计出更加灵活的、模块化的、可复用的和易理解的软件 ——这也是你为何着迷于面向对象技术的源动力，不是吗？ —— 《设计模式》作者四人帮 你在初学 Java 的时候，是不是遇到过这样的场景，不经意间写过这样的代码： 原型模式与享元模式有一些相似的地方，但本质是不同的。在 GOF的书里，原型模式是创建型模式，而享元模式则属于结构姓模式。从性能优化的角度分析，原型模式是在创建多个实例时，对创建过程的性能进行调优；享元模式是用减少创建实例的方式，来调优系统性能。 原型模式的一个经典应用场景是优化创建重复对象： int i = 1000; while(i &gt; 0) { Student student = new Student(); i--; } 自己实现属性拷贝太繁琐，代码冗余 apache 的 Beanuitils: 反射 apache 的 PropetiesUtils: 反射 SPring 的 beanutils: 反射 cglib 的 BeanCopier: 动态代理，性能很高，达到上面反射方式的几十倍甚至是数百倍 原型模式和享元模式的设计模式讲解 代码实现 优化深度克隆：List: 其实深拷贝就是基于浅拷贝来递归实现具体的每个对象 CgLib 底层实现 new一个对象和clone一个对象，性能差在哪里呢？文中提到直接从内存复制二进制这里不是很理解 作者回复: 一个对象通过new创建的过程为： 1、在内存中开辟一块空间； 2、在开辟的内存空间中创建对象； 3、调用对象的构造函数进行初始化对象。 而一个对象通过clone创建的过程为： 1、根据原对象内存大小开辟一块内存空间； 2、复制已有对象，克隆对象中所有属性值。 相对new来说，clone少了调用构造函数。如果构造函数中存在大量属性初始化或大对象，则使用clone的复制对象的方式性能会好一些。 引入 pom: &lt;!-- cglib的BeanCopier需要的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;asm&lt;/groupId&gt; &lt;artifactId&gt;asm&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;asm&lt;/groupId&gt; &lt;artifactId&gt;asm-commons&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;asm&lt;/groupId&gt; &lt;artifactId&gt;asm-util&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib-nodep&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt; public class BeanCopierUtils { /** * BeanCopier缓存 */ public static Map&lt;String, BeanCopier&gt; beanCopierCacheMap = new HashMap&lt;String, BeanCopier&gt;(); /** * 将source对象的属性拷贝到target对象中去 * @param source source对象 * @param target target对象 */ public static void copyProperties(Object source, Object target){ String cacheKey = source.getClass().toString() + target.getClass().toString(); BeanCopier beanCopier = null; if (!beanCopierCacheMap.containsKey(cacheKey)) { synchronized(BeanCopierUtils.class) { if (!beanCopierCacheMap.containsKey(cacheKey)) { beanCopier = BeanCopier.create(source.getClass(), target.getClass(), false); beanCopierCacheMap.put(cacheKey, beanCopier); } } } else { beanCopier = beanCopierCacheMap.get(cacheKey); } beanCopier.copy(source, target, null); } } 参考： Design Patterns: Elements of Reusable Object-Oriented Software Java性能调优实战 ","link":"https://panson.top/post/ji-yu-yuan-xing-mo-shi-he-xiang-yuan-mo-shi-wan-cheng-bu-tong-fen-ceng-pojo-zhi-jian-de-shu-ju-kao-bei/"},{"title":"MacOS 环境如何使用 GitHub + Typora + PicGo 搭建写作环境","content":"在某些方面，不得不承认自己是一个强迫症患者。比如说写作环境，本身习惯了 Typora 的简洁与即时渲染，但 Typora 本身不支持图床，我在犹豫良久之后，还是切换回了有道云笔记。 尽管有道云笔记支持 Markdown，但界面审美还停留在上个世纪，普通的笔记有没办法给我较为满意的写作体验。直到最近陆陆续续整理有道云上的笔记，才发现我在有道云上已经写了上百篇的文档，出于对数据的安全性考虑，我准备将所有的文档都备份一份，存储在本地和坚果云上（实时同步），然后不定期将本地文件上传到有道云笔记上（异步），这样的话，即使我的电脑出现损坏，也不至于丢失数据。 但这样的话，问题又来了，图床呢，Markdown 文件本身仅持有图片的链接。好在可选的方案很多，最终我选择了 GitHub + PicGo 搭建。 网上的教程给出的大多是 Windows 环境下 使用 GitHub + Typora + PicGo 搭建，所以这里写一份 MacOS 环境下搭建的教程。 步骤： 软件下载：Typora 、PicGo，从官网上就可以下载 https://typora.io/ https://github.com/Molunerfinn/PicGo GitHub账号以及一个用于存储图片的仓库 安装 node 环境 安装 PicGo: npm install picgo -g PicGo 设置: picgo set uploader Typora 设置： 点击 Test Uploader 查看测试是否配置正确。如果顺利的话，你就可以看到如下提示： 如果中途遇到问题，因为随着软件版本的迭代，可能会出现一些小问题，你可以参考官方doc获取帮助 upload image。 ","link":"https://panson.top/post/macos-huan-jing-ru-he-shi-yong-github-typora-picgo-da-jian-xie-zuo-huan-jing/"},{"title":"Redis 核心原理总结","content":"本文主要总结了 Redis 底层的数据结构和线程模型。 1 底层数据结构 1.1 数据结构总览 1.2 压缩列表 1.3 跳表 2 redis 的线程模型 2.1 单线程 2.1.1 Redis 单线程模型也能效率这么高？ 2.2 多线程 2.3 总结 3 缓存雪崩、缓存击穿、缓存穿透 3.1 缓存雪崩 3.1.1 什么是缓存雪崩 3.1.1 解决办法 3.2 缓存穿透 3.2.1 什么是缓存穿透？ 3.2.2 穿透带来的问题 3.2.3 解决办法 3.3 缓存击穿 3.3.1 什么是缓存击穿 3.3.2 解决办法 4 过期策略 5 持久化之 AOF 与 RDB 5.1 AOF 5.1.1 AOF 的写后日志方式的优点与缺点 5.1.2 写回策略 5.1.3 AOF(Append Only File) 重写机制 5.2 RDB(Redis DataBase) 6 主从同步 6.1 全量复制同步流程 6.1.1 第一阶段 6.1.2 第二阶段 6.1.3 第三阶段 6.2 主从级联模式 6.3 增量复制 7 哨兵机制 7.1 原理 7.2 Redis 哨兵主备切换的数据丢失问题 7.3 quorum、majority、configuration epoch、configuration 传播 7.3.1 quorum 和 majority 7.3.2 configuration epoch 7.3.3 configuration 传播 参考： 1 底层数据结构 1.1 数据结构总览 String类型的底层实现只有⼀种数据结构，也就是简单动态字符串。⽽List、Hash、Set和 Sorted Set这四种数据类型，都有两种底层实现结构。 1.2 压缩列表 压缩列表实际上类似于⼀个数组，数组中的每⼀个元素都对应保存⼀个数据。 和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表⽰列表⻓度、列表尾的偏移量和列表中的entry个数；压缩列表在表尾还有⼀个 zlend，表⽰列表结束。 在压缩列表中，如果我们要查找定位第⼀个元素和最后⼀个元素，可以通过表头三个字段的⻓度直接定位， 复杂度是O(1)。⽽查找其他元素时，就没有这么⾼效了，只能逐个查找，此时的复杂度为 O(N)。 使⽤压缩列表本质上是将所有元素紧挨着存储，所以分配的是⼀块连续的内存空间，虽然数据结构本⾝没有时间复杂度的优势，但是这样节省空间⽽且也能避免⼀些内存碎⽚。 1.3 跳表 跳表在链表的基础上，增加了多级索引，通过索引位置的⼏个跳转，实现数据的快速定位。 2 redis 的线程模型 2.1 单线程 在 redis 启动初始化的时候，redis 会将连接应答处理器跟 AE_READABLE 事件关联起来，接着如果一个客户端跟 redis 发起连接，此时会产生一个 AE_READBLE 事件，然后由连接应答处理器来处理与客户端建立连接，创建客户端对应的 socket，同时将这个 socket 的 AE_READABLE 事件跟命令请求处理器关联起来。 当客户端向 redis 发起请求的时候（不管是读请求还是写请求，都一样），首先都会在 socket 中产生一个 AE_READABLE 事件，然后由对应的命令请求处理器来处理。这个命令请求处理器就会从 socket 中读取请求相关数据，然后进行执行和处理。 接着 redis 这边准备好了给客户端的响应数据之后，就会将 socket 的 AE_WRITABLE 事件跟命令回复处理器 关联起来，当客户端这边准备好读取响应数据时，就会在 socket 上产生一个 AE_READABLE 事件，会由对应的命令回复处理器来处理，就是将准备好的响应数据写入 socket，供客户端来读取。 命令回复处理器写完之后，就会删除这个 socket 的 AE_WRITABLE 事件和命令回复处理器的关联关系。 redis 内部使用文件事件处理器（file event handler），这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。 如果被监听的 socket 准备好执行 accept、read、write、close 等操作的时候，跟操作对应的文件事件就会产生，这个时候文件事件处理器就会调用之前关联好的事件处理器来处理这个事件。 文件事件处理器是单线程模式运行的，但是通过 IO 多路复用机制监听多个 socket，可以实现高性能的网络通信模型，又可以跟内部的其他单线程的模块进行对接，保证了redis 内部的线程模型的简单性。 文件事件处理器包含 4 个部分： 多个 socket IO 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 多个socket 可能并发地产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，将 socket 放入一个队列中排队，每次从队列中取出一个 socket 给事件分派器，事件分派器把 sokcet 给对应的时间处理器。 然后一个 socket 的事件处理完之后，IO 多路复用程序才会将队列中的下一个 socket 给事件分配器。文件事件分派器会根据每个 socket 当前产生的事件，来选择对应的事件处理器来处理。 2.1.1 Redis 单线程模型也能效率这么高？ 纯内存操作。 核心是基于非阻塞的 IO 多路复用机制。 C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。 2.2 多线程 Redis 6.0 之后的版本抛弃了单线程模型这一设计，原本使用单线程运行的 Redis 也开始选择性地使用多线程模型。 前面还在强调 Redis 单线程模型的高效性，现在为什么又要引入多线程？这其实说明 Redis 在有些方面，单线程已经不具有优势了。因为读写网络的 Read/Write 系统调用在 Redis 执行期间占用了大部分 CPU 时间，如果把网络读写做成多线程的方式对性能会有很大提升。 Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。 之所以这么设计是不想 Redis 因为多线程而变得复杂，需要去控制 key、lua、事务、LPUSH/LPOP 等等的并发问题。 2.3 总结 Redis 选择使用单线程模型处理客户端的请求主要还是因为** CPU 不是 Redis 服务器的瓶颈**，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；而 Redis 引入多线程操作也是出于性能上的考虑，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间也能减少对 Redis 主线程阻塞的时间，提高执行的效率。 3 缓存雪崩、缓存击穿、缓存穿透 3.1 缓存雪崩 3.1.1 什么是缓存雪崩 缓存雪崩的情况是说，当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上面。结果就是DB 撑不住，挂掉。 3.1.1 解决办法 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。 事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。 3.2 缓存穿透 3.2.1 什么是缓存穿透？ 正常情况下，我们去查询数据都是存在。 那么请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。 这种查询不存在数据的现象我们称为缓存穿透。 3.2.2 穿透带来的问题 黑客拿一个不存在的 key 不断请求你的接口，这样所有的请求最终都会打到数据库中，从而导致数据库宕机。 3.2.3 解决办法 缓存空值 之所以会发生穿透，就是因为缓存中没有存储这些空数据的key。从而导致每次查询都到数据库去了。 那么我们就可以为这些key对应的值设置为null 丢到缓存里面去。后面再出现查询这个key 的请求的时候，直接返回null 。 这样，就不用在到数据库中去走一圈了，但是别忘了设置过期时间。 BloomFilter 这种方案可以加在第一种方案中，在缓存之前在加一层 BloomFilter ，在查询的时候先去 BloomFilter 去查询 key 是否存在，如果不存在就直接返回，存在再走查缓存 -&gt; 查 DB。 3.3 缓存击穿 3.3.1 什么是缓存击穿 缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。 3.3.2 解决办法 解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。 但是由于这样做会阻塞其他的线程，此时系统吞吐量会下降，需要结合实际的业务去考虑是否要这么做。 4 过期策略 Redis 的高性能有一个原因是 Redis 使用内存做缓存，但内存是宝贵且有限的，Redis 不可能使用内存做持久化。 使用 Redis 的过程中，常见的有两个问题： Redis 数据丢失 数据缓存过期了，但是还占用着内存 要想理解这些问题的产生原因，就不得不了解 Redis 的过期策略。 Redis 使用定期删除 + 懒惰删除的策略 定期删除：指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。（因为是随机的，所以可能会有一些 key 一直没删除掉） 懒惰删除：获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了，如果过期了此时就会删除，不会给你返回任何东西。 但是如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，内存中还是会存在大量的无用数据。 所以 Redis 也就有了内存淘汰机制。 redis 内存淘汰机制有以下 6 种： noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。 allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。 Redis lru 底层原理：Redis采用了一个近似的lru 算法，就是随机取出若干个key，然后按照访问时间排序后，淘汰掉最不经常使用的。 Redis会基于server.maxmemory_samples配置选取固定数目的key，然后比较它们的lru访问时间，然后淘汰最近最久没有访问的key，maxmemory_samples的值越大，Redis的近似LRU算法就越接近于严格LRU算法，但是相应消耗也变高，对性能有一定影响。 手写一个 LRU 算法： class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; { private final int CACHE_SIZE; /** * 传递进来最多能缓存多少数据 * * @param cacheSize 缓存大小 */ public LRUCache(int cacheSize) { // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。 super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true); CACHE_SIZE = cacheSize; } @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) { // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。 return size() &gt; CACHE_SIZE; } } 测试代码： static LRUCache&lt;Integer, Integer&gt; lruCache = new LRUCache&lt;&gt;(16); public static void main(String[] args) { for (int i = 0; i &lt; 16; i++) { lruCache.put(i, i); } System.out.println(lruCache.entrySet()); for(int i = 16; i &lt; 20; i++) { lruCache.put(i, i); System.out.println(lruCache.entrySet()); } } 结果： [0=0, 1=1, 2=2, 3=3, 4=4, 5=5, 6=6, 7=7, 8=8, 9=9, 10=10, 11=11, 12=12, 13=13, 14=14, 15=15] [1=1, 2=2, 3=3, 4=4, 5=5, 6=6, 7=7, 8=8, 9=9, 10=10, 11=11, 12=12, 13=13, 14=14, 15=15, 16=16] [2=2, 3=3, 4=4, 5=5, 6=6, 7=7, 8=8, 9=9, 10=10, 11=11, 12=12, 13=13, 14=14, 15=15, 16=16, 17=17] [3=3, 4=4, 5=5, 6=6, 7=7, 8=8, 9=9, 10=10, 11=11, 12=12, 13=13, 14=14, 15=15, 16=16, 17=17, 18=18] [4=4, 5=5, 6=6, 7=7, 8=8, 9=9, 10=10, 11=11, 12=12, 13=13, 14=14, 15=15, 16=16, 17=17, 18=18, 19=19] 可以看到在 size 超过 16 个时，进行了 LRU 缓存淘汰。 5 持久化之 AOF 与 RDB 5.1 AOF 5.1.1 AOF 的写后日志方式的优点与缺点 我们以Redis收到“set key1 value1”命令后记录的⽇志为例，看看AOF⽇志的内容。 *3 $3 set $4 key1 $6 value1 其中，“*3”表⽰当前命令有三个部分，每部分都是由“$+数字”开头，后⾯紧跟着具体的命令、键或值。这⾥，“数字”表⽰这部分中的命令、键或值⼀共有多少字节。例如，“$3 set”表⽰这部分有3个字节。 AOF 采用写后⽇志这种⽅式，就是先让系统执⾏命令，只有命令能执⾏成功，才会被记录到⽇志中，否则，系统就会直接向客⼾端报错。所以，Redis使⽤写后⽇志这⼀⽅式的⼀⼤好处是，可以避免出现记录错误命令的情况。 不过，AOF也有两个潜在的⻛险。 如果刚执⾏完⼀个命令，还没有来得及记⽇志就宕机了，那么这个命令和相应的数据就有丢失的⻛ 险。如果此时Redis是⽤作缓存，还可以从后端数据库重新读⼊数据进⾏恢复，但是，如果Redis是直接⽤作 数据库的话，此时，因为命令没有记⼊⽇志，所以就⽆法⽤⽇志进⾏恢复了。 AOF虽然避免了对当前命令的阻塞，但可能会给下⼀个操作带来阻塞⻛险。这是因为，AOF⽇志也是 在主线程中执⾏的，如果在把⽇志⽂件写⼊磁盘时，磁盘写压⼒⼤，就会导致写盘很慢，进⽽导致后续的操 作也⽆法执⾏了。 5.1.2 写回策略 Always，同步写回：每个写命令执⾏完，⽴⻢同步地将⽇志写回磁盘； Everysec，每秒写回：每个写命令执⾏完，只是先把⽇志写到AOF⽂件的内存缓冲区，每隔⼀秒把缓冲区中的内容写⼊磁盘； No，操作系统控制的写回：每个写命令执⾏完，只是先把⽇志写到AOF⽂件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。 5.1.3 AOF(Append Only File) 重写机制 AOF 的重写根据键值对的最新状态，将中间过程省略，从而缩小日志文件大小。 和AOF⽇志由主线程写回不同，重写过程是由后台线程bgrewriteaof来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。 重写的过程可以总结为“⼀个拷⻉，两处⽇志”。 “⼀个拷⻉”就是指，每次执⾏重写时，主线程fork出后台的bgrewriteaof⼦进程。此时，fork会把主线程的内存拷⻉⼀份给bgrewriteaof⼦进程，这⾥⾯就包含了数据库的最新数据。然后，bgrewriteaof⼦进程就可以在不影响主线程的情况下，逐⼀把拷⻉的数据写成操作，记⼊重写⽇志。 “两处⽇志”⼜是什么呢？因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第⼀处⽇志就是指正在使⽤的AOF⽇志，Redis会把这个操作写到它的缓冲区。这样⼀来，即使宕机了，这个AOF⽇志的操作仍然是⻬全的，可以⽤于恢复。⽽第⼆处⽇志，就是指新的AOF重写⽇志。这个操作也会被写到重写⽇志的缓冲区。这样，重写⽇志也不会丢失最新的操作。等到拷⻉数据的所有操作记录重写完成后，重写⽇志记录的这些最新操作也会写⼊新的AOF⽂件，以保证数据库最新状态的记录。此时，我们就可以⽤新的AOF⽂件替代旧⽂件了。 总结来说，每次AOF重写时，Redis会先执⾏⼀个内存拷⻉，⽤于重写；然后，使⽤两个⽇志保证在重写过 程中，新写⼊的数据不会丢失。⽽且，因为Redis采⽤额外的线程进⾏数据重写，所以，这个过程并不会阻 塞主线程。 5.2 RDB(Redis DataBase) Redis的数据都在内存中，为了提供所有数据的可靠性保证，RDB 执⾏的是全量快照。 Redis提供了两个命令来⽣成RDB⽂件，分别是save和bgsave。 save：在主线程中执⾏，会导致阻塞； bgsave：创建⼀个⼦进程，专⻔⽤于写⼊RDB⽂件，避免了主线程的阻塞，这也是Redis RDB⽂件⽣成的默认配置。 为了快照⽽暂停写操作，肯定是不能接受的。所以这个时候，Redis就会借助操作系统提供的写时复制技术 （Copy-On-Write, COW），在执⾏快照的同时，正常处理写操作。 简单来说，bgsave⼦进程是由主线程fork⽣成的，可以共享主线程的所有内存数据。bgsave⼦进程运⾏ 后，开始读取主线程的内存数据，并把它们写⼊RDB⽂件。 Redis 4.0中提出了⼀个混合使⽤AOF⽇志和内存快照的⽅法。简单来说，内存快照以⼀定的频率执⾏，在两次快照之间，使⽤AOF⽇志记录这期间的所有命令操作。 此时，如果主线程对这些数据也都是读操作（例如图中的键值对A），那么，主线程和bgsave⼦进程相互不影响。但是，如果主线程要修改⼀块数据（例如图中的键值对C），那么，这块数据就会被复制⼀份，⽣成该数据的副本。然后，bgsave⼦进程会把这个副本数据写⼊RDB⽂件，⽽在这个过程中，主线程仍然可以直接修改原来的数据。 6 主从同步 6.1 全量复制同步流程 6.1.1 第一阶段 第⼀阶段是主从库间建⽴连接、协商同步的过程，主要是为全量复制做准备。在这⼀步，从库和主库建⽴起 连接，并告诉主库即将进⾏同步，主库确认回复后，主从库间就可以开始同步了。 具体来说，从库给主库发送psync命令，表⽰要进⾏数据同步，主库根据这个命令的参数来启动复制。 psync命令包含了主库的runID和复制进度offset两个参数。 runID，是每个Redis实例启动时都会⾃动⽣成的⼀个随机ID，⽤来唯⼀标记这个实例。当从库和主库第一次复制时，因为不知道主库的runID，所以将runID设为“？”。 offset，此时设为-1，表⽰第⼀次复制。 主库收到psync命令后，会⽤FULLRESYNC响应命令带上两个参数：主库runID和主库⽬前的复制进度offset，返回给从库。从库收到响应后，会记录下这两个参数。 这⾥有个地⽅需要注意，FULLRESYNC响应表⽰第⼀次复制采⽤的全量复制，也就是说，主库会把当前所 有的数据都复制给从库。 6.1.2 第二阶段 这⾥有个地⽅需要注意，FULLRESYNC响应表⽰第⼀次复制采⽤的全量复制，也就是说，主库会把当前所有的数据都复制给从库。 具体来说，主库执⾏bgsave命令，⽣成RDB⽂件，接着将⽂件发给从库。从库接收到RDB⽂件后，会先清空当前数据库，然后加载RDB⽂件。这是因为从库在通过replicaof命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。 在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚⽣成的RDB⽂件中。为了保证主从库的数据⼀致性，主库会在内存中⽤专⻔的replication buffer，记录RDB⽂件⽣成后收到的所有写操作。 6.1.3 第三阶段 主库会把第⼆阶段执⾏过程中新收到的写命令，再发送给从库。 具体的操作是，当主库完成RDB⽂件发送后，就会把此时replication buffer中的修改操作发给从库，从库再重新执⾏这些操作。这样⼀来，主从库就实现同步了 6.2 主从级联模式 ⼀次全量复制中，对于主库来说，需要完成两个耗时的操作： ⽣成RDB⽂件 传输RDB⽂件 我们可以通过“主-从-从”模式将主库⽣成RDB和传输RDB的压⼒，以级联的⽅式分散到从库上. 6.3 增量复制 当主从库断连后，主库会把断连期间收到的写操作命令，写⼊replication buffer，同时也会把这些操作命令也写⼊repl_backlog_buffer这个缓冲区。 repl_backlog_buffer是⼀个环形缓冲区，主库会记录⾃⼰写到的位置，从库则会记录⾃⼰已经读到的位 置。 刚开始的时候，主库和从库的写读位置在⼀起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常⽤偏移量来衡量这个偏移距离的⼤⼩，对主库来说，对应的偏移量就是master_repl_offset。主库接收的新写操作越多，这个值就会越⼤。 同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已 复制的偏移量slave_repl_offset也在不断增加。正常情况下，这两个偏移量基本相等。 增量复制流程如下所示： 注意： 因为repl_backlog_buffer是⼀个环形缓冲区，所以在缓冲区写满后，主库会继续写⼊，此时，就会覆盖掉之前写⼊的操作。如果从库的读取速度⽐较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不⼀致。 因此，我们要想办法避免这⼀情况，⼀般⽽⾔，我们可以调整repl_backlog_size这个参数。这个参数和所 需的缓冲空间⼤⼩有关。缓冲空间的计算公式是：缓冲空间⼤⼩ = 主库写⼊命令速度 * 操作⼤⼩ - 主从库间⽹络传输命令速度 * 操作⼤⼩。在实际应⽤中，考虑到可能存在⼀些突发的请求压⼒，我们通常需要把这个缓冲空间扩⼤⼀倍，即repl_backlog_size = 缓冲空间⼤⼩ * 2，这也就是repl_backlog_size的最终值。 举个例⼦，如果主库每秒写⼊2000个操作，每个操作的⼤⼩为2KB，⽹络每秒能传输1000个操作，那么，有1000个操作需要缓冲起来，这就⾄少需要2MB的缓冲空间。否则，新写的命令就会覆盖掉旧操作了。为了应对可能的突发压⼒，我们最终把repl_backlog_size设为4MB。 7 哨兵机制 7.1 原理 主从集群模式下，如果主库宕机，那就需要哨兵机制登场了。在Redis主从集群中，哨兵机制是实现主从库⾃动切换的关键机制，它有效地解决了主从复制模式下故障转移的三个问题： 主库真的挂了吗？ 该选择哪个从库作为主库？ 怎么把新主库的相关信息通知给从库和客⼾端呢？ 哨兵其实就是⼀个运⾏在特殊模式下的Redis进程，主从库实例运⾏的同时，它也在运⾏。哨兵主要负责的 就是三个任务：监控、选主（选择主库）和通知。 监控：监控是指哨兵进程在运⾏时，周期性地给所有的主从库发送PING命令，检测它们是否仍然在线运⾏。如果从库没有在规定时间内响应哨兵的PING命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的PING命令，哨兵就会判定主库下线，然后开始⾃动切换主库的流程。 选主：主库挂了以后，哨兵就需要从很多个从库⾥，按照⼀定的规则选择⼀个从库实例，把它作为新的主库。这⼀步完成后，现在的集群⾥就有了新主库。 通知：在执⾏通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执⾏replicaof命令，和新主库建⽴连接，并进⾏数据复制。同时，哨兵会把新主库的连接信息通知给客⼾端，让它们把请求操作发到新主库上。 为了降低哨兵监控的误判率，通常会采⽤多实例组成的集群模式进⾏部署，这也被称为哨兵集群。引⼊多个哨兵实例⼀起来判断，就可以避免单个哨兵因为⾃⾝⽹络状况不好，⽽误判主库下线的情况。同时，多个哨兵的⽹络同时不稳定的概率较⼩，由它们⼀起做决策，误判率也能降低。在判断主库是否下线时，不能由⼀个哨兵说了算，只有⼤多数的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线”。 在选主时，除了要检查从库的当前在线状态，还要判断它之前的⽹络连接状态。使⽤配置项down-after-milliseconds * 10。其中，down-after-milliseconds是我们认定主从库断连的最⼤连接超时时间。如果在down-after-milliseconds毫秒内，主从节点都没有通过⽹络联系上，我们就可以认为主从节点断连了。如果发⽣断连的次数超过了10次，就说明这个从库的⽹络状况不好，不适合作为新主库。 接下来就要给剩余的从库打分了。我们可以分别按照三个规则依次进⾏三轮打分，这三个规则分别是 从库优先级 从库复制进度 从库ID号。 只要在某⼀轮中，有从库得分最⾼，那么它就是主库了，选主过程到此结束。如果没有出现得分最⾼的从库，那么就继续进⾏下⼀轮。 第⼀轮：优先级最⾼的从库得分⾼。 ⽤⼾可以通过slave-priority配置项，给不同的从库设置不同优先级。⽐如，你有两个从库，它们的内存⼤⼩不⼀样，你可以⼿动给内存⼤的实例设置⼀个⾼优先级。在选主时，哨兵会给优先级⾼的从库打⾼分，如果有⼀个从库优先级最⾼，那么它就是新主库了。如果从库的优先级都⼀样，那么哨兵开始第⼆轮打分。 第⼆轮：和旧主库同步程度最接近的从库得分⾼。 这个规则的依据是，如果选择和旧主库同步最接近的那个从库作为主库，那么，这个新主库上就有最新的数据。 主从库同步时有个命令传播的过程。在这个过程中，主库会⽤master_repl_offset记录当前的最新写操作在repl_backlog_buffer中的位置，⽽从库会⽤slave_repl_offset这个值记录当前的复制进度。此时，我们想要找的从库，它的slave_repl_offset需要最接近master_repl_offset。如果在所有从库中，有从库的slave_repl_offset最接近master_repl_offset，那么它的得分就最⾼，可以作为新主库。 第三轮：ID号⼩的从库得分⾼。 每个实例都会有⼀个ID，这个ID就类似于这⾥的从库的编号。⽬前，Redis在选主库时，有⼀个默认的规 定：在优先级和复制进度都相同的情况下，ID号最⼩的从库得分最⾼，会被选为新主库。 总结：⾸先，哨兵会按照在线状态、⽹络状态，筛选过滤掉⼀部分不符合要求的从库，然后，依次按照优先级、复制进度、ID号⼤⼩再对剩余的从库进⾏打分，只要有得分最⾼的从库出现，就把它选为新主库。 备注： 哨兵实例之间可以相互发现，要归功于Redis提供的pub/sub机制，也就是发布/订阅机制。主从集群中，主库上有⼀个名为“sentinel:hello”的频道，不同哨兵就是通过它来相互发现，实现互相通信的。 哨兵除了彼此之间建⽴起连接形成集群外，还需要和从库建⽴连接。这是因为，在哨兵的监控任务中，它需要对主从库都进⾏⼼跳判断，⽽且在主从库切换完成后，它还需要通知从库，让它们和新主库进⾏同步。 哨兵是如何知道从库的IP地址和端⼝？这是由哨兵向主库发送INFO命令来完成的。就像下图所⽰，哨兵2给主库发送INFO命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建⽴连接，并在这个连接上持续地对从库进⾏监控。哨兵1和3可以通过相同的⽅法和从库建⽴连接。 7.2 Redis 哨兵主备切换的数据丢失问题 导致数据丢失的两种情况： 异步复制导致的数据丢失 因为 master-&gt;slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了。 脑裂导致的数据丢失 脑裂，也就是说，某个 master 所在机器突然脱离了正常的网络，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会认为 master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的脑裂。 此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。 7.3 quorum、majority、configuration epoch、configuration 传播 7.3.1 quorum 和 majority 每次一个哨兵要做主备切换，首先需要 quorum 数量的哨兵认为 odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到 majority 哨兵的授权，才能正式执行切换。 如果 quorum &lt; majority，比如 5 个哨兵，majority 就是 3，quorum 设置为 2，那么就 3 个哨兵授权就可以执行切换。 但是如果 quorum &gt;= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。 7.3.2 configuration epoch 哨兵会对一套 Redis master+slaves 进行监控，有相应的监控的配置。 执行切换的那个哨兵，会从要切换到的新 master（salve-&gt;master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 version 号都必须是唯一的。 如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 version 号。 7.3.3 configuration 传播 哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 pub/sub 消息机制。 这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的 version 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。 参考： 《Redis 设计与实现》 Java-Interview-Advanced 阿里一面：关于【缓存穿透、缓存击穿、缓存雪崩、热点数据失效】问题的解决方案 Redis核心技术与实战 ","link":"https://panson.top/post/redis-he-xin-yuan-li-zong-jie/"},{"title":"聊聊进程间通信","content":"进程间的通信有很多种方式，比如说：管道（pipe）、命名管道（fifo）、消息队列，共享内存（System V） 管道（pipe） unix操作系统里面，有一个fork操作，可以创建进程的子进程，或者说是复制一个进程完全一样的子进程，共享代码空间，但是各自有独立的数据空间，不过子进程的数据空间是拷贝父进程的数据空间的。 管道机制要求的是两个进程之间是有血缘关系的，就比如fork出来的父子进程。 linux操作系统里，管道用来缓存要在进程间传输的数据，管道是一个固定大小的缓冲区，是4kb。管道中的数据一旦被读取出来，就不在管道里了。 但是如果管道满了，那么写管道的操作就阻塞了，直到别人读了管道的数据；反之如果管道是空的，那么读操作就阻塞了。就这个意思。管道一边连着一个进程的输出，一边连着一个进程的输入，然后就一个进程写数据，另外一个进程读数据，两个进程都没了，管道也就没了。管道是半双工的，就是数据只能流向一个方向，比如说你架设一个管道，只能一个进程写，另外一个进程读。 linux里面对管道的实现，是用了两个文件，指向了一个VFS（虚拟文件系统）的索引节点inode，然后VFS索引节点指向一个物理页面，接着一个进程通过自己关联的那个文件写数据，另外一个进程通过自己关联的那个文件读数据。 命名管道（fifo） 管道的通信，要求必须是父子关系的进程间通信，就受到了限制，所以可以用命名管理来解决这个问题。 之前的管道，是没有名字的，所以必须是有父子关系的进程才能使用。但是这个命名管道是有名字的。这个命名管道，相当于是一个有名字的文件，是有路径的，所以没有血缘关系的进程多可以通过这个命名管道来通信，名字在文件系统上，数据在内存里。其他的跟管道一样，一个进程写，一个进程读，也是半双工的，数据只能单向流动。 消息队列 linux的消息队列可以认为是个链表结构，linux内核有一个msgque链表，这个链表里每个指针指向一个msgid_ds结构，这个结构就描述了一个消息队列。然后进程之间就通过这个消息队列通信就可以，一样是写入数据和消费数据。消息队列的好处就是对每个消息可以指定类型，消费的时候就消费指定类型的消息就行了，功能更多一些。这种方式其实用的不多的。 共享内存 一块物理内存被映射到两个进程的进程地址空间，所以进程之间互相都可以立即看到对方在共享内存里做出的修改，但是因为是共享内存，所以需要锁来保证同步。这个说对了很复杂，我在这里就不多说了，我觉得如果被人问到这个问题，短期内突击的话，回答到这个程度就行了，就是知道有哪些方式。如果你要深入理解各种机制，那是要好好学习linux的各种东西了。 ","link":"https://panson.top/post/liao-liao-jin-cheng-jian-tong-xin/"},{"title":"老生常谈：TCP 三次握手、四次挥手","content":"本文图解讲述 TCP 三次握手、四次挥手流程，扩展添加了对应的高频面试题。文中所有的网格图都使用 draw.io 制作。 先看看 TCP 报文格式： TCP FLAG 位由 bit 组成，分别代表 ACK、SYN、FIN、URG、PSH、RST ，都以置 1 表示有效。在三次握手和四次挥手中我们重点关注 SYN、ACK、FIN。 SYN ( Synchronize Sequence Numbers ）用作建立连接时的同步信号； ACK (Acknowledgement ）用于对收到的数据进行确认，所确认的数据由确认序列号表示； FIN ( Finish ）表示后面没有数据需要发送，通常意昧着所建立的连接需要关闭了。 在三次握手中，流程如下： A 机器发出一个数据包并将 SYN 置为 1，表示希望建立连接。这个包中的序列号假设是 x。 B 机器收到 A 机器发过来的数据包后，通过 SYN = 1 得知这是一个建立连接的请求，于是发送一个响应包并将 SYN ACK 标记都置为 1。假设这个包中的序列号是 y，而确认序列号必须是 x+1 ，表示收到了 A 发过来的 SYN。在 TCP 中， SYN 被当作数据部分的一个字节。 A 收到 B 的响应包后需进行确认，确认包中将 ACK 置为 1 ，并将确认序列号置为 y + 1，表示收到了来自 B 的 SYN。 为什么需要三次握手？如果是两次握手又会有什么问题？ 信息对等 脏连接 四次挥手： 四次挥手释放连接时，等待2MSL的意义？ 确认被动关闭方能够顺利进入 CLOSED 状态 防止失效请求 ","link":"https://panson.top/post/lao-sheng-chang-tan-tcp-san-ci-wo-shou-si-ci-hui-shou/"},{"title":"JDK 源码阅读011：ReentrantReadWriteLock","content":" 1 引言 2 写锁实现原理 3 可重入写锁实现原理 4 读写锁的护互斥实现原理 1 引言 读写锁，可以加读锁，也可以加写锁。 读锁和写锁是互斥的，也就是说，你加了读锁之后，就不能加写锁；如果加了写锁，就不能加读锁。但是如果有人加了读锁之后，别人可以同时加读锁。 如果你有一份数据，有人读，有人写，如果你全部都是用synchronized的话，会导致如果多个人读，也是要串行化，一个接一个的读。我们希望的效果是多个人可以同时来读，如果使用读锁和写锁分开的方式，就可以让多个人来读数据，多个人可以同时加读锁。 小结： 如果有人在读数据，就不能有人写数据，读锁 -&gt; 写锁 -&gt; 互斥 如果有人在写数据，别人不能写数据，写锁 -&gt; 写锁 -&gt; 互斥；如果有人在写数据，别人也不能读数据，写锁 -&gt; 读锁 &gt; 互斥 2 写锁实现原理 protected final boolean tryAcquire(int acquires) { /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); // 获取到一个state = 0 int c = getState(); // // w，剧透一下，人家读写锁，非常聪明的利用state的值 // 二进制值里面的高低16位分别代表了读锁和写锁，AQS就一个，state // state二进制值的高16位代表了读锁，低16位代表了写锁 // 可以认为下面的w就是从c（二进制值）通过位运算 // 获取到了state的低16位，代表了写锁的状态 int w = exclusiveCount(c); // 如果c != 0，说明有人加过锁，但是此时c = 0 if (c != 0) { // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire setState(c + acquires); return true; } // 非公平锁，此时一定会去尝试加锁 // 如果是公平锁，此时会判断如果队列中有等待线程，就不加锁 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; } static int exclusiveCount(int c) { return c &amp; EXCLUSIVE_MASK; } static final int SHARED_SHIFT = 16; static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1; 3 可重入写锁实现原理 protected final boolean tryAcquire(int acquires) { Thread current = Thread.currentThread(); // 获取到一个state = 1 int c = getState(); int w = exclusiveCount(c); // 如果c != 0，说明有人加过锁，但是此时c = 0 if (c != 0) { // c != 0，w == 0，c肯定不是0，但是低16位是0，说明有人加了读锁，没有人加写锁， // 此时你要加写锁，而且你还不是之前加锁的那个线程，加锁失败 if (w == 0 || current != getExclusiveOwnerThread()) return false; // 走到这里说明：加了写锁且之前是当前线程加的锁 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); // 加锁成功，设置值 setState(c + acquires); return true; } if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; } 4 读写锁的护互斥实现原理 protected final int tryAcquireShared(int unused) { /* * Walkthrough: * 1. If write lock held by another thread, fail. * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ Thread current = Thread.currentThread(); int c = getState(); // 已经被别的线程加写锁，加锁失败 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) { if (r == 0) { firstReader = current; firstReaderHoldCount = 1; } else if (firstReader == current) { firstReaderHoldCount++; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; } return 1; } return fullTryAcquireShared(current); } ","link":"https://panson.top/post/jdk-yuan-ma-yue-du-011reentrantreadwritelock/"},{"title":"JDK 源码阅读010：ReentrantLock ","content":" 1 引言 2 构造函数 3 AQS基于无锁化的CAS机制实现高性能的加锁 3.1 lock 方法 3.2 compareAndSetState() 3.3 setExclusiveOwnerThread() 4 可重入性实现原理 5 非公平锁与公平锁 6 tryLock() 7 可重入锁释放锁的流程 1 引言 关于 ReentrantLock，有太多可以讨论的东西，捋一捋，循循渐进的话，我们先看以下几点： ReentrantLock 底层基于 AQS 实现 AQS 底层又是基于 CAS 实现的 可重入锁的实现原理 2 构造函数 public ReentrantLock() { sync = new NonfairSync(); } public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } 默认的构造函数这里，创建了一个Sync，FairSync 和 NonfairSync 两者看起来是一个非常关键的组件，其实 NonfairSync 和 FairSync 都是 Sync 的子类，覆盖重写了几个方法，没什么特别的东西在里面，大概代表了一个Sync的具体实现。 我们继续往下看。 3 AQS基于无锁化的CAS机制实现高性能的加锁 3.1 lock 方法 再看一下核心方法： lock 方法 public void lock() { sync.lock(); } ReentrantLock 在进行加锁的时候，他其实是直接基于底层的 Sync 来实现的 lock 操作，这样看来，我们还需要再看看 Sync 的底层源码实现。 abstract static class Sync extends AbstractQueuedSynchronizer { // …… } Sync 是一个抽象的静态内部类，也是 AQS 的子类，AQS 是 Java 并发包各种并发工具（锁、同步器）的底层的基础性的组件 AQS 里关键的一些东西，一个是Node（自定义数据结构，可以组成一个双向链表，也就是所谓的一个队列），另一个是 state（核心变量，加锁、释放锁都是基于state来完成的）。 AQS 底层加锁、释放锁，都是大量的基于CAS的操作来实现的，底层是基于 NonfairSync 的 lock 操作来实现加锁的。 final void lock() { // 见 3.2 小节 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } 3.2 compareAndSetState() /** * 返回值为 true 代表加锁成功 */ protected final boolean compareAndSetState(int expect, int update) { return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } AQS里有一个核心的变量，state，代表了锁的状态；看一下state是否是0，如果是0的话，代表没人加过锁，此时当前线程就可以加锁，把这个state设置为1。 CAS 可以无锁化地保证一个数值修改的原子性。 compareAndSetState(0, 1)相当于是在尝试加锁，底层原来是基于Unsafe来实现的，JDK内部使用的API，基于cpu指令实现原子性的CAS（Atomic原子类底层也是基于 Unsafe 来实现的CAS操作）。 上面这行代码可以保证：在一个原子操作中，如果发现值是我们期望的这个expect值，说明符合要求，没人修改过，此时可以将这个值设置为update，state如果是0的话，就修改为1，代表加锁成功了，这个操作是CAS原子性的。 如果加锁成功了，compareAndSetState(0, 1)返回的是true，此时就说明加锁成功，它需要设置一下自己是当前加锁的线程。 关于 stateOffset，可以看看初始化的代码块： private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long stateOffset; private static final long headOffset; private static final long tailOffset; private static final long waitStatusOffset; private static final long nextOffset; static { try { stateOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(&quot;state&quot;)); headOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(&quot;head&quot;)); tailOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(&quot;tail&quot;)); waitStatusOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(&quot;waitStatus&quot;)); nextOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(&quot;next&quot;)); } catch (Exception ex) { throw new Error(ex); } } 3.3 setExclusiveOwnerThread() setExclusiveOwnerThread(Thread.currentThread())：设置当前线程自己是加了一个独占锁的线程，标识出来自己是加锁的线程。 /** * 这个方法是 AQS 的父类 AbstractOwnableSynchronizer 的方法 */ protected final void setExclusiveOwnerThread(Thread thread) { exclusiveOwnerThread = thread; } 4 可重入性实现原理 假设线程 1 已经获得锁了，此时线程1再次进入，会是怎样的流程。 如果是一个线程可重入的加锁会是什么样子呢？是如何来实现的呢？ compareAndSetState(0, 1)：这个方法一定是false，会失败，此时state = 1，不是0，CAS操作会失败，返回false，此时会执行acquire(1) 方法，这个方法时 AQS 的方法。 public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } tryAcquire(1)：此时首先会走这个方法，传递进去一个值是1，AQS的父类实现是一个空，其实是留给子类来实现的 protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); } nonfairTryAcquire(1)：这个方法会走到Sync（父类） final boolean nonfairTryAcquire(int acquires) { // 先获取到当前的线程 -&gt; 线程1 final Thread current = Thread.currentThread(); // 获取state变量值的过程，JDK源码里大量的运用了volatile，可见性的问题，保证一些关键变量，修改 -&gt; 读取的可见性 int c = getState(); // 为什么会有这段代码呢？其实进入到这里，代表他之前一定是看到state != 0，才会进入到这里 // 就是人家代码的健壮性，怕的是之前state != 0，所以加锁失败了，但是进入到这里，人家再次判断一下，如果state是0，那么再次尝试加锁，就怕中间有人释放了锁 if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } // 也就是说没有人释放锁，state != 0 // 再次判断，如果执行这个方法的线程 = exclusiveOwnerThread（加锁的线程） // 代表的就是一个线程在可重入的加锁 // 之前他自己加过锁，然后在这里他就再次加锁 else if (current == getExclusiveOwnerThread()) { // 此时，c = 1 // nextc = c(1) + acquires(1) = 2 // 其实就是代表了一个线程可重入加锁了1次，2代表了加锁的次数 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); // 修改这个state的值，volatile保证了可见性 setState(nextc); return true; } return false; } 假设线程2过来尝试加锁，此时的源码会如何走向呢？ final boolean nonfairTryAcquire(int acquires) { // 先获取到当前的线程 -&gt; 线程1 final Thread current = Thread.currentThread(); // 获取state变量值的过程，JDK源码里大量的运用了volatile，可见性的问题，保证一些关键变量，修改 -&gt; 读取的可见性 int c = getState(); // 为什么会有这段代码呢？其实进入到这里，代表他之前一定是看到state != 0，才会进入到这里 // 就是人家代码的健壮性，怕的是之前state != 0，所以加锁失败了，但是进入到这里，人家再次判断一下，如果state是0，那么再次尝试加锁，就怕中间有人释放了锁 if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } // 也就是说没有人释放锁，state != 0 // 再次判断，如果执行这个方法的线程 = exclusiveOwnerThread（加锁的线程） // 代表的就是一个线程在可重入的加锁 // 之前他自己加过锁，然后在这里他就再次加锁 else if (current == getExclusiveOwnerThread()) { // 此时，c = 1 // nextc = c(1) + acquires(1) = 2 // 其实就是代表了一个线程可重入加锁了1次，2代表了加锁的次数 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); // 修改这个state的值，volatile保证了可见性 setState(nextc); return true; } // 如果已经有一个线程加了锁，其他线程此时会走到这里 // 此时方法认为加锁失败，返回false return false; } public final void acquire(int arg) { // 此时加锁失败，第一个条件是false // 开始走第二个条件，调用acquireQueued()方法 // 将当前线程入队阻塞等待 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } addWaiter(Node.EXCLUSIVE)：EXCLUSIVE（排他性，独占锁，同一时间只能有一个线程获取到锁，此时是排他锁，独占锁） 将当前线程（线程2）封装成了一个Node，mode = EXCLUSIVE（排他锁，尝试获取一个排他锁，但是失败了）， Node 是 AQS 里面的一个静态内部类，核心属性： /** * 如果一个线程无法获取到锁的话，会进入一个阻塞等待的状态 * 卡住不动，线程挂起，阻塞状态又细分为很多种不同的阻塞状态： * CANCELED、SIGNAL、CONDITION、PROPAGATE */ volatile int waitStatus; /** * 一个节点可以有上一个节点，prev指针，指向了Node的上一个Node */ volatile Node prev; /** * 一个节点还可以有下一个节点，next指针，指向了Node的下一个Node */ volatile Node next; /** * Node里面封装了一个线程 */ volatile Thread thread; /** * 可以认为是下一个等待线程 */ Node nextWaiter; 对于获取不到锁，处于等待状态的线程，会被封装为一个Node，最后多个处于阻塞等待状态的线程可以封装为一个Node双向链表，这也是为什么被叫做抽象队列同步器的原因。 // 最后返回的事线程 2 对应的 node private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; // 尝试比较tail变量是否为t，如果为t的话，那么tail指针就指向node if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); return node; } // pred 为 null，则无限 for 循环 private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize // 为 null 初始化 head，并将 tail 也指向 head if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; // 尝试比较tail变量是否为t，如果为t的话，那么tail指针就指向传参进来的 node if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } private final boolean compareAndSetHead(Node update) { return unsafe.compareAndSwapObject(this, headOffset, null, update); } private final boolean compareAndSetTail(Node expect, Node update) { return unsafe.compareAndSwapObject(this, tailOffset, expect, update); } headOffset -&gt; 在AQS类里，head变量所在的位置，CAS操作的，判断一下，head变量是否为null，如果是null的话，就将head设置为空Node节点 compareAndSetTail(t, node)：尝试比较tail变量是否为t，如果为t的话，那么tail指针就指向node final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { // 获取到node的上一个节点 // prev指针指向的节点 final Node p = node.predecessor(); // 这个地方，其实会再次调用tryAcquire方法尝试加锁 // 如果加锁成功，其实是会将线程2对应的Node从队列中移除 if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } // 如果说再次尝试加锁失败了 // 那么此时会判断一下，是否需要将当前线程挂起，阻塞等待 // 如果是需要的话，此时就会使用park操作挂起当前线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { // pred -&gt; 空Node // 默认情况下，watiStatus应该是0，或者是空 int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 将空Node的waitStatus设置为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } private final boolean parkAndCheckInterrupt() { // LockSupport的park操作，就是将一个线程进行挂起，不让你动了 // 必须得有另外一个线程来对当前线程执行unpark操作，唤醒挂起的线程 LockSupport.park(this); return Thread.interrupted(); } public final void acquire(int arg) { // 先尝试加锁 // 如果加锁失败，addWaiter()方法将自己挂到队列中去 // 接着acquireQueued()方法负责park操作挂起当前线程，阻塞等待 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 5 非公平锁与公平锁 ReentrantLock 默认是非公平锁。不遵循先来先加锁的原则，可以竞争。 公平锁则保证先来先加锁，按照顺序排队来加锁。 if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } 公平锁的核心，就是一行代码，每次加锁的时候，都要先判断一下，如果前面没有排队等待的线程的话，那就尝试加锁，否则是不能尝试加锁的。 public final boolean hasQueuedPredecessors() { // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; // h != t，如果h != t，说明head和tail不一样，如果一样代表了队列里有人在排队 return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); } h != t，如果h != t，说明head和tail不一样，如果一样还要接着判断； 但是如果说head的下一个节点是null，说明没人在排队，因为有一个是null，所以此时也是返回true； 或者是s，也就是排在队头的节点，队头节点的线程如果不是当前线程，所以此时也是返回true。 公平锁，任何一个线程过来会先判断一下，当前是否有人在排队，而且是不是自己在排队，如果不是的话，说明有别人在排队，此时自己不能尝试加锁，直接入队阻塞等待。 6 tryLock() 这一小节我们来看看 tryLock 是如何实现加锁等待一段时间过后并放弃的。 方法调用流程： public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(timeout)); } public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout); } private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return true; } nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); 核心的流程是这样的：先尝试加锁，加锁失败放到队列里，并设置一个过期时间，如果过了过期时间，会尝试再次加锁，如果加锁失败，就返回 false。 7 可重入锁释放锁的流程 方法调用链路： public void unlock() { sync.release(1); } 走到 AQS 里面 public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } // ReentrantLock 的方法，核心思想是判断 state - 1 是否等于 0，等于 0 则返回 true，否则返回 false protected final boolean tryRelease(int releases) { int c = getState() - releases; // 当前线程不等于加锁的线程，说明不是你加的锁，结果你来释放锁 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free; } private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) { s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } if (s != null) LockSupport.unpark(s.thread); } 此时我们可以看到，会唤醒处于队头的元素。也就是说如果一个线程来释放锁的话，他除了更新state和锁占有线程以外，他其实主要干的一个事儿就是用 LockSupport 的 unpark 操作唤醒了一个处于队头的一个线程。 队头线程此时被unpark唤醒之后会干什么？我们可以看 parkAndCheckInterrupt() 方法： private final boolean parkAndCheckInterrupt() { // 某一个线程其实是在这里会被挂起 LockSupport.park(this); return Thread.interrupted(); } 如果一旦被unpark唤醒之后，就会在这里苏醒过来，重新进入一个for循环里面 for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } 此时线程2会再次尝试去获取锁，因为他是队头线程，他的上一个节点一定就是那个head指针指向的节点了 ","link":"https://panson.top/post/jdk-yuan-ma-yue-du-010reentrantlock/"},{"title":"JDK 源码阅读009：AtomicInteger","content":" 1 引言 2 先聊聊 Unsafe 类 3 核心属性 4 核心方法 4.1 compareAndSet()方法 4.2 getAndIncrement()方法 5 CAS 的缺陷 5.1 ABA 问题 5.2 无限循环问题 5.3 多变量原子问题 1 引言 我们在日常的开发中，经常会使用 i++， 但是在并发环境下 i++是非线程安全的，此时我们可以使用 AtomicInteger 来保证线程安全性。 Atomic原子类底层核心的原理就是 CAS（Compare and Set），每次尝试修改的时候，就对比一下，有没有人修改过这个值，没有人修改，自己就修改，如果有人修改过，就重新查出来最新的值，再次重复这个过程。 2 先聊聊 Unsafe 类 Unsafe类是在 JDK 底层的一个类，底层限制不允许开发者直接实例化以及使用里面的方法。 private Unsafe() { } 构造函数是私有的，不可以直接进行实例化，其次，如果用Unsafe.getUnsafe()方法来获取一个实例是不行的，它会判断一下，如果当前是属于我们的用户的应用系统，识别到有用户的类加载器以后，就会报错，不让获取实例。 当然，我们其实可以使用反射来改变访问权限。 @CallerSensitive public static Unsafe getUnsafe() { Class var0 = Reflection.getCallerClass(); if (!VM.isSystemDomainLoader(var0.getClassLoader())) { throw new SecurityException(&quot;Unsafe&quot;); } else { return theUnsafe; } } Unsafe 类是JDK自己内部使用的，不是对外的。 Unsafe，封装了一些不安全的操作，指针相关的一些操作，就是比较底层了，Atomic原子类底层大量的运用了Unsafe。 JUC下面大量使用了CAS操作，它们的底层是调用的Unsafe的 CompareAndSwapXXX()方法。这种方式广泛运用于无锁算法，与java中标准的悲观锁机制相比，它可以利用CAS处理器指令提供极大的加速。 3 核心属性 AtomicInteger 核心属性主要包括： unsafe 实例 valueOffset：标识value字段的偏移量 value：存储int类型值的地方，使用volatile修饰 // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; private volatile int value; Unsafe 类中使用静态代码块来初始化 valueOffset，valueOffset 表示 value 这个字段具体是在 AtomicInteger 这个类的哪个位置，offset 即偏移量，底层是通过unsafe来实现的。在类初始化的时候，就会完成这个操作，一旦初始化完毕，就不会再变更了。 static { try { valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } 4 核心方法 4.1 compareAndSet()方法 public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } // Unsafe 类中的方法 public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 调用Unsafe.compareAndSwapInt()方法实现，这个方法有四个参数： （1）操作的对象； （2）对象中字段的偏移量； （3）原来的值，即期望的值； （4）要修改的值； 可以看到，这是一个native方法，底层是使用C/C++写的，主要是调用CPU的CAS指令来实现，它能够保证只有当对应偏移量处的字段值是期望值时才更新，即类似下面这样的两步操作： if(value == expect) { value = newValue; } 通过CPU的CAS指令可以保证这两步操作是一个整体，也就不会出现多线程环境中可能比较的时候value值是a，而到真正赋值的时候value值可能已经变成b了的问题。 4.2 getAndIncrement()方法 public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1); } // Unsafe 类中的方法 public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; } getAndIncrement()方法底层是调用的Unsafe的getAndAddInt()方法，这个方法有三个参数： （1）操作的对象； （2）对象中字段的偏移量； （3）要增加的值； 查看Unsafe的getAndAddInt()方法的源码，可以看到它是先获取当前的值，然后再调用compareAndSwapInt()尝试更新对应偏移量处的值，如果成功了就跳出循环，如果不成功就再重新尝试，直到成功为止，这可不就是（CAS+自旋）的乐观锁机制么^^ AtomicInteger中的其它方法几乎都是类似的，最终会调用到Unsafe的compareAndSwapInt()来保证对value值更新的原子性。 5 CAS 的缺陷 5.1 ABA 问题 如果某个值一开始是A，后来变成了B，然后又变成了A，你本来期望的是值如果是第一个A才会设置新值，结果第二个A一比较也符合条件，也设置了新值，这跟期望是不符合的。所以atomic包里有 AtomicStampedReference 类，就是会比较两个值的引用是否一致，如果一致，才会设置新值。 举个例子：假设一开始变量i = 1，你先获取这个i的值是1，然后累加了1，变成了2。但是在此期间，别的线程将i -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 1。这个期间，这个值是被人改过的，只不过最后将这个值改成了跟你最早看到的值一样的值。结果你后来去compareAndSet的时候，会发现这个i还是1，就将它设置成了2，就设置成功了。 不过 AtomicInteger 常见使用场景的是计数，所以说一般是不断累加的，所以ABA问题比较少见 5.2 无限循环问题 大家看源码就知道Atomic类设置值的时候会进入一个无限循环，只要不成功，就不停循环再次尝试，这个在高并发修改一个值的时候其实挺常见的，比如你用AtomicInteger在内存里搞一个原子变量，然后高并发下，多线程频繁修改，其实可能会导致这个compareAndSet()里要循环N次才设置成功，所以还是要考虑到的。 JDK 1.8引入的LongAdder来解决，采用了分段 CAS 思路。 5.3 多变量原子问题 一般的AtomicInteger，只能保证一个变量的原子性，但是如果多个变量呢？你可以用 AtomicReference，这个是封装自定义对象的，多个变量可以放一个自定义对象里，然后他会检查这个对象的引用是不是一个。 ","link":"https://panson.top/post/jdk-yuan-ma-yue-du-009atomicinteger/"},{"title":"JDK 源码阅读008：synchronized 关键字","content":" 1 synchronized 常见使用方式 1.1 synchronized 修饰普通方法 1.2 synchronized 修饰 this 对象 1.3 synchronized 修饰一个静态方法 2 synchronized 底层如何保证原子性 2.1 从字节码角度聊聊 synchronized 关键字 2.2 synchronized 可重入性在字节码上的表现形式 2.3 synchronized 可重入的加锁与释放锁流程 2.4 monitor 对 wait 和 notify 的支持 3 保证可见性和有序性 4 锁消除、锁粗化、偏向锁、轻量级锁、适应锁 4.1 锁消除 4.2 锁粗化 4.3 偏向锁 4.4 轻量级锁 4.5 适应锁 1 synchronized 常见使用方式 synchronized 在使用的时候，为了更细粒度地控制加锁的范围，以达到更高的并发效率，需要开发人员熟悉 sychronized 常用的使用方式以及每种方式对应的范围。 synchronized 锁包含两个方面：一种是对某个实例对象加锁，另外一种是对这个类进行加锁。对类加锁，也是在针对一个对象实例进行加锁，其实他的意思就是对那个类的Class对象进行加锁。 总而言之，synchronized 可以对两种对象加锁， 对象实例 Class 对象 1.1 synchronized 修饰普通方法 synchronized 修饰普通方法，那么就是对当前这个对象实例在加锁，访问同一个对象实例的synchronized方法，同一时间只有一个线程可以做到，如果是下面那种synchronized代码片段，也是这个意思。 synchronized(myObject) { // do something } 但是如果是两个线程，分别进入不同的对象的synchronized方法或者代码片段，这两个线程并不会互相干扰，因为是在不同的对象上加锁。 1.2 synchronized 修饰 this 对象 我们也可以使用 synchronized 来修饰 this 对象，其实意思就是基于当前这个对象实例来加锁，如下代码所示： synchronized(this) { // do something } 1.3 synchronized 修饰一个静态方法 synchronized 修饰一个静态方法，就是对这个类的Class对象加锁，每个类都对应了一个Class对象，那么对同一个类的synchronized静态方法，同一时间只能有一个线程加锁进入其中，下面的那个代码片段，也是这个意思： synchronized(MyObject.class) { } synchronized 能保证原子性、有序性和可见性。下面从分析一下 synchronized 是如何从底层实现这三个特性的。 2 synchronized 底层如何保证原子性 2.1 从字节码角度聊聊 synchronized 关键字 其实 synchronized 底层的原理，是跟 jvm 指令和 monitor 有关系的。先大致说几个概念，后面我们再解释。 monitor 对象 反编译工具：javap monitorenter 和 monitorexit 指令 可重入锁 你如果用到了synchronized关键字，在底层编译后的jvm指令中，会有monitorenter和monitorexit两个指令 monitorenter // 代码对应的指令 monitorexit 我们可以来看个示例，如下为一个最简单的代码示例： public class Test { public static void main(String[] args) { synchronized (Test.class) { System.out.println(&quot;hello world&quot;); } } } 编译之后得到 Test.class 文件，我们可以使用内置的反编译工具 javap来看看具体的内容： javap 命令的具体使用方法我在这里也列一下，也可以使用 javap -help 来查看： 用法: javap &lt;options&gt; &lt;classes&gt; 其中, 可能的选项包括: -help --help -? 输出此用法消息 -version 版本信息 -v -verbose 输出附加信息 -l 输出行号和本地变量表 -public 仅显示公共类和成员 -protected 显示受保护的/公共类和成员 -package 显示程序包/受保护的/公共类 和成员 (默认) -p -private 显示所有类和成员 -c 对代码进行反汇编 -s 输出内部类型签名 -sysinfo 显示正在处理的类的 系统信息 (路径, 大小, 日期, MD5 散列) -constants 显示最终常量 -classpath &lt;path&gt; 指定查找用户类文件的位置 -cp &lt;path&gt; 指定查找用户类文件的位置 -bootclasspath &lt;path&gt; 覆盖引导类文件的位置 执行命令javap -verbose -p Test.class，这里限于篇幅我只截取了部分输出结果： public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: ldc #2 // class com/panson/Test 2: dup 3: astore_1 4: monitorenter 5: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 8: ldc #4 // String hello world 10: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 13: aload_1 14: monitorexit 15: goto 23 18: astore_2 19: aload_1 20: monitorexit 21: aload_2 22: athrow 23: return 可以定位到： 4: monitorenter 5: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 8: ldc #4 // String hello world 10: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 13: aload_1 14: monitorexit 确实是使用了 monitorenter 和 monitorexit 两个指令。 那么monitorenter指令执行的时候会干什么呢？ 每个对象都有一个关联的 monitor，比如一个对象实例就有一个monitor，一个类的Class对象也有一个monitor，如果要对这个对象加锁，那么必须获取这个对象关联的monitor的lock锁 底层原理和思路大概是这样的：monitor里面有一个计数器，从0开始的。如果一个线程要获取monitor的锁，就看看他的计数器是不是0，如果是 0 的话，那么说明没人获取锁，他就可以获取锁了，然后对计数器加 1。 2.2 synchronized 可重入性在字节码上的表现形式 我们还是使用一个简单的代码示例，来看看反编译之后的代码有什么不一样，在该代码示例中，我们使用了两层加锁机制。 代码示例： public class Test { public static void main(String[] args) { synchronized (Test.class) { System.out.println(&quot;hello world&quot;); synchronized (Test.class) { System.out.println(&quot;peace&quot;); } } } } 反编译之后的代码： public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=5, args_size=1 0: ldc #2 // class com/panson/Test 2: dup 3: astore_1 4: monitorenter 5: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 8: ldc #4 // String hello world 10: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 13: ldc #2 // class com/panson/Test 15: dup 16: astore_2 17: monitorenter 18: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 21: ldc #6 // String peace 23: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 26: aload_2 27: monitorexit 28: goto 36 31: astore_3 32: aload_2 33: monitorexit 34: aload_3 35: athrow 36: aload_1 37: monitorexit 38: goto 48 41: astore 4 43: aload_1 44: monitorexit 从反编译之后的代码可以看到，monitorenter 和 monitorexit 各自出现了两次，对应着两次 synchronized。可重入锁的直观展示便如上述代码所示。 2.3 synchronized 可重入的加锁与释放锁流程 synchronized(myObject) { // do something synchronized(myObject) { // do something } } 如果一个线程第一次synchronized那里，获取到了 myObject 对象的 monitor 的锁，计数器加 1 ，然后第二次 synchronized 那里，会再次获取 myObject 对象的 monitor 的锁，这个就是重入加锁了，然后计数器会再次加 1，变成 2。 这个时候，其他的线程在第一次synchronized那里，会发现说myObject对象的monitor锁的计数器是大于0的，意味着被别人加锁了，然后此时线程就会进入block阻塞状态，什么都干不了，就是等着获取锁。 接着如果出了synchronized修饰的代码片段的范围，就会有一个monitorexit的指令。此时获取锁的线程就会对那个对象的monitor的计数器减1，如果有多次重入加锁就会对应多次减1，直到最后，计数器是0。 然后后面block住阻塞的线程，会再次尝试获取锁，但是只有一个线程可以获取到锁。 总结：sychronized 从底层来说，就是在进入加锁代码块的时候加一个monitorenter的指令，然后针对锁对象关联的monitor累加加锁计数器，同时标识自己这个线程加了锁，同时通过monitor里的加锁计数器可以实现可重入的加锁。 2.4 monitor 对 wait 和 notify 的支持 其实wait和notify关键字的实现也是依托于monitor实现的，有线程执行wait之后，自己会加入一个waitset中等待唤醒获取锁，notifyall操作会从monitor的waitset中唤醒所有的线程，让他们竞争获取锁。 MyObject lock = new MyObject(); synchronized(lock) { } Java对象都是分为对象头和实例变量两块的，其中实例变量就是大家平时看到的对象里的那些变量数据。然后对象头包含了两块东西，一个是 Mark Word（包含hashCode、锁数据、GC数据，等等），另一个是 Class Metadata Address（包含了指向类的元数据的指针）。 在Mark Word里就有一个指针，是指向了这个对象实例关联的monitor的地址，这个monitor是c++实现的，不是java实现的。这个monitor实际上是c++实现的一个ObjectMonitor对象。 ObjectMonitor 里面包含了一个 _owner指针，指向了持有锁的线程。 ObjectMonitor 里还有一个 entrylist，想要加锁的线程全部先进入这个entrylist等待获取机会尝试加锁，实际有机会加锁的线程，就会设置_owner指针指向自己，然后对_count计数器累加1次。 各个线程尝试竞争进行加锁，此时竞争加锁是在JDK 1.6以后优化成了基于CAS来进行加锁，理解为跟之前的Lock API的加锁机制是类似的，CAS操作，操作_count计数器，比如说将_count值尝试从0变为1。 然后释放锁的时候，先是对_count计数器递减1，如果为0了就会设置_owner为null，不再指向自己，代表自己彻底释放锁。 如果获取锁的线程执行wait，就会将计数器递减，同时_owner设置为null，然后自己进入waitset中等待唤醒，别人获取了锁执行notify的时候就会唤醒waitset中的线程竞争尝试获取锁。 有人会问，那尝试加锁这个过程，也就是对_count计数器累加操作，是怎么执行的？如何保证多线程并发的原子性呢？很简单，JDk 1.6之后，对synchronized内的加锁机制做了大量的优化，这里就是优化为CAS加锁的。 3 保证可见性和有序性 int b = 0; int c = 0; synchronized(this) { -&gt; monitorenter Load内存屏障 Acquire内存屏障 int a = b; c = 1; =&gt; synchronized代码块里面还是可能会发生指令重排 Release内存屏障 } -&gt; monitorexit Store内存屏障 java的并发技术底层很多都对应了内存屏障的使用，包括synchronized，他底层也是依托于各种不同的内存屏障来保证可见性和有序性的。 按照可见性来划分的话，内存屏障可以分为Load屏障和Store屏障。 Load屏障的作用是执行refresh处理器缓存的操作，说白了就是对别的处理器更新过的变量，从其他处理器的高速缓存（或者主内存）加载数据到自己的高速缓存来，确保自己看到的是最新的数据。 Store屏障的作用是执行flush处理器缓存的操作，说白了就是把自己当前处理器更新的变量的值，都刷新到高速缓存（或者主内存）里去。 在monitorexit指令之后，会有一个Store屏障，让线程把自己在同步代码块里修改的变量的值都执行flush处理器缓存的操作，刷到高速缓存（或者主内存）里去；然后在monitorenter指令之后会加一个Load屏障，执行refresh处理器缓存的操作，把别的处理器修改过的最新值加载到自己高速缓存里来。 所以说通过Load屏障和Store屏障，就可以让synchronized保证可见性。 按照有序性保障来划分的话，还可以分为Acquire屏障和Release屏障。 在monitorenter指令之后，Load屏障之后，会加一个Acquire屏障，这个屏障的作用是禁止读操作和读写操作之间发生指令重排序。 在monitorexit指令之前，会加一个Release屏障，这个屏障的作用是禁止写操作和读写操作之间发生重排序。 所以说，通过 Acquire屏障和Release屏障，就可以让synchronzied保证有序性，只有synchronized内部的指令可以重排序，但是绝对不会跟外部的指令发生重排序。 总结 synchronized： 原子性：加锁和释放锁，ObjectMonitor 可见性：加了Load屏障和Store屏障，释放锁flush数据，加锁会refresh数据 有序性：Acquire屏障和Release屏障，保证同步代码块内部的指令可以重排，但是同步代码块内部的指令和外面的指令是不能重排的 4 锁消除、锁粗化、偏向锁、轻量级锁、适应锁 4.1 锁消除 锁消除是JIT编译器对synchronized锁做的优化，在编译的时候，JIT会通过逃逸分析技术，来分析synchronized锁对象，是不是只可能被一个线程来加锁，没有其他的线程来竞争加锁，这个时候编译就不用加入monitorenter和monitorexit的指令。 这就是，仅仅一个线程争用锁的时候，就可以消除这个锁了，提升这段代码的执行的效率，因为可能就只有一个线程会来加锁，不涉及到多个线程竞争锁。 4.2 锁粗化 synchronized(this) { } synchronized(this) { } synchronized(this) { } 这个意思就是，JIT编译器如果发现有代码里连续多次加锁释放锁的代码，会给合并为一个锁，就是锁粗化，把一个锁给搞粗了，避免频繁多次加锁释放锁。 4.3 偏向锁 这个意思就是说，monitorenter和monitorexit是要使用CAS操作加锁和释放锁的，开销较大，因此如果发现大概率只有一个线程会主要竞争一个锁，那么会给这个锁维护一个偏好（Bias），后面他加锁和释放锁，基于Bias来执行，不需要通过CAS，性能会提升很多。 但是如果有偏好之外的线程来竞争锁，就要收回之前分配的偏好。 4.4 轻量级锁 如果偏向锁没能成功实现，就是因为不同线程竞争锁太频繁了，此时就会尝试采用轻量级锁的方式来加锁，就是将对象头的Mark Word里有一个轻量级锁指针，尝试指向持有锁的线程，然后判断一下是不是自己加的锁，如果是自己加的锁，那就执行代码就好了，如果不是自己加的锁，那就是加锁失败，说明有其他人加了锁，这个时候就是升级为重量级锁。 4.5 适应锁 这是JIT编译器对锁做的另外一个优化，如果各个线程持有锁的时间很短，那么一个线程竞争锁不到，就会暂停，发生上下文切换，让其他线程来执行。但是其他线程很快释放锁了，然后暂停的线程再次被唤醒。也就是说在这种情况下，线程会频繁的上下文切换，导致开销过大。所以对这种线程持有锁时间很短的情况，是可以采取忙等策略的，也就是一个线程没竞争到锁，进入一个while循环不停等待，不会暂停不会发生线程上下文切换，等到机会获取锁就继续执行好了。 这样可以大幅度减少线程上下文的切换，而这种自旋等待获取锁的方式，就是所谓自旋锁，就是不断的自旋尝试获取锁。 如果一个线程持有锁的时间很长，那么其他线程获取不到锁，就会暂停，发生上下文切换，让其他线程来执行，这种自己暂停获取锁的方式，就是所谓的重量级锁。这个根据不同情况自动调整的过程，就是适应锁的意思。 ","link":"https://panson.top/post/lao-sheng-chang-tan-sychronized-di-ceng-yuan-li/"},{"title":"JDK 源码阅读007：volatile 关键字","content":" 1 引言 2 CPU 缓存模型 3 MESI 4 Java 内存模型 5 可见性、原子性、顺序性 6 happens-before 原则 7 volitile 底层实现原理：lock 指令以及内存屏障 7.1 volatile 是如何保证可见性的 7.2 volatile 是如何保证有序性的 8 经典的双重检查锁 1 引言 多个线程共用一个共享变量，会遇到并发读写的问题，volatile 关键字就是来解决这个问题的。 本文将会从以下几个方面来讲解 volatile： cpu 缓存模型 Java 内存模型 原子性、可见性、有序性 volatile 的作用 volatile 的底层原理 2 CPU 缓存模型 现代的计算机技术，内存的读写速度没什么突破，cpu如果要频繁的读写主内存的话，会导致性能较差，计算性能就会低，不适应现代计算机技术的发展，于是又在 CPU 中加了几层缓存，如下图所示： 这样 CPU 可以直接操作自己对应的高速缓存，不需要直接频繁的跟主内存通信，这样可以保证 cpu 的计算效率。 但是这样会产生并发问题：假设某个时刻 CPU a 更新了本地缓存的 flag，但此时还没更新到主内存，CPU b 此时读取到的值还是旧值。这便产生了一致性的问题。 其实上述场景只是并发问题中的一个，本质上都是因为各个 CPU 的本地缓存跟主内存之间没有同步，一个数据，在各个地方，可能都不一样，这样就导致了数据的不一致。 3 MESI 对于这个缓存不一致的问题，在计算机上古时期，采用了一种总线加锁机制。简单来说就是，某个cpu如果要修改一个数据，会通过一个总线，对这个数据加一个锁，其他的cpu就没法去读和写这个数据了，只有当这个cpu修改完了以后，其他 cpu 才可以读到最新的数据。 但这种总线加锁机制显然太过粗暴，可以想象的是，如果并发数比较大，那么效率肯定很低。 现在计算机流行的是 MESI 协议： 缓存行有4种不同的状态: 已修改Modified (M) 缓存行是脏的（dirty），与主存的值不同。如果别的CPU内核要读主存这块数据，该缓存行必须回写到主存，状态变为共享(S). 独占Exclusive (E) 缓存行只在当前缓存中，但是干净的（clean）--缓存数据同于主存数据。当别的缓存读取它时，状态变为共享；当前写数据时，变为已修改状态。 共享Shared (S) 缓存行也存在于其它缓存中且是干净的。缓存行可以在任意时刻抛弃。 无效Invalid (I) 缓存行是无效的 线程修改了缓存行，会刷到主内存中，CPU 会采用嗅探机制，将其他 CPU 的对应缓存行设置为无效状态，强制其他 CPU 从主内存中读取最新的值。 通过这样的机制，我们才能保证线程工作内存和主内存是一致的。 4 Java 内存模型 Java内存模型是跟cpu缓存模型是类似的，基于cpu缓存模型来建立的java内存模型，只不过java内存模型是标准化的，屏蔽掉底层不同的计算机的区别。 首先我们来看看几个概念： read：从主存读取 load：将主存读取到的值写入工作内存 use：从工作内存读取数据来计算 assign：将计算好的值重新赋值到工作内存中 store：将工作内存数据写入主存 write：将store过去的变量值赋值给主存中的变量 可以参考下图来记忆： 5 可见性、原子性、顺序性 可见性：前述问题讲述了主内存和工作内存中最新修改的值不可见的问题，其实就是可见性的问题，voilatile 可以解决此问题。 原子性：volatile 一般意义上并不能保证原子性（i++ 的操作不是原子性操作）。 有序性：还有一个问题是指令重排序，编译器和指令器，有的时候为了提高代码执行效率，会将指令重排序，就是说比如下面的代码 flag = false; // 线程1: prepare(); // 准备资源 flag = true; //线程2: while(!flag){ Thread.sleep(1000); } execute(); // 基于准备好的资源执行操作 重排序之后，让flag = true先执行了，会导致线程2直接跳过while等待，执行某段代码，结果prepare()方法还没执行，资源还没准备好呢，此时就会导致代码逻辑出现异常。 6 happens-before 原则 上文说过，编译器、指令器可能会对代码进行重排序，但是不能乱排，要遵守一定的规则，这个规则就是 happens-before 原则，只要符合 happens-before 的原则，那么就不能胡乱重排，反之，那就可以进行重排序。 happens-before原则： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作。volatile变量写，再是读，必须保证是先写，再读。 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 7 volitile 底层实现原理：lock 指令以及内存屏障 前文已经讲述过，volatile 可以保证可见性和有序性，那么留给我们的就有两个问题： volatile 是如何保证可见性的？ volatile 是如何保证有序性的？ 7.1 volatile 是如何保证可见性的 对 volatile 修饰的变量，执行写操作的话，JVM会发送一条lock前缀指令给CPU，CPU在计算完之后会立即将这个值写回主内存，同时因为有MESI缓存一致性协议，所以各个CPU都会对总线进行嗅探，自己本地缓存中的数据是否被别人修改。 如果发现别人修改了某个缓存的数据，那么CPU就会将自己本地缓存的数据过期掉，然后这个CPU上执行的线程在读取那个变量的时候，就会从主内存重新加载最新的数据了。 7.2 volatile 是如何保证有序性的 Java 内存模型里有 4 种内存屏障。 LoadLoad StoreStore LoadStore StoreLoad Load1： int localVar = this.variable LoadLoad屏障 Load2： int localVar = this.variable2 LoadLoad屏障：Load1；LoadLoad；Load2，确保Load1数据的装载先于Load2后所有装载指令，他的意思，Load1对应的代码和Load2对应的代码，是不能指令重排的 Store1： this.variable = 1 StoreStore屏障 Store2： this.variable2 = 2 StoreStore屏障：Store1；StoreStore；Store2，确保Store1的数据一定刷回主存，对其他cpu可见，先于Store2以及后续指令 LoadStore屏障：Load1；LoadStore；Store2，确保Load1指令的数据装载，先于Store2以及后续指令 StoreLoad屏障：Store1；StoreLoad；Load2，确保Store1指令的数据一定刷回主存，对其他cpu可见，先于Load2以及后续指令的数据装载。 对于volatile修改变量的读写操作，都会加入内存屏障 每个volatile写操作前面，加StoreStore屏障，禁止上面的普通写和他重排；每个volatile写操作后面，加StoreLoad屏障，禁止跟下面的volatile读/写重排。 每个volatile读操作后面，加LoadLoad屏障，禁止下面的普通读和voaltile读重排；每个volatile读操作后面，加LoadStore屏障，禁止下面的普通写和volatile读重排。 8 经典的双重检查锁 不使用 volatile 的双重检查锁 public class DoubleCheckSingleton { // 私有变量 private static DoubleCheckSingleton instance; // 公共方法 public DoubleCheckSingleton getInstance() { if(instance == null) { synchronized (DoubleCheckSingleton.class) { if(instance == null) { instance = new DoubleCheckSingleton(); } } } return instance; } } 在执行这一行代码的时候： instance = new DoubleCheckSingleton(); 实际上这个步骤并不是原子性的，有三个过程： 分配内存空间 调用构造器方法，执行初始化 将对象指向刚分配的内存空间 但是有些编译器为了性能的原因，可能会将第二步和第三步进行重排序，顺序就成了： 分配内存空间 将对象指向刚分配的内存空间 调用构造器方法，执行初始化 这样就会造成多线程在调用改方法时，有可能会得到一个未被初始化的对象，此时也就是说没有保证可见性。 我们可以使用 volatile 来实现可见性。 public class DoubleCheckSingleton { // 私有变量 private volatile static DoubleCheckSingleton instance; // 公共方法 public DoubleCheckSingleton getInstance() { if(instance == null) { synchronized (DoubleCheckSingleton.class) { if(instance == null) { instance = new DoubleCheckSingleton(); } } } return instance; } } ","link":"https://panson.top/post/jdk-yuan-ma-yue-du-007volatile-guan-jian-zi/"},{"title":"JDK 源码阅读006：Thread","content":"1 类继承体系 Runnable 接口只有一个核心方法： public abstract void run(); 子类通过继承 Thread 并重写 run 方法实现自己的业务逻辑。 2 初始化 当我们使用 new Thread() 的方法创建新的线程时，会调用init方法: ThreadGroup g：线程组，如果没有指定线程组，那么默认的线程组就是父线程的线程组，比如说如果你的父线程是main线程的话，那么你的线程组就是main线程的线程组（main线程组）。 Runnable target：目标 name：线程名字 stackSize：默认是0。它的作用是控制jvm给线程分配栈内存的大小。如果这个值比JVM规定的最小值还小的话，取JVM的默认值，一般是1M。 public Thread() { init(null, null, &quot;Thread-&quot; + nextThreadNum(), 0); } private void init(ThreadGroup g, Runnable target, String name, long stackSize) { init(g, target, name, stackSize, null, true); } 默认情况下，如果你没有指定你是否为daemon的话，那么你的daemon的状态是由父线程决定的，就是说如果你的父线程是daemon线程，那么你也是daemon线程；同理，你的优先级如果没有指定的话，那么就跟父线程的优先级保持一致。 private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { if (name == null) { throw new NullPointerException(&quot;name cannot be null&quot;); } this.name = name; Thread parent = currentThread(); SecurityManager security = System.getSecurityManager(); if (g == null) { if (security != null) { g = security.getThreadGroup(); } if (g == null) { g = parent.getThreadGroup(); } } g.checkAccess(); if (security != null) { if (isCCLOverridden(getClass())) { security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION); } } g.addUnstarted(); this.group = g; this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; setPriority(priority); if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); this.stackSize = stackSize; // 每个线程其实都有一个线程id，threadId，第一个分配的线程，它的id是1，之后的线程是2,3,4,5，依次分配各个线程的id tid = nextThreadID(); } 3 初始化总结 创建 A 线程的线程，就是 A 线程的父线程 如果没有指定ThreadGroup，A 线程的ThreadGroup就是父线程的ThreadGroup A 线程的daemon状态默认是父线程的daemon状态 A 线程的优先级默认是父线程的优先级 如果没有指定线程的名称，那么默认就是 Thread-0 格式的名称 线程id是全局递增的，从 1 开始 4 线程启动 看一下 start() 方法的源码： public synchronized void start() { // 状态不为 0（对应着 NEW 状态），则抛出异常 if (threadStatus != 0) throw new IllegalThreadStateException(); // 将线程加入线程组 group.add(this); boolean started = false; try { start0(); // 启动成功，标记为启动成功 started = true; } finally { try { if (!started) { group.threadStartFailed(this); } } catch (Throwable ignore) { } } } 4.1 多次调用 start() 永远都不能对一个线程多次调用和执行start()方法： if (threadStatus != 0) throw new IllegalThreadStateException(); 线程一旦执行过一次以后，那么它的 threadStatus 就一定会变为非 0 的一个状态。如果是非0状态，那么再次调用 start() 方法，会抛出一个异常IllegalThreadStateException（非法的线程状态的异常）。 4.2 启动成功 一旦是start0()成功地启动之后，他就会去执行我们重写的run()方法（如果传入进去的是 Runnalbe 对象，就会执行那个Runnable对象的方法）。 @Override public void run() { if (target != null) { target.run(); } } 如果采用如下方式： new Thread(new Runnable() { public void run() { } }).start(); 传递一个 Runnable 对象（target），如果 target 不为 null 的话，那么此时就会执行 target 的 run方法。反之，如果你是直接自己用Thread 类继承了一个子类的话，那么你会重写这个 run()方法，start0()启动线程之后，就会来执行你的run()方法。 5 线程启动总结 一旦启动了线程之后，就不能再重新启动了。再次调用start()方法，会抛出异常。因为启动之后，threadStatus就会变成非0的状态。 启动线程之后，这个线程就会加入之前处理好的那个线程组中。 启动一个线程实际上走的是 native 方法，start0()，会实际的启动一个线程 一个线程启动之后就会执行run()方法。 ","link":"https://panson.top/post/jdk-yuan-ma-yue-du-006thread/"},{"title":"JDK 源码解析005：LinkedHashMap","content":"1 引言 HashMap 的遍历顺序与插入顺序不一定是一致的，LinkedHashMap 继承了 HashMap，扩展了一些功能，用于维护插入顺序。 public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt; { 与 TreeMap 对比，他们相同的地方在于都可以维护 key 的顺序，只是 LinkedHashMap 底层是基于双向链表来实现顺序，TreeMap 是基于红黑树来实现。 LinkedHashMap 与 HashMap 基本操作和原理相似，主要区别在于插入、覆盖、删除的时候，会使用双向链表来记录 key-value 对的顺序，在遍历的时候按照这个顺序来遍历。 2 核心属性 // 双向链表头节点, 旧数据存在头节点。 transient LinkedHashMap.Entry&lt;K,V&gt; head; // 双向链表尾节点，新数据存在尾节点。 transient LinkedHashMap.Entry&lt;K,V&gt; tail; // 是否按访问顺序排序，如果为false则按插入顺序存储元素，如果是true则按访问顺序存储元素。 final boolean accessOrder; 3 核心原理 3.1 put 在调用 LinkedHashMap 的 put() 方法的时候，一定会调用到 HashMap 的 put() 方法里面去，调用完 put() 方法，插入一个 key-value 对之后，其实就会调用 afterNodeInsertion(evict)，这个方法就会去回调 LinkedHahsMap 里面的子类的实现。 在 put 操作之后执行，当 removeEldestEntry() 方法返回 true 时会移除最晚的节点，也就是链表首部节点 first。 evict 只有在构建 Map 的时候才为 false，在这里为 true。 void afterNodeInsertion(boolean evict) { // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) { K key = first.key; removeNode(hash(key), key, null, false, true); } } 另外还有一个子类实现 afterNodeAccess(Node&lt;K,V&gt; e) 方法： 当一个节点被访问时，如果 accessOrder 为 true，则会将该节点移到链表尾部。也就是说指定为 LRU 顺序之后，在每次访问一个节点时，会将这个节点移到链表尾部，保证链表尾部是最近访问的节点，那么链表首部就是最近最久未使用的节点。 void afterNodeAccess(Node&lt;K,V&gt; e) { // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) { LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else { p.before = last; last.after = p; } tail = p; ++modCount; } } removeEldestEntry() 默认为 false，如果需要让它为 true，需要继承 LinkedHashMap 并且覆盖这个方法的实现，这在实现 LRU 的缓存中特别有用，通过移除最近最久未使用的节点，从而保证缓存空间足够，并且缓存的数据都是热点数据。 protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) { return false; } 3.2 accessOrder 覆盖，如果是你再次将某个key的值覆盖一下，会怎么样呢？ LinkedHashMap 有一个带参的构造函数： public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) { super(initialCapacity, loadFactor); this.accessOrder = accessOrder; } accessOrder，默认是false，此时访问这个元素，并不会改变顺序。 但是如果accessOrder是true的话，那么 get 一个 key，或者是覆盖这个 key 的值，就会导致个 key-value 对顺序会在链表里改变，它会被挪动到链表的尾部去。 3.3 总结 LinkedHashMap继承自HashMap，具有HashMap的所有特性； LinkedHashMap内部维护了一个双向链表存储所有的元素； 如果accessOrder为false，则可以按插入元素的顺序遍历元素； 如果accessOrder为true，则可以按访问元素的顺序遍历元素； LinkedHashMap的实现非常精妙，很多方法都是在HashMap中留的钩子（Hook），直接实现这些Hook就可以实现对应的功能了，并不需要再重写put()等方法； 默认的LinkedHashMap并不会移除旧元素，如果需要移除旧元素，则需要重写removeEldestEntry()方法设定移除策略； LinkedHashMap可以用来实现LRU缓存淘汰策略； 4 使用 LinkedHashMap 实现 LRU class LRU&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; { private int capacity; public LRU(int capacity, float loadFactor) { super(capacity, loadFactor, true); this.capacity = capacity; } @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) { return size() &gt; capacity; } } ","link":"https://panson.top/post/jdk-yuan-ma-jie-xi-005linkedhashmap/"},{"title":" JDK 源码阅读004：HashMap","content":" 1 引言 2 数据结构 2.1 数据结构总览 2.2 Node 2.3 table 3 核心字段 4 hash 算法优化 与 hash 寻址优化 4.1 hash 算法优化 4.2 hash 寻址优化 5 put 方法 5.1 put 方法的源码解析 5.2 什么时候会出现 hash 冲突 5.3 put 流程总结 6 resize 扩容 6.1 扩容算法优化 6.2 resize 方法 6.3 resize 流程总结 7 get 方法 1 引言 尽管哈希表是一种非常常见的数据结构，但是具体的代码实现依旧有很多可以优化的地方，我们可以通过阅读 JDK1.8 的HashMap 源码实现来学习这些优秀的设计。 我们重点关注一些核心的问题： HashMap 底层数据结构是怎样的？ hash 算法为什么要高位与低位做异或运算？ hash 冲突的处理机制：链表、红黑树 扩容机制：两倍扩容、rehash、rehash 的算法优化 put、get 过程 2 数据结构 2.1 数据结构总览 HashMap(1.8) 底层数据结构是由数组、链表和红黑树组成的。 2.2 Node static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { // 用来定位数组索引位置 final int hash; final K key; V value; // 链表的下一个node Node&lt;K,V&gt; next; } 2.3 table table，即哈希桶数组是一个 Node 数组 transient Node&lt;K,V&gt;[] table; 3 核心字段 // threshold = capacity * loadFactor，扩容大小的阈值 int threshold; // 负载因子 final float loadFactor; // 当前 HashMap 中 &lt;key, value&gt; 的对数 transient int size; 4 hash 算法优化 与 hash 寻址优化 4.1 hash 算法优化 来看看 hash 方法的源码： static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); } 如果 key 为 null，则会返回 0，否则计算出 key 的 hash 值和 hash 值无符号右移 16 位，并将两者进行异或操作，返回结果值。 我们模拟一下，假设 key.hashCode(）为 ：1111 1111 1111 1111 1100 1100 1100 1100， 将其无符号右移 16 位，得到：0000 0000 0000 0000 1111 1111 1111 1111， 两者异或，得到：1111 1111 1111 1111 0011 0011 0011 0011。 为什么要进行异或操作呢？其实在后续进行 hash 寻址的过程中，一般都是用低 16 位进行运算。进行异或操作，可以让高 16 位也参与运算，在低 16 位同时保留原先高 16 位和低 16 位的特征，从而降低 hash 冲突的概率。 4.2 hash 寻址优化 在 putVal() 方法中，有这么一段代码： if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); 这里的 (n - 1) &amp; hash 其实就是寻址，相当于 hash / n，但是位运算又比取模运算速度快。 5 put 方法 5.1 put 方法的源码解析 public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 1. 数组容量初始化：如果数组为 null 或者数组的长度为 0，会进行初次扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 2. Node 初始化：使用优化后的寻址算法，如果定位到的 Node 元素为 null if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { // 定位到元素不为空，有3 个分支 Node&lt;K,V&gt; e; K k; // 如果桶中第一个元素的key与待插入元素的key相同，保存到e中用于后续修改value值 if (p.hash == hash &amp;&amp;((k = p.key) == key || (key != null &amp;&amp; key.equals(k)) e = p; // 如果第一个元素是树节点，则调用树节点的putTreeVal插入元素 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { // 遍历这个桶对应的链表，binCount用于存储链表中元素的个数 for (int binCount = 0; ; ++binCount) { // 如果链表遍历完了都没有找到相同key的元素，说明该key对应的元素不存在，则在链表最后插入一个新节点 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // 如果插入新节点后链表长度大于8，则判断是否需要树化 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 先判断table的长度是否大于64，如果小于64，就通过扩容的方式来解决，避免红黑树结构化 treeifyBin(tab, hash); break; } // 如果待插入的key在链表中找到了，则退出循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } // 如果找到了对应key的元素, 记录下旧值 if (e != null) { // existing mapping for key V oldValue = e.value; // 判断是否需要替换旧值 if (!onlyIfAbsent || oldValue == null) // 替换旧值 e.value = value; // 在节点被访问后做点什么事，在LinkedHashMap中用到 afterNodeAccess(e); // 返回旧值 return oldValue; } } // 到这里了说明没有找到元素，修改次数加1 ++modCount; // 元素数量加1，判断是否需要扩容 if (++size &gt; threshold) resize(); // 在节点插入后做点什么事，在LinkedHashMap中用到 afterNodeInsertion(evict); // 没找到元素返回null return null; } 5.2 什么时候会出现 hash 冲突 key 不一样，但是 hashcode() 方法乱写，导致 hash 值一样； hash 值不一样，但是寻址之后在数组中的位置是一样的，出现了 hash 冲突。 5.3 put 流程总结 计算key的hash值； 如果桶（数组）数量为0，则初始化桶； 如果key所在的桶没有元素，则直接插入； 如果key所在的桶中的第一个元素的key与待插入的key相同，说明找到了元素，转后续流程 9 处理； 如果第一个元素是树节点，则调用树节点的putTreeVal()寻找元素或插入树节点； 如果不是以上三种情况，则遍历桶对应的链表查找key是否存在于链表中； 如果找到了对应key的元素，则转后续流程 9 处理； 如果没找到对应key的元素，则在链表最后插入一个新节点并判断是否需要树化； 如果找到了对应key的元素，则判断是否需要替换旧值，并直接返回旧值； 如果插入了元素，则数量加1并判断是否需要扩容； 6 resize 扩容 6.1 扩容算法优化 上文已经讲过寻址的 hash 算法，将 hash &amp; n -1，可以保证扩容之后，根据 hash 值寻址到的地方要么还是原来的 index，要么就是 index + oldCap。 hash &amp; n -1：判断二进制结果中是否多出一个 bit 的 1，如果没多，那么就是原来的 index，否则就是 index + oldCap。通过这种方式，就避免了 rehash 的时候，用每个 hash 对新数组的 length 取模（位运算比取模效率高一些）。 6.2 resize 方法 简而言之就是：两倍扩容 + rehash。 每次 put 了一个新的key-value对之后，size++，比较一下 size 和 threshold（数组的长度 * 负载因子），看是否需要扩容。 if (++size &gt; threshold) resize(); final Node&lt;K,V&gt;[] resize() { // 旧数组 Node&lt;K,V&gt;[] oldTab = table; // 旧容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 旧阈值 int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { // 如果旧容量达到了最大容量，则不再进行扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 如果旧容量的两倍小于最大容量并且旧容量大于默认初始容量（16），则容量扩大为两倍，扩容阈值也扩大为两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } // 使用非默认构造方法创建的map，第一次插入元素会走到这里 // 如果旧容量为0且旧扩容门槛大于0，则把新容量赋值为旧阈值 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults // 调用默认构造方法创建的map，第一次插入元素会走到这里 // 如果旧容量旧扩容阈值都是0，说明还未初始化过，则初始化容量为默认容量，扩容阈值为默认容量*默认装载因子 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { // 如果新扩容为0，则计算为容量*装载因子，但不能超过最大容量 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } // 赋值扩容门槛为新门槛 threshold = newThr; // 新建一个新容量的数组 @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 如果旧数组不为空，则搬移元素 if (oldTab != null) { for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; // 如果桶中第一个元素不为空，赋值给e if ((e = oldTab[j]) != null) { oldTab[j] = null; // 如果这个桶中只有一个元素，则计算它在新桶中的位置并把它搬移到新桶中 // 因为每次都扩容两倍，所以这里的第一个元素搬移到新桶的时候新桶肯定还没有元素 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 如果第一个元素是树节点，则把这颗树打散成两颗树插入到新桶中去 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order // 如果这个链表不止一个元素且不是一颗树 // 则分化成两个链表插入到新的桶中去 // 比如，假如原来容量为4，3、7、11、15这四个元素都在三号桶中 // 现在扩容到8，则3和11还是在三号桶，7和15要搬移到七号桶中去 // 也就是分化成了两个链表 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 6.3 resize 流程总结 如果使用是默认构造方法，则第一次插入元素时初始化为默认值，容量为16，扩容门槛为12； 如果使用的是非默认构造方法，则第一次插入元素时初始化容量等于扩容门槛，扩容门槛在构造方法里等于传入容量向上最近的2的n次方； 如果旧容量大于0，则新容量等于旧容量的2倍，但不超过最大容量2的30次方，新扩容门槛为旧扩容门槛的2倍； 创建一个新容量的桶； 搬移元素，原链表分化成两个链表，低位链表存储在原来桶的位置，高位链表搬移到原来桶的位置加旧容量的位置； 7 get 方法 public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 如果桶的数量大于0并且待查找的key所在的桶的第一个元素不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { // 检查第一个元素是不是要查的元素，如果是直接返回 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { // 如果第一个元素是树节点，则按树的方式查找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { // 否则就遍历整个链表查找该元素 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } 计算key的hash值； 找到key所在的桶及其第一个元素； 如果第一个元素的key等于待查找的key，直接返回； 如果第一个元素是树节点就按树的方式来查找，否则按链表方式查找； 参考： Java中的移位运算符：https://zhuanlan.zhihu.com/p/30108890 红黑树：https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/03.01.md HashMap &amp; ConcurrentHashMap: https://crossoverjie.top/%2F2018%2F07%2F23%2Fjava-senior%2FConcurrentHashMap%2F 死磕 java集合之HashMap源码分析：https://mp.weixin.qq.com/s/UFeLHR4qtGYPODTiNJDmHQ https://tech.meituan.com/2016/06/24/java-hashmap.html 深入浅出ConcurrentHashMap1.8：https://www.jianshu.com/p/c0642afe03e0 老生常谈，HashMap的死循环：https://www.jianshu.com/p/1e9cf0ac07f4 深入分析ConcurrentHashMap1.8的扩容实现：https://www.jianshu.com/p/f6730d5784ad ConcurrentHashMap的红黑树实现分析：https://www.jianshu.com/p/23b84ba9a498 谈谈ConcurrentHashMap1.7和1.8的不同实现：https://www.jianshu.com/p/e694f1e868ec ","link":"https://panson.top/post/lao-sheng-chang-tan-hashmap-yuan-ma-jie-du/"},{"title":"JDK 源码阅读 003：LinkedList","content":" 1 引言 LinkedList 底层基于双向链表实现，插入、获取、删除，都可以从队头、队尾来实现，完全可以当做一个队列来用，offer()往队尾插入元素，poll()从队头删除元素。 优点：队头、队尾、队中插入数据，哪怕是插入大量的数据，也不会出现任何的大量元素的挪动和数组扩容。在中间插入元素性能没有队头和队尾那么好，需要遍历链表到指定的位置，然后完成元素的插入。 缺点：如果是要随机位置获取一个元素，get(int index)这个方法，需要遍历，如果数据很多，性能比较差的。 2 类继承关系 LinkedList不仅实现了List接口，还实现了Queue和Deque接口，所以它既能作为List使用，也能作为双端队列使用，当然也可以作为栈使用。 3 主要属性与内部类 // 元素个数 transient int size = 0; // 链表首节点 transient Node&lt;E&gt; first; // 链表尾节点 transient Node&lt;E&gt; last; 属性很简单，定义了元素个数size和链表的首尾节点。 Node 内部类：典型的双向链表结构。 private static class Node&lt;E&gt; { E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) { this.item = element; this.next = next; this.prev = prev; } } 4 主要方法 4.1 add add()：默认就是在队列的尾部插入一个元素，在那个双向链表的尾部插入一个元素 public boolean add(E e) { linkLast(e); return true; } void linkLast(E e) { final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; } add(index, element)：是在队列的中间插入一个元素，会判断是在前半段插入还是在后半段插入。 public void add(int index, E element) { checkPositionIndex(index); // 在尾部插入 if (index == size) linkLast(element); else // 指定索引位置插入 linkBefore(element, node(index)); } /** * Returns the (non-null) Node at the specified element index. */ Node&lt;E&gt; node(int index) { // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) { Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; } else { Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; } } /** * Inserts element e before non-null Node succ. */ void linkBefore(E e, Node&lt;E&gt; succ) { // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++; } addFirst()：在队列的头部插入一个元素 public void addFirst(E e) { linkFirst(e); } private void linkFirst(E e) { final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; if (f == null) last = newNode; else f.prev = newNode; size++; modCount++; } addLast()：跟add()方法是一样的，也是在尾部插入一个元素 public void addLast(E e) { linkLast(e); } offer() == add()：就是在队列尾部入队，将一个元素插入队列尾部，同理还有offerFirst()，offerLast() 4.2 get poll()：从队列头部出队 public E poll() { final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); } private E unlinkFirst(Node&lt;E&gt; f) { // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element; } peek()：获取队列头部的元素，但是头部的元素不出队 public E peek() { final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; } getFirst() public E getFirst() { final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item; } getLast() public E getLast() { final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item; } get(int index) public E get(int index) { checkElementIndex(index); return node(index).item; } 4.3 remove remove()：删除头结点 public E remove() { return removeFirst(); } public E removeFirst() { final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f); } private E unlinkFirst(Node&lt;E&gt; f) { // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element; } remove(int index) public E remove(int index) { checkElementIndex(index); return unlink(node(index)); } removeLast() public E removeLast() { final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l); } ","link":"https://panson.top/post/jdk-yuan-ma-yue-du-004linkedlist/"},{"title":"JDK 源码阅读002：ArrayList","content":"ArrayList 源码阅读~ 1 引言 2 继承关系 3 初始化 4 核心方法 4.1 set 4.2 add 4.3 get 4.4 remove 5 扩容机制 6 Fail-Fast 参考 1 引言 首先，我们要对 ArrayList 的特点有一个基本的认识，比如说 ： ArrayList 底层是用什么实现的？ 缺点是什么？有点又是什么？ 扩容机制了解吗 其实 ArrayList 底层是基于数组来实现的，随机读的时间复杂度为 O(1)， 对于删除的的时间复杂度为O(N)。所以 ArrayList 的优势在于随机读，缺点有两个地方，一个是不断地添加元素的时候，会扩容，扩容会导致性能较差，另一个删除元素的时候，会导致大量元素的拷贝，性能也较差。 2 继承关系 public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable ArrayList实现了List, RandomAccess, Cloneable, java.io.Serializable等接口。 ArrayList实现了List，提供了基础的添加、删除、遍历等操作。 ArrayList实现了RandomAccess，提供了随机访问的能力。 ArrayList实现了Cloneable，可以被克隆。 ArrayList实现了Serializable，可以被序列化。 3 初始化 一共 3 个构造函数 不指定初始大小，默认为 10 public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } 指定初始大小 public ArrayList(int initialCapacity) { if (initialCapacity &gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); } } 传入指定集合初始化 public ArrayList(Collection&lt;? extends E&gt; c) { Object[] a = c.toArray(); if ((size = a.length) != 0) { if (c.getClass() == ArrayList.class) { elementData = a; } else { elementData = Arrays.copyOf(a, size, Object[].class); } } else { // replace with empty array. elementData = EMPTY_ELEMENTDATA; } } 4 核心方法 4.1 set public E set(int index, E element) { // 判断是否数组越界 rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue; } private void rangeCheck(int index) { if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } 4.2 add 在末尾插入 public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; } 在指定下标插入 public void add(int index, E element) { // 添加时判断数据越界 rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! // 数组拷贝 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; } // 添加时判断数据越界 private void rangeCheckForAdd(int index) { if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } 4.3 get 直接通过索引下标获取元素 public E get(int index) { rangeCheck(index); checkForComodification(); return ArrayList.this.elementData(offset + index); } 4.4 remove 调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)。 public E remove(int index) { rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; } 5 扩容机制 在添加元素的时候，可能会触发扩容机制，新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1)， 大约是旧容量的 1.5 倍左右。 相关源码如下： public boolean add(E e) { // ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; } private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity); } private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity); } private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; // 新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1) // 大约是旧容量的 1.5 倍左右 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); } 6 Fail-Fast modCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。 在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。 参考 ArrayList ","link":"https://panson.top/post/jdk-yuan-ma-yue-du-bi-ji-arraylist/"},{"title":"JDK 源码阅读001：String ","content":"本文剖析了 String 的源码（1.8），主要讲述了 String 的一些特性以及一些核心方法的设计与实现。 一、String 的不可变性 public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence { /** The value is used for character storage. */ private final char value[]; } 上面的String 源码解释了 String 的不可变性。 String 被 final 修饰，意味着该类不能被继承，也就没有子类，无法通过继承的方式覆写 String 的方法。 final 修饰 class，可以参考 Java 虚拟机规范 A class can be declared final if its definition is complete and no subclasses are desired or required. It is a compile-time error if the name of a final class appears in the extends clause (§8.1.4) of another class declaration; this implies that a final class cannot have any subclasses. It is a compile-time error if a class is declared both final and abstract, because the implementation of such a class could never be completed (§8.1.1.1). Because a final class never has any subclasses, the methods of a final class are never overridden (§8.4.8.1). String 底层使用一个 value 字符数组来存储，使用 private 和 final 修饰，意味着 value 一旦被赋值，内存地址不会再改变(final)，并且不能再被修改（private） 二、String.intern() 方法 String 类的intern()方法涉及到一个叫做 “常量池“ 的概念，可以理解成 Java 系统级别的缓存。 直接使用双引号声明出来的String对象会直接存储在常量池中。 如果不是用双引号声明的String对象，可以使用String提供的intern方法。intern 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中 JAVA 使用 jni 调用c++实现的StringTable的intern方法, StringTable的intern方法跟Java中的HashMap的实现是差不多的, 只是不能自动扩容。默认大小是1009。 要注意的是，String的String Pool是一个固定大小的Hashtable，默认值大小长度是1009，如果放进String Pool的String非常多，就会造成Hash冲突严重，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用String.intern时性能会大幅下降（因为要一个一个找）。 在 jdk6中StringTable是固定的，就是1009的长度，所以如果常量池中的字符串过多就会导致效率下降很快。在jdk7中，StringTable的长度可以通过一个参数指定： -XX:StringTableSize=99991 三、String 的构造函数和若干重要方法 1. 构造函数 String 类有4个核心构造函数 // String 为参数的构造方法 public String(String original) { this.value = original.value; this.hash = original.hash; } // char[] 为参数构造方法 public String(char value[]) { this.value = Arrays.copyOf(value, value.length); } // StringBuffer 为参数的构造方法 public String(StringBuffer buffer) { synchronized(buffer) { this.value = Arrays.copyOf(buffer.getValue(), buffer.length()); } } // StringBuilder 为参数的构造方法 public String(StringBuilder builder) { this.value = Arrays.copyOf(builder.getValue(), builder.length()); } 2. 使用频率很高的几个方法 length() // 字符串长度 public int length() { return value.length; } isEmpty() public boolean isEmpty() { return value.length == 0; } charAt() public char charAt(int index) { if ((index &lt; 0) || (index &gt;= value.length)) { throw new StringIndexOutOfBoundsException(index); } return value[index]; } equals() 和 equalsIgnoreCase() public boolean equals(Object anObject) { // 对象引用相同直接返回 true if (this == anObject) { return true; } // 判断需要对比的值是否为 String 类型，如果不是则直接返回 false if (anObject instanceof String) { String anotherString = (String)anObject; int n = value.length; // 比较底层数组长度，长度不同，直接返回 false，长度相同，遍历字符数组，循环比较，只要有一个字符不同，返回 false if (n == anotherString.value.length) { char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) { if (v1[i] != v2[i]) return false; i++; } return true; } } return false; } 直接使用 equals() 方法时，应该小心空指针。非空字符串放在前面，或者直接使用 apache commons 相关工具类 StringUtils： // StringUtils::equals public static boolean equals(String str1, String str2) { return str1 == null ? str2 == null : str1.equals(str2); } equalsIgnoreCase(): 该方法 与 equals() 不同之处在于前者忽略大小写比较字符串。 compareTo()和 compareToIgnoreCase() // 返回值为 0 表示等于，正数表示大于，负数表示小于 public int compareTo(String anotherString) { int len1 = value.length; int len2 = anotherString.value.length; int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k &lt; lim) { char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) { return c1 - c2; } k++; } return len1 - len2; } compareToIgnoreCase()：比较忽略大小写 其他 indexOf()：查询字符串首次出现的下标位置 lastIndexOf()：查询字符串最后出现的下标位置 contains()：查询字符串中是否包含另一个字符串 toLowerCase()：把字符串全部转换成小写 toUpperCase()：把字符串全部转换成大写 trim()：去掉字符串首尾空格 replace()：替换字符串中的某些字符 split()：把字符串分割并返回字符串数组 join()：把字符串数组转为字符串 参考： 深入解析String#intern ","link":"https://panson.top/post/arraylist-yuan-ma-yue-du/"},{"title":"译文：Java EE vs J2EE vs Jakarta","content":"本文为译文，已投稿至码农翻身公众号。文章主要介绍了一些 Java 开发中的 3 个名词：Java EE 、J2EE 、 Jakarta ，以及 Java 的发展史。 原文链接：JEE vs J2EE vs Jakarta 原文作者：Rodrigo Graciano 1.引言 听说过 Java EE 吗？那关于 Java 2EE 、J2EE 或者现在的 Jakarta EE，你又是否有所耳闻呢？实际上，这些各异的术语描述的都是相同的东西：由 Java SE 扩展出的一系列企业规范。 在本篇短文中，我们将讲述 Java EE 的发展史。 2.历史 在 Java 的第一个版本中，Java 企业扩展还只是核心 JDK 的一部分（译者注：核心 JDK 通常指 Java SE） 。然而到了 1999 年，Java 企业扩展已经被剥离出 Java SE，成为了 Java 2 的一部分，这也意味着 J2EE，或者说Java 2 平台企业版（Java 2 Platform Enterprise Edition）的诞生。J2EE 这个称呼一直维持到2006年。 2006 年发布的 Java 5，J2EE 被重命名为 Java EE，或者说 Java 平台企业版（Java Platform Enterprise Edition）。这次改名后的称呼一直延续到 了 2017 年的 9 月。那年发生了一件重大的事，Oracle 决定将 Java EE 捐赠给 Eclipse 基金会（但 Java仍然属于 Oracle）。 3.转变阶段 事实上，因为 Oracle 拥有 “Java” 商标权。按照法律要求，Eclipse 基金会需要对 Java EE 进行更名。 经过社区的投票选择，Java EE 被更名为 Jakarta EE。从某种意义上来说，Java EE 依然叫 JEE。（译者注： 将 Java EE 首字母缩写也可简称为 JEE）。 版本 时间 J2EE 1.2 1999 年 12月 J2EE 1.3 2001 年 09 月 J2EE 1.4 2003 年 11 月 Java EE 5 2006 年 05 月 Java EE 6 2009 年 12 月 Java EE 7 2013 年 04 月 Java EE 8 2017 年 08 月 Jakarta EE 2018 年 02 月 宣布新名字[译者注：译者怀疑此处是原文排版没排好] 不过这仍然是个正在进行的故事，还未完全尘埃落定。 举个例子，虽然 Oracle 开源了 Java 源代码，但却并未开源所有的文档。关于这个问题，因为涉及到一些法律事宜，导致开源一些文档（例如与 JMS、EJB相关的）非常棘手，至今仍有许多争议。 现在还无法得知新的 Eclipse 基金会文档是否能够参考原文档。 同样令人奇怪的是 Eclipse 基金会不能使用 javax 的命名空间来创建新的 Java 包，但是可以在现有包的下面创建新的类和子类。 转变阶段也意味着对 Jakarta EE 添加规范的新流程。为了更好地理解这一点，让我们快速看一下 Oracle 添加规范的流程以及 Eclipse 基金会相应做出的改变。 4.未来 在过去，为了将一个特性添加进 “EE”（译者注：原文作者为了避免 Jakarta EE 历史名字的混杂性，使用“EE”来代指全部的版本，下同），我们需要 3 样东西 ：规范、参考实现与测试。社区里的任何人都可以提交这 3 样东西，之后执行委员会将会决定何时将它们整合进 Java 语言中。 为了更好地理解添加规范的旧流程，让我们进一步了解 JSRs、Glassfish 和 TCK是什么 ，以及它们是如何整合新特性的。 我们也将一睹在未来可以预期的事。 4.1.JCP 以及现在的 EFSP 在过去，产生EE 新特性的流程被称为 JCP（Java Community Process）。 Java SE 现在仍然采用 JCP。但是由于 EE 的所有权已经从 Oracle 移交至 Eclipse 基金会，EE 已经有了新的流程，这个流程是Eclipse 开发流程的扩展，与 Java SE 的流程互不干扰，我们称之为 EFSP（Eclipse Foundation Specification Process）。 尽管 JCP 与 EFSP 之间有一些大的差异，但大都围绕着“透明、公开、集体负责和供应商中立”这几条准则展开。例如，EFSP 的组织者设想的合作工作团体是供应商中立的，认证流程是自助服务的，组织的运作与管理是精英化的。 4.2.JSRs 在 JCP 中，为 EE 添加新特性的第一步是创建一个 JSR（Java Specification Request）。JSR 有点类似于一个 EE 特性的接口。JCP 执行委员会会核准一个完整的 JSR，然后相应的 JSR 贡献者会编写代码，使其在社区内生效。 JSR-339 或者 JAX-RS 对于阐述上面的流程是一个好例子。JAX-RS 最初于 2011 年提出，在2012年被 JCP 批准，最终在 2013 年得以发布。 虽然在讨论规范时，社区可以随时加入进来，但时间表明，一个实现优先（ implementation-first）的方式更利于创建能被广泛接受的特性与 API。所谓的实现优先，类似于JSR 310中的 java.time 和 Joda Time这个例子（译者注：JDK 1.8 之前 Java 关于时间的 API 很不如人意，使用广泛的是 Joda-Tme）。 因此，EFSP（Eclipse Foundation Specification Process）在其设定的目标中阐述了这个观点：“EFSP 将基于是否先进行了动手实验和编码，来判断其是否值得添加进规范中。” 4.3.Glassfish 此外，JSR 作为 JCP 的一部分，需要一个参考实现。这有点类似于实现接口的类。对于那些想要创建自己的规范实现的群体，比如说兼容库的开发人员或者其他组织，参考实现都可以给予帮助。 对于 Java EE 特性，JCP 使用 Glassfish 作为参考实现。 虽然 Glassfish 的中心化简化了实现者的探索过程，但是这种中心化也要求更多的管理，并且倾向于偏袒某个供应商。 因此，EFSP 不要求参考实现，而只要求兼容的实现。简而言之，这种微妙的变化使得类似 Glassfish 之类的中心体系结构内的实现，不会被基金会无缘由地首选。 4.4.TCK 最后，JCP 要求 EE 特性需通过 TCK（Technology Compatibility Kit）的测试。 TCK 是一组验证特定 EE JSR 的测试。简而言之，为了遵循 Java EE，应用服务器需要实现所有 JSR， 并通过特定 TCK 上的所有测试。 与前述类似，Oracle虽然开源了TCK和EE jsr的源代码（译者注：但并没有开源相应的文档）。当然，未来所有的文档和 TCK 都将是开源的。 5.总结 这些年来，Java EE 无疑前进了许多。很高兴看到它继续变化与变好。 前方之路充满坎坷，希望 Java 的转变能够平滑些。 ","link":"https://panson.top/post/hello-gridea/"}]}